[
  {
    "query": "Answer the question based on the following context: To examine further the relationship between diabetes mellitus (DM), genotype and prostate cancer aggressiveness. Specifically, we sought to evaluate for effect modification between DM, a newly discovered prostate cancer susceptibility locus on chromosome 17q12 (single nucleotide polymorphism rs4430796) and prostate cancer features. In 593 genotyped men treated with radical prostatectomy (RP), we examined RP features stratified by DM and rs4430796 carrier status. Despite a significantly higher body mass index among patients with DM, individual pathological features were similar between men with and without DM. Using a dominant model, 17q12 carriers were less likely to have DM and more likely to have a RP Gleason score of>or=7. However, the presence or absence of DM did not modify the relationship between 17q12 susceptibility alleles and pathological features.\nQuestion: Does diabetes mellitus modify the association between 17q12 risk variant and prostate cancer aggressiveness?",
    "gt": "Among 17q12 risk allele carriers, there was no significant relationship between DM and adverse tumour features. However, there were relatively few men with DM (7%) in our RP cohort, particularly compared with its 21% prevalence in the USA population aged>60 years. It is unclear whether this reflects selection bias, genetic protection from prostate cancer among patients with DM, or both. Despite these limitations, the present data suggest that DM alone does not appear to modify any association between 17q12 risk alleles with prostate cancer features.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Our goal was to evaluate whether active management of labor lowers cesarean section rates, shortens the length of labor, and overcomes any negative effects of epidural analgesia on nulliparous labor. We randomly assigned 405 low-risk term nulliparous patients to either an active management of labor (n = 200) or our usual care control protocol (n = 205). Patients who were undergoing active management of labor were diagnosed as being in labor on the basis of having painful palpable contractions accompanied by 80% cervical effacement, underwent early amniotomy, and were treated with high-dose oxytocin for failure to progress adequately in labor. The cesarean section rate in the active management of labor group was lower than that of controls but not significantly so (active management, 7.5%; controls, 11.7%; p = 0.36). The length of labor in the active management group was shortened by 1.7 hours (from 11.4 to 9.7 hours, p = 0.001). Fifty-five percent of patients received epidural analgesics; a reduction in length of labor persisted despite the use of epidural analgesics (active management 11.2 hours vs control 13.3 hours, p = 0.001). A significantly greater proportion of active management patients were delivered by 12 hours compared with controls (75% vs 58%, p = 0.01); this difference also persisted despite the use of epidural analgesics (66% vs 51%, p = 0.03).\nQuestion: Active management of labor: does it make a difference?",
    "gt": "Patients undergoing active management had shortened labors and were more likely to be delivered within 12 hours, differences that persisted despite the use of epidural analgesics. There was a trend toward a reduced rate of cesarean section.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Long axis strain (LAS) has been shown to be a fast assessable parameter representing global left ventricular (LV) longitudinal function in cardiovascular magnetic resonance (CMR). However, the prognostic value of LAS in cardiomyopathies with reduced left ventricular ejection fraction (LVEF) has not been evaluated yet. In 146 subjects with non-ischemic dilated cardiomyopathy (NIDCM, LVEF ≤45 %) LAS was assessed retrospectively from standard non-contrast SSFP cine sequences by measuring the distance between the epicardial border of the left ventricular apex and the midpoint of a line connecting the origins of the mitral valve leaflets in end-systole and end-diastole. The final values were calculated according to the strain formula. The primary endpoint of the study was defined as a combination of cardiac death, heart transplantation or aborted sudden cardiac death and occurred in 24 subjects during follow-up. Patients with LAS values> -5 % showed a significant higher rate of cardiac events independent of the presence of late gadolinium enhancement (LGE). The multivariate Cox regression analysis revealed that LVEDV/BSA (HR: 1.01, p < 0.05), presence of LGE (HR: 2.51, p < 0.05) and LAS (HR: 1.28, p < 0.05) were independent predictors for cardiac events. In a sequential cox regression analysis LAS offered significant incremental information (p < 0.05) for the prediction of outcome in addition to LGE and LVEDV/BSA. Using a dichotomous three point scoring model for risk stratification, including LVEF<35 %, LAS> -10 % and the presence of LGE, patients with 3 points had a significantly higher risk for cardiac events than those with 2 or less points.\nQuestion: Left ventricular long axis strain: a new prognosticator in non-ischemic dilated cardiomyopathy?",
    "gt": "Assessment of long axis function with LAS offers significant incremental information for the prediction of cardiac events in NIDCM and improves risk stratification beyond established CMR parameters.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Earlier studies have given conflicting results regarding the effect of exposure to tobacco smoke on atopic sensibilization. A cross-sectional study of present and former smoking habits in relation to atopic disorders from data on 6909 young and middle-aged adults (16-49 years) and their 4472 children (3-15 years) from the Swedish Survey of Living Conditions in 1996-97. The prevalence of allergic asthma and allergic rhino-conjunctivitis decreased, in a dose-response manner (P = 0.03 and P = 0.004, respectively), with increasing exposure to tobacco smoke in the adult study population. This pattern was little changed when potential confounders (sex, age, education, domicile, country of birth) were entered into a multivariate analysis: the adjusted odds ratio (OR) for allergic rhino-conjunctivitis was 0.5 (0.4-0.7) for those who smoked at least 20 cigarettes a day and OR 0.7 (0.6-0.9) for those smoking 10-19 cigarettes, compared with those who reported that they never had smoked Former smokers had a tendency for a slightly lower risk: OR 0.9 (0.8-1.0). In a multivariate analysis, children of mothers who smoked at least 15 cigarettes a day tended to have lower odds for suffering from allergic rhino-conjunctivitis, allergic asthma, atopic eczema and food allergy, compared to children of mothers who had never smoked (ORs 0.6-0.7). Children of fathers who had smoked at least 15 cigarettes a day had a similar tendency (ORs 0.7-0.9).\nQuestion: Does tobacco smoke prevent atopic disorders?",
    "gt": "This study demonstrates an association between current exposure to tobacco smoke and a low risk for atopic disorders in smokers themselves and a similar tendency in their children. There is a need for further studies with a prospective design to certify the causal direction of this association. Smoking habits and atopic disorder in parents should not be considered independent variables in epidemiological studies of the connection between exposure to tobacco smoke and atopy in children.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patient dissatisfaction has been previously associated with motor block in shoulder surgery patients receiving brachial plexus block. For elective minor wrist and hand surgery, we tested whether a regional block accelerating the early return of upper extremity motor function would improve patient satisfaction compared with a long-acting proximal brachial plexus block. A total of 177 patients having elective 'minor' wrist and hand surgery under awake regional block randomly received adrenalized infraclavicular lidocaine 2% 10 ml+ropivacaine 0.75% 20 ml ('long acting', n=90), or adrenalized infraclavicular lidocaine 1.5% 30 ml+long-acting distal median, radial, and ulnar nerve blocks selected according to the anticipated area of postoperative pain ('short acting', n=87). A blinded observer questioned patients on day 1 for numerically rated (0-10) subjective outcomes. With 95% power, there was no evidence for a 1-point satisfaction shift in the short acting group: satisfaction was similarly high for both groups [median (inter-quartile range)=10 (8-10) vs 10 (8-10), P=0.71], and also demonstrated strong evidence for equivalence [mean difference (95% confidence interval)=-0.18 (-0.70 to 0.35)]. There was no difference between the groups for weakness- or numbness-related dissatisfaction (low for both groups), or for numerically rated or time to first pain. Surgical anaesthesia success was similar between the groups (short acting, 97% vs 93%, P=0.50), although more patients in the short acting group had surgery initiated in ≤25 min (P=0.03).\nQuestion: Does motor block related to long-acting brachial plexus block cause patient dissatisfaction after minor wrist and hand surgery?",
    "gt": "Patient satisfaction is not improved after elective minor wrist and hand surgery with a regional block accelerating the early return of motor function. For this surgery, motor block related to a long-acting brachial plexus block does not appear to cause patient dissatisfaction. Clinical Trial Registration number. ACTRN12610000749000, https://www.anzctr.org.au/registry/trial_review.aspx?ID=335931.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Appropriateness criteria for the treatment of Crohn’s disease (CD) and ulcerative colitis (UC) have been developed by expert panels. Little is known about the acceptance of such recommendations by care providers. The aim was to explore how treatment decisions of practicing gastroenterologists differ from those of experts, using a vignette case study and a focus group. Seventeen clinical vignettes were drawn from clinical indications evaluated by the expert panel. A vignette case questionnaire asking for treatment options in 9 or 10 clinical situations was submitted to 26 practicing gastroenterologists. For each vignette case, practitioners’ answers on treatments deemed appropriate were compared with panel decisions. Qualitative analysis was performed on focus group discussion to explore acceptance and divergence reasons. Two hundred thirty-nine clinical vignettes were completed, 98 for CD and 141 for UC.Divergence between proposed treatments and panel recommendations was more frequent for CD (34%) than for UC (27%). Among UC clinical vignettes, the main divergences with the panel were linked to 5-aminosalicylate (5-ASA) failure assessment and to situations in which stopping treatment was the main decision. For CD, the propositions of care providers diverged from the panel in mild to moderate active disease, for which practitioners were more prone to an accelerated step-up than the panel’s recommendations.\nQuestion: Acceptance of inflammatory bowel disease treatment recommendations based on appropriateness ratings: do practicing gastroenterologists agree with experts?",
    "gt": "In about one-third of vignette cases, inflammatory bowel disease treatment propositions made by practicing gastroenterologists diverged from expert recommendations. Practicing gastroenterologists may experience difficulty in applying recommendations in daily practice.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Although socioeconomic patterns of smoking across the different stages of the tobacco epidemic have been well researched, less is known about these patterns among immigrant populations. This paper aims to assess the smoking prevalence and its socioeconomic gradients among three immigrant populations. Three cross-sectional studies, using structured face-to-face interviews, were conducted in three representative (for socioeconomic status) samples of 385 Turkish, 316 Moroccan, and 1072 Surinamese first-generation immigrants aged 35-60 years in Amsterdam, The Netherlands. Information gathered included information about smoking behaviour, educational level and background characteristics. The associations between educational level and smoking rates were assessed using logistic regression analyses stratified by age and sex, for each ethnic group separately. The prevalence of smoking differed per group, being highest among Turkish and Surinamese men (63% and 55%, respectively), followed by Moroccan men and Turkish and Surinamese women (30%, 32% and 27%, respectively). Higher smoking rates were found among women with higher educational levels, except for Surinamese women aged 35-44 years. However, among Turkish and Moroccan men aged 35-44 years and Surinamese men, smoking rates were higher in lower socioeconomic groups.\nQuestion: Smoking in immigrants: do socioeconomic gradients follow the pattern expected from the tobacco epidemic?",
    "gt": "The prevalence figures and educational associations suggest that the socioeconomic gradient changes in earlier stages of the epidemic in immigrant populations than in the Western host populations, particularly in men. This provides indications to suggest that smoking prevention measures in male immigrant groups need to be tailored to lower socioeconomic groups in particular throughout the tobacco epidemic, and to higher socioeconomic groups among women.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate prospectively pubertal and predicted adult height progression until final height (FH) or near FH in girls with apparent idiopathic precocious puberty who were not treated. The decision not to treat at the time of initial evaluation was based on evidence of slowly progressive puberty as shown by bone age (BA) advancement<2 years above the chronologic age, whatever the hypothalamic pituitary ovarian axis activation, or no evidence of hypothalamic pituitary ovarian axis activation, whatever the BA advancement. During follow-up, patients who showed a significant decrease in predicted FH were treated with gonadotropin-releasing hormone agonist. Twenty-six girls with idiopathic precocious puberty were studied at a mean chronologic age of 7.4 +/- 0.9 years during a follow-up period of 6.6 +/- 2.2 years until FH or near FH. During the first 2 years of follow-up, most of the patients (group 1, n = 17; 65% of the cases) showed no substantial changes in predicted FH. They never required treatment, and menarche occurred at a mean chronologic age of 11.9 +/- 0.6 years. Their mean FH (or near FH) at 160.7 +/- 5.7 cm was close to their target height (161.3 +/- 4.7 cm). On the other hand, after a mean follow-up period of 1.4 +/- 0.8 years, 9 patients (group 2) had acceleration of bone maturation and deterioration of their predicted FH (from 162.1 +/- 6. 2 cm to 155.3 +/- 5.6 cm; P<.01), which was at that time significantly lower than their target height (P<.05) (mean target height = 159.8 +/- 4.6 cm). They received a gonadotropin-releasing hormone agonist for 2.1 +/- 0.7 years, resulting in a restoration of growth prognosis (mean FH or near FH = 160.2 +/- 6.7 cm).\nQuestion: Do all girls with apparent idiopathic precocious puberty require gonadotropin-releasing hormone agonist treatment?",
    "gt": "This study demonstrates that not all patients with apparent idiopathic precocious puberty require medical treatment, notably when there is no evidence of hypothalamo-pituitary ovarian activation or no significantly advanced BA to impair height potential. Most show a slowly progressing puberty. However, careful follow-up of these patients is necessary up to at least 9 years of age, because until then height prediction may deteriorate, necessitating gonadotropin-releasing hormone agonist treatment in one third of the cases.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: In recent years, Performance Based Financing (PBF); a form of result based financing, has attracted a global attention in health systems in developing countries. PBF promotes autonomous health facilities, motivates and introduces financial incentives to motivate health facilities and health workers to attain pre-determined targets. To achieve this, the Tanzanian government through the Christian Social Services Commission initiated a PBF pilot project in Rungwe district, Mbeya region. Kilimanjaro Christian Medical Center was given the role of training health workers on PBF principles in Rungwe. The aim of this study was to explore health care providers' perception on a three years training on PBF principles in a PBF pilot project at Rungwe District in Mbeya, Tanzania. This was an explorative qualitative study, which took place at Rungwe PBF pilot area in October 2012. Twenty six (26) participants were purposively selected. Six took part in- depth interviews (IDIs) and twenty (20) in the group discussions. Both the IDIs and the GDs explored the perceived benefit and challenges of implementing PBF in their workplace. Data were manually analyzed using content analysis approach. Overall informants had positive perspectives on PBF training. Most of the health facilities were able to implement some of the PBF concepts in their work places after the training, such as developing job descriptions for their staff, creating quarterly business plans for their facilities, costing for their services and entering service agreement with the government, improved record keeping, customer care and involving community as partners in running their facilities. The most common principle of paying individual performance bonuses was mentioned as a major challenge due to inadequate funding and poor design of Rungwe PBF pilot project.\nQuestion: Does training on performance based financing make a difference in performance and quality of health care delivery?",
    "gt": "Despite poor design and inadequate funding, our findings have shown some promising results after PBF training in the study area. The findings have highlighted the potential of PBF to act as leverage for initiating innovative and proactive actions, which may motivate health personnel performance and quality of care in the study setting with minimal support. However, key policy issues at the national level should be addressed in order to exploit this opportunity.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate the potential of a simple and widely available technique as two-dimensional (2D) echocardiography to identify patients with ischemic cardiomyopathy and low likelihood of functional recovery after coronary revascularization. Two-dimensional echocardiography and radionuclide ventriculography (RNV) were performed before coronary revascularization in 94 patients with ischemic cardiomyopathy. Left ventricular ejection fraction (LVEF) was measured by RNV. Regional wall motion abnormalities, wall motion score index, end-diastolic wall thickness (EDWT), left ventricular (LV) volumes and LV sphericity index were assessed in the echocardiographic images. RNV was repeated 9-12 months after revascularization to assess LVEF change; an improvement>or=5% was considered clinically significant. Nine hundred and ninety-nine segments were severely dysfunctional; 149 out of 999 (15%) had an EDWT<or=6 mm. A severe enlargement of the end-diastolic volume index (EDVI) (>or=100 ml/ml) and of the end-systolic volume index (>or=80 ml) was present in 32 (34%) and 21 (22%) patients, respectively. A spherical shape of the LV was observed in 35 (37%) patients. LVEF after revascularization increased in 30 out of 94 patients (32%) from 30+/-8% to 39+/-9% (P<0.0001). On multivariate analysis, the EDVI was the only predictor of no recovery in LVEF [odds ratio, 1.06, confidence interval (CI), 1.04-1.1, P<0.0001]. The cut-off value of EDVI>or=90 ml/ml accurately identified patients that virtually never recover. Post-operatively, LVEF increased in three out of 42 (7%, 95% CI 0-15%) patients with EDVI>or=90 ml/ml as compared to 27 out of 52 (52%) patients with EDVI<90 ml/ml (P<0.0001).\nQuestion: Does resting two-dimensional echocardiography identify patients with ischemic cardiomyopathy and low likelihood of functional recovery after coronary revascularization?",
    "gt": "In patients with ischemic cardiomyopathy and severe LV enlargement, improvement of LVEF after revascularization is unlikely to occur. Conversely, in patients with relatively preserved LV size, a higher likelihood of functional recovery may be anticipated.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Pretreatment urinary, bowel, and sexual dysfunction may increase the toxicity of prostate cancer treatments or preclude potential benefits. Using patient-reported baseline dysfunction from a prospective cohort study, we determined the proportion of patients receiving relatively contraindicated ('mismatched') treatments. Baseline obstructive uropathy and bowel dysfunction relatively contraindicate brachytherapy (BT) and external beam radiation therapy (EBRT), respectively, because they increase patients' vulnerability to treatment-related toxicity. Baseline sexual dysfunction renders moot the intended benefit of nerve-sparing radical prostatectomy (NSRP), which is to preserve sexual function. We categorized patients' clinical circumstances by increasing complexity and counted the mismatches in each, expecting weaker or multiple contraindications to increase mismatched treatments. Of 438 eligible patients, 389 (89%) reported preexisting dysfunction, and more than one-third received mismatched treatments. Mismatches did not significantly increase with clinical complexity, and watchful waiting was very infrequent, even when all treatment options were contraindicated. Patient age and comorbidity, but not preexisting dysfunction, were associated with treatment choice. As expected, mismatched BT and EBRT led to worsened urinary and bowel symptoms, respectively, and NSRP did not improve outcomes after baseline sexual dysfunction.\nQuestion: Treatment 'mismatch' in early prostate cancer: do treatment choices take patient quality of life into account?",
    "gt": "Pretreatment dysfunction does not appear to reliably influence treatment choices, and patients receiving mismatched treatments had worse outcomes. Further study is needed to determine why mismatched treatments were chosen, including the role of incomplete patient-physician communication of baseline dysfunction, and whether using a validated questionnaire before treatment decision-making would bypass this difficulty. Treatment mismatch may be a useful outcome indicator of the quality of patient-centered decisions.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: In the past, many surgeons could practise their craft with little or no knowledge of patent law. But in the world of robotic and computerized surgery, this is increasingly a myopic approach, because the principle means of protecting high-tech surgical instruments is through the application of patent law. The issue is: does the Brookhill-Wilk patent, which covers the performance of remote robotic surgery, impede the growth of cybersurgery? Review of the Brookhill-Wilk patent and relevant law. Patent law, which first took its form in the Middle Ages, attempts to balance the rewarding of innovation with the stifling of market growth. Using US patent law as a model, it would appear that the Brookhill-Wilk patent, a particular example of a medical process patent, could inhibit the growth of cybersurgery, as potential sums of money could be demanded by the patent holder from anyone who practises cybersurgery. However, two recent US Supreme Court cases appear to have seriously undermined the validity of a number of medical process patents, including the Brookhill-Wilk patent.\nQuestion: Are the Brookhill-Wilk patents impediments to market growth in cybersurgery?",
    "gt": "Based on recent changes in patent law, it is not expected that Brookhill-Wilk patent will hinder the growth of cybersurgery.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There is extensive evidence that major depression, and particularly melancholia, is characterized by hypothalamic-pituitary-adrenal (HPA) axis hyperactivity as well as systemic immune activation, which may be accompanied by increased interleukin-1 beta production. Interleukin-1 beta is known to enhance HPA axis activity during an immune response. This study investigated whether interleukin-1 beta production is related to HPA axis activity in depressed subjects. The subjects were 28 inpatients with major or minor depression and 10 normal comparison subjects. The authors measured 1) the subjects' cortisol levels after an overnight 1-mg dexamethasone suppression test (DST) and 2) mitogen-stimulated supernatant interleukin-1 beta production by peripheral blood mononuclear cells. Statistically significant positive correlations between interleukin-1 beta production and post-DST cortisol values were found in the study group as a whole and in the depressed and normal subgroups separately.\nQuestion: Interleukin-1 beta: a putative mediator of HPA axis hyperactivity in major depression?",
    "gt": "It is suggested that constituents of the immune response (such as interleukin-1 beta) in major depression may contribute to HPA axis hyperfunction in that illness.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine the relationship between CD4 status and the P24 antigen level and survival in children infected with the human immunodeficiency virus. Cohort, case-control. Clinical Center at the National Institutes of Health, Bethesda, Md. One hundred forty-seven children infected with the human immunodeficiency virus enrolled in antiretroviral therapy protocols at the National Cancer Institute were reviewed and the relationships between CD4 counts, P24 antigenemia, and death were analyzed. None.MEASUREMENTS/ The presence of a very low CD count, less than 21% of the lower limit of normal values for age (equivalent to 0.05 x 10(9)/L in an adult), was associated with a significantly increased risk of death within 2 years. Although the risk of death was highest for children with CD4 counts below this level and who had detectable P24 antigen levels, P24 antigenemia by itself contributed little to the prognostic value of the CD4 count alone. However, it was also notable that a group of children with low CD4 counts also experienced prolonged survival.\nQuestion: CD4 status and P24 antigenemia. Are they useful predictors of survival in HIV-infected children receiving antiretroviral therapy?",
    "gt": "The association between low CD4 counts and death suggests that the age-adjusted CD4 count should be used as a marker to guide therapeutic intervention. At the same time, the presence of a very low CD4 count alone should not be considered a reason for therapeutic nihilism.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Since 2011, all acute general surgical admissions have been managed by the consultant-led emergency general surgery service (EGS) at our institution. We aim to compare EGS management of acute biliary disease to its preceding model. Retrospective review of prospectively collated databases was performed to capture consecutive emergency admissions with biliary disease from 1st February 2009 to 31st January 2013. Patient demographics, surgical intervention, use of diagnostic radiology, histological diagnosis, complications and hospital length of stay (LOS) were retrieved. A total of 566 patients were included (pre-EGS 254 vs. EGS 312). In the EGS period, the number of patients having surgery on index admission increased from 43.7 to 58.7 % (p<0.001) as did use of intra-operative cholangiography from 75.7 to 89.6 % (p = 0.003). The conversion to open cholecystectomy rate also was reduced from 14.4 to 3.3 % (p<0.001). Overall, a 14 % reduction in use of multiple (>1) imaging modalities for diagnosis was noted (p = 0.003). There was a positive trend in reduction of bile leaks but no significant difference in the overall morbidity and mortality. Time to theatre was reduced by 1 day [pre-EGS 2.7 (IQR 1.5-5.0) vs. EGS 1.7 (IQR 1.2-2.6) p<0.001]. The overall hospital LOS was reduced by 1.5 days [pre-EGS 5.0 (IQR 3-7) vs. EGS 3.5 (IQR 2-5) p<0.001].\nQuestion: Emergency Management of Gallbladder Disease: Are Acute Surgical Units the New Gold Standard?",
    "gt": "Since the advent of EGS, more judicious use of diagnostic radiology, reduced complications, reduced LOS, reduced time to theatre and an increased rate of definitive management during the index admission were demonstrated.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess in vitro the cariogenic and erosive potentials of Brazilian liquid oral paediatric medicines. Twenty-three paediatric medicines available on the Brazilian market were evaluated. The sample consisted of antihistamines, antitussives, bronchodilators and mucolytics. Duplicates of each bottle were analyzed for sugar concentration using normal-phase- high-performance liquid chromatography (HPLC). Quantification of sugars and sorbitol was calculated using the peak heights of commercial standards as references. pH measurements were determined using a digital pH meter. Titratable acidity was assessed by diluting three aliquots of each medicine, and increments of 0.1N NaOH were titrated until neutrality was reached. Viscosity was determined using a viscosemeter. Sugars were detected in 56.5% of the medicines. Sucrose was identified in 10 medicines, with concentrations ranging from 11.36 g% to 85.99 g%. Glucose was detected in five medicines, with concentrations varying from 4.64 g% to 40.19 g%; fructose in six medicines, with concentrations ranging from 5.09 g% to 46.71 g%. Twelve medicines exhibited sorbitol, with values ranging from 5.39 g% to 46.09 g%. Most tested medicines were acidic, with pH values ranging between 2.6 and 5.7. Only two medicines (Fluimucil and Polaramine) presented pH 6.4 and 6.0, respectively. Titratable acidity mean values ranged between 0.28 and 16.33 mL. Viscosity values varied between 2.8 cP and 412.3 cP.\nQuestion: Are paediatric medicines risk factors for dental caries and dental erosion?",
    "gt": "Many paediatric medicines showed high sugar concentration, pH values below the critical value and high titratable acidity values, all of which increase the medicines' cariogenic and erosive potentials.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Individuals with celiac disease (CD) are at increased risk of sepsis. The aim of this study was to examine whether CD influences survival in sepsis of bacterial origin. Nationwide longitudinal registry-based study. Through data on small intestinal biopsies from Sweden's 28 pathology departments, we identified 29,096 individuals with CD (villous atrophy, Marsh stage III). Each individual with CD was matched with five population-based controls. Among these, 5,470 had a record of sepsis according to the Swedish Patient Register (1,432 celiac individuals and 4,038 controls). Finally we retrieved data on mortality in sepsis patients through the Swedish Cause of Death Registry. CD was associated with a 19% increase in overall mortality after sepsis (95% confidence interval (CI) = 1.09-1.29), with the highest relative risk occurring in children (adjusted hazard ratio (aHR) = 1.62; 95%CI = 0.67-3.91). However, aHR for death from sepsis was lower (aHR = 1.10) and failed to reach statistical significance (95%CI = 0.72-1.69). CD did not influence survival within 28 days after sepsis (aHR = 0.98; 95%CI = 0.80-1.19).\nQuestion: Does Celiac Disease Influence Survival in Sepsis?",
    "gt": "Although individuals with CD seem to be at an increased risk of overall death after sepsis, that excess risk does not differ from the general excess mortality previously seen in celiac patients in Sweden. CD as such does not seem to influence short-term or sepsis-specific survival in individuals with sepsis and therefore is not an independent risk factor for poor prognosis in sepsis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Mobile C-arm imaging is commonly used in operating rooms worldwide. Especially in orthopaedic surgery, intraoperative C-arms are used on a daily basis. Because of new minimally-invasive surgical procedures a development in intraoperative imaging is required. The purpose of this article is investigate if the choice of mobile C-arms with flat panel detector technology (Siemens Cios Alpha and Ziehm Vision RFD) influences image quality and dose using standard, commercially available test devices. For a total of four clinical application settings, two zoom formats, and all dose levels provided, the transmission dose was measured and representative images were recorded for each test device. The data was scored by four observers to assess low contrast and spatial resolution performance. The results were converted to a relative image quality figure allowing for a direct image quality and dose comparison of the two systems. For one test device, the Cios Alpha system achieved equivalent (within the inter-observer standard error) or better low contrast resolution scores at significantly lower dose levels, while the results of the other test device suggested that both systems achieved similar image quality at the same dose. The Cios Alpha system achieved equivalent or better spatial resolution at significantly lower dose for all application settings except for Cardiac, where a comparable spatial resolution was achieved at the same dose.\nQuestion: Does the choice of mobile C-arms lead to a reduction of the intraoperative radiation dose?",
    "gt": "The correct choice of a mobile C-arm is very important, because it can lead to a reduction of the intraoperative radiation dose without negative effects on image quality. This can be a big advantage to reduce intraoperative radiation not only for the patient but also for the entire OR-team.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The proportion of patients with idiopathic chronic pancreatitis (ICP) that have an autoimmune origin is unknown. Three forms of ICP have been described: pseudotumoral, duct-destructive, and usual chronic pancreatitis. The aim of this study was to identify autoimmune stigmata in the 3 forms. All patients who underwent exploration for ICP were included. The following data were recorded: examination by an internal medicine specialist, autoantibodies and immunoglobulin screening, and pancreatic duct imaging. Sixty patients were included (pseudotumoral, n = 11; duct-destructive, n = 27; usual, n = 22). There were no significant differences among the 3 types with regard to sex ratio, age, frequency of acute pancreatitis, or obstructive jaundice. Pancreatic calcifications were seen only in the usual form (81%; P = .0001). Autoimmune disease was present in 10 patients: ulcerative colitis in 5 patients, primary sclerosing cholangitis in 2 patients, and Sjögren's syndrome, Hashimoto's thyroiditis, and Graves' disease in 1 patient each. Autoimmune diseases were not more frequent in patients with pseudotumoral (36%) or duct-destructive (19%) forms than in those with the usual form (5%, P = .06). Immunoglobulin G4 levels were increased in 2 of 6 in the pseudotumoral, 1 of 9 in the duct-destructive, and 0 of 12 patients in the usual group. Combining clinical and biochemical autoimmune parameters, 24 patients (40%) had at least 1 autoimmune marker or disease.\nQuestion: Is idiopathic chronic pancreatitis an autoimmune disease?",
    "gt": "Clinical or biochemical autoimmune stigmata are present in 40% of patients with ICP. Autoimmune mechanisms may be frequent in idiopathic pancreatitis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Formal efforts to improve patient education are associated with fewer disease complications in a number of conditions. The possible relationship between knowledge about ulcerative colitis and its cancer risk, and the development of colorectal cancer using a previously developed and validated instrument-the Crohn's and colitis knowledge (CCKNOW) score-were investigated. The 24 item CCKNOW questionnaire was mailed to patients known to have developed colorectal cancer as a complication of ulcerative colitis (cases) and to colitics from the Leicestershire inflammatory bowel disease patient database who had not developed cancer (controls). The mean (SD) CCKNOW scores for cases was 8.21 (3.02) and for controls was 8.27 (4.3). These scores did not differ significantly between cases and controls (difference 0.06, 95% confidence interval (CI) -1.7 to 1.5, p=0.9). There were four times as many members of the National Association of Crohn's and Colitis (NACC) in the control group compared with the cancer group and patients who are members of NACC achieve statistically significantly higher scores than non-members (11.6 v 7.8, p=0.05, 95% CI -0.1 to 7.6). However, after adjusting for NACC membership, the CCKNOW score did not appear to be associated with having developed cancer (odds ratio 1.04, 95% CI 0.92 to 1.18, p=0.5).\nQuestion: Does patient knowledge affect the colorectal cancer risk in ulcerative colitis?",
    "gt": "The CCKNOW scores were comparable in cases and controls. Thus, in a retrospective study, no evidence has been demonstrated of an association between patient knowledge and the risk of developing colorectal cancer in patients with ulcerative colitis. However, knowledge may have been increased in cases as a direct result of having had colorectal cancer as a complication of ulcerative colitis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The opinion on the use of retrograde ureteropyelography (RUPG) prior to routine pyeloplasty for an ureteropelvic (UPJ) obstruction has been divided. This study analyses the efficacy of a preoperative RUPG and determines if a dorsal lumbotomy (DL) approach offers any advantage in this situation. This is a retrospective analysis of application of RUPG prior to pyeloplasty in children with ages ranging from 42 days to 16.2 years who underwent surgery at the Children's Hospital at Westmead between 2009 and 2013. We identified a total of 95 children with isolated UPJ obstruction, with 59 (62.1%) boys and 36 (37.8%) girls. Overall, open pyeloplasties were performed in 89 (42 DL: 47 loin incision) and the rest (n = 6) laparoscopically. Preoperative RUPG was performed in 58 (61%) and it provided additional information in 11 (18.9%) patients for whom the surgical approach was modified. Hospital stay, operative time, and time to full diet were shorter with the DL approach (p<0.05).\nQuestion: Does the surgical approach change the need for a retrograde pyelogram prior to pyeloplasty?",
    "gt": "The current study suggests that RUPG is avoidable if the approach for pyeloplasty is through the conventional loin incision. The short-term advantages might rationalize the use of RUPG if a DL incision is employed.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate the inter-rater reliability of results from Global Trigger Tool (GTT) reviews when one of the three reviewers remains consistent, while one or two reviewers rotate. Comparison of results from retrospective record review performed as a cross-sectional study with three review teams each consisting of two non-physicians and one physician; Team I (three consistent reviewers), Team II (one of the two non-physician reviewers or/and the physician from Team I are replaced for different review periods) and Team III (three consistent reviewers different from reviewers in Team I and Team II). Medium-sized hospital trust in Northern Norway. A total of 120 records were selected as biweekly samples of 10 from discharge lists between 1 July and 31 December 2010 for a 3-fold review. Replacement of review team members was tested to assess impact on inter-rater reliability and adverse events measurment. Inter-rater reliability assessed with the Cohen kappa coefficient between different teams regarding the presence and severity level of adverse events. Substantial inter-rater reliability regarding the presence and severity level of adverse events was obtained between Teams I and II, while moderate inter-rater reliability was obtained between Teams I and III.\nQuestion: Is inter-rater reliability of Global Trigger Tool results altered when members of the review team are replaced?",
    "gt": "Replacement of reviewers did not influence the results provided that one of the non-physician reviewers remains consistent. The experience of the consistent reviewer can result in continued consistency in interpretation with the new reviewer through discussion of events. These findings could encourage more hospital to rotate reviewers in order to optimize resources when using the GTT.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate the effect of immediate postpartum curettage on rapid resolution of clinical and laboratory indices in pre-eclampsia and eclampsia women. A randomized controlled study, comprised of 420 pre-eclamptic or eclamptic women with singleton pregnancy 24 weeks gestation and more. Patients were divided into two groups: 220 patients underwent immediate postpartum curettage and 200 patients as a control group. The clinical and laboratory prenatal parameters showed no statistical significant differences between both groups. The follow-up for the postnatal clinical and laboratory data showed significant improvement for the mean arterial blood pressure in the curettage group over 6, 12, and 24 h after delivery and significant improvement in the platelet count as well. The average time required for MAP to reach 105 mmHg or less was significantly shorter (P<0.05) in the curettage group (40 ± 3.15 h) than the control group (86 ± 5.34 h). Two patients in the curettage group developed convulsions versus 11 patients in the control group within the first 24 h after delivery. No maternal mortalities were reported in both groups.\nQuestion: Does immediate postpartum curettage of the endometrium accelerate recovery from preeclampsia-eclampsia?",
    "gt": "Immediate postpartum curettage is a safe and effective procedure and can accelerate recovery from pre-eclampsia or eclampsia.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The uneven distribution of allied health professionals (AHPs) in rural and remote Australia and other countries is well documented. In Australia, like elsewhere, service delivery to rural and remote communities is complicated because relatively small numbers of clients are dispersed over large geographic areas. This uneven distribution of AHPs impacts significantly on the provision of services particularly in areas of special need such as mental health, aged care and disability services. This study aimed to determine the relative importance that AHPs (physiotherapists, occupational therapists, speech pathologists and psychologists - \"therapists\") living in a rural area of Australia and working with people with disability, place on different job characteristics and how these may affect their retention. A cross-sectional survey was conducted using an online questionnaire distributed to AHPs working with people with disability in a rural area of Australia over a 3-month period. Information was sought about various aspects of the AHPs' current job, and their workforce preferences were explored using a best-worst scaling discrete choice experiment (BWSDCE). Conditional logistic and latent class regression models were used to determine AHPs' relative preferences for six different job attributes. One hundred ninety-nine AHPs completed the survey; response rate was 51 %. Of those, 165 completed the BWSDCE task. For this group of AHPs, \"high autonomy of practice\" is the most valued attribute level, followed by \"travel BWSDCE arrangements: one or less nights away per month\", \"travel arrangements: two or three nights away per month\" and \"adequate access to professional development\". On the other hand, the least valued attribute levels were \"travel arrangements: four or more nights per month\", \"limited autonomy of practice\" and \"minimal access to professional development\". Except for \"some job flexibility\", all other attributes had a statistical influence on AHPs' job preference. Preferences differed according to age, marital status and having dependent children.\nQuestion: Should I stay or should I go?",
    "gt": "This study allowed the identification of factors that contribute to AHPs' employment decisions about staying and working in a rural area. This information can improve job designs in rural areas to increase retention.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Choledocholithiasis commonly occurs in patients with symptomatic cholelithiasis. Although the recently developed multidetector computed tomography (MDCT) scan enhances the ability to diagnose choledocholithiasis, this technique is considered to have some limitations for evaluating the common bile duct (CBD).AIM: The purpose of this study was to evaluate the necessity for performing endoscopic ultrasound (EUS) as an add-on test to detect choledocholithiasis in patients who were diagnosed with gallstone disease without choledocholithiasis based on MDCT. Three hundred twenty patients with gallstone disease and no evidence of CBD stones according to MDCT underwent EUS between March 2006 and April 2011. If CBD stones were suspected based on the EUS results or clinical symptoms, a final diagnosis was obtained by endoscopic retrograde cholangiopancreatography (ERCP). The patients' medical records were retrospectively analyzed based on clinical symptoms, biochemical findings, and results of the imaging studies. CBD stones were not detected with MDCT in 41 (12.8 %) out of 320 patients with gallstone disease. The causes for these discrepancies could be attributed to small stone size (n = 19, 46.3 %), isodensity (n = 18, 43.9 %), impacted stones (n = 1, 2.4 %), and misdiagnosis (n = 3, 7.3 %). If EUS were used as a triage tool, unnecessary diagnostic ERCP and its complications could be avoided for 245 (76.6 %) patients.\nQuestion: Is endoscopic ultrasound needed as an add-on test for gallstone diseases without choledocholithiasis on multidetector computed tomography?",
    "gt": "MDCT may not be a primary technique for detecting CBD stones. EUS should be performed instead as an add-on test to evaluate the CBD for patients with gallstone-related disease. In particular, EUS should be routinely recommended for patients with abnormal liver enzyme levels, pancreatitis, and dilated CBD.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: With the increased occurrence of methicillin-resistant staphylococcus aureus infections, linezolid treatment might be administered more often. New rare adverse events are likely to follow. A 65-year-old man (weight, 91 kg; height, 185 cm) presented to the emergency department at the University of Virginia-affiliated Salem Veterans Affairs Medical Center, Salem, Virginia, after a recent (8 weeks) kidney transplantation with a 24-hour history of fatigue, chills, arthralgias, increased urinary frequency, and onset of tongue discoloration. Two days before admission, he completed a 14-day course of linezolid 600 mg PO BID for ampicillin-resistant enterococcal urinary tract infection. He was afebrile on admission and the dorsal aspect of his tongue was blackened centrally, browner peripherally, with normal pink mucosa on the periphery. Based on the Naranjo probability scale, the calculated score for tongue discoloration as a drug-related adverse event was 7 out of a maximum score of 13 points, designating it as a probable cause. The patient's tongue discoloration improved moderately during the hospital stay and resolved 6 months after the discontinuation of linezolid.\nQuestion: Tongue discoloration in an elderly kidney transplant recipient: Treatment-related adverse event?",
    "gt": "We report a rare association of linezolid and tongue discoloration in an elderly kidney transplant recipient that improved with discontinuation. We present this case to increase clinicians' awareness of the potential adverse event.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The literature is inconsistent as to whether HIV-infected patients have higher rates of surgical complication rates than HIV-uninfected patients. This inconsistency reflects the failure to control for confounding variables in many of the previous studies. A retrospective cohort study of records of HIV-infected individuals who underwent surgical procedures between 1990 and 1995 was matched with the records of HIV-uninfected control patients. We performed a logistic regression analysis to determine the independent effects of HIV infection and other potential risk factors for surgical complications. The crude rates of death and infectious and hematologic complications were higher among HIV-infected patients than among uninfected patients. Although the crude risk of having any complication was higher among the HIV-infected (odds ratio [OR]=2.47, p=0.015), the adjusted risk was not (OR=0.72 [p<0.613]). Variables significantly associated with complications were American Society of Anesthesiology (ASA) risk class (OR=2.7), age (OR=1.06 per year), and weight (OR=0.96 per kg).\nQuestion: Is HIV infection a risk factor for complications of surgery?",
    "gt": "HIV sero-status was not found to be an independent risk factor for complications of surgery. The most important risk factor for complication of surgery in HIV-infected patients is ASA risk class.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Sixteen patients with 19 renal artery stents underwent CT angiography. A biphasic protocol was performed including arteriographic acquisition at standard 120 kVp and a late-arterial scan at 100 kVp (n=9) or 80 kVp (n=7). Images were reconstructed under various algorithms. Signal-to-noise and contrast-to-noise ratios (SNR, CNR) were determined within stent, aorta and renal arteries. Image quality and the presence of restenosis were assessed. Volume CT dose-index was recorded and dose reduction (DR%) between phases was calculated. Ten patients presented with Hounsfield values>250 HU in all segments, phases and reconstructions and were further evaluated. The 120 kVp protocol performed better in all vessels and reconstruction algorithms. SNR at 120 kVp (B31f) did not differ significantly compared to 100 kVp (B31f). CNR within stent was borderline compromised at 100 kVp (p=0.042). All but two image sets (at 80 kVp) were considered diagnostic. Minor loss of subjective image quality was noticed at 100 kVp. No difference in assessment of restenosis was observed between 120 kVp and the diagnostic low-exposure scans. Mean DR% was estimated 45% at 100 kVp and 77% at 80 kVp.\nQuestion: MDCT angiography assessment of renal artery in-stent restenosis: can we reduce the radiation exposure burden?",
    "gt": "Renal MDCT angiography and stent-restenosis assessment are feasible at 100 kVp with minor loss of image quality and almost half radiation exposure.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Reactive oxygen species have been shown to be initiators/promotors of tumorigenesis. Because evidence supports the role of increased oxidative stress in solid tumors, we sought to establish this relationship in neuroblastoma (NB). The aim of the study was to investigate the extent of oxidative DNA damage and antioxidative status in a progressive animal model of human NB. Tumors were induced in the left kidneys of nude mice by the injection of cultured human NB cells (10(6)). Blood was collected from tumor-bearing mice and controls at 2, 4, and 6 weeks. Peripheral blood leukocyte oxidative DNA damage was determined using single-cell gel electrophoresis (comet assay), and plasma antioxidant capacity was assessed by the Trolox equivalent antioxidant capacity method. Levels of oxidative DNA damage in peripheral blood leukocytes of NB-bearing mice were increased by 166%, 110%, and 87% as compared with healthy controls at 2, 4, and 6 weeks, respectively. Plasma total antioxidant values for tumor-bearing mice were not significantly different from control mice.\nQuestion: Oxidative status in neuroblastoma: a source of stress?",
    "gt": "Our results indicate an increase of oxidative stress in an animal model of human NB, especially in the early stages of growth. Yet, we did not observe an appreciable response in plasma antioxidant activity. Because an altered redox status has been implicated in tumor maintenance and progression, these findings support the notion of a complex oxidant-antioxidant imbalance contributing to NB growth.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The authors reviewed their institutional experience with pure low-grade oligodendroglioma (LGO), correlating outcomes with several variables of possible prognostic values. Sixty-nine patients with WHO-classified LGOs were treated between 1992 and 2006 at the McGill University Health Center. Clinical, pathological, and radiological records were carefully reviewed. Demographic characteristics; the nature and duration of presenting symptoms; baseline neurological function; extent of resection; Karnofsky Performance Scale score; preoperative radiological findings including tumor size, location, and absence/presence of enhancement; and pathological data including chromosome arms 1p/19q codeletion and O-methylguanine-DNA methyltransferase promoter gene methylation status were all compiled. The timing and dose of radio- and/or chemotherapy, date of tumor progression, pathological finding at disease progression, treatment at time of disease progression, and status at the last follow-up were also recorded. The median follow-up period was 6.1 years (range 1.3-16.3 years). The majority (78%) of patients presented with seizures; contrast enhancement was initially seen in 16 patients (25%). All patients had undergone an initial surgical procedure: gross-total resection in 27%, partial resection in 59%, and biopsy only in the remaining 13%. Fifteen patients received adjuvant radiotherapy. Data on O-methylguanine-DNA methyltransferase promoter gene methylation status was available in 47 patients (68%) and in all but 1 patient for 1p/19q status. Survival at 5, 10, and 15 years was 83, 63, and 29%, respectively. Multivariate analysis showed that seizures at presentation and the absence of contrast enhancement were the only independent favorable prognostic factors for survival. The 5-, 10-, and 15-year progression-free survival rates were 46, 7.7, and 0%, respectively.\nQuestion: Low-grade oligodendroglioma: an indolent but incurable disease?",
    "gt": "This retrospective review confirms the indolent but progressively fatal nature of LGOs. Contrast enhancement was the most evident single prognostic factor. New treatment strategies are clearly needed in the management of this disease.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine the relationship between hospital admissions for falls and hip fracture in elderly people and area characteristics such as socio-economic deprivation. Ecological study of routinely collected hospital admissions data for falls and hip fracture in people aged 75 years or over for 1992-1997, linked at electoral ward level with characteristics from census data. In total, 42,293 and 17,390 admissions were identified for falls and hip fracture, respectively, from 858 electoral wards in Trent. Rate ratios (RRs) for hospital admissions for falls and hip fracture were calculated by the electoral wards' Townsend score divided by quintiles. RRs were estimated by negative binomial regression and adjusted for the ward characteristics of age, gender, ethnicity, rurality, proportion of elderly people living alone and distance from hospital. There was a small but statistically significant association at electoral ward level between hospital admissions for falls and the Townsend score, with the most deprived wards having a 10% higher admission rate for falls compared with the most affluent wards (adjusted RR 1.10, 95% CI 1.01-1.19). No association was found between hospital admission for hip fracture and deprivation (adjusted RR 1.05, 95% CI 0.95-1.16).\nQuestion: Do rates of hospital admission for falls and hip fracture in elderly people vary by socio-economic status?",
    "gt": "There is some evidence of an association at electoral ward level between hospital admissions for falls and socio-economic deprivation, with higher rates in deprived areas. No such association was found for hip fracture. Further work is required to assess the impact of interventions on reducing inequalities in hospital admission rates for falls in elderly people.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Carotid angioplasty and stenting has been proposed as a treatment option for carotid occlusive disease in patients at high risk, including those 80 years of age or older or with contralateral carotid occlusion. We analyzed 30-day mortality and stroke risk rates of carotid endarterectomy (CEA) in patients aged 80 years or older with concurrent carotid occlusive disease. From a retrospective review of 1000 patients undergoing 1150 CEA procedures to treat symptomatic and asymptomatic carotid lesions over 13 years, we identified 54 patients (5.4%) aged 80 years or older with concurrent contralateral carotid occlusion. These patients were compared with 38 patients (3.8%) aged 80 years or older with normal or diseased patent contralateral carotid artery and 81 patients (8.1%) younger than 80 years with contralateral carotid occlusion. All CEA procedures involved either standard CEA with patching or eversion CEA, and were performed by the same surgeon, with the patients under deep general anesthesia and cerebral protection involving continuous perioperative electroencephalographic monitoring for selective shunting. Shunting criteria were based exclusively on electroencephalographic abnormalities consistent with cerebral ischemia. The 30-day mortality and stroke rate in patients aged 80 years or older with concurrent contralateral carotid occlusion was zero.\nQuestion: Octogenarians with contralateral carotid artery occlusion: a cohort at higher risk for carotid endarterectomy?",
    "gt": "The concept of high-risk CEA needs to be revisited. Patients with two of the criteria considered high risk in the medical literature, that is, age 80 years or older and contralateral carotid occlusion, can undergo CEA with no greater risks or complications. Until prospective randomized trials designed to evaluate the role of carotid angioplasty and stenting have been completed, CEA should remain the standard treatment in such patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Defocus curves are used to evaluate the subjective range of clear vision of presbyopic corrections such as in eyes implanted with accommodating intraocular lenses (IOLs). This study determines whether letter sequences and/or lens presentation order ought to be randomised when measuring defocus curves. Defocus curves (range +2.00DS to -2.00DS) were measured on 18 pre-presbyopic subjects (mean age 24.1+/-4.2 years) for six combinations of sequential or randomised positive or negative lens progression and non-randomised or randomised letter sequences. The letters were presented on a computerised logMAR chart at 6m. Overall there was a statistically significant difference between the six combinations (ANOVA, p<0.05) attributable to the combination of non-randomised letters with non-randomised lens progression from negative to positive defocus (p<0.01). There was no statistically significant difference in defocus curve measurements if both letters and lens order were randomised compared to if only one of these variables was randomised (p>0.05). Non-randomised letters, with a sequential lens progression from negative to positive, was significantly different to all other combinations when compared individually (Student's T-test, p<0.003 on all comparisons), and was confirmed as the sole source of the overall significant difference. There was no statistically significant difference if both lens presentation order and letter sequences were randomised compared to if only one or the other of these variables was randomised.\nQuestion: Is randomisation necessary for measuring defocus curves in pre-presbyopes?",
    "gt": "Non-randomised letters and non-randomised lens progression on their own did not affect the subjective amplitude of accommodation as measured by defocus curves, although their combination should be avoided.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To identify patients with ureteropelvic junction (UPJ) obstruction who will benefit from endoscopic Acucise incision of the stenosis and to compare the open Hynes-Anderson pyeloplasty with this minimally invasive technique. In a prospective trial, 22 patients with primary and secondary UPJ obstruction were treated by Acucise endopyelotomy, and 18 patients were treated by Hynes-Anderson pyeloplasty. Preoperative and postoperative renal scans were used to determine the degree of obstruction and intravenous urography, ultrasound scanning, or both to assess the degree of dilation. There was a vast difference in the cure rate of the two groups: Hynes-Anderson pyeloplasty cured 94.5% of the patients, while in the Acucise group, the cure rate was only 32%. There was some improvement in another 22% of the patients, but the renal scan curve remained obstructed. The remaining 45% of patients failed to show any improvement.\nQuestion: Retrograde acucise endopyelotomy: is it worth its cost?",
    "gt": "Acucise endopyelotomy will improve or cure only patients with good renal function and mild dilation of the pelvicaliceal system. Patients with severe dilation should be treated by Hynes-Anderson pyeloplasty.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: An increased platelet activation status is present in patients with preeclampsia. Our purpose was (1) to establish by means of flow cytometry whether platelets circulate in an activated state during the first and second trimesters of pregnancy and (2) to establish whether early platelet activation predicts the onset of preeclampsia. Consecutively, 244 pregnant women were included in a prospective study design. Platelets in whole blood samples from the pregnant women in the first trimester, the second trimester, and after delivery were labeled with the following antibodies associated with platelet activation: anti-CD62P (P-selectin, alpha-granule secretion), anti-CD63 (GP53, lysosomal secretion), anti-CD31 (GPIIa', platelet endothelial cell adhesion molecule-1). The surface antigen exposure was determined by double-label flow cytometry with anti-CD42b (GPIb, a platelet-specific monoclonal glycoprotein) to select platelets and platelet-derived materials. Preeclampsia was defined as a diastolic blood pressure>or = 90 mm Hg and proteinuria>or = 0.3 gm in a 24-hour urine sample (International Society for Study of Hypertension in Pregnancy criteria). Seventeen of 244 patients had preeclampsia (6.9%). Only first-trimester CD63 expression had an area under the curve>0.5 by receiver-operator characteristic curve analysis and was selected as a possible predictor of preeclampsia. We found a sensitivity of 47% and a specificity of 76% with use of a percentage of activated platelets above 2% as a positive test. Likelihood ratios were 1.94 for positive likelihood and 0.69 for negative likelihood. Univariate logistic regression analysis results were odds ratio 2.8 (95% confidence interval 1.0 to 7.6). Multivariate logistic regression analysis results were odds ratio 2.9 (95% confidence interval 0.92 to 8.9). However, the odds ratio of first antenatal diastolic blood pressure was two to four times higher than the odds ratio of first-trimester CD63 expression. The combination of first-trimester CD63 and first antenatal diastolic blood pressure increases the positive likelihood ratio from 1.94 to 9.4, with a sensitivity of 41%, a specificity of 96%, and a negative likelihood ratio of 0.62.\nQuestion: Can flow cytometric detection of platelet activation early in pregnancy predict the occurrence of preeclampsia?",
    "gt": "Increased first-trimester CD63 expression is an independent risk factor for development of preeclampsia. CD63 expression might be useful to identify a subgroup of patients with a high risk for development of preeclampsia, especially in combination with first-trimester antenatal diastolic blood pressure. This method of patient selection may enable more efficient intervention studies in patients at risk than do the selection methods used so far.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: In cardiac hypertrophy, ECG T-wave changes imply an abnormal sequence of ventricular repolarization. We investigated the hypothesis that this is due to changes in the normal regional differences in action potential duration. We assessed the contribution of potassium- and calcium-dependent currents to these differences. Both the altered sequence of ventricular repolarization and the underlying cellular mechanisms may contribute to the increased incidence of ventricular arrhythmias in hypertrophy. Rats received daily isoproterenol injections for 7 days. Myocytes were isolated from basal subendocardial (endo), basal midmyocardial (mid), and apical subepicardial (epi) regions of the left ventricular free wall. Action potentials were stimulated with patch pipettes at 37 degrees C. The ratio of heart weight to body weight and mean cell capacitance are increased by 22% and 18%, respectively, in hypertrophy compared with controls (P<.001). Normal regional differences in action potential duration at 25% repolarization (APD25) are reduced in hypertrophy (control: endo, 11.4+/-0.9 ms; mid, 8.2+/-0.9 ms; epi, 5.1+/-0.4 ms; hypertrophy: endo, 11.6+/-0.9 ms; mid, 10.4+/-0.8 ms; epi, 7.8+/-0.6 ms). The regional differences in APD25 are still present in 3 mmol/L 4-aminopyridine. Hypertrophy affects APD75 differently, depending on the region of origin of myocytes (ANOVA P<.05). APD75 is shortened in subendocardial myocytes but is prolonged in subepicardial myocytes (control: endo, 126+/-7 ms; epi, 96+/-10 ms; hypertrophy: endo, 91+/-6 ms; epi, 108+/-7 ms). These changes in APD75 are altered by intracellular calcium buffering.\nQuestion: Effects of hypertrophy on regional action potential characteristics in the rat left ventricle: a cellular basis for T-wave inversion?",
    "gt": "Normal regional differences in APD and the changes observed in hypertrophy are only partially explained by differences in I(tol). In hypertrophy, the normal endocardial/epicardial gradient in APD75 appears to be reversed. This may explain the T-wave inversion observed and will have implications for arrhythmogenesis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The effect on resident behaviors of adding a wander garden to an existing dementia facility was investigated. 34 male residents were observed for 12 months before and after opening the garden. Behaviors were assessed using the Cohen-Mansfield Agitation Inventory Short Form (CMAI), incident reports, as needed medications (pro re nata [PRN]), and surveys of staff and residents' family members as indices of affect. Final CMAI scores and total PRNs employed were lower than baseline values with a trend for residents who used the garden more often to have less agitated behavior. Verbal inappropriate behaviors did not change significantly whereas physical incidents increased. Staff and family members felt that the wander garden decreased inappropriate behaviors and improved mood and quality of life of the dementia residents.\nQuestion: Does a wander garden influence inappropriate behaviors in dementia residents?",
    "gt": "Study design characteristics and garden management may have affected behaviors both positively and negatively. Additional studies are needed to explore the benefits of wander gardens for dementia residents.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Neoadjuvant chemoradiation for rectal cancers may result in complete clinical response (cCR) in some patients. The aim of this study was to analyze the long-term outcomes of such patients in a tertiary cancer center. Patients with rectal cancer who had a cCR to neoadjuvant chemoradiation were divided into two groups: Group A (n=23) did not undergo surgery, and Group B (n=10) underwent elective surgery. The recurrence patterns and survival outcomes were compared between the two groups. After a median follow-up of 72 months (range 12-180), seven patients (30%) in Group A developed an isolated local recurrence. In Group B, after a median follow-up of 37 months (range 12-180) there were no local recurrences. The median disease-free and overall survival was 36 months (range 6-168) and 66 months (range 12-180) in Group A and 36 months (range 12-180) and 37 months (range 18-180) in Group B respectively.\nQuestion: Complete clinical response to neoadjuvant chemoradiation in rectal cancers: can surgery be avoided?",
    "gt": "Our results suggest that surgery could be avoided in selected patients with rectal cancer who have a cCR to neoadjuvant chemoradiation. However, until the safety of a non-surgical approach is proven in a prospective randomized trial, it cannot be recommended outside a clinical protocol study.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The discrepancy between high rates of sensitivity, specificity, and accuracy for intraductal ultrasonography (IDUS) in extrahepatic bile duct carcinoma and the failure to depict different wall layers as defined by the TNM classification have not yet been elucidated sufficiently. In a prospective study, endosonographic images were correlated with histomorphology including immunohistochemistry. Using IDUS, we examined fresh resection specimens of patients who had undergone pancreato-duodenectomy. For histological analysis, the formalin-fixed and paraffin-embedded specimens were stained by hematoxylin-eosin, elastica-van-Gieson, and immunohistochemically by smooth muscle-actin. To confirm our hypothesis, further cases from the archives were analyzed histopathologically and immunohistochemically. The various wall layers of the extrahepatic bile duct as described by the International Union Against Cancer are neither histomorphologically nor immunohistochemically consistently demonstrable. Especially, a clear differentiation between tumor invasion beyond the wall of the bile duct (T2) and invasion of the pancreas (T3) by histopathological means is often not possible. Endosonographic images using high-resolution miniprobes similarly confirm the difficulty in imaging various layers in the bile duct wall.\nQuestion: Endosonographic and histopathological staging of extrahepatic bile duct cancer: time to leave the present TNM-classification?",
    "gt": "Most adaptations made by the sixth edition of the TNM classification accommodate to the endosonographic and most of the histopathological findings as demonstrated in our study. In contrast to the new edition, however, our findings suggest to combine T2- and T3-staged tumors into one single class leading to clarification, and improved reproducibility of histopathological staging.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Although observational studies suggest that inflammatory markers are associated with autonomic nervous system function, the causal relationship of this is not clear. We tested the hypothesis that acute inflammation will temporarily attenuate vagal reactivation as measured by heart rate recovery after exercise. In this double-blind randomized study, 24 healthy subjects were assigned to receive either an influenza vaccine (n = 15) as a model to generate a systemic inflammatory response or a sham vaccine (n = 9). Heart rate recovery after exercise testing was used as an index of parasympathetic nervous function and was calculated as the difference between maximal heart rate during the test and heart rate 1 and 2 min after cessation of exercise. Both blood analysis and treadmill exercise stress tests were conducted before and 48 h after each vaccination. Inflammatory marker, log C-reactive protein (1.9 +/- 1.2 to 2.8 +/- 1.4, p<0.05) was significantly increased after the influenza vaccine. Heart rate recovery 1 was significantly attenuated 48 h after the influenza vaccination (23.4 +/- 6.4 to 20.5 +/- 4.9, p<0.05) but not sham vaccination.\nQuestion: Does an acute inflammatory response temporarily attenuate parasympathetic reactivation?",
    "gt": "These findings show that acute inflammation is associated with a temporary deterioration in cardiac autonomic nervous system function in healthy subjects.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Reports on the specificity of breast MRI are heterogeneous, depending on the respective setting of the performed study. To retrospectively estimate the sensitivity and especially the specificity of breast MRI in the non-screening setting as an adjunct to mammography sorted by breast density and to estimate the accuracy of breast MRI in cases rated BI-RADS 0 and 3 mammographically. A total of 216 consecutive patients with referral to breast MRI and previously acquired mammography were enrolled in this analysis. Negative findings were followed up with a mean time of 26.7 months. The loss to follow-up was 10.8%. The single breast was regarded as the study subject (n=399, 364 cases were eligible for calculation of diagnostic accuracy). BI-RADS 1 and 2 were rated as benign, 4 and 5 as malignant. BI-RADS 0 and 3 were analyzed separately. The 95% confidence intervals (CIs) were calculated from the normally approximated binomial distribution and taken to represent significant differences for the two imaging modalities if they did not overlap. Among the study population, 62 malignant neoplasms were detected. For cases rated BI-RADS 1, 2, 4, and 5 (n=251), the sensitivity of breast MRI was 95.7% (95% CI 89.9-100.0%) and 74.5% (95% CI 62.0-87.0%) for mammography, respectively. The specificity of breast MRI was 96.1% (95% CI 93.4-98.8%) and 92.2% (95% CI 88.5-95.9%) for mammography, respectively. The diagnostic accuracy of breast MRI did not depend on breast density. In cases rated BI-RADS 0, n=57 (3, n=56), breast MRI achieved a sensitivity of 100% (90.9%) and a specificity of 98.1% (88.9%). There was a significant (P<0.01) accumulation of dense breast tissue (ACR IV) in breasts rated BI-RADS 0 in mammography. Breast MRI missed three malignant lesions, two of them being smaller than 3 mm.\nQuestion: Breast MRI as an adjunct to mammography: Does it really suffer from low specificity?",
    "gt": "There is no rationale to criticize the low specificity of breast MRI when used as an adjunct to mammography. The independency of the diagnostic accuracy of breast MRI from breast density makes it a worthwhile choice in mammographic BI-RADS 0 cases.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Among patients with peptic ulcer disease, the prevalence of Helicobacter pylori has been reported to range from 80% to 90%. Thus empirical cost-effective therapy has been suggested. We surveyed patients with peptic ulcer disease in Rochester, NY. From two teaching hospitals all patients who had duodenal ulcers (DU) and/or gastric ulcers (GU) on esophagogastroduodenoscopy (EGD) with antral biopsy for histology for H. pylori and for rapid urease (CLO) test were included in the study. We examined a total of 160 patients with DU and 145 patients with GU, age range 18-92 yr, obtaining clinical data, race, medication profile, and history of use of nonsteroidal antiinflammatory drugs (NSAIDs). An ulcer was defined if the lesion with loss of mucosal integrity was>or = 0.5 cm, with apparent depth. H. pylori was considered present if CLO test and/or histology were positive for H. pylori. To confirm the reliability of nonuse of NSAIDs, we randomly checked blood samples of 90 such patients from the ambulatory clinic for the presence of salicylates. To identify the sensitivity of the CLO test, we performed a serology test for H. pylori antibody in 100 subjects to compare the CLO test results. Also, 500 CLO test results were compared to the histology results for H. pylori. Among 160 DU patients, 16 were NSAID users with negative H. pylori and excluded from the prevalence study. Of the remaining 144 patients with DU, H. pylori was present in 88 patients (61%). When these data were analyzed according to race, H. pylori was present in 54 (52%) of 104 whites compared to 34 of 40 (85%) nonwhites (blacks, Hispanics, Asians) (p<0.01). Among 145 GU patients 18 were NSAID users with negative H. pylori and excluded from the prevalence analysis. Of the remaining 127 patients with GU, H. pylori was present in 87 patients (61%). Among them, H. pylori was present in 46 of 87 (53%) whites, whereas 31 of 40 nonwhites (78%) were H. pylori-positive (p<0.01). Antral histology and CLO test for H. pylori were in agreement in 92% of cases. Serology and CLO test for H. pylori were in agreement in 87% of cases. None of the randomly screened patients, including 16 ulcer patients with negative H. pylori, showed presence of salicylate in blood.\nQuestion: Prevalence of Helicobacter pylori in peptic ulcer patients in greater Rochester, NY: is empirical triple therapy justified?",
    "gt": "In greater Rochester, NY, where the majority of our patients with EGD were whites, the prevalence of H. pylori among ulcer patients was lower compared to other regions, particularly among whites. This suggests that an additional causative factor or factors for peptic ulcers may be present. Hence, empirical antibiotic therapy of ulcer patients without confirming the presence of H. pylori may not be justified.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The pain-relieving efficacy of antagonists of histamine 1 (H1) receptors that are widely found in the ureter and that cause contractions in renal colic was presented in comparison with a placebo. Eighty-six patients who presented to the emergency service because of renal colic accompanied by nausea, and who had urinary system stones detected were included in the study. The patients were separated into 2 groups by double-blind, random assignment. The 45 patients in group 1 received 50 mg intramuscular (IM) dimenhydrinate. The 41 patients in group 2 received 2 mL IM saline solution as a placebo. The visual analogous scale (VAS) values were detected at referral of the patients and at 10, 20, and 30 minutes of therapy to detect the pain intensity. Verbal descriptive scale (VDS) was used for evaluation of nausea and vomiting before and after the therapy. VAS values were statistically quite low in group 1 at 10, 20, and 30 minutes of therapy. VDS scores were also statistically significantly low in group 1 at 30 minutes of treatment.\nQuestion: Histamine 1 receptor antagonist in symptomatic treatment of renal colic accompanied by nausea: two birds with one stone?",
    "gt": "Dimenhydrinate, which is an ethanolamine group H1 receptor blocker, appeared to be effective compared with the placebo in relieving renal colic pain and nausea and vomiting symptoms in patients. Comparative studies with other analgesics will be useful for determining how to use this agent for analgesic purposes in renal colic.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Topical capsaicin application was shown to reduce infarct size in experimental animal models. We hypothesized that cardioprotective properties of topical capsaicin application could be related to its hypothermic effect. In the first arm of the study, anesthetized rats received capsaicin cream (Caps group) or vehicle (Control group, Ctrl) applied either 15 or 30 min prior to a 30-min coronary artery occlusion followed by 2-h reperfusion. Core body temperature was allowed to run its course, and was monitored via rectal probe. At the end of the protocol, hearts were excised and risk zone and infarct size were measured. In an additional set of animals, hearts were excised immediately after a 15-min application of capsaicin/vehicle, and were used to measure phosphorylated Akt and Erk1/2 with western blots. In the second arm of the study Ctrl (n = 6) and Caps-treated (n = 5) animals were subjected to the same protocol as rats in the first arm, but core body temperature was maintained at 36 °C. In the first arm of the study, capsaicin produced a rapid decrease in rectal temperature ranging from 0.22 to 1.78 °C at pre-occlusion, with a median level of 0.97 °C. A capsaicin-induced temperature decrease of>0.97 °C was associated with a 31.2 % smaller infarct compared to the control group. Capsaicin treatment induced an increase in the levels of phosphorylated Akt and Erk1/2 at the end of capsaicin cream application. No increase in the phosphorylation of downstream p70S6 was observed. Levels of phosphorylated Akt- and Erk1/2 did not correlate with temperature changes after treatment. In the second arm of the study, in which body core temperature was maintained at 36 °C, no change in the infarct size was observed in the capsaicin vs. control group.\nQuestion: Capsaicin-induced cardioprotection. Is hypothermia or the salvage kinase pathway involved?",
    "gt": "In the current study we for the first time demonstrated that the capsaicin induced cardioprotective effect might be related to mild hypothermia, caused by capsaicin topical application. The salvage kinase pathway appears not to be critical for capsaicin-induced cardioprotection.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Tracheal drug administration is a route for drug delivery during cardiopulmonary resuscitation when intravenous access is not immediately available. However, tracheal adrenaline (epinephrine) injection has been recently shown to be associated with detrimental decrease in blood pressure. This was attributed to exaggerated early beta2 mediated effects unopposed by alpha-adrenergic vasoconstriction. We hypothesized that endobronchial adrenaline administration is associated with better drug absorption, which may abolish the deleterious drop of blood pressure associated with tracheal drug administration. To determine haemodynamic variables after endobronchial adrenaline administration in a non-arrest canine model. Prospective, randomized, laboratory study. Adrenaline (0.02, 0.05, 0.1 mg/kg) diluted with normal saline was injected into the bronchial tree of five anaesthetized dogs. Injection of 10-ml saline served as control. Heart rate, blood pressure and arterial blood gases were monitored for 60 min after drug instillation. The protocol was repeated after 1 week. Adrenaline at a dose of 0.02 mg/kg produced only a minor initial decrease in diastolic (from 90 +/- 5 to 78 +/- 3 mmHg, P=0.05), and mean blood pressure (from 107 +/- 4 to 100 +/- 3 mmHg, P=0.05), in all dogs. This effect lasted less then 30 s following the drug administration. In contrast, higher adrenaline doses (0.05 and 0.1 mg/kg) produced an immediate increase in diastolic (from 90 +/- 5 to 120 +/- 7 mmHg; and from 90 +/- 5 to 170 +/- 6 mmHg, respectively), and mean blood pressure (from 107 +/- 4 to 155 +/- 10 mmHg; and from 107 +/- 4 to 219 +/- 6 mmHg, respectively). All adrenaline doses resulted in an immediate increase in systolic blood pressure and pulse. Endobronchial administration of saline (control) affected none of the haemodynamic variables.\nQuestion: Endobronchial adrenaline: should it be reconsidered?",
    "gt": "In a non-arrest model, endobronchial adrenaline administration, as opposed to the effect of tracheal adrenaline, produced only a minor decrease in diastolic and mean blood pressure. We suggest that endobronchial adrenaline administration should be investigated further in a CPR low-flow model when maintaining adequate diastolic pressure may be crucial for survival.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To compare the efficacy of Valsalva maneuver and pneumatic compression techniques in detecting lower extremity deep venous and saphenofemoral insufficiency. Eighty-one extremities evaluated in 43 patients who had undergone Doppler ultrasound examination of the lower extremity venous system were included in the study. Valsalva maneuver and pneumatic cuff techniques were used to elicit reflux in the standing position. Reflux was investigated with spectral Doppler in the superficial femoral vein, popliteal vein, the proximal segment of the great saphenous vein close to its junction with the femoral vein and in its caudal segment at the medial aspect of the knee. The same measurements were repeated after rapid deflation of the pneumatic cuff, which was applied to the calf and was initially inflated to 200 mmHg. Retrograde flow exceeding 1000 msec was regarded as insufficiency. The results of the two techniques at each venous segment were compared with the McNemar test. Deep venous and/or saphenofemoral insufficiency were detected in 61 of the 81 extremities. The cuff deflation technique was superior at the popliteal vein and caudal segment of the great saphenous vein. The Valsalva maneuver was superior at the superficial femoral vein. The statistical results did not change when the McNemar test was repeated for reflux exceeding 2000 msec.\nQuestion: Doppler ultrasound diagnosis of lower extremity deep vein insufficiency: Valsalva maneuver or pneumatic cuff?",
    "gt": "Combined application of Valsalva maneuver and pneumatic cuff techniques will lead to more accurate evaluation and increased detection of lower extremity venous insufficiency.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There is an expectation that interns can perform the core procedural skill of male catheterisation; however, it is unclear if our medical graduates are competent to do so, because there is no formal practical skills exit assessment in our current programme.AIM: We sought to investigate the level of experience, the self-reported confidence, and measured competency of our pre-intern (PRINT) students to perform the procedural skill of male catheterisation. We asked 100/147 (68%) PRINT students to complete a questionnaire to elucidate their experience and confidence prior to being practically assessed on a plastic manikin, using a faculty member validated 26-item checklist. Students were also invited to attend focus groups to help identify factors that had contributed to their practical performance. Between 2010 and 2012, 100/147 (68%) PRINT students completed a questionnaire prior to being formatively assessed. The mean score for self-reported confidence was 78.3/100 (95% CI 74.8-81.8), and the mean performance score was 85.6/100 (95% CI 83.2-87.9); however, the correlation coefficient between the confidence score and performance score was weak (r = 0.18). Three focus groups were conducted, with a total of 12/100 (12%) students attending. Although students reported that they had sound knowledge of the skill, the lack of opportunity to perform the skill in the clinical setting had led to mediocre performance outcomes.\nQuestion: Pre-interns: ready to perform?",
    "gt": "We found no significant correlation among the level of experience, the self-reported ability and actual performance when students were assessed under direct observation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine the proportion of patients who received a blood transfusion after joint replacement, and to devise a simple method to ensure patients were transfused based on strict clinical and haematological need. Prospective audit over 2 years. The study group was 151 patients who underwent total hip and knee arthroplasty in a typical district general hospital (Kettering) over a 2-year period. They were divided into three consecutive groups. Current practice was audited (producing the first group of 62 patients) and transfusion rates were compared to regional figures. Local guidelines were drawn up. A form was introduced on which the indications for any transfusion had to be documented prior to transfusion of the blood. This was designed to encourage transfusion only on strong clinical grounds or an haemoglobin (Hb) level<8 g/dl. Transfusion practice was then re-audited (producing the second group of 44 patients) to assess whether practice had improved. A year later, all relevant staff were reminded by letter of the guidelines. The process was then re-audited (producing the third group of 45 patients) again to determine whether practice remained improved or not. In the first audit (current practice) of 62 patients, the overall transfusion rate was 71%, with a higher rate in the hip replacement group (84%) ordered mainly by anaesthetic staff. Ward staff were reluctant not to transfuse patients whose Hb level fell below 10 g/dl. In the second audit, the transfusion rate fell by nearly 50% to 37%, with almost identical figures for knee and hip replacement. In the third audit of 45 patients, a year later, the transfusion rate was 40% overall.\nQuestion: Are we overusing blood transfusing after elective joint replacement?",
    "gt": "Patients were being transfused routinely, generally without good clinical evidence of benefit to the patient. The audit process was successful in instituting change for the better in blood transfusion practice for elective joint replacement. The improved practice can be largely maintained provided staff are regularly reminded of appropriate guidelines and encouraged to transfuse for clinical need only. For absolute adherence to guidelines, we would recommend a compulsory form system be introduced for transfusion in the per-operative period, to ensure blood transfusion is only given when absolutely necessary.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this study was to compare the distribution of virulence-associated genotypes of Helicobacter pylori in two Colombian populations with contrasting gastric cancer risk but with similar H. pylori infection prevalence. Gastric biopsies were taken from 241 subjects from the high gastric cancer risk area of Pasto and from 93 subjects from the low risk area of Tumaco. Four gastric biopsies from each patient were fixed in 10% buffered formalin for histopathologic analysis, and one was frozen immediately in liquid nitrogen and used for genotyping. CagA and vacA genotypes were determined by multiplex polymerase chain reaction and reverse hybridization on a line probe assay. In patients from the population with high risk for gastric cancer, statistically significant higher relative frequencies of cagA positive and vacA s1 and ml genotypes were found as compared to the population from the low risk area.\nQuestion: Virulence-associated genotypes of Helicobacter pylori: do they explain the African enigma?",
    "gt": "Although H. pylori infection has been recognized as a cause of gastric cancer in humans, some large populations with high prevalence of infection have low gastric cancer rates. This so-called \"African enigma\" so far remains unexplained. Our findings suggest that virulence-associated genes of H. pylori may partially explain the African enigma. Other factors, including human genetic polymorphisms and diet, are also suspected to play a major role. Further investigations are needed to test this hypothesis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It is unclear if disparities described in diabetes primary care extend to subspecialty diabetes care. This retrospective observational study examined disparities in diabetes outcomes in a subspecialty practice by assessing glycemic improvement in type 2 diabetes patients during the first year of enrollment. Electronic data were gathered on 3,945 subjects. The outcome was the proportion of white and minority (Asian, black, and Hispanic) subjects achieving a hemoglobin A1C (A1C) level of ≤7% after the first year of care. Logistic regression was used to identify factors associated with odds of achieving A1C ≤7%. Minority patients had greater diabetes duration, more social disadvantages and missed appointments, and worse control at presentation than whites. The proportion of patients reaching target A1C rose from 37 to 52% among white patients and from 28 to 40% among minority patients. Significant differences between whites and minorities in the rates of patients reaching A1C ≤7% were found only among those with higher initial A1C (iA1C) levels (32% vs. 20.9%; P = .002 in third iA1C quartile, and 28.2% vs. 17.9%; P = .0003 in fourth iA1C quartile). The interaction between race/ethnicity and the top two iA1C quartiles remained significant in the fully adjusted model.\nQuestion: Do ethnic disparities extend to subspecialty diabetes care?",
    "gt": "Reaching an A1C level of ≤7% depends strongly upon the glycemic level at initial presentation to specialty care, not race. However, minority patients with the highest baseline A1C levels do not improve to the same degree as white patients, and therefore should be targeted for more intensive diabetes care management.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: to investigate whether patients with lichen planus (LP) are really prone to urolithiasis or not. We performed a prospective analysis of 40 patients diagnosed with lichen planus (LP) (group I), and 40 volunteers did not have LP before (group II). Participants were all checked for urolithiasis by radiological investigations. Blood samples were analyzed for biochemistry parameters including calcium and uric acid. 24-h urine samples were analyzed to investigate oxalate, citrate calcium, uric acid, magnesium, sodium and creatinine. Men/women ratio and mean age were similar between group I and II (p>0.05). A presence or history of urolithiasis was detected in 8 (20%) and 2 (%5) patients in group I and II, respectively (p<0.05). Hypocitraturia was the most common anomaly with 35% (n:14) in group I. The rate of hypocitraturia in group II was 12.5% (n:5) and the difference was statistically significantly different (p=0.036). In group I, hyperuricosuria and hyperoxaluria followed with rates of 27.5% (n:11) and 25% (n:10), respectively. The rate of hyperuricosuria and hyperoxaluria were both 5% (n:2) in group II and the differences were significant (p<0.05). Hyperuricemia was another importante finding in the patients with LP. It was detected in 13 (32.5%) patients in group I and in 1 (2.5%) participant in group II (p=0.001).\nQuestion: Are patients with lichen planus really prone to urolithiasis?",
    "gt": "According to our results, metabolic disorders of urolithiasis were highly detected in the patients with LP. However, similar to the etiology of LP, the exact reasons for these metabolic abnormalities in LP remain a mystery.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Breast cancer is characterized by hormone dependency, and endocrine therapy is a key treatment in breast cancer. Recently, targeted therapies such as Trastuzumab treatment for HER2-positive breast cancer has been important. Triple-negative (TN) breast cancer is characterized by lack of expression of estrogen receptor (ER) and progesterone receptor (PgR), and the absence of HER2 protein overexpression, and so there is no targeted therapy for this subtype. In this study, we examined the biological and prognostic characteristics in TN breast cancer. Between January 1998 and September 2006, 1,552 patients with primary breast cancer were investigated retrospectively in this study and ER, PgR and HER2 status were evaluated in all cases. Furthermore, p53 overexpression and Ki67 values were examined immunohistochemically. Patient distribution according to ER, PgR or HER2 status was as follows: ER and PgR positive: 57.9%, and ER and PgR negative: 25.1%. With regards to the HER2 status, HER2 positive was 23.3%, and triple negative (TN) was 14.0%. TN breast cancer has a high proliferation rate, high nuclear grade and frequent p53 overexpression. Patients with TN tumors had a significantly poorer disease-free survival (DFS) than those with non-TN tumors. After recurrence the overall survival (OS) rate in TN cases was significantly lower than that of the non-TN cases. Multivariate analysis revealed that TN was a significant factor for DFS and OS after recurrence.\nQuestion: Is triple negative a prognostic factor in breast cancer?",
    "gt": "TN breast cancer is a rare subtype with a high proliferation rate and a high nuclear grade, p53 overexpression, and lower DFS/OS. To improve the prognosis of TN breast cancer, a new effective strategy needs to be developed.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To perform a frequency analysis of start minute digits (SMD) and end minute digits (EMD) taken from the electronic, computer-assisted, and manual anesthesia billing-record systems. Retrospective cross-sectional review. University medical center. This cross-sectional review was conducted on billing records from a single healthcare institution over a 15-month period. A total of 30,738 cases were analyzed. For each record, the start time and end time were recorded. Distributions of SMD and EMD were tested against the null hypothesis of a frequency distribution equivalently spread between zero and nine. SMD and EMD aggregate distributions each differed from equivalency (P<0.0001). When stratified by type of anesthetic record, no differences were found between the recorded and expected equivalent distribution patterns for electronic anesthesia records for start minute (P<0.98) or end minute (P<0.55). Manual and computer-assisted records maintained nonequivalent distribution patterns for SMD and EMD (P<0.0001 for each comparison). Comparison of cumulative distributions between SMD and EMD distributions suggested a significant difference between the two patterns (P<0.0001).\nQuestion: Are anesthesia start and end times randomly distributed?",
    "gt": "An electronic anesthesia record system, with automated time capture of events verified by the user, produces a more unified distribution of billing times than do more traditional methods of entering billing times.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Elastic nailing is a common method of fixation for tibial shaft fractures in skeletally immature individuals. Poor outcomes of titanium elastic nails for femoral shaft fractures have been associated with increasing patient age and weight, especially patients weighing>50 kg. Our objective is to determine if there is an upper weight or age limit to the safe and effective use of titanium elastic nails for tibial shaft fractures in the pediatric population. This is a retrospective cohort study of patients who underwent stabilization of a tibial shaft fracture with titanium elastic nails at a large tertiary-care pediatric trauma center. Data collected included patient demographics, injury characteristics, and radiographic data. Weight groups were stratified as ≥ or<50 kg, and age groups as 14 years or older or less than 14 years old. Malunion was defined as 10 degrees of angulation in either the sagittal or coronal plane. Union was defined as bridging of ≥3 cortices on orthogonal radiographs. A significant difference in time to union was considered to be 3 weeks. Ninety-five patients were included with a mean age of 12.1 years (range, 6 to 16 y) and a mean weight of 50.2 kg (range, 21 to 122 kg). Malunion rate was similar between weight cohorts: 13.3% (6/45) in the ≥50-kg group and 10% (5/50) in the<50-kg group (P=0.61). Malunion rate was similarly comparable between age groups: 17.6% (6/34) in the 14 years and older group and 8.2% (5/61) in the less than 14-year-old group (P=0.17). There was no statistically significant difference in time to union between weight or age cohorts. In sum, we did not find a significant difference in the rate of malunion or time to healing between younger and older patients or between lighter and heavier patients.\nQuestion: Titanium Elastic Nailing for Pediatric Tibia Fractures: Do Older, Heavier Kids Do Worse?",
    "gt": "The use of titanium elastic nails for tibial shaft fractures, unlike for other long bone fractures, seems not to be precluded in older and heavier patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Feedback from multiple-choice question (MCQ) assessments is typically limited to a percentage correct score, from which estimates of student competence are inferred. The students' confidence in their answers and the potential impact of incorrect answers on clinical care are seldom recorded. Our purpose was to evaluate student confidence in incorrect responses and to establish how confidence was influenced by the potential clinical impact of answers, question type and gender. This was an exploratory, cross-sectional study conducted using a convenience sample of 104 Year 3 dental students completing 20 MCQs on implant dentistry. Students were asked to select the most correct response and to indicate their confidence in it for each question. Identifying both correctness and confidence allowed the designation of uninformed (incorrect and not confident) or misinformed (incorrect but confident) responses. In addition to recording correct/incorrect responses and student confidence, faculty staff designated incorrect responses as benign, inappropriate or potentially harmful if applied to clinical care. Question type was identified as factual or complex. Logistic regression was used to evaluate relationships between student confidence, and question type and gender. Students were misinformed more often than uninformed (22% versus 8%), and misinformed responses were more common with complex than factual questions (p < 0.05). Students were significantly more likely to be confident of correct than incorrect benign, incorrect inappropriate or incorrect harmful answers (p < 0.001), but, contrary to expectations, confidence did not decrease as answers became more harmful.\nQuestion: Does student confidence on multiple-choice question assessments provide useful information?",
    "gt": "Recording student confidence was helpful in identifying uninformed versus misinformed responses, which may allow for targeted remediation strategies. Making errors of calibration (confidence and accuracy) more visible may be relevant in feedback for professional development.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There is increased risk for the occurrence of deep venous thrombosis (DVT) and renovascular thrombosis after kidney transplantation. A disruption of the blood homeostasis caused by surgery and leading to clotting and bleeding malfunctions is widely accepted. However, other causes such as inherited or acquired disorders of the clotting system may further increase the risk of thrombosis. Here, we summarize and review data on possible causes, incidence and ways to prevent the occurrence of DVT and/or renovascular thrombosis after kidney transplantation. The incidence of DVT after kidney transplantation is 6.2-8.3% and approximately 25% of these patients suffer from pulmonary embolism. The DVT occurs primarily on the side of the transplant with an increased risk throughout the first 5 months after transplantation. Thereby, 2-12% of the patients develop renovascular thromboses, most of which are related directly to the surgery. However, inherited or acquired thrombophilia may also play an important role. A severe course is known for prothrombin gene G20210A polymorphism, which can result in graft loss. A great diversity of prophylactic treatments is available but adjustment to the underlying circumstances is crucial for a favourable outcome. Low-dose heparin prophylaxis for at least 2-3 weeks can be used as standard therapy to prevent the occurrence of DVT after kidney transplantation. However, this may not be sufficient for concurrent disorders of the blood homeostasis such as elevated levels of antiphospholipid antibodies, lupus anticoagulant, prothrombin gene G20210A polymorphism or a combined inherited thrombophilia. These patients may need a prophylactic anticoagulation with coumarins starting prior to transplantation and being continued for at least 1 year or even lifelong. Only randomized trials can answer the question concerning optimal duration and safety of coumarins in this setting.\nQuestion: Do we need screening for thrombophilia prior to kidney transplantation?",
    "gt": "DVT and/or renovascular thromboses are severe complications after kidney transplantation. Inherited and acquired thrombophilia, apart from surgery and abnormal anatomy itself, have to be considered and proper prophylactic treatment initiated.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: lt is estimated that epilepsy affects approximately 50 million people worldwide and about 40 million of them live in developing countries. Studies have indicated high rates of poor knowledge, negative attitude and poor first aid management skills of students with epilepsy among practicing teachers. However, there is paucity of such studies on trainee teachers to ascertain any similarities or differences (if any) and the effect of educational interventions. To determine the effect of a health education intervention on trainee teachers' knowledge, attitude and first aid management of epilepsy. The effect of a health education intervention in first aid management of epilepsy was assessed among 226 trainee teachers, attending the Federal College of Education (Technical), Akoka. This was done using a quasi-experimental study design. Data were analyzed using the SPSS version 15. The respondents had a median age of 22 years with a range of 18 to 56 years. The majority of them were females (68.6%), single (79.2%), Christians (81.9%), Yoruba (70.4%) and in first year (100 level) of their study (69.9%). The highest proportion was from the Accounting department (46.0%). A consistent increase in responses to items on knowledge, attitude and first aid management of epileptic seizure items from baseline to post-intervention was observed. For instance, the proportion of responses that epileptic seizures originate from the brain significantly (p = 0.025) increased from 62.5% at baseline to 74.1% after intervention. Generally, slightly more than two-fifths (44.2%) and about two thirds (61.9%) of the respondents were observed to have poor knowledge and negative attitude to epilepsy respectively at baseline. Overall, giving health education on epilepsy led to a reduction in the proportion of respondents with poor knowledge by 15.5% (increase of good knowledge by 29.6%), decrease of negative attitude by 16.4% and increase of good first aid management skill by 25.0%. The knowledge scores were significantly associated with age (p = 0.001), marital status (p = 0.003) and department (p = 0.004) while the attitude scores were significantly associated with teaching duration (p = 0.020). The knowledge was predicted by department (p = 0.001) while the attitude was predicted by teaching duration (p = 0.036).\nQuestion: Improving First Aid Management of Epilepsy by Trainee Teachers of the Federal College of Education (Technical), Akoka - Lagos, South West Nigeria--Can Health Education have an Effect?",
    "gt": "This study reveals that health education could improve the knowledge, attitude. and first aid management of students with epilepsy among trainee teachers. It is therefore proposed that an intervention programme on baseline knowledge of epilepsy and its first aid management be incorporated into the teacher-training curriculum, particularly those in health-related programmes, to address their deficiencies in knowledge, attitude and first aid management of students with epilepsy.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Vasopressors are recommended for cardiopulmonary resuscitation (CPR) after cardiac arrest. In order to assess possible benefits regarding neurological recovery, vasopressin versus adrenaline and the combination of both was tested against placebo in a cardiac arrest model in rats. Under anaesthesia with halothane and N2O, cardiac arrest was initiated via transoesophageal electrical fibrillation. After 7 min of global ischaemia, CPR was performed by external chest compression combined with defibrillation. Animals were randomly assigned to three groups receiving adrenaline, vasopressin and a combination of both (n = 15 per group) versus placebo (n = 8). At 1, 3 and 7 days animals were tested according to a neurological deficit score (NDS). After 7 days of reperfusion, coronal brain sections were analysed by Nissl- and TUNEL-staining. Viable as well as TUNEL-positive neurons were counted in the hippocampal CA-1 sector. For statistical analysis, the log rank and the Kruskal-Wallis ANOVA test were used. All data are given as mean+/-S.D.; a p-value<0.05 was considered significant. Mean arterial blood pressure (MAP) measured in the aorta did not differ between the vasopressor groups, whereas placebo animals had significantly lower levels. Survival to 7 days revealed significant differences between the placebo (n = 0/8) and all vasopressor groups (adrenaline, 10/15; adrenaline/vasopressin, 8/15; vasopressin, 12/15). Histological deficit scoring by quantitative analysis of the Nissl- and TUNEL-staining showed no difference in the amount of viable and apoptotic neurons in the vasopressin group (viable: 33+/-18; apoptotic: 63+/-23) versus the adrenaline group (viable: 21+/-12; apoptotic: 67+/-17) and the adrenaline/vasopressin group (viable: 31+/-26; apoptotic: 61+/-27). Neurological deficit scoring did not show any differences between the vasopressor groups.\nQuestion: Vasopressors are essential during cardiopulmonary resuscitation in rats: Is vasopressin superior to adrenaline?",
    "gt": "Administration of arginine-vasopressin during CPR does not improve behavioural and cerebral histopathological outcome, compared to the use of adrenaline or the combination of both vasopressors, after cardiac arrest in rats.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of the study was to investigate whether changes in the level of oxidized LDL (oxLDL) over 2-years contribute to the development of subclinical macroangiopathy and/or microvascular complications in patients with DM1. Basic clinical and biochemical parameters and oxLDL level were measured in 70 patients at baseline and after 2 years of the study. In addition, an ultrasonographic study was performed to assess the carotid intima media thickness (IMT). Patients did not differ according to basic clinical and biochemical parameters at the beginning and after 2 years of the study. IMT increased (p=0.000001) whereas oxLDL level decreased (p=0.00001) in DM1 patients during 2 years. Multivariate regression analysis showed that oxLDL independently influences IMT in DM1 patients (β=0.454, R2=0.35). Further, positive correlations between oxLDL value and LDL-C concentration (r=0.585, p<0.05, n=70) and between oxLDL level and apo-B concentration have been established (r=0.610, p<0.05, n=70). Moreover, patients with chronic microvascular complications showed a higher value of IMT in comparison with patients without them (p=0.003).\nQuestion: Does oxidized LDL contribute to atherosclerotic plaque formation and microvascular complications in patients with type 1 diabetes?",
    "gt": "Our results provide the evidence that oxLDL accelerates atherosclerotic plaque formation and may contribute to the development of microvascular complications in DM1.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To examine for evidence of clustering in time, in space and in space/time in the occurrence of rheumatoid arthritis (RA). A population-based incidence register of RA in the East Anglian region of the UK: population size 413,000. In all 687 new cases of inflammatory joint disease registered between 1 January 1990 and 31 December 1994 were studied. Population data were obtained from postcode areas by age and sex. Time trend analysis was conducted over the first 36 months and observed and expected distributions compared. Spatial clustering was based on comparison of observed distribution using map grid references to random expectation based on simulation. A similar procedure was undertaken for time/space clustering. There was no evidence of a time trend. There was only modest evidence of spatial clustering with non-random distribution observed in one area but there was no evidence of time/space clustering.\nQuestion: Do new cases of rheumatoid arthritis cluster in time or in space?",
    "gt": "Although a viral aetiology is the strongest candidate for RA, no evidence of a localized event in time was associated with disease development in this population.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To analyze the impact of surgeon's experience on surgical margin status, postoperative continence and operative time after radical prostatectomy (RP) in a surgeon who performed more than 2000 open RP. We retrospectively analyzed 2269 patients who underwent RP by one surgeon from April 2004 to June 2012. Multivariable logistic models were used to quantify the impact of surgeon's experience (measured by the number of prior performed RP) on surgical margin status, postoperative continence and operative time. Negative surgical margin rate was 86 % for patients with pT2 stage, and continence rate at 3 years after RP was 94 %. Patients with negative surgical margin had lower preoperative PSA level (p = 0.02), lower pT stage (p<0.001) and lower Gleason score (p<0.001). The influence of the experience of the surgeon was nonlinear, positive and highly significant up to 750 performed surgeries (75-90 % negative surgical margin) (p<0.01). The probability of continence rises significantly with surgeon's experience (from 88-96 %) (p<0.05). A reduction in operative time (90-65 min) per RP was observed up to 1000 RP.\nQuestion: Surgical learning curve for open radical prostatectomy: Is there an end to the learning curve?",
    "gt": "In the present study, we showed evidence that surgeon's experience has a strong positive impact on pathologic and functional outcomes as well as on operative time. While significant learning effects concerning positive surgical margin rate and preserved long-term continence were detectable during the first 750 and 300 procedures, respectively, improvement in operative time was detectable up to a threshold of almost 1000 RP and hence is relevant even for very high-volume surgeons.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Poor sleep may be associated with the cardiovascular disease (CVD) morbidity and mortality. It is less clear if poor sleep is associated with subclinical CVD. We evaluated cross-sectional associations between self-reported sleep disturbance and duration and calcification in the coronary arteries (CAC) and aorta (AC) in healthy mid-life women. 512 black and white women enrolled in the SWAN Heart Study, underwent a computed tomography protocol for measurement of CAC and AC and completed questionnaires about their sleep. Linear and partial proportional logit regression analyses adjusted for site, race, age, body mass index, and the Framingham risk score (model 1). Additional covariates of education, perceived health, hypnotic medication and alcohol use were evaluated (model 2), plus depressive symptoms (model 3). AC was related to higher levels of trouble falling asleep, waking earlier than planned, overall poor sleep quality, and cough/snoring and shorter sleep duration in linear regression analyses (model 1). Adjustments for additional covariates showed that poor sleep quality and waking earlier than planned remained associated with higher AC (models 2 and 3). CAC was unrelated to sleep characteristics.\nQuestion: Do reports of sleep disturbance relate to coronary and aortic calcification in healthy middle-aged women?",
    "gt": "Poor sleep quality is related to AC in middle-aged women. Sleep quality should routinely be assessed in mid-life women.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A substantial proportion of patients with clinical stage I non-small cell lung cancer (NSCLC) have more advanced disease on final pathologic review. We studied potentially modifiable factors that may predict pathologic upstaging. Data of patients with clinical stage I NSCLC undergoing resection were obtained from the National Cancer Database. Univariate and multivariate analyses were performed to identify variables that predict upstaging. From 1998 to 2010, 55,653 patients with clinical stage I NSCLC underwent resection; of these, 9,530 (17%) had more advanced disease on final pathologic review. Of the 9,530 upstaged patients, 27% had T3 or T4 tumors, 74% had positive lymph nodes (n>0), and 4% were found to have metastatic disease (M1). Patients with larger tumors (38 mm vs 29 mm, p<0.001) and a delay greater than 8 weeks from diagnosis to resection were more likely to be upstaged. Upstaged patients also had more lymph nodes examined (10.9 vs 8.2, p<0.001) and were more likely to have positive resection margins (10% vs 2%, p<0.001). Median survival was lower in upstaged patients (39 months vs 73 months). Predictors of upstaging in multivariate regression analysis included larger tumor size, delay in resection greater 8 weeks, positive resection margins, and number of lymph nodes examined. There was a linear relationship between the number of lymph nodes examined and the odds of upstaging (1 to 3 nodes, odds ratio [OR] 2.01;>18 nodes OR 6.14).\nQuestion: Pathologic Upstaging in Patients Undergoing Resection for Stage I Non-Small Cell Lung Cancer: Are There Modifiable Predictors?",
    "gt": "Pathologic upstaging is a common finding with implications for treatment and outcomes in clinical stage I NSCLC. A thorough analysis of regional lymph nodes is critical to identify patients with more advanced disease.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The actual gold standard of Botulin A toxin (BoTx A) batches qualification is the mouse lethality assay. With this assay it is nevertheless impossible to set a therapeutic value unit. The goal of this research was to study the effects of BoTx A increasing concentrations on glutamatergic rat neurons. We studied the glutamate release with increasing concentrations of BoTx A. We also studied the BoTx A target cleavage with a western blot technique. Our results proved that it is possible to establish a dose-response - like curve of BoTx A effects on glutamate release. Moreover the cleavage of the target protein was visible for the same toxin concentrations that inhibited the glutamate release.\nQuestion: Measurement of botulinum toxin activity: towards a new cellular culture assay?",
    "gt": "This technique could be the first step toward a new way of setting a better pharmaceutical profile for toxin batches.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To investigate whether the 'inverse care law' applies to New South Wales (NSW) hospital admissions--especially to older people with high socio-economic status (SES). Cross-sectional study analysing inequalities in public and private hospital admission rates by SES, defined in terms of age, sex and family income/size at the small geographic area level. Admissions to NSW public and private hospitals in 1999-2000 (1.8 million admissions against a NSW population of 6.4 million). Inequalities in hospitalisation rates were expressed as rate ratios across the most and least disadvantaged 20% of the NSW population. Public hospital admission rates for people aged 0-60 years were 24-35% higher for the most disadvantaged 20% of the NSW population than for the least disadvantaged 20%. For 70+ year-olds the direction of this difference was reversed--being 14% lower for the most disadvantaged 20% of the population (5% higher for public patients). For private hospitals this reversal prevailed for all age groups (23-49% lower). For all hospitals it was 16% and 27% lower for 60-69 and 70+ year-olds respectively, with higher admission rates for top SES 60+ year-olds most pronounced for renal dialysis, chemotherapy, colonoscopies and other diagnostic scopes, rehabilitation and follow-up, and cataract operations.\nQuestion: Hospital admissions by socio-economic status: does the 'inverse care law' apply to older Australians?",
    "gt": "While the 'inverse care law' did apply to 60+ year-olds, it did not apply either to younger NSW hospital users or to public patients in public hospitals.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Our study aimed at defining the role of tamsulosin as adjunctive therapy after extracorporeal shock wave lithotripsy (ESWL) in patients with stones in the kidney and ureter. A placebo-controlled, randomized, double-blind clinical trial prospectively performed between February 2008 and September 2009 on 150 patients with 4-20 mm in diameter renal and ureteral stones referred to our ESWL center. After ESWL, all patients randomly assigned to two groups (placebo and tamsulosin). The drugs administration was started immediately after ESWL and was continued for a maximum of 30 days. From 150 patients, 71 in control group and 70 in case group completed the study. Of 71 patients (60.56%) in control group, 43 patients became stone free; and other patients (39.44%) did not succeed in stone expulsion during 12 weeks after ESWL. In case group of 70 patients (71.4%), 50 patients became stone free. Time of stone passage in most of the patients happened between 20th and 30th day in control group (32.6%) and between 10th and 20th day (50%) in case group after ESWL. There is no statistically significant difference between stone passage in two groups (p = 0.116) and location of stone (p = 0.114), but there is statistically significant difference in time of stone passage from onset of treatment in case and control groups (p = 0.002).\nQuestion: Is there a role for tamsulosin after shock wave lithotripsy in the treatment of renal and ureteral calculi?",
    "gt": "At last, this study suggested that tamsulosin facilitate earlier clearance of fragments after ESWL.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: While a considerable body of research has explored the relationship between patient expectations and clinical outcomes, few studies investigate the extent to which patient expectations change over time. Further, the temporal relationship between expectations and symptoms is not well researched. We conducted a latent class growth analysis on patients (n = 874) with back pain. Patients were categorised in latent profile clusters according to the course of their expectations over 3 months. Nearly 80% of participants showed a pattern of stable expectation levels, these patients had either high, medium or low levels of expectations for the whole study period. While baseline levels of symptom severity did not discriminate between the three clusters, those in the groups with higher expectations experienced better outcome at 3 months. Approximately 15% of patients showed decrease in expectation levels over the study period and the remainder were categorised in a group with increasingly positive expectations. In the former clusters, decrease in expectations appeared to be concordant with a plateau in symptom improvement, and in the latter, increase in expectations occurred alongside an increase in symptom improvement rate.\nQuestion: Do recovery expectations change over time?",
    "gt": "The expectations of most people presenting to primary care with low back pain do not change over the first 3 months of their condition. People with very positive, stable expectations generally experience a good outcome. While we attempted to identify a causal influence of expectations on symptom severity, or vice versa, we were unable to demonstrate either conclusively.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It is unknown whether physical activity during pregnancy (PA) has long-term impact on the metabolic profile of the offspring. We investigated associations of PA with markers of the metabolic syndrome (MS) in 20y old offspring. Longitudinal study where 965 pregnant women during 1988-1989 had four dimensions of PA assessed by questionnaires in gestation week 30: PA at work; leisure time PA, daily amount of walking-biking and sport participation. The following MS markers were assessed in the offspring (n=439): body mass index (BMI), waist circumference, blood pressure, homeostasis model assessment insulin resistance as well as fasting plasma glucose, triglycerides, cholesterol (high-density lipoprotein (HDL), low-density lipoprotein and total cholesterol), insulin and leptin levels. Walking-biking PA in pregnancy is associated with unchanged or subtle, adverse changes of distinct MS markers among offspring including lower levels of HDL cholesterol (ratio 0.95 (95% CI 0.92 to 0.98) per 1 h increment in walking-biking), a higher diastolic blood pressure (difference 1.12 (95% CI 0.03 to 2.20) mm Hg/1 h increment) and a higher BMI (ratio 1.03 (95% CI 1.01 to 1.05) per 1 h increment). In separate analyses in males, these associations persisted and additional adverse associations were found for triglycerides, systolic blood pressure, waist circumference and leptin. No associations were detected with other measures of PA.\nQuestion: Does physical activity during pregnancy adversely influence markers of the metabolic syndrome in adult offspring?",
    "gt": "The study did not substantiate any protective effects of PA in pregnancy. In contrast, data suggested that high amounts of daily walking-biking in pregnancy may have adverse effects on levels of HDL cholesterol, diastolic blood pressure and BMI in young adult offspring.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Recent studies reported lower quality of care for black vs. white patients with community-acquired pneumonia and suggested that disparities persist at the individual hospital level. We examined racial differences in emergency department and intensive care unit care processes to determine whether differences persist after adjusting for case-mix and variation in care across hospitals. Prospective, observational cohort study. Twenty-eight U.S. hospitals. Patients with community-acquired pneumonia: 1738 white and 352 black patients. None. We compared care quality based on antibiotic receipt within 4 hrs and adherence to American Thoracic Society antibiotic guidelines, and intensity based on intensive care unit admission and mechanical ventilation use. Using random effects and generalized estimating equations models, we adjusted for case-mix and clustering of racial groups within hospitals and estimated odds ratios for differences in care within and across hospitals. Black patients were less likely to receive antibiotics within 4 hrs (odds ratio, 0.55; 95% confidence interval, 0.43-0.70; p<.001) and less likely to receive guideline-adherent antibiotics (odds ratio, 0.72; 95% confidence interval, 0.57-0.91; p = .006). These differences were attenuated after adjusting for casemix (odds ratio, 0.59; 95% confidence interval; 0.46-0.76 and 0.84; 95% confidence interval, 0.66 -1.09). Within hospitals, black and white patients received similar care quality (odds ratio, 1; 95% confidence interval, 0.97-1.04 and 1; 95% confidence interval, 0.97-1.03). However, hospitals that served a greater proportion of black patients were less likely to provide timely antibiotics (odds ratio, 0.84; 95% confidence interval, 0.78-0.90). Black patients were more likely to receive mechanical ventilation (odds ratio, 1.57; 95% confidence interval, 1.02-2.42; p = .042). Again, within hospitals, black and white subjects were equally likely to receive mechanical ventilation (odds ratio, 1; 95% confidence interval, .94-1.06) and hospitals that served a greater proportion of black patients were more likely to institute mechanical ventilation (odds ratio, 1.13; 95% confidence interval, 1.02-1.25).\nQuestion: Do hospitals provide lower quality of care to black patients for pneumonia?",
    "gt": "Black patients appear to receive lower quality and higher intensity of care in crude analyses. However, these differences were explained by different case-mix and variation in care across hospitals. Within the same hospital, no racial differences in care were observed.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this paper is to determine the possible association between five different profiles of immunohistochemical expression related to clinical, histopathological and immunohistochemical known prognostic value variables for breast cancer. A total of 194 breast carcinoma tumour samples were studied. In this study five groups or immunohistochemical profiles were defined, based on expression of hormone receptors (oestrogen or progesterone) and/or Her2/neu (luminal-type A, luminal-type B, mixed profile, Her2/neu profile and triple-negative-type profile) and we studied whether there are differences between them with regard to clinical, histopathological and immunohistochemical variables that have a known prognostic significance. In the series we found 134 (69%) cases corresponding to a luminal immunophenotype, of which 98 (50.5%) were from the luminal A group and 36 (18.6%) from luminal B. Twenty-nine cases (15.9%) were triple-negative, 18 (9.3%) mixed and 13 (6.7%) Her2/neu type. It is worth noting the relationship between the triple-negative and Her2/neu immunophenotypes and the more poorly differentiated histological forms (62% and 60%, respectively) and between the luminal A group and well-differentiated tumours (p = 0.008). Expression of ki67 was high in the triple-negative group (73.9%) and low in the luminal A group (26.3%; p = 0.001). The expression of p53 was also greater for the Her2/neu (55.5%) and triple-negative (60.8%) groups (p = 0.0005) than for the others.\nQuestion: Immunohistochemical characterisation of breast cancer: towards a new clasification?",
    "gt": "The subgroups without hormone receptor expression, with Her2/neu overexpression or without (triple-negative group), have characteristics associated with variables of a poorer prognosis. The lack of progesterone receptor expression also seems to be associated with these.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Data shows vanadium protects pancreatic beta cells (BC) from diabetic animals. Whether this effect is direct or through the relief of glucose toxicity is not clear. This study evaluated the potential effect of oral vanadyl sulfate (vanadium) on glycemic status and pancreatic BC of normal and diabetic rats. Rats were divided into five groups of normal and diabetic. Diabetes was induced with streptozocin (40 mg/kg, i.v.). Normal rats used water (CN) or vanadium (1 mg/ml VOSO4, VTN). Diabetic rats used water (CD), water plus daily neutral protamine Hagedorn insulin injection (80 U/kg, ITD) or vanadium (VTD). Blood samples were taken for blood glucose (BG, mg/dL) and insulin (ng/dL) measurements. After two months, the pancreata of sacrificed rats were prepared for islet staining. Pre-treated normal BG was 88 ± 2, and diabetic BG was 395 ± 9. The final BG in CD, VTD, and ITD was 509 ± 22, 138 ± 14, and 141 ± 14, respectively. Insulin in VTN (0.75 ± 0.01) and VTD (0.78 ± 0.01) was similar, higher than CD (0.51 ± 0.07) but lower than CN (2.51 ± 0.02). VTN islets compared to CN had larger size and denser central core insulin immunoreactivity with plentiful BC. CD and ITD islets were atrophied and had scattered insulin immunoreactivity spots and low BC mass. VTD islets were almost similar to CN.\nQuestion: Does the relief of glucose toxicity act as a mediator in proliferative actions of vanadium on pancreatic islet beta cells in streptozocin diabetic rats?",
    "gt": "Besides insulin-like activity, vanadium protected pancreatic islet BC, and the relief of glucose toxicity happening with vanadium had a little role in this action.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: At depths below 10 m, reefs are dominated by blue-green light because seawater selectively absorbs the longer, 'red' wavelengths beyond 600 nm from the downwelling sunlight. Consequently, the visual pigments of many reef fish are matched to shorter wavelengths, which are transmitted better by water. Combining the typically poor long-wavelength sensitivity of fish eyes with the presumed lack of ambient red light, red light is currently considered irrelevant for reef fish. However, previous studies ignore the fact that several marine organisms, including deep sea fish, produce their own red luminescence and are capable of seeing it. We here report that at least 32 reef fishes from 16 genera and 5 families show pronounced red fluorescence under natural, daytime conditions at depths where downwelling red light is virtually absent. Fluorescence was confirmed by extensive spectrometry in the laboratory. In most cases peak emission was around 600 nm and fluorescence was associated with guanine crystals, which thus far were known for their light reflecting properties only. Our data indicate that red fluorescence may function in a context of intraspecific communication. Fluorescence patterns were typically associated with the eyes or the head, varying substantially even between species of the same genus. Moreover red fluorescence was particularly strong in fins that are involved in intraspecific signalling. Finally, microspectrometry in one fluorescent goby, Eviota pellucida, showed a long-wave sensitivity that overlapped with its own red fluorescence, indicating that this species is capable of seeing its own fluorescence.\nQuestion: Red fluorescence in reef fish: a novel signalling mechanism?",
    "gt": "We show that red fluorescence is widespread among marine fishes. Many features indicate that it is used as a private communication mechanism in small, benthic, pair- or group-living fishes. Many of these species show quite cryptic colouration in other parts of the visible spectrum. High inter-specific variation in red fluorescence and its association with structures used in intra-specific signalling further corroborate this view. Our findings challenge the notion that red light is of no importance to marine fish, calling for a reassessment of its role in fish visual ecology in subsurface marine environments.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Late-life depression is associated with increased subcortical white matter hyperintensities. There is some evidence that they are associated with a poorer response to acute treatment. Neurological signs and neuropsychological dysfunction are further evidence of abnormalities in the brain, but they have not been studied in relation to therapy resistance. A prospective study of 24 normal controls and 75 consecutive elderly (aged 65 to 85) patients with DSM-III-R major depression entered a naturalistic study of treatment. Assessment of response to monotherapy and then lithium augmentation or ECT created three outcome groups. Investigations included magnetic resonance brain imaging, neuropsychological and neurological examination. Response to monotherapy within 12 weeks was shown by 42.7%, a further 37.3% responded to lithium augmentation or ECT within 24 weeks and 20% had responded poorly to all treatments at 24 weeks. Subcortical hyperintensities were significantly increased in the more resistant patients. These included confluent deep white matter, multiple (>5) basal ganglia lesions and pontine reticular formation lesions. Most of the neuropsychological impairment was restricted to the resistant groups and was of a subcortico-frontal type. Extrapyramidal, frontal and pyramidal neurological signs characterized the resistant groups. The combination of extrapyramidal signs, pyramidal tract signs and impairment of motor hand sequencing strongly predicted resistance to 12 weeks of antidepressant monotherapy with 89% sensitivity and 95% specificity.\nQuestion: Is subcortical disease associated with a poor response to antidepressants?",
    "gt": "In late-life depression a poor response to antidepressant monotherapy can be expected in those patients with a frontal lobe syndrome, extrapyramidal signs or if MRI T2-weighted lesions are present in both the basal ganglia and the pontine reticular formation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The objective of this national survey was to describe the routine use of procedures and technologies in Canadian hospitals providing maternity care, and to determine the extent to which current use was consistent with the existing evidence and recommended guidelines for maternal and newborn care. Representatives of 572 hospitals providing maternity care across Canada were sent questionnaires in the spring and summer of 1993; 523 (91.4%) responded. The primary outcome measures consisted of the self-reported use of obstetric procedures and technologies (perineal shaves, enemas/suppositories, intravenous infusions, initial and continuous electronic fetal heart monitoring, episiotomy rates). Hospitals were grouped according to location, size (number of live births per year), and university affiliation status. The hospitals in the Prairie provinces, in Quebec, and in the Atlantic provinces were significantly less likely than those in Ontario to restrict their use of perineal shaves and enemas to women on admission in labor. Small hospitals were significantly more likely than large hospitals (>1000 live births) to restrict their use of intravenous infusions, and initial and continuous electronic fetal monitoring. The university-affiliated and nonteaching hospitals were significantly less likely than the university teaching hospitals to have episiotomy rates of less than 40 percent for primiparous women. Small hospitals were more likely than large hospitals to report episiotomy rates of less than 20 percent for multiparous women.\nQuestion: A national survey of use of obstetric procedures and technologies in Canadian hospitals: routine or based on existing evidence?",
    "gt": "Considerable variations occur in the routine use of obstetric procedures and technologies in Canadian hospitals providing maternity care, according to hospital location, size, and university affiliation status. Despite the existing evidence suggesting that the routine use of these practices and procedures is both unnecessary and potentially harmful, a significant number of Canadian hospitals continued to use them routinely in 1993.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Initial classification of diabetes of young may require revision to improve diagnostic accuracy of different forms of diabetes. The aim of our study was to examine markers of beta-cell autoimmunity in a cohort of young (0-25 years) patients with type 1 diabetes and compare the presentation and course of the disease according to the presence of pancreatic antibodies. Cross-sectional population-based study was performed covering 100% of pediatric (n = 860) and 70% of 18-25 years old adult patients (n = 349) with type 1 diabetes in Lithuania. No antibodies (GAD65, IA-2, IAA and ICA) were found in 87 (7.5%) cases. Familial history of diabetes was more frequent in those with antibodies-negative diabetes (24.1 vs. 9.4%, p < 0.001). Gestational age, birth weight and age at diagnosis was similar in both groups. Ketosis at presentation was more frequent in patients with autoimmune diabetes (88.1 vs. 73.5%, p < 0.05). HbA1c at the moment of investigation was 8.6 (3) vs. 8.7 (2.2)% in antibodies-negative and antibodies-positive diabetes groups, respectively, p > 0.05. In the whole cohort, neuropathy was found in 8.8% and nephropathy - in 8.1% of cases, not depending on autoimmunity status. Adjusted for age at onset, disease duration and HbA1c, retinopathy was more frequent in antibodies-negative subjects (13.8 vs. 7.8%, p < 0.05).\nQuestion: The course of diabetes in children, adolescents and young adults: does the autoimmunity status matter?",
    "gt": "Antibodies-negative pediatric and young adult patients with type 1 diabetes in this study had higher incidence of family history of diabetes, higher frequency of retinopathy, less frequent ketosis at presentation, but similar age at onset, HbA1c, incidence of nephropathy and neuropathy compared to antibodies-positive patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Adherence to drug treatment and health-related quality of life (HRQL) are two distinct concepts. Generally one would expect a positive relationship between the two. The purpose of this study was to assess the relationship between adherence and HRQL. HRQL was measured using the physical and mental summary measures of the RAND-12 (PHC-12, MHC-12), the SF-12 (PCS-12, MCS-12), HUI-2 and HUI-3. Adherence was assessed using Morisky's instrument. Three longitudinal datasets were used. One dataset included 100 hypertensive patients. Another dataset covered 199 high risk community-dwelling individuals. The third dataset consisted of 365 elderly patients. Spearman's correlation coefficients were used to assess association. Subgroup analyses by type of medication and inter-temporal analyses were also performed. Correlation between adherence and PHC-12 ranged from 0.08 (p = 0.26) to 0.22 (p<0.01). Correlations between adherence and MHC-12 ranged from 0.11 (p = 0.11) to 0.15 (p<0.01). Similar results were observed using HUI-2, HUI-3, and SF-12 as well as by type of medication and in the lagged analyses.\nQuestion: Is adherence to drug treatment correlated with health-related quality of life?",
    "gt": "Correlations between HRQL and adherence were positive but typically weak or negligible in magnitude.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Fetuin-A is a circulating inhibitor of ectopic calcification. Low plasma levels have been associated in some studies with increased vascular calcification, aortic stiffness and mortality in patients with Chronic Kidney Disease (CKD). However, there are other studies examining the association of fetuin-A with vascular parameters and mortality, which do not show these associations. These conflicting data may be explained by methodological differences. We compared plasma fetuin-A measurements made with two widely-used commercial fetuin-A ELISA kits (Biovendor, Modrice, Czech Republic; Epitope Diagnostics Inc., San Diego, US) in samples from patients with and without CKD. We evaluated the effect of differences in fetuin-A glycosylation status on assay specificity. Deming regression analysis showed poor agreement between methods (for CKD cohort: y=-0.05+2.52x, S(y|x)=0.099g/L, R(2)=0.694). The Epitope Diagnostics kit demonstrated significant positive bias and greater specificity for deglycosylated fetuin-A relative to the Biovendor assay.\nQuestion: Poor agreement between commercial ELISAs for plasma fetuin-A: An effect of protein glycosylation?",
    "gt": "The apparently contradictory nature of reports of the association of fetuin-A with biological variables may reflect differences in the specificity of different ELISA methods for glycosylated plasma fetuin-A.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this study was to evaluate therapy response in patients undergoing cetuximab-CapIri-based chemoradiation for rectal cancer using dynamic magnetic resonance imaging (dMRI). The volumetric degree of tumor regression and contrast media perfusion were compared to the results of the histopathologic ypTN staging. 33 patients were examined using a 1.5-T scanner with repetitive 2D FLASH sequences after contrast media application. All patients were examined twice - before therapy and immediately before surgery. In all patients, the tumor volume decreased (mean 72 +/- 16%). In 25/33 patients, the slope of the contrast media enhancement curve decreased (mean 31 +/- 20%). In histopathologically proven downstaging after therapy, the decrease in slope was significantly higher than in the group without downstaging, and the decrease in slope was better for distinguishing between 'responder' and 'non-responder' than the decrease in volume.\nQuestion: Can dynamic MR imaging predict response in patients with rectal cancer undergoing cetuximab-based neoadjuvant chemoradiation?",
    "gt": "Using dMRI helps to identify responders undergoing cetuximab-based chemoradiation better than volume decrease alone.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether the time of dosing (morning or evening) affects the tolerability or efficacy of tamsulosin in the treatment of lower urinary tract symptoms. Data were analysed from an open-label, observational study in which patients were treated with 0.4 mg tamsulosin once daily for 12 weeks. Treatment effects were determined using the Benign Prostatic Hyperplasia Impact Index, the quality-of-life question of the International Prostate Symptom Score, a similarly phrased question about sexual satisfaction, the maximum urinary flow rate, the postvoid residual urine volume, and the overall efficacy and tolerability. The results were analysed statistically for differences between dosing times, using analysis of covariance for the quantitative variables and logistic regression for the qualitative variables. While no specific recommendation about the dosing time was given in the trial, the retrospective analysis showed that 4420 and 2087 patients received tamsulosin in the morning and evening, respectively. Both groups had similar values for all variables before treatment. The efficacy and tolerability of tamsulosin treatment was also similar in both groups; there were small advantages for morning dosing, which were statistically significant because there were many patients.\nQuestion: Does the time of administration (morning or evening) affect the tolerability or efficacy of tamsulosin?",
    "gt": "In contrast to other alpha-blockers, night-time dosing is not necessary to improve the tolerability or efficacy of tamsulosin.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There are sporadic reports, with different verdicts, of restorative proctectomy by laparoscopic transanal pull-through (LTPT) without the use of a minilaparotomy for a part of the procedure. This study aimed to explore the applicability and advantages of LTPT with colon pouch-anal anastomosis for low rectal cancer, and to evaluate the results. From January 2002 to July 2003, 10 of 12 patients (6 men and 4 women) undergoing a laparoscopic procedure for low rectal cancer (<6 cm from the anal verge) underwent LTPT. The mean age of these patients was 58 years. The results have been compared with those for 12 similar non-pull-through procedures performed during the same period. There was no operative mortality. An anastomotic leakage and a hemorrhagic gastropathy occurred in the LTPT group. During a mean follow-up period of 18 months (range, 12-26 months), there was no local relapse. Four patients manifested moderate incontinence. No significant differences in functional outcome were observed between the LTPT and control groups.\nQuestion: Restorative proctectomy with colon pouch-anal anastomosis by laparoscopic transanal pull-through: an available option for low rectal cancer?",
    "gt": "The authors' experience supports use of the LTPT procedure with colonic pouch-anal anastomosis for selected lower rectal cancers with indications for a laparoscopic approach as an appropriate and reproducible surgical treatment.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Ultrasonography (US) is used in rheumatology to assess small joints in inflammatory arthritis. Recently there has been some investigation into the utility of US in osteoarthritis (OA), however there has been little comparison of US to other imaging modalities in OA. This study aimed to compare the detection of osteophytosis and joint space narrowing (JSN) by US and conventional radiography (CR) in OA of the hand. with OA of the hand underwent US and CR examination of the small joints of both hands to identify osteophytosis and joint space narrowing. 1106 joints of 37 patients were imaged with US and CR. US detected osteophytosis in 448 joints, compared to CR that detected osteophytosis in 228 joints (approximately 30% fewer joints). Where osteophytosis was detected by US but not CR, this was usually proximal to the joint line. Joint space narrowing was detected in 450 joints by US, but only 261 joints by CR. The distribution of US and CR detected osteoarthritis changes in this cohort was consistent with population studies of radiographic hand OA, although metacarpophalangeal (MCP) involvement was higher than might be expected\nQuestion: Can ultrasonography improve on radiographic assessment in osteoarthritis of the hands?",
    "gt": "US detected more osteophytosis and joint space narrowing than CR in OA of the hand. Involvement of MCP joints was more common than would be expected from population radiographic studies. The increased detection of OA structural pathology by US may make this a useful tool for hand OA research.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Lung tissue is metabolically active and consumes oxygen. The oxygen content difference between arterial and mixed venous blood does not include the effect of pulmonary tissue oxygen uptake. Thus, oxygen consumption (VO2) of the lung should be reflected as a difference between VO2 measured by gas exchange and VO2 derived by the Fick principle. The purpose of this study was to measure in clinical conditions this difference (taken to represent the VO2 of the lung), and to evaluate the sources of error in lung VO2 estimation. Nine patients undergoing coronary artery bypass grafting were studied. VO2 was measured by indirect calorimetry (VO2gasex) and compared to Fick-derived VO2 (VO2Fick) after induction of anaesthesia, after closure of the chest, at admission to intensive care, after stabilization of haemodynamics and during weaning from mechanical ventilation. The Fick-derived VO2 was calculated from blood samples taken at the beginning and at the end of each 20 min measurement period, and the mean of 12 consecutive thermodilution cardiac output measurements taken during each 20 min measurement period. VO2gasex was higher than VO2Fick (P<0.01; in all except 4 of 45 measurements). The difference between the measured and the calculated VO2 was 33 +/- 25 ml/min (mean +/- SD, range -16-100 ml/min). This difference represented 14 +/- 3% (range 11-18%) of the whole body VO2. The VO2-difference was highest after the induction of anaesthesia (50 +/- 19 ml/min; range 20-41 ml/min, P<0.03) and lowest on arrival at the intensive care unit (10 +/- 16 ml/min; range -16-39 ml/min). Core temperature did not correlate with the oxygen consumption difference.\nQuestion: Calculated versus measured oxygen consumption during and after cardiac surgery. Is it possible to estimate lung oxygen consumption?",
    "gt": "A constant difference between measured and calculated VO2 can be detected in carefully controlled clinical conditions. The difference between the two methods is due to both lung oxygen consumption and errors in the measurement of VO2 thermodilution cardiac output, haemoglobin and blood oxygen contents. We suggest that the perioperative changes of the VO2-difference are due not only to variation of the measurements but also to changes in lung metabolic activity.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Disease in the musculoskeletal system accounts for the largest proportion of chronic disease in Denmark, and the associated costs amount to billions of kroner every year. Prevention and treatment have focussed on exercise and training. Training in fitness centres is one of the most popular forms of exercise in Denmark and the number of users is increasing rapidly. We suspect that musculoskeletal problems are common among members of fitness centres, and that good communication between the centres and the health care sector would optimize treatment. The purpose of the present study is to describe the extent of musculoskeletal problems among members of fitness centres and the degree of communication between the centres and the health care sector. Information regarding age, sex, musculoskeletal complaints, possible treatment, and whether there had been any communication between health care providers and the fitness centres before or during the period of training was collected among members of five fitness centres in Denmark. 485 (94%) out of a total of 516 members participated in the study. 56% reported that they had one or more musculoskeletal problem when joining the centre. Out of these, 77% stated that musculoskeletal problems were the main or a contributing reason for joining the centre. More than half the participants with musculoskeletal complaints had received some kind of treatment within the previous year. However, communication between health care providers and fitness centres was uncommon.\nQuestion: Are fitness centres part of the health care sector?",
    "gt": "The fitness sector is growing rapidly and more than 50% of members suffer from musculoskeletal problems. Most of these also receive treatment for their problems but there is very little and almost no formal communication between the health care sector and the fitness centres.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The published articles examining obesity and CABG surgery contain conflicting results about the role of body mass index (BMI) as a risk factor for in-hospital mortality. We studied 16 218 patients who underwent isolated CABG in the Providence Health System Cardiovascular Study Group database from 1997 to 2003. The effect of BMI on in-hospital mortality was assessed by logistic regression, with BMI group (underweight, normal, overweight, and 3 subgroups of obesity) as a categorical variable or transformations, including fractional polynomials, of BMI as a continuous variable. BMI was not a statistically significant risk factor for mortality in any of these assessments. However, using cumulative sum techniques, we found that the lowest risk-adjusted CABG in-hospital mortality was in the high-normal and that overweight BMI subgroup patients with lower or higher BMI had slightly increased mortality.\nQuestion: Is obesity a risk factor for mortality in coronary artery bypass surgery?",
    "gt": "Body size is not a significant risk factor for CABG mortality, but the lowest mortality is found in the high-normal and overweight subgroups compared with obese and underweight.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Sustained efforts have not attenuated racial and ethnic disparities in unintended pregnancy and effective contraceptive use in the United States. The roles of attitudes toward contraception, pregnancy and fertility remain relatively unexplored. Knowledge of contraceptive methods and attitudes about contraception, pregnancy, childbearing and fertility were assessed among 602 unmarried women aged 18-29 at risk for unintended pregnancy who participated in the 2009 National Survey of Reproductive and Contraceptive Knowledge. The contribution of attitudes to racial and ethnic disparities in effective method use was assessed via mediation analysis, using a series of regression models. Blacks and Latinas were more likely than whites to believe that the government encourages contraceptive use to limit minority populations (odds ratio, 2.5 for each). Compared with white women, Latinas held more favorable attitudes toward pregnancy (2.5) and childbearing (coefficient, 0.3) and were more fatalistic about the timing of pregnancy (odds ratio, 2.3); blacks were more fatalistic about life in general (2.0). Only one attitude, skepticism that the government ensures contraceptive safety, was associated with contraceptive use (0.7), but this belief did not differ by race or ethnicity. Although blacks and Latinas used less effective methods than whites (0.3 and 0.4, respectively), attitudes did not explain disparities. Lower contraceptive knowledge partially explained Latinas' use of less effective methods.\nQuestion: Do racial and ethnic differences in contraceptive attitudes and knowledge explain disparities in method use?",
    "gt": "Providing basic information about effective methods might help to decrease ethnic disparities in use. Research should examine other variables that might account for these disparities, including health system characteristics and provider behavior.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Practice-based Internet communication allows patients to obtain health information, ask questions, and submit requests through a personalized Web site. While such online tools also bring great promise for educating patients with the goal of fostering behavior change, it is important to examine how individuals currently using such services differ from those who do not. The study used administrative information to characterize a population of patients communicating with a medical practice through the Internet during the end of 1999 and through 2000. Patient claims data generated during clinical encounters from January 1999 through May 2000 were examined to measure the relationship between patient demographics, frequency of visits, specific acute diagnoses, and specific chronic diagnoses and the use of online communication with the practice. Ten percent of patients, and 13.2% of patients 18 years or older, used the practice Web site. There were differences in use of the practice Web site by age and insurance status, but not by gender. Use of the practice Web site was similar or higher among patients having a diagnosis for a variety of acute and chronic conditions compared to those not having such a diagnosis. Patients with more clinic visits were more likely to use the Web-based service.\nQuestion: Using claims data to examine patients using practice-based Internet communication: is there a clinical digital divide?",
    "gt": "Patients using practice-based Internet communication and having significant health risks can be identified through the use of administrative data, presenting an opportunity to test online educational efforts to improve health.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The following study was conducted to identify risk factors for a postoperative CSF leak after vestibular schwannoma (VS) surgery. The authors reviewed a prospectively maintained database of all patients who had undergone resection of a VS at the Mayo Clinic between September 1999 and May 2013. Patients who developed a postoperative CSF leak within 30 days of surgery were compared with those who did not. Data collected included patient age, sex, body mass index (BMI), tumor size, tumor side, history of prior tumor treatment, operative time, surgical approach, and extent of resection. Both univariate and multivariate regression analyses were performed to evaluate all variables as risk factors of a postoperative CSF leak. A total of 457 patients were included in the study, with 45 patients (9.8%) developing a postoperative CSF leak. A significant association existed between increasing BMI and a CSF leak, with those classified as overweight (BMI 25-29.9), obese (BMI 30-39.9), or morbidly obese (BMI≥40) having a 2.5-, 3-, and 6-fold increased risk, respectively. Patients undergoing a translabyrinthine (TL) approach experienced a higher rate of CSF leaks (OR 2.5, 95% CI 1.3-4.6; p=0.005), as did those who had longer operative times (OR 1.04, 95% CI 1.02-1.07; p=0.0006). The BMI, a TL approach, and operative time remained independent risk factors on multivariate modeling.\nQuestion: Are there modifiable risk factors to prevent a cerebrospinal fluid leak following vestibular schwannoma surgery?",
    "gt": "Elevated BMI is a risk factor for the development of a postoperative CSF leak following VS surgery. Recognizing this preoperatively can allow surgeons to better counsel patients regarding the risks of surgery as well as perhaps to alter perioperative management in an attempt to decrease the likelihood of a leak. Patients undergoing a TL approach or having longer operative times are also at increased risk of developing a postoperative CSF leak.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The authors examined whether patients with comorbid borderline personality disorder and posttraumatic stress disorder (PTSD) have a more severe clinical profile than patients with either disorder without the other. Outpatients with borderline personality disorder without PTSD (N=101), PTSD without borderline personality disorder (N=121), comorbid borderline personality disorder and PTSD (N=48), and major depression without PTSD or borderline personality disorder (N=469) were assessed with structured interviews for psychiatric disorders and for degree of impairment. Outpatients with diagnoses of comorbid borderline personality disorder and PTSD were not significantly different from outpatients with borderline personality disorder without PTSD, PTSD without borderline personality disorder, or major depression without PTSD or borderline personality disorder in severity of PTSD-related symptoms, borderline-related traits, or impairment.\nQuestion: Is comorbidity of posttraumatic stress disorder and borderline personality disorder related to greater pathology and impairment?",
    "gt": "The additional diagnosis of PTSD or borderline personality disorder does little to augment the pathology or dysfunction of patients who have either disorder without the other.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It has been suggested that the use of a short-stem prosthesis could conserve proximal bone by proximal load transfer. Proximal stress shielding should be reduced, a phenomenon that has been associated with bone resorption around traditional stems. Bone remodelling of a metaphyseal fixed stem (Nanos, Smith&Nephew Int.) was analysed by the dual-energy x-ray absorptiometry. This study included 36 patients undergoing the total hip replacement using the Nanos short stem in comparison to 36 patients operated by a traditional long-stemmed femoral stem (Alloclassic). In all cases a threaded cup was inserted. Both groups were not different in regard to the BMI or in regard to the quality of bone (BMI). The average age of the group of patients with the short-stem prosthesis was slightly younger (average 54.2 years [range: 29 to 75]) than the patient group with the long-stem prosthesis (average 61.1 years [range: 39 to 71]). A prospective clinical analysis was done by the Harris hip score (HHS) and the Sutherland score to evaluate the social quality of life. With a minimum follow-up of 12 months in all cases, radiological changes in regard to stem subsidence, periprosthetic osteolysis or linear radiolucencies were analysed. The changes of periprosthetic bone density were examined with DEXA in all patients 3 and 12 months postoperatively. No patients required reoperation because of loosening or subsidence of the short-stem prosthesis. The HHS improved from a mean of 43.1 (range: 9 to 51) to 96.5 points (range: 79 to 100) in the short-stem group and to 91.3 points (range: 61 to 100) in the group of patients with long-stemmed femoral component. Radiographic follow-up revealed no evidence of component loosening or migration of the short-stem. Along the greater trochanter an osteolysis of the bone structure was found in two cases. A decrease of the proximal periprosthetic bone density (Gruen zone I, -6.4%) and in zone VII (-7.2%) were measured. An increase of the BMD in the lateral inferior region (Gruen zone II, +9.7%) superior to the polished tip of the short stem was observed over a period of one year after implantation. At the polished tip of the prosthesis a significant change of bone density in zone III (+1.03%) and in zone V (+0.7%) could not be observed.\nQuestion: Is there a bone-preserving bone remodelling in short-stem prosthesis?",
    "gt": "The desired proximal load transfer of a short-stemmed implant in the metaphyseal region of the proximal femur could not be reached with this device. On the basis of the excellent clinical results of the patients operated with the Nanos short-stem prosthesis we conclude that the component induces bone ingrowth in the lateral/distal region of the proximal femur.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To study which cut off point of DAS28 corresponds to fulfilment of the American Rheumatism Association (ARA) preliminary remission criteria, and clinical remission criteria in patients with rheumatoid arthritis (RA). All adult patients diagnosed with RA at Jyväskylä Central Hospital 1997-98 were assessed for remission at 5 years. Remission was defined as (a) ARA remission; (b) clinical remission (defined as no tender or swollen joints and normal erythrocyte sedimentation rate). DAS28 was used to measure disease activity. A receiver operating characteristics curve analysis was performed to calculate a cut off point of DAS28 that best corresponds to the ARA remission criteria and the clinical remission criteria. 161 patients (mean age 57 years, 107 (66%) female, 98 (61%) with positive rheumatoid factor, and 51 (32%) with erosions) were studied. At 5 years, 19 (12%) patients met the ARA remission criteria, and 55 (34%) met the clinical remission criteria. The cut off value of DAS28 was 2.32 for the ARA remission criteria, and 2.68 for the clinical remission criteria. In patients with DAS28<2.32, 11/57 (19%) had tender joints, 6/57 (11%) had swollen joints, and 4/57 (7%) had both tender and swollen joints (66 joint count).\nQuestion: Is DAS28 an appropriate tool to assess remission in rheumatoid arthritis?",
    "gt": "In this study the DAS28 cut off point for the ARA remission was lower than in previous studies. The cut off point for DAS28 remission remains controversial. A substantial proportion of patients below the DAS28 cut off point for remission have tender or swollen joints, or both. DAS28 may not be an appropriate tool for assessment of remission in RA.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Questionnaire. Sisters/charge nurses were allocated patients in addition to being in charge of their ward for, on average, half of their shifts each week. Most of them did not have time to complete their managerial duties, which included supporting and supervising other staff on patient care issues. More than 50 per cent of the sisters/charge nurses did not have the time to attend clinical supervision.\nQuestion: Are ward sisters and charge nurses able to fulfil their role?",
    "gt": "Sisters/charge nurses treat clinical care--both delivering it directly themselves and advising other staff on its delivery--as a higher priority than their managerial and administrative duties; lack of time is a barrier to the successful fulfilment of their role.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Chronic pain is common in persons with multiple sclerosis (MS), but the co-morbidity of fibromyalgia (FM) has yet to be investigated in MS. Objectives of the study were to evaluate, among the various types of chronic pain, the frequency of FM in MS and its impact on MS patients' health-related quality of life (HRQoL). 133 MS patients were investigated for the presence and characterization of chronic pain within 1 month of assessment. A rheumatologist assessed the presence FM according to the 1990 ACR diagnostic criteria. Depression, fatigue, and HRQoL were also assessed by means of specific scales. Chronic pain was present in 66.2% of patients (musculoskeletal in 86.3%; neuropathic in 13.7%; absent in 33.8% [called NoP]). Pain was diagnosed with FM (PFM+) in 17.3% of our MS patients, while 48.9% of them had chronic pain not FM type (PFM-); the prevalence of neuropathic pain in these 2 sub-groups was the same. PFM+ patients were prevalently females and had a higher EDSS than NoP. The PFM+ patients had a more pronounced depression than in the NoP group, and scored the worst in both physical and mental QoL.\nQuestion: Chronic pain in multiple sclerosis: is there also fibromyalgia?",
    "gt": "In our sample of MS patients we found a high prevalence of chronic pain, with those patients displaying a higher disability and a more severe depression. Moreover, FM frequency, significantly higher than that observed in the general population, was detected among the MS patients with chronic pain. FM occurrence was associated with a stronger impact on patients' QoL.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Observed reductions in firearm suicides in Australia have been linked to the 1997 national firearms agreement (NFA) introduced following the 1996 Port Arthur massacre. The NFA placed strong access restrictions on firearms. To assess the impact of legislative restrictions on the incidence of firearm suicide in Queensland and explore alternative or contributory factors behind observed declines. The Queensland suicide register (QSR) provided detailed information on all male suicides in Queensland (1990-2004), with additional data for Australia (1968-2004) accessed from other official sources. Trends in suicide rates pre/post NFA, and in method selection, were assessed using negative binomial regressions. Changing method selection patterns were examined using a cohort analysis of 5 years of age classes for Australian males. The observed reduction in firearms suicides was initiated prior to the 1997 introduction of the NFA in Queensland and Australia, with a clear decline observed in Australian figures from 1988. No significant difference was found in the rate pre/post the introduction of the NFA in Queensland; however, a significant difference was found for Australian data, the quality of which is noticeably less satisfactory. A marked age-difference in method choice was observed through a cohort analysis demonstrating both time and age influences. Within sequential birth cohorts, rates of firearms suicides decreased in younger males but increased in hanging suicides; this trend was far less marked in older males.\nQuestion: Controlling firearms use in Australia: has the 1996 gun law reform produced the decrease in rates of suicide with this method?",
    "gt": "The implemented restrictions may not be responsible for the observed reductions in firearms suicide. Data suggest that a change in social and cultural attitudes could have contributed to the shift in method preference.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study evaluated the marginal quality of differently bonded direct resin composite restorations in enamel and dentin, before and after thermomechanical loading (TML). Special attention was focussed on the performance of selective enamel etching, etch-and-rinse, and self-etching adhesives. Eighty MO cavities with proximal margins beneath the cementoenamel junction were prepared in extracted human third molars. Direct resin composite restorations (Tetric EvoCeram, n=8) were placed with 4-step selective enamel etching (Syntac SE), 4-step etch-and-rinse (Syntac ER), 2-step etch-and-rinse (XP Bond, Scotchbond 1 XT/Single Bond Plus), 2-step self-etching (AdheSE, Clearfil SE Bond), 2-step self-etching with selective enamel etching (AdheSE SE, Clearfil SE Bond SE), and 2-step self-etching with etch-and-rinse (AdheSE TE, Clearfil SE Bond TE). Marginal gaps were analyzed using epoxy resin replicas under a scanning electron microscope at 200X magnification. Initially, high percentages of gap-free margins were identified for all adhesives. After TML, the results were as follows: (A) Enamel margins: When phosphoric acid was used on enamel, results were constantly higher (approximately 90%) compared with two-step self-etchin adhesives (approximately 70%; p<0.05). (B) Dentin margins: No statistical differences were found when etch-and-rinse and selective etch approaches were compared (59% to 64%; p>0.05). When self-etching adhesives were used as per manufacturers' directions, dentin margins exhibited the best marginal quality (74% to 82%; p<0.05). When self-etching adhesives were used under etch-and-rinse conditions, marginal quality in dentin was significantly reduced to 35% to 42% (p<0.05).\nQuestion: Selective enamel etching reconsidered: better than etch-and-rinse and self-etch?",
    "gt": "Enamel bonding was generally more effective with phosphoric-acid etching. Enamel bonding performance of 2-step self-etching adhesives was improved when phosphoric acid was applied on enamel selectively.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The Israeli National Health Insurance Law stipulates a National List of Health Services (NLHS) to which all residents are entitled from their HMOs. This list has been updated annually for almost a decade using a structured review and decision-making process. Although this process has been described in detail in previous papers, none of these have fully addressed legitimacy and fairness. We examine the legitimacy and fairness of the process of updating the NLHS in Israel. We assessed the priority-setting process for compliance with the four conditions of accountability for reasonableness outlined by Daniels and Sabin (relevance, publicity, appeals, and enforcement). These conditions emphasize transparency and stakeholder engagement in democratic deliberation. Our analysis suggests that the Israeli process for updating the NLHS does not fulfill the appeals and enforcement conditions, and only partially follows the publicity and relevance conditions, outlined in the accountability for reasonableness framework. The main obstacles for achieving these goals may relate to the large number of technologies assessed each year within a short time frame, the lack of personnel engaged in health technology assessment, and the desire for early adoption of new technologies.\nQuestion: The process of updating the National List of Health Services in Israel: is it legitimate?",
    "gt": "The process of updating the NLHS in Israel is unique and not without merit. Changes in the priority-setting process should be made to increase its acceptability among the different stakeholders.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Down syndrome is known to affect the natural history of complete atrioventricular septal defect. We analyzed whether Down syndrome affect the long-term results of complete atrioventricular septal defect when the defect is repaired during the first year of life. Repairs of complete atrioventricular septal defect were performed in 64 infants. Thirty-four infants were associated with Down syndrome, while the other 30 were non-Down patients. Complete follow-up rate was 95% with mean follow-up period of 99+/-47 months (maximum 169 months) in Down patients and 80+/-64 months (maximum 213 months) in non-Down patients. There was one operative death in each group (mortality rate of 2.9% in Down patients and 3.3% in non-Down patients), and three patients died at the late phase (one in Down patients and two in non-Down patients). Five patients underwent re-operation due to postoperative left atrioventricular valve regurgitation (one in Down patients and four in non-Down patients). Freedom from re-operation for left atrioventricular valve regurgitation and actuarial survival rate at 13 years were 96+/-4 and 94+/-4% in Down patients and 85+/-7 and 90+/-5% in non-Down patients (not significantly different).\nQuestion: Does Down syndrome affect the long-term results of complete atrioventricular septal defect when the defect is repaired during the first year of life?",
    "gt": "Down syndrome does not affect the long-term results of complete atrioventricular septal defect when the defect is repaired during the first year of life.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Diabetes requires substantial ongoing medical management and use of monitoring tests. However, physicians' performance of these tests is often suboptimal. This study explored primary care physicians' management of diabetes in the context of both planned diabetes visits and acute visits for conditions unrelated to diabetes. Semi-structured depth interviews were conducted with 12 primary care physicians in 9 family practice and internal medicine practices distributed throughout the state of South Carolina. All interviews were tape recorded and transcribed. Themes, divergences, and trends were identified and discussed by the investigators. Although all participants reported a preference toward planned diabetes management, because most patients fail to adhere to scheduled care, opportunistic disease management tended to be the default mode of diabetes care. Participants reported performing appropriate tests during scheduled visits but acknowledged that when confined to acute visits, diabetes care was difficult to perform. Reasons included time constraints and patient agenda. Participants reported that inadequate tracking of completion of diabetes standards of care influenced their adherence to guidelines.\nQuestion: Disease management for diabetes among family physicians and general internists: opportunism or planned care?",
    "gt": "The current system of delivering diabetes care opportunistically in the context of non-diabetes acute visits may need to be more closely examined in an effort to improve the delivery of services.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Recently, a strategy for treating stroke directly at the emergency site was developed. It was based on the use of an ambulance equipped with a scanner, a point-of-care laboratory, and telemedicine capabilities (Mobile Stroke Unit). Despite demonstrating a marked reduction in the delay to thrombolysis, this strategy is criticized because of potentially unacceptable costs. We related the incremental direct costs of prehospital stroke treatment based on data of the first trial on this concept to one year direct cost savings taken from published research results. Key parameters were configuration of emergency medical service personnel, operating distance, and population density. Model parameters were varied to cover 5 different relevant emergency medical service scenarios. Additionally, the effects of operating distance and population density on benefit-cost ratios were analyzed. Benefits of the concept of prehospital stroke treatment outweighed its costs with a benefit-cost ratio of 1.96 in the baseline experimental setting. The benefit-cost ratio markedly increased with the reduction of the staff and with higher population density. Maximum benefit-cost ratios between 2.16 and 6.85 were identified at optimum operating distances in a range between 43.01 and 64.88 km (26.88 and 40.55 miles). Our model implies that in different scenarios the Mobile Stroke Unit strategy is cost-efficient starting from an operating distance of 15.98 km (9.99 miles) or from a population density of 79 inhabitants per km2 (202 inhabitants per square mile).\nQuestion: Is prehospital treatment of acute stroke too expensive?",
    "gt": "This study indicates that based on a one-year benefit-cost analysis that prehospital treatment of acute stroke is highly cost-effective across a wide range of possible scenarios. It is the highest when the staff size of the Mobile Stroke Unit can be reduced, for example, by the use of telemedical support from hospital experts. Although efficiency is positively related to population density, benefit-cost ratios can be greater than 1 even in rural settings.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this study was to explore how activity of daily living (ADL) stages and the perception of unmet needs for home accessibility features associate with a history of falling. Participants were from a nationally representative sample from the Second Longitudinal Survey of Aging conducted in 1994. The sample included 9250 community-dwelling persons 70 yrs or older. The associations of ADL stage and perception of unmet needs for home accessibility features with a history of falling within the past year (none, once, or multiple times) were explored after accounting for sociodemographic characteristics and comorbidities using a multinomial logistic regression model. The adjusted relative risk of falling more than once peaked at 4.30 (95% confidence interval, 3.29-5.61) for persons with severe limitation (ADL-III) compared those with no limitation (ADL-0) then declined for those at complete limitation (ADL-IV). The adjusted relative risks of falling once and multiple times were 1.42 (95% confidence interval, 1.07-1.87) and 1.85 (95% confidence interval, 1.44-2.36), respectively, for those lacking home accessibility features.\nQuestion: Do elderly people at more severe activity of daily living limitation stages fall more?",
    "gt": "Risk of falling appeared greatest for those whose homes lacked accessibility features and peaked at intermediate ADL limitation stages, presumably at a point when people have significant disabilities but sufficient function to remain partially active.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Vaginal intraepithelial neoplasia (VAIN) is usually detected in patients with synchronous or antecedent cervical or vulval intraepithelial or invasive cancer. VAIN has the potential to progress to malignancy. To determine the incidence and severity and analyse the management of vaginal dysplasia in patients undergoing primary hysterectomy for cervical cancer. A retrospective study (1984-1998) identified 210 primary invasive cervical cancers. One-hundred and twenty-three patients had a primary hysterectomy. In follow-up six patients were found to have dyskaryosis in a second vaginal smear. Biopsies in the six patients with colposcopic lesions showed VAIN II (n=2), VAIN III (n=1),VAIN III / possible early invasion (n = 1) and invasive carcinoma (n=2). One patient with recurrent squamous cancer received salvage radiotherapy and one with recurrent adenocarcinoma received high dose progestogens and topical 5-fluorouracil.\nQuestion: Vaginal cytology following primary hysterectomy for cervical cancer: is it useful?",
    "gt": "All patients are disease-free at follow-up.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There is increasing evidence that environmental factors such as air pollution from mine dumps, increase the risk of chronic respiratory symptoms and diseases. The aim of this study was to investigate the association between proximity to mine dumps and prevalence of chronic respiratory disease in people aged 55 years and older. Elderly persons in communities 1-2 km (exposed) and 5 km (unexposed), from five pre-selected mine dumps in Gauteng and North West Province, in South Africa were included in a cross-sectional study. Structured interviews were conducted with 2397 elderly people, using a previously validated ATS-DLD-78 questionnaire from the British Medical Research Council. Exposed elderly persons had a significantly higher prevalence of chronic respiratory symptoms and diseases than those who were unexposed., Results from the multiple logistic regression analysis indicated that living close to mine dumps was significantly associated with asthma (OR = 1.57; 95% CI: 1.20 - 2.05), chronic bronchitis (OR = 1.74; 95 CI: 1.25 - 2.39), chronic cough (OR = 2.02; 95% CI: 1.58 - 2.57), emphysema (OR = 1.75; 95% CI: 1.11 - 2.77), pneumonia (OR = 1.38; 95% CI: 1.07 - 1.77) and wheeze (OR = 2.01; 95% CI: 1.73 - 2.54). Residing in exposed communities, current smoking, ex-smoking, use of paraffin as main residential cooking/heating fuel and low level of education emerged as independent significant risk factors for chronic respiratory symptoms and diseases.\nQuestion: Chronic respiratory disease among the elderly in South Africa: any association with proximity to mine dumps?",
    "gt": "This study suggests that there is a high level of chronic respiratory symptoms and diseases among elderly people in communities located near to mine dumps in South Africa.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate the cumulative effect of repeated transcutaneous electrical nerve stimulation (TENS) on chronic osteoarthritic (OA) knee pain over a four-week treatment period, comparing it to that of placebo stimulation and exercise training given alone or in combination with TENS. Sixty-two patients, aged 50-75, were stratified according to age, gender and body mass ratio before being randomly assigned to four groups. Patients received either (1) 60 minutes of TENS, (2) 60 minutes of placebo stimulation, (3) isometric exercise training, or (4) TENS and exercise (TENS&Ex) five days a week for four weeks. Visual analogue scale (VAS) was used to measure knee pain intensity before and after each treatment session over a four-week period, and at the four-week follow-up session. Repeated measures ANOVA showed a significant cumulative reduction in the VAS scores across the four treatment sessions (session 1, 10, 20 and the follow-up) in the TENS group (45.9% by session 20, p<0.001) and the placebo group (43.3% by session 20, p = 0.034). However, linear regression of the daily recordings of the VAS indicated that the slope in the TENS group (slope = -2.415, r = 0.943) was similar to the exercise group (slope = -2.625, r = 0.935), which were steeper than the other two groups. Note that the reduction of OA knee pain was maintained in the TENS group and the TENS&Ex group at the four-week follow-up session, but not in the other two groups.\nQuestion: Does four weeks of TENS and/or isometric exercise produce cumulative reduction of osteoarthritic knee pain?",
    "gt": "The four treatment protocols did not show significant between-group difference over the study period. It was interesting to note that isometric exercise training of the quadriceps alone also reduced knee pain towards the end of the treatment period.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Web-based course evaluation systems offer the potential advantage of timely evaluations. The authors examined whether elapsed time between teaching and student evaluation of teaching impacts preclinical courses' quality ratings. The overall relationship of elapsed time with evaluation rating was explored with regression and ANOVA. Time between teaching event and evaluation was categorized by weeks. Within-teaching-events means and variances in evaluations related to elapsed weeks were compared using repeated-measures ANOVA. With more elapsed weeks, quality mean ratings increased (P<.001) and variability decreased (P<.001); effect sizes were small (average effect size = 0.06). Trends were similar in regression analysis and for data aggregated by event.\nQuestion: Elapsed time between teaching and evaluation: does it matter?",
    "gt": "Summaries of event quality are negligibly impacted by evaluation timing. Future studies should examine the impact of other Web-based evaluation features on evaluation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Because the response to treatment is limited, patients with metastatic renal cell carcinoma (mRCC) typically receive multiple treatments. Guidelines recommend everolimus for patients previously treated with tyrosine kinase inhibitors (TKI) sunitinib or sorafenib. This study evaluated the efficacy of TKI re-treatment in patients with disease progression after a TKI-everolimus sequence. Data were reviewed for patients enrolled in RECORD-1 (Renal Cell Cancer Treatment With Oral RAD001 Given Daily) at French sites. Response, progression-free survival (PFS), and overall survival were evaluated in patients treated with a TKI-everolimus-TKI sequence. Thirty-six patients received a TKI after everolimus: sunitinib in 17 patients, sorafenib in 15, and dovitinib (TKI258) in 4. The response rate with TKI re-treatment was 8%, and the disease-control rate (response plus stable disease) was 75%. The median PFS with each component of the TKI-everolimus-TKI sequence was 10.7 months (95% CI, 1.8-28.5 months), 8.9 months (95% CI, 1.7-34.6 months), and 8.2 months (95% CI, 5.2-11.9 months), respectively. The median overall survival from the start of everolimus was 29.1 months (95% CI 21.1 to not reached months), which suggests a benefit in using TKI in this setting.\nQuestion: Are tyrosine kinase inhibitors still active in patients with metastatic renal cell carcinoma previously treated with a tyrosine kinase inhibitor and everolimus?",
    "gt": "Administration of a TKI-everolimus-TKI sequence may be associated with clinical benefit and should be prospectively investigated.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Reports from the National Wilms' Tumor Study (NWTS) Group on the subject of chest computed tomography (CT) versus chest radiograph for the detection of lung metastases from Wilms tumor are reviewed. Thirty-two patients with lung nodules detected by CT, with negative chest radiographs, were identified. Five patients were excluded from further analysis. Of the remaining 27 patients, 18 were treated as stage IV, receiving therapy with three drugs and lung irradiation; the other nine were treated with less intensive therapy and no lung irradiation. The investigators found no significant difference between the overall survival between these two groups of patients (94% and 88%, respectively). In an earlier study, four of 11 children (36%) with normal chest radiographs and positive chest CT results were treated by ignoring the CT findings. These data compared with a relapse rate of only 20% in a control population. The studies do not statistically address the question of the impact of CT of the chest on survival.\nQuestion: Current controversy: is computed tomography scan of the chest needed in patients with Wilms' tumor?",
    "gt": "All children should have the benefit of the most sensitive imaging available, including CT, to detect tumor spread.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The study included 45 Belgian families with at least one type 1 diabetic child aged six to 18 years (25 girls and 20 boys). Parents completed demographic questionnaires about themselves and their children. Information on type 1 diabetes in their child and the family-medical history were also collected. The number of severe-hypoglycaemic events and hospitalizations for hyperglycaemia were documented for the last 12 months, as were HbA(1c) levels over the last 16 months. Finally, family cohesiveness (FACES-III) and parental alexithymia (TAS-20) were assessed. Hierarchical regression analyses showed that the perception of family cohesion by mothers (P<0.05) was a predictor of the number of severe hypoglycaemic events in the last 12 months. Parents' demographic variables (marital and professional status, P<0.001) and maternal alexithymia (P<0.05) were found to be predictors of the number of hospitalizations for hyperglycaemia in the last 12 months. As for HbA(1c), only two parental demographic variables were significant predictors (marital and professional status, P<0.01 and P<0.05, respectively).\nQuestion: Does family cohesiveness and parental alexithymia predict glycaemic control in children and adolescents with diabetes?",
    "gt": "The maternal perception of family cohesiveness and maternal alexithymia predict on glycaemic control in children and adolescents with diabetes.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Growth reference charts are usually based on measurements of children free from a medical condition that affects growth. However, samples collected during the past decades often contain a large proportion of overweight or obese children. Because obesity increases linear growth, the question arises to what extent the percentiles curves for length/height are affected by the presence of children with overweight or obesity. Data from two cross-sectional samples of 2-year-old to 18-year-old children were analysed: 12,252 Belgian children, measured in 2002-2004, and 6159 Norwegian children, measured in 2003-2006. The LMS method was used to estimate height-for-age curves with and without children considered overweight or obese according to the International Obesity Task Force thresholds. The prevalence of overweight (including obesity) and obesity was 13.0% and 2.8% in the Belgian and 13.8% and 2.3% in the Norwegian sample. Children were taller when overweight (+0.49 and 0.43 SD, in the Belgian and Norwegian sample, respectively) or obese (+0.73 and 0.72 SD in the Belgian and Norwegian sample, respectively). Effect sizes were smaller in younger and older children, which points to an advanced age of maturation as a possible cause. Excluding overweight and obese children had only a minor impact on the growth curves with largest difference in mean height SD scores -0.09 in the Belgian and -0.12 in the Norwegian sample with a corresponding increase of up to 0.5% and 1.2% in number of children>+2 SD.\nQuestion: Should children with overweight or obesity be excluded from height references?",
    "gt": "Current Belgian and Norwegian growth references for length/height were found to be largely unaffected by the current proportion of overweight and obese children. There is, therefore, no need for revised height charts that exclude overweight or obese children.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Working while ill has been found to predict coronary heart disease. We tested if this association was due to triggering. We used a nested case-control study in an occupational cohort to examine sickness absences during a 2-year period immediately before the first coronary event for 133 cases and 928 matched controls without a history of coronary events. Working while ill was defined as no absence despite being unhealthy (suboptimal self-rated health or psychological distress). The odds of a coronary event were not higher for cases who worked while ill than for correspondingly unhealthy controls who took>0 to 14 days of absence per year (OR = 0.62; 95% CI = 0.28 to 1.38). These results were little affected by multiple adjustments.\nQuestion: Does working while ill trigger serious coronary events?",
    "gt": "We found no evidence that working while ill acts as a short-term trigger for coronary events.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Potential lymphatic drainage patterns from cutaneous melanomas of the head and neck are said to be variable and frequently unpredictable. The aim of this article is to correlate the anatomic distribution of pathologically involved lymph nodes with primary melanoma sites and to compare these findings with clinically predicted patterns of metastatic spread. A prospectively documented series of 169 patients with pathologically proven metastatic melanoma was reviewed by analyzing the clinical, operative, and pathologic records. Clinically, it was predicted that melanomas of the anterior scalp, forehead, and face could metastasize to the parotid and neck levels I-III; the coronal scalp, ear, and neck to the parotid and levels I-V; the posterior scalp to occipital nodes and levels II-V; and the lower neck to levels III-V. Minimum follow up was 2 years. There were 141 therapeutic (97 comprehensive, 44 selective) and 28 elective lymphadenectomies (4 comprehensive dissections, 21 selective neck dissections, and 3 cases in which parotidectomy alone was performed). Overall, there were 112 parotidectomies, 44 of which were therapeutic and 68 elective. Pathologically positive nodes involved clinically predicted nodal groups in 156 of 169 cases (92.3%). The incidence of postauricular node involvement was only 1.5% (3 cases). No patient was initially seen with contralateral metastatic disease; however, 5 patients (2.9%) failed in the contralateral neck after therapeutic dissection. In 68% of patients, metastatic disease involved the nearest nodal group, and in 59% only a single node was involved.\nQuestion: Do nodal metastases from cutaneous melanoma of the head and neck follow a clinically predictable pattern?",
    "gt": "Cutaneous malignant melanomas of the head and neck metastasized to clinically predicted nodal groups in 92% of patients in this series. Postauricular and contralateral metastatic node involvement was uncommon.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Numerous predictors of coronary artery bypass grafting (CABG) outcomes have been identified. We aimed to determine whether the duration of surgery independently predicts outcome in patients undergoing CABG. We retrospectively reviewed data from 337 patients (mean age 62 +/- 7 years) who underwent CABG consecutively at our institution between January 2005 and December 2006. Duration of surgery correlated positively with length of both surgical intensive care unit (SICU) stay (r = .147, P = .004) and ventilator support (r = .097, P = .038) in univariate analysis, but only with length of SICU stay (P = .01) in a multivariate logistic regression after confounding factors were controlled for in the model. The regression coefficient was .006; every additional 30 minutes of surgery time was associated with 4.32 more hours of SICU stay. Duration of surgery was not associated with survival (P>.05).\nQuestion: Does the duration of surgery affect outcomes in patients undergoing coronary artery bypass grafting?",
    "gt": "Although duration of surgery did not affect short-term survival after CABG, surgical duration independently predicted length of SICU stays. Efforts to reduce the length of operations may promote more efficient use of hospital resources.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this study is to verify the existence of an association between maternal periodontal disease and pre-term delivery in an unselected population of post-partum Turkish women. This case-control study was conducted on 100 women who gave birth in either a special or a government maternity hospital. The case group consisted of 50 mothers who had delivered an infant before 37 weeks' gestation and weighed under 2500 g. The control group included 50 mothers who had given birth to an infant with a birth weight of more than 2500 g and a gestational age of ≥37 weeks. Data of mothers and infants were collected using medical registers and questionnaires. Clinical periodontal examinations were carried out in six sites on every tooth in the mother's mouth. A participant who presented at least four teeth with one or more sites with a PPD ≥4 mm and CAL ≥3 mm at the same site was considered to have periodontal disease. Statistical methods included parametric and non-parametric tests and multiple logistic regression analysis. There were no statistically significant differences between the cases and controls with regard to periodontal disease and pre-term delivery (OR = 1.48; 95% CI = 0.54-4.06).\nQuestion: Is there a relationship between maternal periodontitis and pre-term birth?",
    "gt": "The findings indicated that maternal periodontitis was not a possible risk factor for pre-term delivery. Further studies with additional clinical trials are needed to explore the possible relationship between periodontal disease and pre-term birth.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The objective of the study was to determine whether a model for predicting vaginal birth after cesarean (VBAC) can also predict the probabilty of morbidity associated with a trial of labor (TOL). Using a previously published prediction model, we categorized women with 1 prior cesarean by chance of VBAC. Prevalence of maternal and neonatal morbidity was stratfied by probability of VBAC success and delivery approach. Morbidity became less frequent as the predicted chance of VBAC increased among women who underwent TOL (P<.001) but not elective repeat cesarean section (ERCS) (P>.05). When the predicted chance of VBAC was less than 70%, women undergoing a TOL were more likely to have maternal morbidity (relative risk [RR], 2.2; 95% confidence interval [CI], 1.5-3.1) than those who underwent an ERCS; when the predicted chance of VBAC was at least 70%, total maternal morbidity was not different between the 2 groups (RR, 0.8; 95% CI, 0.5-1.2). The results were similar for neonatal morbidity.\nQuestion: Can a prediction model for vaginal birth after cesarean also predict the probability of morbidity related to a trial of labor?",
    "gt": "A prediction model for VBAC provides information regarding the chance of TOL-related morbidity and suggests that maternal morbidity is not greater for those women who undergo TOL than those who undergo ERCS if the chance of VBAC is at least 70%.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Although the apolipoprotein E genotype epsilon4 (apoE4) has been associated with high cholesterol levels, whether it is an independent predictor of coronary events is not certain. We measured apoE genotypes in 730 participants in the Baltimore Longitudinal Study of Aging (421 men and 309 women, mean [+/- SD] age of 52+/-17 years) who were free of preexisting coronary heart disease. A proportional hazards regression model was used to study the association between risk factors and the occurrence of coronary events, defined as angina pectoris, documented myocardial infarction by history or major Q waves on the electrocardiogram (Minnesota Code 1:1 or 1:2), or coronary death, adjusted for other risk factors, including total plasma cholesterol level. The apoE4 allele was observed in 200 subjects (27%), including 183 heterozygotes and 17 homozygotes. Coronary risk factor profiles were similar in those with and without apoE4. Coronary events developed in 104 (14%) of the 730 subjects, including 77 (18%) of the 421 men during a mean follow-up of 20 years and 27 (9%) of the 309 women during a mean follow-up of 13 years. Coronary events occurred significantly more frequently in subjects with apoE4 (n = 40, 20%) than in those without this allele (64, 12%, P<0.05). In a multivariate model, apoE4 was an independent predictor of coronary events in men (risk ratio [RR]= 2.9, 95% confidence interval [CI]: 1.8 to 4.5, P<0.0001) but not in women (RR = 0.9, 95% CI: 0.4 to 1.9, P = 0.62).\nQuestion: Is the apoE4 allele an independent predictor of coronary events?",
    "gt": "The apoE4 genotype is a strong independent risk factor for coronary events in men, but not women. The association does not appear to be mediated by differences in total cholesterol levels.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: In recent times, medical schools have committed to developing good communication and history taking skills in students. However, there remains an unresolved question as to which constitutes the best educational method. Our study aims to investigate whether the use of videotape recording is superior to verbal feedback alone in the teaching of clinical skills and the role of student self-assessment on history taking and communication skills. A randomized controlled trial was designed. The study was conducted with 52 of the Dokuz Eylul University Faculty of Medicine second year students. All students' performances of communication and history taking skills were assessed twice. Between these assessments, the study group had received both verbal and visual feedback by watching their video recordings on patient interview; the control group received only verbal feedback from the teacher. Although the self-assessment of the students did not change significantly, assessors' ratings increased significantly for videotaped interviews at the second time.\nQuestion: Is the use of videotape recording superior to verbal feedback alone in the teaching of clinical skills?",
    "gt": "Feedback based on videotaped interviews is superior to the feedback given solely based on the observation of assessors.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Our objective was to assess the impact of disruption by a new 2-week vacation break on outcomes of required third-year clerkships. Mean scores on National Board of Medical Examiners (NBME) clerkship specific clinical science subject (\"subject\") examinations and overall student evaluations were compared for clerkships with the break and those over the previous 3 years without the break. Students were surveyed about the impact of the break on learning and the time spent studying during the break. No significant differences were found in examination scores between clerkships with the break and those without. Overall student clerkship evaluations were significantly different only for the surgery clerkship. The break was regarded more favorably by students on the 8-week than the 6-week clerkships, but student perspectives varied significantly by specialty. The time reported studying varied significantly by specialty and campus. Student comments were predominantly supportive of the break and focused on the advantages of opportunity to relax, spend time with family, and to study. Concerns included forgetting content knowledge, losing skills, and having difficulty regaining momentum on return to the clerkship.\nQuestion: Does a Vacation Break Impact the Outcomes of Required Clinical Clerkships?",
    "gt": "Interruption of clerkships by a 2-week break was not associated with any significant change in subject examination scores or overall student evaluation of the clerkship, despite predominantly positive comments. Significant differences were reported by specialty in student perception of benefit and reported time studying during the break.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether preoperative helical CT angiography (CTA) with three-dimensional (3D) reconstructed images improves outcome in patients with ureteropelvic junction obstruction (UPJO) by identifying crossing vessels that may lead to surgical failure. Twenty-five patients with UPJO underwent imaging with CTA to identify crossing vessels. Patients with crossing vessels or severe hydronephrosis underwent laparoscopic dismembered pyeloplasty. In the absence of crossing vessels, and with>25% renal function on MAG-3 scan, the patient underwent an endopyelotomy. Procedures were assessed as successful by resolution of patient symptoms as well as relief of obstruction on renal scintography. Twenty-seven procedures (14 laparoscopic dismembered pyeloplasties [9 in the setting of a crossing vessel], 11 ureteroscopic endopyelotomies, and two antegrade endopyelotomy procedures) were performed. Follow-up ranged from 2.4 to 40 months (mean 21.6 months). Twenty-three of the primary procedures (92.0%) were successful. Primary laparoscopic pyeloplasty was successful in 100% of patients, while primary endopyelotomy had a success rate of 83.3%. Both secondary procedures were successful rendering the patients unobstructed and pain free. No complications occurred. The sensitivity and specificity of CTA in determining crossing vessels was 78% and 40%, respectively.\nQuestion: Ureteropelvic junction obstruction: does CT angiography allow better selection of therapeutic modalities and better patient outcome?",
    "gt": "Helical CT angiography with 3D reconstructed images provides valuable preoperative information in patients with UPJO scheduled for surgical intervention. This study may be used in selecting patients for proper operative intervention according to the anatomy of crossing vessels to attain high treatment success rates.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The relation between white matter loss (WML) and diabetes is still debated. The aim of this study was to investigate the correlation between typical WML- and diabetes-related magnetic resonance imaging (MRI) findings in a cohort of patients scheduled for carotid endarterectomy (CEA). Ninety-three consecutive patients (mean age 71±9years; male 71) were included in a single-centre retrospective study. All the patients underwent MRI as baseline evaluation prior to CEA. A neuroradiologist blinded to the presence of risk factors calculated WML volume and number of lesions on FLAIR images using a semi-automated segmentation technique. Receiver operating characteristics analysis was performed to search for any association between WML volume and the number of WML lesions. The Mann-Whitney tests were used to determine significant WML differences between diabetic and non-diabetic patients. Logistic regression analysis was performed to evaluate the potential association of other variables. The prevalence of diabetes was 20.4% (n=19). WML volume and number of WML lesions were significantly associated with diabetes (P=0.001). A statistically significant difference in WML volume was found between diabetic and non-diabetic patients (P<0.0001). Only diabetes, among all the investigated variables (WML volume, CAD status, age, smoking status, gender, hypertension, hyperlipidemia, diabetes) was significantly associated with WML (P=0.0001).\nQuestion: Is there an association between leukoaraiosis volume and diabetes?",
    "gt": "Our results demonstrate a strong statistical correlation between diabetes and WML. Future scientific challenges could include the identification of potential therapeutic targets and the creation of dedicated screening protocols for WML in diabetic patients other than the simple measurement of leukoaraiosis total burden.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This matched-paired analysis explores disparities in health-related quality of life (QOL) and common toxicities between African American (AA) and white patients following proton therapy for prostate cancer at our institution. A total of 1536 men with clinically localized prostate cancer were treated from 2006 to 2009 with definitive proton therapy to a median dose of 78 Gy +/- androgen deprivation therapy. A cohort of 92 consecutively treated AA men was matched to a cohort of 92 white men on the basis of National Comprehensive Cancer Network risk category and age. The 2 groups were compared with regard to comorbidities, demographics, and treatment regimen. Differences in genitourinary and gastrointestinal (GI) toxicity according to the Common Terminology Criteria for Adverse Events scale and QOL data from the Expanded Prostate Index Composite 26-question questionnaire were reported. Median follow-up was 2.1 years. Baseline patient and treatment characteristics were similar between the 2 groups with the exception of prostate-specific antigen ≥10 (32% for AAs vs. 20% for whites; P=0.068) and use of androgen deprivation therapy (26% for AAs vs. 21% for whites; P=0.38). No difference in Expanded Prostate Index Composite 26-question sexual summary, urinary incontinence, urinary obstruction, or bowel summary scores was detected between the 2 groups, nor was there a difference in grade 2 or higher GI toxicity (P=0.45). AAs had a statistically nonsignificant higher absolute incidence of late grade 3 genitourinary toxicity (4.4% vs. 0%; P=0.12).\nQuestion: Does Race Influence Health-related Quality of Life and Toxicity Following Proton Therapy for Prostate Cancer?",
    "gt": "After 2 years, there were no disparities in health-related QOL, physician-reported Common Terminology Criteria for Adverse Events GI toxicity, or biochemical relapse. Longer follow-up is needed to confirm these findings.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To explore cultural context for smoking cessation within Chinese communities in Vancouver, and identify opportunities to support development of culturally appropriate resources for cessation. Applied participatory approach involving community members, patients, and key-informants in the design and implementation of the research. Whereas many participants were motivated to quit, their perceptions of desire to do so were not supported by effective interventions and many attempts to quit were unsuccessful.\nQuestion: Does culture or illness change a smoker's perspective on cessation?",
    "gt": "Tobacco control clinics and care providers need to adopt culturally and linguistically relevant interventions to facilitate behavioral modifications and cessation in ethnic minority communities.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Concerns have been raised regarding residual symptoms of caudal segment (L5-S1) degeneration that may affect clinical outcomes or require additional surgery after isolated L4-5 fusion, especially if there is pre-existing L5-S1 degeneration. This study aimed to evaluate the L5-S1 segment after minimally invasive lumbar interbody fusion at the L4-5 segment, as well as the influence of pre-existing L5-S1 degeneration on radiologic and clinical outcomes. This retrospective study evaluated patients with isthmic spondylolisthesis and degenerative spondylolisthesis who underwent mini-open anterior lumbar interbody fusion with percutaneous pedicle screw fixation (PSF) or minimally invasive transforaminal interbody fusion with PSF at the L4-5 segment. The minimum follow-up period was 7 years, and radiographic evaluations were conducted via magnetic resonance imaging, computed tomography, and plain radiography at the 5-year follow-up. Clinical outcomes were assessed using the Visual Analog Score, Oswestry Disability Index, and surgical satisfaction rate. Patients were divided into two groups, those with and without pre-existing L5-S1 degeneration, and their final outcomes and incidence of radiographic and clinical adjacent segment disease (ASD) were compared. Among 70 patients who underwent the procedures at our institution, 12 (17.1%) were lost to follow-up. Therefore, this study evaluated 58 patients, with a mean follow-up period of 9.4 ± 2.1 years. Among these patients, 22 patients had pre-existing L5-S1 degeneration, while 36 patients did not have pre-existing L5-S1 segmental degeneration. There were no significant differences in the clinical outcomes at the final follow-up when the two groups were compared. However, radiographic ASD at L5-S1 occurred in seven patients (12.1%), clinical ASD at L5-S1 occurred in three patients (5.2%), and one patient (1.7%) required surgery. In the group with pre-existing degeneration, L5-S1 degeneration was radiographically accelerated in four patients (18.2%) and clinical ASD developed in one patient (4.5%). In the group without pre-existing degeneration, L5-S1 degeneration was radiographically accelerated in three patients (8.3%) and clinical ASD developed in two patients (5.7%). There were no differences in the incidence of ASD when we compared the two groups.\nQuestion: Does pre-existing L5-S1 degeneration affect outcomes after isolated L4-5 fusion for spondylolisthesis?",
    "gt": "Pre-existing L5-S1 degeneration does not affect clinical and radiographical outcomes after isolated L4-5 fusion.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Varicocelectomy after previous inguinal surgery poses a potential risk of testicular volume loss. To assess the extent to which varicocelectomy can be done without the complication of ipsilateral testis atrophy we present outcomes in adolescent patients with a history of inguinal surgery who underwent ipsilateral varicocelectomy. We retrospectively reviewed patient data from a single urologist practice. Testicular volume was recorded preferentially by ultrasound or, when unavailable, by ring orchidometry. Testicular asymmetry was calculated using the formula, [(right testis volume - left testis volume)/right testis volume] × 100. Symmetry was defined as less than 10% asymmetry. Catch-up growth was defined as resolution of asymmetry. We identified 22 adolescent patients who fit study criteria. The patients underwent a total of 25 varicocelectomies since 3 underwent bilateral repair after previous bilateral inguinal surgery. Initial inguinal surgery included inguinal herniorrhaphy, hydrocelectomy and orchiopexy. Varicocelectomy was done laparoscopically in 17 cases and via open technique in 8 with variations in preservation/sacrifice of the lymphatics and artery. Median ± SD followup was 24.2 ± 18.2 months. After varicocelectomy mean testicular asymmetry decreased from 27.6% to 10.5%. There was no incidence of testicular atrophy postoperatively. The incidence of catch-up growth was 43% with no difference between the artery sparing and the nonartery sparing technique.\nQuestion: Is adolescent varicocelectomy safe after previous inguinal surgery?",
    "gt": "Varicocelectomy with a history of previous inguinal surgery is safe and provides a significant incidence of testicular catch-up growth. Artery sparing vs sacrificing technique did not make a difference in terms of catch-up growth.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Most youth smokers intend to quit, but the majority is neither aware nor interested in most conventional cessation approaches. As such, a critical first step in understanding youth cessation is to better understand the beliefs youth have about different cessation options. This cross-sectional study used self-reported data collected from 26,379 grade 9 to 12 students in Ontario, Canada. We examined both the attitudes of youth smokers toward common smoking cessation approaches and factors associated with intentions to join a school-based cessation program. The majority of youth smokers intend to quit smoking but tend to have negative attitudes toward most formal smoking cessation approaches; Nicotine Replacement Therapy (NRT) was an exception. Among occasional smokers, self-identification as a smoker and being physically active were positively associated with intending to join a school-based cessation program. Having tried to quit smoking at least once in the past year more than doubled the likelihood of being interested in a school-based program among both occasional and daily smokers.\nQuestion: Youth smokers' beliefs about different cessation approaches: are we providing cessation interventions they never intend to use?",
    "gt": "Findings have the potential for informing the development of more effective campaigns for engaging adolescent smokers into smoking cessation treatment. Results also reinforce the need for programmatic innovation within and beyond school settings.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patient satisfaction is an increasing area of interest due to implications of pay for performance and public reporting of results. Although scores are adjusted for patient factors, little is known about the relationship between hospital structure, postoperative outcomes, and patient satisfaction with the hospital experience. Hospitals participating in the University HealthSystem Consortium database from 2011-2012 were included. Patients were restricted to those discharged by general surgeons to isolate surgical patients. Hospital data were paired with Hospital Consumer Assessment of Healthcare Providers and Systems (HCAHPS) results from the Hospital Compare website. Postoperative outcomes were dichotomized based on the median for all hospitals and stratified based on surgical volume. The primary outcome of interest was high on overall patient satisfaction, whereas other HCAHPS domains were assessed as secondary outcomes. Chi square and binary logistic regression analyses were performed to evaluate whether postoperative outcomes or surgical volume more significantly influenced high patient satisfaction. The study population consisted of 171 hospitals from the University HealthSystem Consortium database. High surgical volume was a more important predictor of overall patient satisfaction regardless of hospital complication (P<0.001), readmission (P<0.001), or mortality rates (P = 0.009). Volume was found to play less of a role in predicting high satisfaction on the other HCAHPS domains. Postoperative outcomes were more predictive of high satisfaction with providers, the hospital experience, and environment.\nQuestion: Patient satisfaction: does surgical volume matter?",
    "gt": "High surgical volume more strongly predicted overall patient satisfaction on the HCAHPS survey than postoperative outcomes, whereas volume was less predictive in other HCAHPS domains. Patients may require more specific questioning to identify high quality, safe hospitals.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Oncoplastic breast reduction has been shown to be an effective approach to breast conservation surgery in women with macromastia. Clear surgical margins can be achieved while simultaneously improving symptomatic macromastia and enhancing aesthetic outcomes. Little has been written about postoperative complications after this procedure, beyond the risk of locoregional recurrence. This study aimed to compare the complication profile for oncoplastic breast reduction versus reduction for benign macromastia. A retrospective review of our experience with oncoplastic breast reduction was performed. This represented a consecutive series of 118 patients undergoing bilateral breast reduction during the 7-year study period from March 2005 to March 2012. There were 64 patients identified who underwent oncoplastic breast reduction. Patients were determined to be a good candidate for breast conservation therapy if it was felt that clear surgical margins could be obtained without mastectomy. Postoperative complications (within 6 weeks of surgery) were compared to a control group of 56 patients undergoing reduction for benign macromastia. The associations between complications and potential risk factors were analyzed using logistic regression. Patients undergoing oncoplastic breast reduction and reduction for benign macromastia had some key differences. In general, macromastia patients were younger (mean age, 42.3 vs 57.5 years; P<0.001) and had lower body mass index (mean, 26.1 vs 30.6 kg/m2; P<0.001) compared to those patients having oncoplastic reduction. Within the oncoplastic reduction group, 14 (21.9%) patients had a total of 16 complications; among the benign macromastia group, 9 (16.1%) patients had a total of 10 complications (P = 0.420). On univariate analysis, oncoplastic reduction was not predictive of having a perioperative complication (odds ratio, 1.462; 95% confidence interval, 0.579-3.696; P = 0.422). Body mass index was found to be predictive of having a complication after reduction for either indication (odds ratio, 1.108; 95% confidence interval, 1.018-1.206; P = 0.017). Within the oncoplastic reduction cohort at an average follow-up of 34.6 months (range, 0.3-90.3 months), 5 (7.9%) patients developed locoregional recurrence and 2 patients developed distant metastasis.\nQuestion: A Comparative Retrospective Analysis of Complications After Oncoplastic Breast Reduction and Breast Reduction for Benign Macromastia: Are These Procedures Equally Safe?",
    "gt": "Compared with reduction mammoplasty for benign macromastia, a widely accepted procedure, patients undergoing oncoplastic breast reduction were equally likely to have a postoperative complication. Elevated body mass index was shown to be a statistically significant predictor of having a complication after reduction for either indication. Overall complication rates were acceptably low for both procedures.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Mast cells (MCs) are multifunctional immune cells that produce a number of vasoactive or thromboactive mediators. Elevated numbers of human heart MCs are observed in the shoulder regions of coronary atherosclerotic plaques, suggesting that they play a role in plaque rupture. Cardiac MC degranulation after myocardial ischemia has been documented in animal models. Cardiac MCs are highly profibrinolytic cells and release tryptase, their specific protease, after ischemic events. Mast cell activation and release of tryptase may differentiate among patients with acute coronary syndromes (ACS), potentially determining the clinical course of ACS. Tryptase levels may indirectly reflect the fibrinolytic status of patients. Mast cell activation after ACS was estimated in 10 controls and 52 patients by measuring the serum levels of tryptase in the acute phase, at 2 weeks, and at 3 months after the ACS episode. Total tryptase levels were determined by using the UniCAP system and analyzed with respect to the patients' clinical types of ACS on admission (ACS with persistent ST-segment elevation on electrocardiogram or with ST-segment depression). Significant differences in serum tryptase levels between the groups were found, with higher serum tryptase concentrations in the ST-segment depression group in the acute phase, and at follow-up.\nQuestion: Tryptase levels in patients after acute coronary syndromes: the potential new marker of an unstable plaque?",
    "gt": "Serum tryptase concentration differences among patients with distinct types of ACS may indicate a more important role of human heart MCs in ACS with ST-segment depression pathogenesis. To our knowledge, this is the first report indicating that serum tryptase levels may differentiate patients with distinct types of ACS.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To test women's ability to recall their past binging and purging behaviors. Ten-year follow-up study of women who had participated in a cross-sectional survey during college. In 1982, a sample of freshman and senior women at a large university in the Boston area were questioned about their weight, dieting history, bulimic symptoms, and eating patterns, attitudes, and concerns. In 1992, all subjects who responded to the 1982 survey were followed up to assess changes in bulimic symptoms and ability to recall past behaviors. Among the 476 women who responded to both surveys, the percentage in 1992 who reported having ever binged and/or purged was less than the percentage in 1982, indicating that the recall of past behaviors was less than perfect. Denial in 1992 of ever having engaged in the behaviors ranged from 22% among the women who were self-inducing vomiting in 1982 to 64% among the women who had reported current fasting or strict dieting in 1982. Recall of past behaviors in 1992 was better among the women who had been current bingers or purgers in 1982.\nQuestion: Disordered eating: can women accurately recall their binging and purging behaviors 10 years later?",
    "gt": "Our results demonstrate that ability to recall past binging and purging is only modest. Therefore to better understand the mental and physical health consequences of these behaviors this information should be collected prospectively.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Despite the widely accepted view that Helicobacter pylori is the most important cause of peptic ulcer disease, recent studies have suggested that the microbe protects against nonsteroidal anti-inflammatory drug (NSAID)-associated gastroduodenal lesions and promotes ulcer healing. We investigated the effects of H. pylori eradication on the healing of NSAID-associated bleeding peptic ulcers. Chronic NSAID users presenting with peptic ulcer haemorrhage underwent endoscopy to secure haemostasis and to document H. pylori infection by rapid urease test and culture. They were prospectively randomized to receive either omeprazole (20 mg once daily) for 8 weeks or a 1-week course of triple therapy (bismuth subcitrate 120 mg, tetracycline 500 mg, metronidazole 400 mg, all given four times daily) plus omeprazole (20 mg once daily) for 8 weeks. Endoscopy was repeated after 8 weeks. Final H. pylori status was determined by a 13C-urea breath test that was performed at least 4 weeks after discontinuation of omeprazole. 195 H. pylori-infected NSAID users, complicated by bleeding ulcers, were randomized to receive omeprazole alone (102) or triple therapy plus omeprazole (93). 174 patients returned for second endoscopy at 8 weeks (91 in the omeprazole group, 83 in the triple therapy group). Urea breath test was negative in 14% in the omeprazole group vs. 92% in the triple therapy group (P<0.001). Complete ulcer healing was achieved in 88 (97%) patients in the omeprazole group and 77 (93%) in the triple therapy group (P=0. 31). On intention-to-treat analysis, ulcers were healed in 86% of the omeprazole group and 83% of the triple therapy group (P=0.50). There was no significant difference in the healing rates of gastric or duodenal ulcers between the two groups.\nQuestion: Does eradication of Helicobacter pylori impair healing of nonsteroidal anti-inflammatory drug associated bleeding peptic ulcers?",
    "gt": "Eradication of H. pylori did not impair the healing of NSAID-associated bleeding peptic ulcers.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Traits and mental states are considered to be inter-related parts of theory of mind. Attribution research demonstrates the influential role played by traits in social cognition. However, there has been little investigation into how individuals with autism spectrum disorders (ASD) understand traits. The ability of individuals with ASD to infer traits from descriptions of behavior was investigated by asking participants to read trait-implying sentences and then to choose one of two words that best related to the sentence. In Experiment 1, individuals with ASD performed similarly to matched controls in being faster at choosing the trait in comparison to the semantic associate of one of the words in the sentence. The results from Experiments 1 and 2 provided converging evidence in suggesting that inferring traits from textual descriptions of behavior occurs with relatively little effort. The results of Experiment 3 suggested that making trait inferences took priority over inferring actions or making semantic connections between words.\nQuestion: Do individuals with autism spectrum disorders infer traits from behavior?",
    "gt": "Individuals with ASD infer traits from descriptions of behavior effortlessly and spontaneously. The possibility of trait inference being a spared socio-cognitive function in autism is discussed.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: No evidence addresses the effectiveness of patient-centered cultural competence training in non-Western settings. To examine whether a patient-centered cultural competency curriculum improves medical students' skills in eliciting the patients' perspective and exploring illness-related social factors. Fifty-seven medical students in Taiwan were randomly assigned to either the control (n = 27) or one of two intervention groups: basic (n = 15) and extensive (n = 15). Both intervention groups received two 2-hour patient-centered cultural competency workshops. In addition, the extensive intervention group received a 2-hour practice session. The control group received no training. At the end of the clerkship, all students were evaluated with an objective structured clinical examination (OSCE). Students in the extensive intervention group scored significantly higher than the basic intervention and control groups in eliciting the patient's perspective (F = 18.38, p<0.001, eta(2) = 0.40). Scores of both intervention groups were significantly higher than the control group in the exploring social factors (F = 6.66, p = 0.003, eta(2) = 0.20).\nQuestion: Cross-cultural medical education: can patient-centered cultural competency training be effective in non-Western countries?",
    "gt": "Patient-centered cultural competency training can produce improvement in medical students' cross-cultural communication skills in non-Western settings, especially when adequate practice is provided.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Low levels of physical activity (PA) and poor fitness tend to predict a decline in mobility. The current study investigated whether PA modifies the predictive value of health-related fitness (HRF) tests on difficulty in walking 2 km (WD). PA was assessed by self-reported questionnaires in 1990 and 1996. Subjects age 55 to 69 years and free of self-reported WD participated in assessment of HRF in 1996. Occurrence of WD was assessed by questionnaire in 2002 (n=537). There were no statistically significant interactions between PA and HRF tests; thus, PA and HRF were both independent predictors of WD. Regardless of the PA level, the subjects in the poorest performing third in each HRF test had higher risk of WD than the subjects in the best performing third.\nQuestion: Does physical activity affect the predictive value of health-related fitness tests on walking difficulty?",
    "gt": "PA and HRF seemed to be independent predictors of WD, although the association of PA with WD was weaker than the association of HRF. Thus, PA did not modify the predictive value of HRF on WD.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To study the influence of continuous administration of heparin on platelet function in intensive care patients. Prospective, serial investigation. Clinical investigation on a surgical and neurosurgical intensive care unit in a university hospital. The study included 45 patients: 15 postoperative with patients sepsis (Acute Physiology and Chronic Health Evaluation II score between 15 and 25), 15 trauma patients (Injury Severity Score 15 to 25), and 15 neurosurgical patients. Management of the patients was carried out according to the guidelines for modern intensive care therapy. Sepsis and trauma patients received standard (unfractionated) heparin continuously [aim: an activated partial thromboplastin time (aPTT) approximately 2.0 times normal value; sepsis-heparin and trauma-heparin patients], whereas neurosurgical patients received no heparin (neurosurgical patients). From arterial blood samples, platelet aggregation was measured by the turbidimetric method. Platelet aggregation was induced by adenosine diphosphate (ADP; 2.0 mumol/l), collagen (10 micrograms/ml), and epinephrine (25 mumol/l). Measurements were carried out on the day of diagnosis of sepsis or 12 h after hemodynamic stabilization (trauma and neurosurgery patients) (baseline) and during the next 5 days at 12.00 noon. Standard coagulation parameters [platelet count and fibrinogen and antithrombin III (AT III) plasma concentrations] were also monitored. Heparin 4-10 U/kg per h (mean dose: approximately 500 U/h) was necessary to reach an aPTT of about 2.0 times normal. Platelet count was highest in the neurosurgical patients, but it did not decrease after heparin administration to the trauma and sepsis patients. AT III and fibrinogen plasma levels were similar in the three groups of patients. In the sepsis group, platelet aggregation variables decreased significantly (e.g., epinephrine-induced maximum platelet aggregation:-45 relative % from baseline value). Platelet function recovered during the study and even exceeded baseline values (e.g., ADP-induced maximum platelet aggregation: +42.5 relative % from baseline value). Continuous heparinization did not blunt this increase of platelet aggregation variables. In the heparinized trauma patients, platelet aggregation variables remained almost stable and were no different to platelet aggregation data in the untreated neurosurgical patients.\nQuestion: Does continuous heparinization influence platelet function in the intensive care patient?",
    "gt": "Continuous administration of heparin with an average dose of approximately 500 U/h did not negatively influence platelet function in the trauma patients. Recovery from reduced platelet function in the sepsis group was not affected by continuous heparinization. Thus, continuous heparinization with this dose appears to be safe with regard to platelet function in the intensive care patient.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Hyperuricemia is commonly associated with obesity, glucose intolerance, hypertension, dyslipidemia, and atherosclerotic cardiovascular disease. The resemblance of the metabolic syndrome and hyperuricemia has led to the suggestion that hyperuricemia is a part of the metabolic syndrome. The purpose of this study is to examine the contribution of uric acid (UA) as an additional component of the metabolic syndrome in middle-aged men. In total, 393 male participants, aged 45-60 years, were recruited from a professional health evaluation program. Anthropometric measurements and blood pressure (BP) were taken after an overnight fast. Fasting blood samples were collected for the measurements of glucose, UA, and lipid profile. Logistic regression models were fitted to examine the relationship between UA and the diagnosis of metabolic syndrome. Factor analysis was performed to explore the relationship between UA and the components of the metabolic syndrome. The diagnosis of the metabolic syndrome was significantly associated with waist circumference (WC), glucose, triglycerides (TG), high-density lipoprotein cholesterol (HDL-C), systolic BP, and liver enzyme levels, but not associated with UA levels. The sensitivity of hyperuricemia (serum UA>or = 7.0 mg/dL) for the diagnosis of the metabolic syndrome was 58.0% and the specificity was 55.3%. In factor analysis, UA aggregated with body mass index, WC, glucose, log TG, and HDL-C as a metabolic factor. Systolic and diastolic BP were loaded on a second factor separately. The model loaded with UA explained a similar proportion of the total variance (56.9%), as did the model loaded without UA (62.5%).\nQuestion: Is hyperuricemia another facet of the metabolic syndrome?",
    "gt": "Our results suggest that the contribution of UA as an additional component of the syndrome seems to be insignificant. We propose that hyperuricemia might not be an important facet for the understanding of the underlying structure of the metabolic syndrome.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The effect of post-transplant maintenance tyrosine kinase inhibitors (TKIs) on the outcomes of allogeneic hematopoietic stem cell transplantation in high-risk Philadelphia chromosome-positive (Ph(+)) leukemia remains unknown. A retrospective analysis that included allograft recipients with accelerated phase and blast phase chronic myeloid leukemia or Ph(+) acute lymphoblastic leukemia who had received post-transplant maintenance TKI therapy from 2004 to 2014. A total of 26 patients, 9 with accelerated phase/blast phase CML and 17 with Ph(+) acute lymphoblastic leukemia, received maintenance post-transplant therapy with imatinib, dasatinib, nilotinib, or ponatinib. The TKI was selected according to the pretransplantation TKI response, anticipated toxicities, and ABL1 domain mutations, when present. Newer generation TKIs were initiated at a ≥ 50% dose reduction from the standard pretransplantation dosing to limit the toxicities and avoid therapy interruptions. TKIs were started a median of 100 days (range, 28-238 days) after transplantation and were administered for a median of 16 months (range, 8 days to 105 months). Eight patients discontinued therapy because of adverse events. With a median follow-up of 3.6 years (range, 4 months to 8.7 years), the 5-year relapse-free survival rate was 61%. All 3 patients who developed a relapse underwent successful salvage treatment and remained disease-free. The 5-year overall survival rate was 78%.\nQuestion: Does Post-Transplant Maintenance Therapy With Tyrosine Kinase Inhibitors Improve Outcomes of Patients With High-Risk Philadelphia Chromosome-Positive Leukemia?",
    "gt": "Maintenance TKI therapy after transplantation is feasible and might reduce the incidence of relapses and improve outcomes after allogeneic hematopoietic stem cell transplantation for patients with high-risk Ph(+) leukemia.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Wine glass size can influence both perceptions of portion size and the amount poured, but its impact upon purchasing and consumption is unknown. This study aimed to examine the impact of wine glass size on wine sales for on-site consumption, keeping portion size constant. In one establishment (with separate bar and restaurant areas) in Cambridge, England, wine glass size (Standard; Larger; Smaller) was changed over eight fortnightly periods. The bar and restaurant differ in wine sales by the glass vs. by the bottle (93 % vs. 63 % by the glass respectively). Daily wine volume purchased was 9.4 % (95 % CI: 1.9, 17.5) higher when sold in larger compared to standard-sized glasses. This effect seemed principally driven by sales in the bar area (bar: 14.4 % [3.3, 26.7]; restaurant: 8.2 % [-2.5, 20.1]). Findings were inconclusive as to whether sales were different with smaller vs. standard-sized glasses.\nQuestion: Does wine glass size influence sales for on-site consumption?",
    "gt": "The size of glasses in which wine is sold, keeping the portion size constant, can affect consumption, with larger glasses increasing consumption. The hypothesised mechanisms for these differential effects need to be tested in a replication study. If replicated, policy implications could include considering glass size amongst alcohol licensing requirements.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We recently showed that diminished motor cortical excitability is associated with high levels of post-stroke fatigue. Motor cortex excitability impacts movement parameters such as reaction and movement times. We predicted that one or both would be influenced by the presence of post-stroke fatigue. 41 first-time stroke survivors (high fatigue n=21, Fatigue Severity Scale 7 (FSS-7) score>5; low fatigue n=20, FSS-7 score<3) participated in the study. Movement times, choice and simple reaction times were measured in all participants. A three way ANOVA with fatigue (high and low), task (movement time, simple reaction time and choice reaction time) and hand (affected and unaffected) as the three factors, revealed a significant difference between affected (but not unaffected) hand movement times in the high compared to low fatigue groups. Reaction times, however, were not different between the high-fatigue and low-fatigue groups in either the affected or unaffected hand.\nQuestion: Post-stroke fatigue: a problem of altered corticomotor control?",
    "gt": "Previously, we showed that motor cortex excitability is lower in patients with high post-stroke fatigue. Our current findings suggest that post-stroke fatigue (1) is a problem of movement speed (possibly a consequence of diminished motor cortex excitability) and not movement preparation, and (2) may have a focal origin confined to the lesioned hemisphere. We suggest that low motor cortex excitability in the lesioned hemisphere is a viable therapeutic target in post-stroke fatigue.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Before being communicated to the caregiver, critical laboratory values are verified by repeat testing to ensure their accuracy and to avoid reporting false or erroneous results. To determine whether 2 testing runs offered any advantage over a single testing run in ensuring accuracy or in avoiding the reporting of false or erroneous results. Within the hematology laboratory, 5 tests were selected: hemoglobin level, white blood cell count, platelet count, prothrombin time, and activated partial thromboplastin time. A minimum of 500 consecutive critical laboratory test values were collected retrospectively for each test category. The absolute value and the percentage of change between the 2 testing runs for each critical value were calculated and averaged for each test category and then compared with our laboratory's preset, acceptable tolerance limits for reruns. The mean results obtained for the absolute value and the percentage of change between the testing runs were 0.08 g/dL (1.4%) for hemoglobin levels, 50 cells/µL (10.2%) for white blood cell counts, 1500 cells/µL (9.9%) for platelet counts, 0.7 seconds (1.4%) for prothrombin time, and 5.1 seconds (4.4%) for activated partial thromboplastin time (all within our laboratory's acceptable tolerance limits for reruns). The percentage of specimens with an absolute value or a mean percentage of change outside our laboratory's acceptable tolerance limits for reruns ranged between 0% and 2.2% among the test categories. No false or erroneous results were identified between the 2 testing runs in any category.\nQuestion: Does routine repeat testing of critical values offer any advantage over single testing?",
    "gt": "Routine, repeat testing of critical hemoglobin level, platelet count, white blood cell count, prothrombin time, and activated partial thromboplastin time results did not offer any advantage over a single run.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this study was to assess whether changes in Cystatin C (CyC) after 48 h post contrast media exposure was a reliable indicator of acute kidney injury and the validity of a risk scoring tool for contrast-induced acute kidney injury (CI-AKI). We enrolled 121 patients for whom diagnostic coronary angiography were planned. The risk score for CI-AKI was calculated and serum creatinine (sCr) and CyC were measured before and 48 h post coronary angiography. CyC and sCr based AKI was calculated as a 25% increase from baseline within 48 h from contrast media exposure. Mean serum CyC and creatinine concentrations were 0.88 ± 0.27 mg/dL and 0.79 ± 0.22 mg/dL, respectively before the procedure and 1.07 ± 0.47 mg/dL and 0.89 ± 0.36 mg/dL, respectively 48 h after contrast media exposure (P<0.001). CyC based AKI occurred in 45 patients (37.19 %) and sCr based AKI occurred in 20 patients (16.52%) after the procedure. Mean risk score was found to be 4.00 ± 3.478 and 3.60 ± 4.122 for CyC based AKI and sCr based AKI, respectively and was significantly increased in CyC based AKI group (P<0.001).\nQuestion: Is cystatin-C superior to creatinine in the early diagnosis of contrast-induced nephropathy?",
    "gt": "CyC measured 48 h after contrast media exposure may be a more sensitive indicator of CI-AKI relative to creatinine and Mehran risk scoring is in good correlation with CyC increase.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The growing number of human immunodeficiency virus type 1 (HIV-1) infections worldwide and the increasing use of immunosuppressive modalities for organ transplantation have contributed to an epidemic of Kaposi's sarcoma (KS), which has been etiologically linked to human herpesvirus 8 (HHV8) or KS-associated virus. Since the onset of the acquired immunodeficiency syndrome epidemic, inflammation has been recognized as an essential component of KS pathology. HHV8 bears a gene (K1) encoding a transmembrane protein with an immunoreceptor tyrosine-based activation motif. This motif is present in receptors that mediate inflammation. To dissect the cellular effects of K1 function and the eventual role of K1 in KS, we developed a cell model for studying K1 expression. K1 was cloned from BC-3 lymphoma cells. To monitor transcriptional activation, K1 was coexpressed with plasmids containing luciferase under control of various promoters. K1 expression was monitored by indirect immunofluorescence and by combined immunoprecipitation/immunoblot analysis. Inflammatory cytokines were measured by enzyme-linked immunosorbent assay. Cellular transfection of the K1 gene induced reporter expression under control of nuclear factor-kappa B (NF-kappaB), which controls the transcription of numerous proteins involved in inflammation. Treatment of cells with aspirin, an agent that targets this intracellular pathway and blocks cell inflammatory responses, blocked K1-induced NF-kappaB-dependent promoter activity. When a second KS cofactor, i.e., the HIV-1-transactivating gene tat, was coexpressed with K1, we observed an additive effect on NF-kappaB-dependent transcription. K1 transfection stimulated the secretion of cytokines interleukin (IL) 6, granulocyte-macrophage colony-stimulating factor, and IL-12. Cells treated with the conditioned media of K1 transfectants exhibited similar characteristics of K1 transfectants, indicating that a paracrine loop was being activated.\nQuestion: Human herpesvirus 8 K1-associated nuclear factor-kappa B-dependent promoter activity: role in Kaposi's sarcoma inflammation?",
    "gt": "Thus, K1 may activate cells in which it is expressed, as well as other cells in a paracrine manner. K1 cooperates in signaling with HIV-1 Tat, suggesting that both of the proteins from these viruses converge to reach an enhanced level of inflammation that may underlie progressive KS.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To compare virologic success between adult patients on tenofovir (TDF) and zidovudine (AZT)-containing first-line antiretroviral (ART) regimens in 10 rural clinics in Lesotho, Southern Africa. Multicentre cross-sectional study, patients ≥16 years, on first-line ART ≥6 months, receiving AZT/lamivudine (3TC) or TDF/3TC combined with efavirenz (EFV) or nevirapine (NVP). Patient characteristics and clinical/therapeutic history were collected on the day of blood draw for viral load (VL). Analysis was stratified for non-nucleoside reverse transcriptase inhibitor (EFV or NVP). A logistic regression model weighted for patients' baseline characteristics was used to assess the likelihood of virologic success (<80 copies/ml) in patients with TDF- as compared to AZT-backbones. In total 1539 patients were included in the analysis. Most were clinically and immunologically stable (clinical failure: 2.7% (AZT) and 2.8% (TDF); immunological failure: 4.6% (AZT) and 4.8% (TDF)). In EFV-based regimens (n = 1162), TDF was significantly associated with higher rates of virologic suppression than AZT (93.8% vs. 88.1%; weighted odds ratio: 2.15 (95% CI: 1.29-3.58; P = 0.003)). In NVP-based regimens, a similar trend was observed, but not significant (89.4% vs. 86.7%; 1.99 (0.83-4.75, P = 0.121)).\nQuestion: Is zidovudine first-line therapy virologically comparable to tenofovir in resource-limited settings?",
    "gt": "These findings support the WHO recommendation to use TDF/3TC/EFV as first-line regimen. They do, however, not support the recommendation that patients who are clinically stable on AZT should continue on this first-line regimen.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Since the introduction of randomized controlled trials (RCT) in clinical research, there has been discussion of whether enrolled patients have worse or better outcomes than comparable non-participants. To investigate whether very preterm infants randomized to a placebo group in an RCT have equivalent neurodevelopmental outcomes to infants who were eligible but not randomized (eligible NR). In the course of an RCT investigating the neuroprotective effect of early high-dose erythropoietin on the neurodevelopment of very preterm infants, the outcome data of 72 infants randomized to placebo were retrospectively compared with those of 108 eligible NR infants. Our primary outcome measures were the mental (MDI) and psychomotor (PDI) developmental indices of the Bayley Scales of Infant Development II at 24 months of corrected age. The outcomes of the two groups were considered equivalent if the confidence intervals (CIs) of their mean differences fitted within our ±5-point margin of equivalence. Except for a higher socioeconomic status of the trial participants, both groups were balanced for most perinatal variables. The mean difference (90% CI) between the eligible NR and the placebo group was -2.1 (-6.1 and 1.9) points for the MDI and -0.8 (-4.2 and 2.5) points for the PDI. After adjusting for the socioeconomic status, maternal age and child age at follow-up, the mean difference for the MDI was -0.5 (-4.3 and 3.4) points.\nQuestion: Randomized controlled trials in very preterm infants: does inclusion in the study result in any long-term benefit?",
    "gt": "Our results indicate that the participation of very preterm infants in an RCT is associated with equivalent long-term outcomes compared to non-participating infants.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The purpose of this study was to evaluate the diagnostic value of computer-aided diagnosis (CADx) in differentiating angiomyolipoma without visible fat from renal cell carcinoma (RCC) on MDCT. The study included 406 patients who had 47 angiomyolipomas without visible fat and 359 RCCs smaller than 4 cm, all of which were diagnosed on the basis of findings from nephrectomy or percutaneous biopsy performed at our institution between 2000 and 2011. MDCT (slice thickness, 2.5 mm for corticomedullary phase image or 5 mm for the other phase images) and clinical findings were blindly reviewed by two radiologists in a single session. At the time the study was performed, radiologist 1 had 8 years of experience, and radiologist 2 had 18 years of experience. On the basis of the MDCT and clinical findings, CADx classified renal tumors as angiomyolipoma and RCC, and each radiologist independently recorded the probability score (0-5) for angiomyolipoma. The accuracy of CADx versus radiologists in diagnosing angiomyolipoma was compared using ROC analysis. Interobserver agreement between the two radiologists was evaluated. CADx yielded an area under the curve (Az) value of 0.949, which was greater than the Az values yielded by radiologists 1 and 2 (0.872 and 0.782, respectively; p<0.05). In addition, the Az value for radiologist 1 was greater than that for radiologist 2 (p = 0.01). CADx with a threshold of -1.0085 showed greater sensitivity than radiologist 1 and greater sensitivity, specificity, and accuracy than radiologist 2 (p<0.05). The interobserver agreement for the differentiation was fair (κ = 0.289).\nQuestion: Does Computer-Aided Diagnosis Permit Differentiation of Angiomyolipoma Without Visible Fat From Renal Cell Carcinoma on MDCT?",
    "gt": "CAD can improve diagnostic performance in differentiating angiomyolipoma from RCC. The diagnostic performance of radiologists is variable according to the clinical experience and physical and emotional states of the radiologists.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A direct comparison of outcomes between moderate mixed aortic valve disease (MAVD) and isolated aortic stenosis (AS) or aortic regurgitation (AR) has not been performed, making evidence-based recommendations difficult in patients with MAVD. This study sought to determine adverse event (AE) occurrence (the primary endpoint), defined as New York Heart Association functional class III/IV symptoms, aortic valve replacement, or cardiac death, and to compare AE rates between MAVD and isolated AS or AR. Asymptomatic patients were identified with moderate MAVD and an ejection fraction ≥50% and were followed at Mayo Clinic from 1994 to 2013. Moderate MAVD was defined as a combination of moderate AS and moderate AR. Age- and sex-matched control groups were selected with isolated moderate AR (n = 117), moderate AS (n = 117), or severe AS (n = 117). At 9.1 ± 4.2 years of follow-up, patients with moderate MAVD (n = 251) had a mean age of 63 ± 11 years, 73% were male, and 38% had bicuspid valve. AE occurred in 193 (77%) patients in this group, including symptom development (69%), aortic valve replacement (67%), and cardiac death (4%). Predictors of AE were older age (hazard ratio [HR]: 1.71 per decade; 95% confidence interval [CI]: 1.38 to 1.97 per decade; p = 0.001), and relative wall thickness>0.42 (HR: 2.01; 95% CI: 1.86 to 2.33; p = 0.002). AE rates were similar in the MAVD and severe AS group (71% vs. 68% at 5 years; p = 0.49), but were significantly higher compared with the moderate AS and AR groups.\nQuestion: Outcomes in Moderate Mixed Aortic Valve Disease: Is it Time for a Paradigm Shift?",
    "gt": "MAVD patients had outcomes comparable to those with severe AS, and preserved ejection fraction and should be monitored closely for symptoms.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Two methods to assess liver echogenicity were compared. Liver/kidney echogenicity ratio was measured in 41 persons with the ultrasound software and visually graded by two radiologists and a radiographer. These echogenicity ratios and grades were related to risk factors for fatty liver and to liver enzyme levels. These determinants explained 55% of the radiologists' mean grades, 14% of the radiographer's and 31% of the measured echogenicity ratios.\nQuestion: Liver echogenicity: measurement or visual grading?",
    "gt": "Radiologists' visual gradings correlated best with the indirect determinants of early liver pathology. Computerized measurements may be inferior to visual grading due to the lack of holistic tissue diagnostics.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Data on the frequency of resolution of anaphylaxis to foods are not available, but such resolution is generally assumed to be rare. To determine whether the frequency of negative challenge tests in children with a history of anaphylaxis to foods is frequent enough to warrant challenge testing to re-evaluate the diagnosis of anaphylaxis, and to document the safety of this procedure. All children (n=441) who underwent a double-blind, placebo-controlled food challenge (DBPCFC) between January 2003 and March 2007 were screened for symptoms of anaphylaxis to food by history. Anaphylaxis was defined as symptoms and signs of cardiovascular instability, occurring within 2 h after ingestion of the suspected food. Twenty-one children were enrolled (median age 6.1 years, range 0.8-14.4). The median time interval between the most recent anaphylactic reaction and the DBPCFC was 4.25 years, range 0.3-12.8. Twenty-one DBPCFCs were performed in 21 children. Eighteen of 21 children were sensitized to the food in question. Six DBPCFCs were negative (29%): three for cows milk, one for egg, one for peanut, and one for wheat. In the positive DBPCFCs, no severe reactions occurred, and epinephrine administration was not required.\nQuestion: Should children with a history of anaphylaxis to foods undergo challenge testing?",
    "gt": "This is the first study using DBPCFCs in a consecutive series of children with a history of anaphylaxis to foods, and no indications in dietary history that the food allergy had been resolved. Our study shows that in such children having specific IgE levels below established cut-off levels reported in other studies predicting positive challenge outcomes, re-evaluation of clinical reactivity to food by DBPCFC should be considered, even when there are no indications in history that anaphylaxis has resolved. DBPCFCs can be performed safely in these children, although there is a potential risk for severe reactions.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Venous thromboembolism is a common source of morbidity and mortality but a variety of preventative measures are available. To audit the current practice of thromboprophylaxis and compare against published protocols. Three-hundred and seventy-six (376) surgical patients were surveyed prospectively. A Performa was completed recording the presence of up to 11 risk factors. A risk score was calculated and the use of specific thromboprophylatic measures identified. Heparin thromboprophylaxis was widely used, eight patients (who were on aspirin therapy) failed to receive any prophylaxis (risk factors 4-6). In addition there were 60 patients at low risk (risk score<2) received LMWH from which they were unlikely to benefit.\nQuestion: Risk-based evaluation of thromboprophylaxis among surgical inpatients: are low risk patients treated unnecessarily?",
    "gt": "Thromboembolic prophylaxis is widely but unselectively applied. Adoption of a risk: benefit ratio approach should ensure those who would benefit from thromboprophylaxis are adequately treated while those in whom thromboprophylaxis is not indicated are spared unnecessary therapy.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Hispanic-Americans are the fastest growing minority group in the United States. Many studies have compared prostate cancer treatment outcomes between black and white men, but few such studies have been done with Hispanic men. We compared clinical and pathological features as well as the treatment failure rate of radical prostatectomy in contemporaneously treated groups of Hispanic and white men with prostate cancer. Between 1995 and 2002, 136 Hispanic men and 315 white men underwent radical prostatectomy. Treatment failure was defined as having a prostate specific antigen (PSA) of 0.2 or greater more than 8 weeks after surgery or receiving any adjuvant therapy. Known predictors of failure and race were evaluated for their ability to predict treatment failure. Median followup was 32 months for Hispanic and 36 months for white patients. Hispanic men were older, had a higher percentage of abnormal rectal examinations, Gleason 7 tumors and preoperative PSA levels greater than 10. Preoperative PSA, specimen Gleason score, pathological stage and surgical margin were all strongly associated with treatment failure (p<0.001). Despite differences in clinical characteristics, overall failure rates did not differ between Hispanic and white men (18.7% vs 17.8%). The odds ratio for treatment failure for Hispanic relative to white men after adjusting for the previously mentioned risk factors was 0.87 (95% CI [0.44, 1.68], p = 0.670).\nQuestion: Is Hispanic race an important predictor of treatment failure following radical prostatectomy for prostate cancer?",
    "gt": "This study shows that Hispanic race does not influence the treatment failure rate of radical prostatectomy in contemporaneously treated patients with prostate cancer at 1 institution. To our knowledge this study represents the largest of its kind, but longer followup and other confirmatory studies are needed.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Anemia in chronic heart failure (CHF) is common, varying in prevalence between 14.4% and 55%, and is more frequent in patients with more severe heart failure. Patients with CHF who have anemia have a poorer quality of life, higher hospital admission rates, and reduced exercise tolerance. We explored the relation between hematinic levels and hemoglobin (Hb) levels and exercise tolerance in a group of patients with CHF. We analyzed data from 173 patients with left ventricular systolic dysfunction (LVSD), 123 patients with symptoms of heart failure, but preserved left ventricular (LV) systolic function (\"diastolic dysfunction\"), and 58 control subjects of similar age. Each underwent echocardiography, a 6-minute walk test, and blood tests for renal function and Hb and hematinic levels (vitamin B12, iron, and folate). We classified patients as having no anemia (Hb level>12.5 g/dL), mild anemia (Hb level from 11.5-12.5 g/dL), or moderate anemia (Hb level<11.5 g/dL). Of patients with LVSD, 16% had moderate anemia and 19% had mild anemia. Of patients with preserved LV function, 16% had moderate anemia and 17% had mild anemia. Four control subjects had a Hb level<12.5 g/dL. Of all patients, 6% were vitamin B12 deficient, 13% were iron deficient, and 8% were folate deficient. There was no difference between patients with LVSD and the diastolic dysfunction group. In patients with LVSDS, the average Hb level was lower in New York Heart Association class III than classes II and I. The distance walked in 6 minutes correlated with Hb level in both groups of patients with CHF (r = 0.29; P<.0001). Patients with anemia achieved a lower pVO2 (15.0 [2.3] vs 19.5 [4.4], P<.05). Peak oxygen consumption correlated with Hb level (r = 0.21, P<.05) in the patients, but not in the control subjects. In patients with anemia, the mean creatinine level was higher than in patients with a Hb level>12.5 g/dL, but there was no clear relationship with simple regression. Hematocrit level and mean corpuscular volume were not different in the patients with diastolic dysfunction, patients with LV dysfunction, or the control subjects. Hematocrit levels were not influenced by diuretic dose. Patients with anemia were not more likely to be hematinic deficient than patients without anemia.\nQuestion: Are hematinic deficiencies the cause of anemia in chronic heart failure?",
    "gt": "Patients with symptoms and signs of CHF have a high prevalence of anemia (34%) whether they have LV dysfunction or diastolic dysfunction, but few patients have hematinic deficiency. Hemoglobin levels correlate with subjective and objective measures of severity and renal function.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Treatment delay, or the time lapse between diagnosis and surgery, may have a detrimental effect on cancer outcomes. This study assesses the effect of treatment delay on cancer-related outcomes in a large, continuous series of surgically treated colon cancer patients. All surgical colon cancer cases at our center from 2004 through 2011 were reviewed. Patients who underwent preoperative chemotherapy, emergency admissions, palliative cases, and incidental and postoperative diagnoses were excluded. Treatment delay was correlated with outcomes in univariate and multivariate regression and proportional hazards models. In 769 included patients, for every treatment-delay quartile increase, odds of death decreased by an odds ratio (OR) of 0.78 (p = 0.001), and metastatic recurrence by OR 0.78 (p = 0.013). Shorter survival duration had a hazard ratio (HR) of 0.81 (p = 0.001) and shorter disease-free survival HR 0.72 (p < 0.001). Multivariate regression adjusting for baseline staging greatly reduces these ratios, and makes them non-significant. Similar patterns were shown in high-risk subsets, including stage III disease, ethnic minorities, patients with positive margins, and extramural vascular invasion.\nQuestion: Treatment delay in surgically-treated colon cancer: does it affect outcomes?",
    "gt": "The inverse relation between treatment delay and survival and recurrence reflected adequate prioritization of advanced and high-risk cases and concurrently showed that, matched for stage and risk categories, treatment delay was not associated with worse cancer outcomes for patients with colon cancer. A reasonable delay between diagnosis and subsequent surgery is not detrimental to patient outcomes and permits more flexibility in scheduling and justifies allowing time to complete proper preoperative evaluation and staging, improving the quality and safety of resection and treatment.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Vaginal radical trachelectomy (VRT) is the most widely evaluated form of conservative management of young patients with early-stage (IB1) cervical cancer. Patients with nodal involvement or a tumor size greater than 2 cm are not eligible for such treatment. The aim of this study is to report the impact of a \"staging\" conization before VRT. This is a retrospective study of 34 patients potentially selected for VRT for a clinical and radiologic cervical tumor less than 2 cm. Among them, 28 underwent finally a VRT (20 of them having a previous conization before this procedure) and 6 patients with macroscopic cervical cancer, confirmed by punch biopsies, \"eligible\" for VRT (<2 cm) had undergone \"staging\" conization (without further VRT) to confirm the tumor size and lymphovascular space involvement (LVSI) status. Six patients having \"staging\" conization before VRT had finally been deemed contraindications to VRT due to the presence of a histologically confirmed tumor greater than 2 cm and/or associated with multiple foci of LVSI. Among 28 patients who underwent VRT, 1 received adjuvant chemoradiation (this patient recurred and died of disease). Two patients treated with RVT (without postoperative treatment) recurred. Ten pregnancies (9 spontaneous and 1 induced) were observed in 9 patients. Among 4 patients with macroscopic \"visible\" tumor who do not underwent a \"staging\" conization before VRT, 2 recurred. Among 11 patients who underwent VRT and having LVSI, 3 recurred.\nQuestion: Analysis of a continuous series of 34 young patients with early-stage cervical cancer selected for a vaginal radical trachelectomy: should \"staging\" conization be systematically performed before this procedure?",
    "gt": "These results suggest that if a conization is not performed initially, it should then be included among the staging procedures to select patients for VRT.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To investigate the attitudes, knowledge and practices of general dental practitioners (GDPs), specialists and consultants in paediatric dentistry in London, towards child protection. Additionally, to determine if children attending paediatric dental casualty at the Eastman Dental Hospital (EDH) and those who need treatment of caries under general anaesthesia (GA) are on the child protection register (CPR). The survey was conducted by postal questionnaires with 14 closed questions. A total of 228 dentists were invited to participate in the study. Children who attended EDH and required treatment under GA or at paediatric dental casualty were checked against the CPR. The respond rate was 46% (105/228). Overall 15% (16/105) of dentists had seen at least one patient with suspected child abuse in the last six months, but only 7% (7/105) referred or reported cases to child protection services. Reasons for dentists not referring included: fear of impact on practice (10%; 11/105); fear of violence to child (66%; 69/105); fear of litigation (28%; 29/105); fear of family violence against them (26%; 27/105); fear of consequences to the child (56%; 59/105); lack of knowledge regarding the procedures for referral (68%; 71/105); and lack of certainty about the diagnosis (86%; 90/105). Of the 220 children attending for dental GA and casualty from October 2004 to March 2005, one child was found to be on the CPR.\nQuestion: A survey of attitudes, knowledge and practice of dentists in London towards child protection. Are children receiving dental treatment at the Eastman Dental Hospital likely to be on the child protection register?",
    "gt": "More information and training is required to raise awareness of the potential importance of the role of dentists in child protection. Improved communication between dental and medical departments is important for safeguarding children.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Although it has been known that folate will participate in colorectal carcinogenesis, the relationship between blood folate level and colorectal cancer is less consistent. The blood folate level does not reflect the systemic folate status. By contrast, serum homocysteine has become a sensitive marker for the folate deficiency. We attempted to explain the correlation between folate and colorectal cancer according to the serum homocysteine level. We reviewed the clinical records, including alcohol history of 184 patients taking the colonoscopy and measurement of the serum homocysteine level at Health Promotion Center from 2001 to 2002. One hundred fifty-one of 184 were included, excluding 33 patients with previous history of colonic polyp, cerebrovascular, cardiovascular attack and thromboembolism. They were divided into the normal control (n=111) and the adenomatous polyp group (n=40). We had selected the colorectal cancer group (n=50) from the collection list of the tissue and blood bank less than 3 months storage interval. There was no significant difference in the mean serum homocysteine level among three groups. However, in the subjects with high alcohol consumption, there was a significant difference in the mean serum homocysteine between the normal control (n=7) and the adenomatous polyp group (n=9) (10.2 vs 15.1 mumol/L, p<0.05).\nQuestion: Is serum homocysteine level elevated in colorectal tumor?",
    "gt": "There was no correlation of serum homocysteine and colorectal tumor. However, in the subjects with high alcohol consumption, high serum homocysteine might be related to the development of adenomatous polyp.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We report our experience with ureterocalyceal anastomosis in children regarding indications and outcome. A retrospective review was performed of all cases that underwent open ureterocalyceal anastomosis at our center between 2000 and 2006. Records were reviewed for patient age, history, affected side, indication of surgery and operative details. Clinical and radiological outcome was assessed. Success was defined as both symptomatic relief and radiographic resolution of obstruction at last follow up. There were 10 cases (six males, four females) with a mean age of 6.5 years (range 3-13 years). Follow up ranged from 6 to 46 months (mean 18). The indications for surgery were failed pyeloplasty in six patients and iatrogenic injury of the ureteropelvic junction or the upper ureter in four. No significant perioperative complications were encountered in the study group. Overall success rate was 80%. Relief of obstruction was evident in eight patients as documented by intravenous urography or nuclear renography, while secondary nephrectomy was necessitated in two patients with severely impaired ipsilateral renal function and normal contralateral kidney. In patients with preserved renal units, the differential function on the involved side was stable on comparing the preoperative and postoperative renographic clearance (26 vs 24 ml/min).\nQuestion: Ureterocalyceal anastomosis in children: is it still indicated?",
    "gt": "Ureterocalyceal anastomosis in children is still indicated in some difficult situations. Excellent functional results can be achieved in properly selected cases. Nephrectomy may be indicated in cases with impaired renal function and inability to perform salvage procedure.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Although the use of laparoscopy for the management of postoperative complications has been previously well documented for different pathologies, there is scarce information regarding its use after laparoscopic colorectal surgery. Data were prospectively collected from all patients undergoing laparoscopic colorectal surgery between June 2000 to October 2007. Patients were divided into two groups according to the approach used for the reoperation: laparoscopy (Group I) or laparotomy (Group II). Data were statistically analyzed by using Student's t-test and chi-squared test. In all, 510 patients were analyzed. Twenty-seven patients (5.2 percent), 14 men and 13 women (men/women Group I: 10/7 vs. Group II: 4/6; P = not significant (NS)), required a second surgery because of postoperative complications (Group I: 17 (63 percent); Group II: 10 (37 percent)). Mean age was 60 +/- 17 years (Group I: 61.7 +/- 17.7 vs. Group II: 57.1 +/- 16 years; P = NS). Fifteen patients (55.5 percent) had anastomotic leaks (Group I 13/17 (76.5 percent) vs. Group II 2/13 (15 percent); P = 0.004). The were no differences between the groups regarding the length of stay or postoperative complications (Group I: 11.9 +/- 9.6 vs. Group II: 18.1 +/- 19.7 days: P = NS; Group I: 1 vs. Group II: 3; P = NS).\nQuestion: Is a laparoscopic approach useful for treating complications after primary laparoscopic colorectal surgery?",
    "gt": "Laparoscopic approach is a useful tool for treating complications after laparoscopic colorectal surgery, especially anastomotic leaks. Randomized, controlled trials are necessary to validate these findings.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate sexual satisfaction on women who have experienced sexual intercourse with the same partner on non-circumcised and circumcised states. A total of 19 women between 19 and 53 y/o, median age 30, in which their sexual partner was programmed for circumcision were included in this study. The survey was a validated version on the Changes on Sexual Functioning Questionnaire (CSFQ). General sexual satisfaction, pain during vaginal penetration, desire, vaginal orgasm, vaginal lubrication, sexual frequency changes in oral and/or anal sexual activities and esthetical perception on circumcised penis were surveyed before the procedure and 2 months after. Changes on Vaginal lubrication during intercourse were significant (p = 0.004), it diminished from 78% to 63%. There were no statistically significant differences on general sexual satisfaction, pain during vaginal penetration, desire, vaginal orgasm.\nQuestion: Does circumcision has an effect on female's perception of sexual satisfaction?",
    "gt": "Circumcision has either negative or positive effect on female's partner perception of sexual satisfaction.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To investigate the relationship between physical impairment and brain-computer interface (BCI) performance. We present a meta-analysis of 29 patients with amyotrophic lateral sclerosis and six patients with other severe neurological diseases in different stages of physical impairment who were trained with a BCI. In most cases voluntary regulation of slow cortical potentials has been used as input signal for BCI-control. More recently sensorimotor rhythms and the P300 event-related brain potential were recorded. A strong correlation has been found between physical impairment and BCI performance, indicating that performance worsens as impairment increases. Seven patients were in the complete locked-in state (CLIS) with no communication possible. After removal of these patients from the analysis, the relationship between physical impairment and BCI performance disappeared. The lack of a relation between physical impairment and BCI performance was confirmed when adding BCI data of patients from other BCI research groups.\nQuestion: Brain-computer interfaces and communication in paralysis: extinction of goal directed thinking in completely paralysed patients?",
    "gt": "Basic communication (yes/no) was not restored in any of the CLIS patients with a BCI. Whether locked-in patients can transfer learned brain control to the CLIS remains an open empirical question.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To demonstrate that the round window insertion (RWI) for cochlear implantation with multichannel electrodes is a reliable, safe, and effective technique. Retrospective case review. Academic tertiary referral center. One hundred thirty consecutive cochlear implants (72 female and 58 male subjects) performed from August 2009 to August 2011. Devices included 83 Cochlear, 40 Med El, and 7 Advanced Bionics (AB) cochlear implants. Subsequent to a full audiometric assessment, patients underwent a mastoidectomy with facial recess approach whereby the primary surgical objective was to perform a RWI. When the surgeon was unable to access the round window safely, a cochleostomy was performed anterior and inferior to the round window. Postoperative performance was measured with Hearing in Noise Test, the Consonant-Nucleus-Consonant test, and/or the Arizona Biomedical Sentences test. Surgical feasibility of reliably performing a RWI, reason for cochleostomy, postoperative complications, and audiometric performance. In 111 (85.4%) of 130 procedures, a RWI was performed; in 19 (14.6%), a cochleostomy was readily performed by the same approach. Reasons for creating a cochleostomy included facial nerve and jugular bulb location. There were no major postoperative complications in either group and 13 total minor complications. There was no statistically significant difference in postoperative complications or in audiometric performance between the 2 groups.\nQuestion: The round window: is it the \"cochleostomy\" of choice?",
    "gt": "The RWI may offer several advantages over a cochleostomy, and it seems to be a reliable, safe, and effective technique for cochlear implantation with today's cochlear implant electrodes. Further studies would be necessary to verify these findings for broad application to the cochlear implant patient population.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study tests the assumption that psychiatric diagnosis facilitates clinical evaluations of need in emergency care before and after controlling for danger. The data are from structured crisis assessments completed by emergency clinicians in four ethnically diverse locales (N = 653). Clinician-assigned diagnosis was categorized as adjustment, disruptive, mood, psychotic, and other, and a Danger scale score reflected danger to self or others. Mood and psychotic disorders significantly increased hospital rates in multivariate analyses which controlled for demographic characteristics, site, and danger when relevant. The model with the best fit included both diagnosis and danger.\nQuestion: Is diagnosis relevant in the hospitalization of potentially dangerous children and adolescents?",
    "gt": "Decisions should be linked to verifiable ratings of need and attention to danger, and its measurement should complement the current focus on diagnosis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Endoscopic vein harvesting is one of the most popular minimally invasive vein-harvesting techniques for coronary artery bypass graft surgery. It is associated with improved cosmetic outcome and fewer wound-related problems compared with the conventional open technique. However, its efficacy with regard to conduit damage and long-term patency has recently been questioned. Learning curve-associated trauma to the vein has a major impact on vein quality and the incidence of graft failure post-surgery. In an attempt to address this problem, we have devised and tested a learning tool termed Manchester Endoscopic Learning Tool (MELT). In this study, we compare vein quality following MELT training with standard recommended training. Fourteen practitioners across seven UK centres were enrolled into the study. Practitioners were categorized into two groups receiving MELT or standard training. Data were collected prospectively from the first eight vein retrievals per operator following training. A total of n = 112 vein-harvesting procedures were included in the study. Veins harvested by MELT practitioners had fewer small avulsions (P<0.001), required fewer repairs (P<0.001) and experienced a lower incidence of bruising (P<0.001) than veins obtained by practitioners receiving standard training. The incidence of very short side branches requiring repair was also significantly reduced (P<0.001) in the MELT group compared with standard training.\nQuestion: Does the introduction of a comprehensive structured training programme for endoscopic vein harvesting improve conduit quality?",
    "gt": "Our formalized training programme consistently minimizes vein trauma resulting in better-quality conduits when compared with the current standard training. Exposure of surgical practitioners to the structured curriculum during their endoscopic vein harvesting training will enhance their learning and lead to better-quality conduits. This is likely to impart clinical benefit post-surgery.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Eotaxin-1 (CCL11) is a protein expressed in various tissues influencing immunoregulatory processes by acting as selective eosinophil chemo-attractant. In prostate cancer (PCa), the expression and functional role of CCL11 have not been intensively investigated so far. Therefore, the aim of the present study was to investigate the diagnostic or prognostic potential of Eotaxin-1 in PCa patients. We analyzed serum from 140 patients who have undergone prostate biopsy due to elevated prostate-specific antigen (PSA) levels as well as serum of 20 individuals with PSA levels< 1ng/ml (healthy control group). Moreover, 40 urine samples were analyzed. A custom-made Q-Plex array ELISA (Quansys Biosciences) for the detection of Eotaxin-1 was performed and Q-View Software used for quantification. In addition, clinical courses of patients documented in our Prostate Biobank database were analyzed. ROC and survival analyses were used to determine the diagnostic and prognostic power of Eotaxin-1 levels. Serum Eotaxin-1 levels were significantly decreased in PCa (P = 0.006) as well as in benign prostate hyperplasia (P = 0.0006) compared to the control group. ROC analysis revealed that Eotaxin-1 is a significant marker to distinguish PCa from disease-free prostate. Moreover, we found that Eotaxin-1 expression is significantly decreased in Gleason score (GS) 6 (P = 0.0135) and GS 8 (P = 0.0057) patients compared to samples of healthy men, respectively. However, PCa aggressiveness was not predictable by Eotaxin-1 levels. In line with serum analyses, urine Eotaxin-1 was significantly decreased in patients with PCa compared to cancer-free individuals (P = 0.0185) but was not different between cancers of different GS. Patientś follow-up analyses showed no significant correlation between serum Eotaxin-1 levels and time to biochemical recurrence. Survival analyses also revealed no significant changes in progression-free survival among low (≤ 112.2 pg/ml) and high (> 112.2 pg/ml) Eotaxin-1 serum levels.\nQuestion: Is Eotaxin-1 a serum and urinary biomarker for prostate cancer detection and recurrence?",
    "gt": "Although this study has not established a prognostic role of Eotaxin-1 in PCa patients, this chemokine may serve as a diagnostic marker to distinguish between disease-free prostate and cancer.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Improved survival after prophylactic implantation of a defibrillator in patients with reduced left ventricular ejection fraction (EF) after myocardial infarction (MI) has been demonstrated in patients who experienced remote MIs in the 1990s. The absolute survival benefit conferred by this recommended strategy must be related to the current risk of arrhythmic death, which is evolving. This study evaluates the mortality rate in survivors of MI with impaired left ventricular function and its relation to pre-hospital discharge baseline characteristics. The clinical records of patients who had sustained an acute MI between 1999 and 2000 and had been discharged from the hospital with an EF of<or = 40% were included. Baseline characteristics, drug prescriptions, and invasive procedures were recorded. Bivariate and multivariate analyses were performed using a primary end point of total mortality. One hundred sixty-five patients were included. During a median follow-up period of 30 months (interquartile range, 22 to 36 months) 18 patients died. The 1-year and 2-year mortality rates were 6.7% and 8.6%, respectively. Variables reflecting coronary artery disease and its management (ie, prior MI, acute reperfusion, and complete revascularization) had a greater impact on mortality than variables reflecting mechanical dysfunction (ie, EF and Killip class).\nQuestion: Reduced ejection fraction after myocardial infarction: is it sufficient to justify implantation of a defibrillator?",
    "gt": "The mortality rate among survivors of MIs with reduced EF was substantially lower than that reported in the 1990s. The strong decrease in the arrhythmic risk implies a proportional increase in the number of patients needed to treat with a prophylactic defibrillator to prevent one adverse event. The risk of an event may even be sufficiently low to limit the detectable benefit of defibrillators in patients with the prognostic features identified in our study. This argues for additional risk stratification prior to the prophylactic implantation of a defibrillator.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Women with fertility problems experience a higher prevalence of negative emotions than women without fertility problems. The goal of this study was to compare the effects of psychological intervention with psychotropic medication on the mental health improvement of depressed infertile women. In a randomized controlled clinical trial, 89 depressed infertile women that they were recruited and divided into three groups in three groups: cognitive behavior therapy (CBT), antidepressant therapy, and a control group. Twenty-nine participants in the CBT method received 10 sessions on relaxation training, restructuring, and eliminating negative automatic thoughts and dysfunctional attitudes to infertility. Thirty participants in the pharmacotherapic group took 20mg fluoxetine daily for 90 days. Thirty control subjects did not receive any intervention. All participants completed the Beck Depression Inventory (BDI) and the General Health Questionnaire (GHQ) at the beginning and end of the study. Paired t-test, ANOVA, chi(2), and McNemar tests were used to analyze the data. Fluoxetine significantly reduced the mean of three subscale scores of the GHQ anxiety (7.3+/-4.1 vs. 5.1+/-3.2), social function (7+/-2.8 vs. 4.3+/-2), and depression (7.8+/-5.2 vs. 4.4+/-2.2) but could not significantly change the mean score of psychosomatic signs. The CBT method effectively reduced the mean of all four GHQ subscales: anxiety (8+/-4 vs. 3.2+/-2), social function (7.2+/-2.6 vs. 4.7+/-2.5), depression (7.7+/-4.2 vs. 3.6+/-2.7), and psychosomatic signs (7.5+/-3.2 vs. 5.5+/-3.2). Also, both methods significantly reduced the total GHQ scores. Successful treatment of depression in three groups was fluoxetine group 50%, CBT 79.3%, and control 10%. The mean Beck scores among the groups at the beginning and end of study were, respectively: fluoxetine 23.2+/-8.6 versus 14.3+/-8.5 (p<0.001), CBT 20+/-7.9 versus 7.7+/-4.8 (p<0.001), and control 19.8+/-8.5 versus 19.7+/-8.4 (p=0.9). Although both fluoxetine and CBT significantly decreased the mean BDI scores more than the control group, the decrease in the CBT group was significantly greater than the fluoxetine group.\nQuestion: Is psychotherapy a reliable alternative to pharmacotherapy to promote the mental health of infertile women?",
    "gt": "Psychotherapy, such as group CBT, was superior to or at least as effective as pharmacotherapy to promote the well being of depressed infertile women.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate the perioperative and long-term results of total pancreatectomy (TP), and to assess whether it provides morbidity, mortality, and quality of life (QoL) comparable to those of the pylorus-preserving (pp)-Whipple procedure in patients with benign and malignant pancreatic disease. TP was abandoned for decades because of high peri- and postoperative morbidity and mortality. Because selected pancreatic diseases are best treated by TP, and pancreatic surgery and postoperative management of exocrine and endocrine insufficiency have significantly improved, the hesitance to perform a TP is disappearing. In a prospective study conducted from October 2001 to November 2006, all patients undergoing a TP (n = 147; 100 primary elective TP [group A], 24 elective TP after previous pancreatic resection [group B], and 23 completion pancreatectomies for complications) were included, and perioperative and late follow-up data, including the QoL (EORTC QLQ-C30 questionnaire), were evaluated. A matched-pairs analysis with patients receiving a pp-Whipple operation was performed. Indications for an elective TP (group A + B) were pancreatic and periampullary adenocarcinoma (n = 71), other neoplastic pancreatic tumors (intraductal papillary mucinous neoplasms, neuroendocrine tumors, cystic tumors; n = 34), metastatic lesions (n = 8), and chronic pancreatitis (n = 11). There were 73 men and 51 women with a mean age of 60.9 +/- 11.3 years. Median intraoperative blood loss was 1000 mL and median operation time was 380 minutes. Postoperative surgical morbidity was 24%, medical morbidity was 15%, and mortality was 4.8%. The relaparotomy rate was 12%. Median postoperative hospital stay was 11 days. After a median follow-up of 23 months, global health status of TP patients was comparable to that of pp-Whipple patients, although a few single QoL items were reduced. All patients required insulin and exocrine pancreatic enzyme replacements. The mean HbA1c value was 7.3% +/- 0.9%.\nQuestion: Is there still a role for total pancreatectomy?",
    "gt": "In this cohort study, mortality and morbidity rates after elective TP are not significantly different from the pp-Whipple. Because of improvements in postoperative management, QoL is acceptable, and is almost comparable to that of pp-Whipple patients. Therefore, TP should no longer be generally avoided, because it is a viable option in selected patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of the present study is to evaluate the effects of the increased number of caesarean deliveries (CDs) in cases of multiple repeat caesarean deliveries (MRCDs) on maternal and neonatal morbidity. MRCDs admitted to our hospital between January 2013 and September 2014 were analysed retrospectively. A total number of 1133 women were included in the study and were divided into 4 groups. Group 1: second CDs (n = 329); Group 2: third CDs (n = 225); Group 3: fourth CDs (n = 447); Group 4: fifth CDs (n = 132). The clinical, demographic, intraoperative and postoperative data of the patients were registered upon the review of patient files. The differences among the groups were found to be statistically significant in terms of mean maternal age, gravida, APGAR (Activity, Pulse, Grimace, Appearance, Respiration) scores, hospital stay and operation time. In addition, the difference was also statistically significant for severe adhesion, bladder injury and premature birth. No statistically significant difference was observed among the groups with respect to placenta previa, placenta accreta, caesarean hysterectomy, uterine scar rupture.\nQuestion: Multiple repeat caesarean deliveries: do they increase maternal and neonatal morbidity?",
    "gt": "According to our findings, MRCDs seem to increasing the maternal and neonatal morbidity even though they are not life-threatening.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate sympathetic system activity in bladder pain syndrome/interstitial cystitis (BPS/IC) patients and to investigate if chronic adrenergic stimulation in intact rats induces BPS/IC-like bladder modifications. Clinical study--In BPS/IC patients and aged and body mass index matched volunteers TILT test was undertaken and catecholamines were measured in plasma and 24 hr urine samples. Experimental study--Phenylephrine was injected subcutaneously (14 days) to female Wistar rats. Pain behavior, spinal Fos expression, urinary spotting, number of fecal pellets expelled, frequency of reflex bladder contractions, and urothelial height were analyzed. Urothelium permeability was investigated by trypan blue staining. Immunoreactivity against caspase 3 and bax were studied in the urothelium and against alpha-1-adrenoreceptor and TRPV1 in suburothelial nerves. Mast cell number was determined in the sub-urothelium. In rats with lipopolysaccharide-induced cystitis, urinary catecholamines, and Vesicular Monoamine Transporter 2 (VMAT2) expression in bladder nerves were analyzed. The TILT test showed an increase of sympathetic activity. Noradrenaline levels in blood at resting conditions and in 24-hr urine samples were higher in BPS/IC patients. Phenylephrine administration increased visceral pain, spinal Fos expression, bladder reflex activity, urinary spotting and the number of expelled fecal pellets. The mucosa showed urothelial thinning and increased immunoreactivity for caspase 3 and bax. Trypan blue staining was only observed in phenylephrine treated animals. Suburothelial nerves co-expressed alpha1 and TRPV1. Mastocytosis was present in the suburothelium. Cystitis increased sympathetic nerve density and urinary noradrenaline levels.\nQuestion: Can the adrenergic system be implicated in the pathophysiology of bladder pain syndrome/interstitial cystitis?",
    "gt": "Excessive adrenergic stimulation of the bladder may contribute to the pathophysiological mechanisms of BPS/IC.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Aminoglycosides have been reported to produce a curare-like neuromuscular blockade in animals at serum concentrations higher than those obtained with traditional dosing (1-2 mg/kg every 8 h) in humans. Aminoglycoside-induced neuromuscular blockade is rarely, if ever, seen in humans with traditional dosing. The recent adoption of once-daily dosing of aminoglycosides has raised concerns about increased potential for this adverse effect because higher serum concentrations are produced. The objective of this study was to determine if once-daily dosing of aminoglycosides inhibits respiratory muscle function. Nine mechanically ventilated ICU patients on once-daily dosing of gentamicin 6 mg/kg/day were assessed for respiratory muscle strength by measuring maximum inspiratory pressure (MIP). MIP is a measurement of the maximal negative pressure generated by repeated inhalations against an occluded airway over 20 s. This was measured within 1 hour before (MIPpre) and within 1 hour after each aminoglycoside dose (MIPpost). Mean values for MIPpre and MIPpost were -26.7 cm H2O and -26.5 cm H2O, respectively. The mean difference between MIPpre and MIPpost was -0.2 cm H2O, which was not statistically significant (P>0.05).\nQuestion: Does once-daily dosing of aminoglycosides affect neuromuscular function?",
    "gt": "The effect of gentamicin (6 mg/kg/day) on respiratory muscle function was not statistically, nor clinically significant, and weaning from mechanical ventilation does not seem to be inhibited by once-daily dosing of aminoglycosides as detectable by measurement of MIP.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: In 1989 the United States Public Health Service Expert Panel on the Content of Prenatal Care reported that health education should become a more integral part of prenatal care. Key questions about providing this education have not been examined. Our study compared the type of information provided to women who sought prenatal care in a public clinic and to those who were seen in a private practice and the degree to which the patients were satisfied with the information they received. One hundred fifty-nine pregnant women (80 seen in a public clinic, 79 seen in a private practice) completed two questionnaires about 38 topics commonly cited as important during pregnancy. At the first prenatal visit, the women reported their level of interest in each of the topics. At 36 to 40 weeks' gestation the women completed a second questionnaire to assess whether information was provided for each topic and whether they had learned as much as desired. Overall, the women in the public sector received more information than did the women who were cared for privately. This was statistically significant at the p<0.05 level for 25 of the 38 topics. Satisfaction with information learned was highly correlated with information received during prenatal care, but, surprisingly, it was not shown to be associated with the patient's interest level at the first visit. Fewer than 50% of private patients reported having received information about such important topics as acquired immunodeficiency syndrome, sexually transmitted diseases, preterm birth prevention, family planning, and family violence.\nQuestion: Are there differences in information given to private and public prenatal patients?",
    "gt": "The one-on-one approach to health education in pregnancy usually used in the private setting may not facilitate addressing many topics believed to be important components of contemporary prenatal care. Providers of private prenatal care should initiate discussion of prenatal health education topics rather than relying on patient interest in requesting information. Just as public prenatal care programs have devoted significant resources to more comprehensive prenatal education, the providers in the private sector must assure that pregnant women receive the same comprehensive information. In so doing, these providers can help promote an optimal outcome for their patients, their patients' unborn children, and the family unit.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Two hundred and fifty patients (response rate 78%) from five tertiary level hospitals in Zagreb, Croatia, anonymously filled in the questionnaire on informed consent and communication practices by Nemcekova et al in the period from April to December 2011. Eighty five percent of patients received complete, understandable information, presented in a considerate manner. Patients in surgical departments received a higher level of information than those in internal medicine departments. Patients were informed about health risks of the proposed treatments (in 74% of cases) and procedures (76%), health consequences of refusing a medical intervention (69%), and other methods of treatment (46%). However, patients pointed out a number of problems in physician-patient communication.\nQuestion: Are physician-patient communication practices slowly changing in Croatia?",
    "gt": "Communication practices during informed consent-obtaining process in hospitals in Zagreb are based on a model of shared decision-making, but paternalistic physician-patient relationship is still present. Our results indicate that Croatia is undergoing a transition in the physician-patient relationship and communication.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine the effect of synchronous endometrial endometrioid cancer (SEEC) on the prognosis of patients with Stage 1 endometrioid ovarian cancer (EOC). Clinicopathological data of cases with Stage 1 EOC from January 2000 to November 2013 were retrieved from the computerized database of Etlik Zubeyde Hanim Women's Health and Research Hospital. Of the 31 patients included in the study, 15 patients had primary synchronous endometrial and ovarian cancer (SEOC) (Group 1) and 16 patients had EOC alone (Group 2). Ovarian cancer substage and grade were compared between the two groups, and no significant differences were found. Most of the patients with SEEC had Grade 1 tumours (n=13, 86.7%). In Group 1, nine (60.0%) patients had endometrial tumours with superficial myometrial invasion, and six (40.0%) patients had deep myometrial invasion. Median follow-up was 94 months. Ten-year disease-free survival rates were 92.9% for Group 1 and 84.6% for Group 2 (p=0.565).\nQuestion: Does synchronous endometrioid endometrial cancer have any prognostic effect on Stage I endometrioid ovarian cancer?",
    "gt": "Patients with Stage 1 EOC have excellent long-term survival. The presence of SEEC does not influence the prognosis of patients with Stage 1 EOC, even in the presence of deep myometrial invasion.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It is usually believed that loss of residual renal function is associated with anorexia and the development of malnutrition. We conducted a retrospective study in our center to evaluate the effect of declining residual renal function on patients' nutritional status. All incident uremic patients (n = 46) who began peritoneal dialysis from January 1, 2003 June 1, 2003 in our center were closely followed for 1 year with focus on maintaining strict volume control with time on dialysis. Patient's residual renal function (RRF) was assessed by the average renal urea and creatinine clearances. Those patients who had more than 50% decrease in GFR were selected for the present analysis. Serum albumin (ALB), dietary protein intake (DPI) and subjective global assessment (SGA) were closely followed. There were 16 patients (9 males and 7 females) included in the present analysis, among whom 31.3% were diabetics. Patients' GFR declined significantly (RRF were 4.32 +/- 2.69, 2.99 +/- 2.21 and 1.24 +/- 0.99 ml/min for Months 1, 6 and 12, respectively, p<0.05), along with a significant decline in urine volume (985.62 +/- 543.29, 698.13 +/- 463.59 and 425.63 +/- 320.52 ml/d for Months 1, 6 and 12, respectively, p<0.01). Although weekly peritoneal Kt/V did not increase significantly, peritoneal ultrafiltration increased significantly during this period (428.75 +/- 408.96, 534.38 +/- 296.39, 844.38 +/- 440.35 ml for Months 1, 6 and 12, respectively, p<0.05). Serum ALB increased significantly (32.34 +/- 5.07, 34.74 +/- 4.89 and 36.21 +/- 3.98 g/l for Months 1, 6 and 12, respectively, p<0.01). DPI also increased significantly. The prevalence of malnutrition (by SGA) decreased from 62.5% at the start of dialysis to 18.8% at the end of this study (p<0.05).\nQuestion: Does loss of residual renal function lead to malnutrition in peritoneal dialysis patients?",
    "gt": "Our study suggests that rapid decline of residual renal function in PD patients does not necessarily lead to decreased dietary protein intake and deteriorated nutritional status. Focus on incremental peritoneal fluid removal along with the decline in residual renal function and, thus, maintaining volume control may be one of the critical reasons for the success.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate whether using long-axis or short-axis view during ultrasound-guided internal jugular and subclavian central venous catheterization results in fewer skin breaks, decreased time to cannulation, and fewer posterior wall penetrations. Prospective, randomized crossover study. Urban emergency department with approximate annual census of 60,000. Emergency medicine resident physicians at the Denver Health Residency in Emergency Medicine, a postgraduate year 1-4 training program. Resident physicians blinded to the study hypothesis used ultrasound guidance to cannulate the internal jugular and subclavian of a human torso mannequin using the long-axis and short-axis views at each site. An ultrasound fellow recorded skin breaks, redirections, and time to cannulation. An experienced ultrasound fellow or attending used a convex 8-4 MHz transducer during cannulation to monitor the needle path and determine posterior wall penetration. Generalized linear mixed models with a random subject effect were used to compare time to cannulation, number of skin breaks and redirections, and posterior wall penetration of the long axis and short axis at each cannulation site. Twenty-eight resident physicians participated: eight postgraduate year 1, eight postgraduate year 2, five postgraduate year 3, and seven postgraduate year 4. The median (interquartile range) number of total internal jugular central venous catheters placed was 27 (interquartile range, 9-42) and subclavian was six catheters (interquartile range, 2-20). The median number of previous ultrasound-guided internal jugular catheters was 25 (interquartile range, 9-40), and ultrasound-guided subclavian catheters were three (interquartile range, 0-5). The long-axis view was associated with a significant decrease in the number of redirections at the internal jugular and subclavian sites, relative risk 0.4 (95% CI, 0.2-0.9) and relative risk 0.5 (95% CI, 0.3-0.7), respectively. There was no significant difference in the number of skin breaks between the long axis and short axis at the subclavian and internal jugular sites. The long-axis view for subclavian was associated with decreased time to cannulation; there was no significant difference in time between the short-axis and long-axis views at the internal jugular site. The prevalence of posterior wall penetration was internal jugular short axis 25%, internal jugular long axis 21%, subclavian short axis 64%, and subclavian long axis 39%. The odds of posterior wall penetration were significantly less in the subclavian long axis (odds ratio, 0.3; 95% CI, 0.1-0.9).\nQuestion: Is long-axis view superior to short-axis view in ultrasound-guided central venous catheterization?",
    "gt": "The long-axis view for the internal jugular was more efficient than the short-axis view with fewer redirections. The long-axis view for subclavian central venous catheterization was also more efficient with decreased time to cannulation and fewer redirections. The long-axis approach to subclavian central venous catheterization is also associated with fewer posterior wall penetrations. Using the long-axis view for subclavian central venous catheterization and avoiding posterior wall penetrations may result in fewer central venous catheter-related complications.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We recently reported that children with acute leukemias who show increasing mixed chimerism (MC) after allogeneic stem-cell transplantation have a significantly enhanced risk of relapse. Here we present the results of a prospective multicenter study to investigate (1) whether relapse of acute lymphoblastic leukemia (ALL) can be determined in advance by serial analysis of chimerism, and (2) if outcome can be influenced by withdrawal of immunosuppression and/or by low-dose donor lymphocyte infusion when increasing MC is detected. Serial and quantitative analysis of chimerism was performed using a fluorescent-based short-tandem-repeat-polymerase chain reaction in 163 children with ALL. One hundred one patients revealed complete chimerism (CC) or low-level MC (CC/low-level MC); increasing MC was found in 46 patients; and decreasing MC, in 16 patients. Relapse was significantly more frequent in patients with increasing MC (26 of 46) than in patients with CC/low-level MC (eight of 101) or in patients with decreasing MC (0 of 16; P<.0001). The probability of 3-year event-free survival (EFS) was 54% for all patients, 66% for patients with CC/low-level MC (n = 101), 66% for patients with decreasing MC (n = 16), and 23% for patients with increasing MC (n = 46; P<.0001). Of the 46 patients with increasing MC, 31 received immunotherapy. This group had a significantly higher 3-year EFS estimate (37%) than the 15 patients who did not receive immunotherapy (0%; P<.001).\nQuestion: Increasing mixed chimerism is an important prognostic factor for unfavorable outcome in children with acute lymphoblastic leukemia after allogeneic stem-cell transplantation: possible role for pre-emptive immunotherapy?",
    "gt": "Serial analysis of chimerism reliably identifies patients at highest risk to relapse. The 3-year EFS of patients with increasing MC without immunotherapy was 0%, by which overt relapse could be prevented in a considerable group of patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patients with incurable cancer are faced with difficult decisions regarding whether to take chemotherapy in an attempt to preserve the quality and/or prolong the quantity of their lives. The average prolongation in survival with chemotherapy compared with best supportive care has not been well described. We performed a literature search using PUBMED combined with expert inquiry to identify trials comparing cytotoxic chemotherapy with best supportive care. Twenty-five randomized, controlled clinical trials comparing cytotoxic chemotherapy with best supportive care were identified. Sixteen trials (64%) were in patients with non-small-cell lung cancer (NSCLC). Data were extracted and analyzed. Sufficient data for statistical modeling were available for NSCLC trials. The mean sample size of the NSCLC trials was 175 patients. Response rates in the treatment arms for NSCLC ranged from 7% to 42%. A relationship between response rate and survival was observed for NSCLC. The estimated relationship for NSCLC suggested that each 3.3% increase in response rate correlated, on average, with a 1-week increase in median survival, and each 2% increase in response rate correlated, on average, with a 1% increase in 1-year survival. The mean increase in 1-year survival for trials of agents with at least a 20% response rate in NSCLC was 16%. Formulas are provided to help estimate how a given response rate may effect median and 1-year survival relative to best supportive care alone for NSCLC.\nQuestion: Are chemotherapy response rates related to treatment-induced survival prolongations in patients with advanced cancer?",
    "gt": "We found a relationship between response rate and both median and 1-year survival in NSCLC. This information may help oncologists estimate how an NSCLC chemotherapy regimen with a given response rate can, on average, impact survival relative to supportive care alone.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Increasing concentrations of N-(4-hydroxyphenyl) retinamide (4-HPR)-treatment pushed autophagy down to apoptosis in a dose-dependent manner, and 4-HPR-induced ROS contribute to this process. Since we found that ASK1-regulated JNK1 and p38 are responsible for 4-HPR-induced autophagy and apoptosis, respectively, we further utilized co-immunoprecipitation followed by liquid chromatography-tandem mass spectrometry analysis to identify proteins that specifically bind to ASK1 under different oxidative states. Of note, DJ-1, a crucial antioxidant protein, was identified. Interestingly, DJ-1 functions as a redox sensor that senses ROS levels and determines the cellular response to 4-HPR: Under mild oxidative stress, moderate oxidation of DJ-1 is recruited to inhibit the activity of ASK1 and maintain cell viability by activating autophagy; under a lethal level of oxidative stress, excessive oxidized DJ-1 dissociates from ASK1 and activates it, thereby initiating p38 activation and enabling the cells to commit to apoptosis. Moreover, the depletion of DJ-1 increases the sensitivity of tumor cells to 4-HPR both in vitro and in vivo. Our results reveal that the different oxidation states of DJ-1 function as a cellular redox sensor of ROS caused by 4-HPR and determine the cell fate of autophagy or apoptosis. Moreover, the results suggest that DJ-1 might be a potent therapeutic target for cancer treatment.\nQuestion: The oxidation states of DJ-1 dictate the cell fate in response to oxidative stress triggered by 4-hpr: autophagy or apoptosis?",
    "gt": "ROS-mediated changes in the oxidation state of DJ-1 are involved in 4-HPR's effect on pushing autophagy down to apoptosis. Consequently, this change mediates ASK1 activation by regulating DJ-1-ASK1 complex formation and determines the cell fate of autophagy or apoptosis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Currently, hospital benchmarking organizations are often limited to short-term surgical quality comparisons among hospitals. The goal of this study was to determine whether long-term rates of incisional hernia repair after common abdominal operations could be used to compare hospital long-term surgical quality. This was a cohort study with up to 4 years of follow-up. Patients who underwent 1 of 5 common inpatient abdominal operations were identified in 2005-2008 American College of Surgeons NSQIP data linked to Medicare inpatient records. The main outcomes included occurrence of an incisional hernia repair. A multivariable, shared frailty Cox proportional hazards regression was used to compare each hospital's incisional hernia rate with the overall mean rate for all hospitals and control for American College of Surgeons NSQIP preoperative clinical variables. A total of 37,134 patients underwent 1 of 5 common inpatient abdominal operations, including colectomy, small bowel resection, ventral hernia repair, pancreatic resection, or cholecystectomy, at 1 of 216 hospitals participating in American College of Surgeons NSQIP during the 4-year period. There were 1,474 (4.0%) patients who underwent an incisional hernia repair, at a median follow-up time of 16 months (interquartile range 8 to 25 months) after initial abdominal surgery. After risk adjustment, there was no significant difference in the ratio of any one hospital's adjusted hazard rate for incisional hernia repair vs the average hospital adjusted hazard rate.\nQuestion: Is there hospital variation in long-term incisional hernia repair after abdominal surgery?",
    "gt": "Risk-adjusted hospital rates of incisional hernia repair do not vary significantly from the average. This suggests that incisional hernia repair might not be sensitive enough as a long-term quality metric for benchmarking hospital performance.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Transoesophageal echocardiography (TEE) is recommended prior to circumferential pulmonary vein ablation (CPVA) in patients with atrial fibrillation (AF) to identify left atrial (LA) or left atrial appendage (LAA) wall thrombi. It is not clear whether all patients undergoing CPVA should receive pre-procedural TEE. We wanted to assess the incidence of LA thrombus in these patients and to identify factors associated with its presence. Consecutive patients referred for CPVA from 2004 to 2009 underwent TEE within 48 h prior to the procedure. Of 408 patients included in the study, 6 patients (1.47%) had LA thrombi, persistent AF, and LA dilation. Compared with patients without thrombus, these six patients had larger LA diameter (P = 0.0001) and more frequently were women (P = 0.002), had persistent AF (P = 0.04), and had underlying structural cardiac disease (P = 0.014). The likelihood of presenting LA thrombus increased with the number of these four risk factors present (P<0.001). None of the patients with paroxysmal AF and without LA dilation had LA thrombus. A cut-off value of 48.5 mm LA diameter yielded 83% sensitivity, 92% specificity, and a 10.1 likelihood ratio to predict LA thrombus appearance.\nQuestion: Usefulness of transoesophageal echocardiography before circumferential pulmonary vein ablation in patients with atrial fibrillation: is it really mandatory?",
    "gt": "The incidence of LA thrombus prior to CPVA is low. Persistent AF, female sex, structural cardiopathy, and LA dilation were associated with the presence of LA thrombus. Our data suggest that the use of TEE prior to CPVA to detect LA thrombi might not be needed in patients with paroxysmal AF and no LA dilation or structural cardiopathy.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To report treatment compliance, toxicity and clinical outcome of chemoradiotherapy (CRT) for anal carcinoma in HIV-negative vs. HIV-positive patients treated with highly active antiretroviral therapy. Between 1997 and 2008, 25 HIV-positive and 45 HIV-negative patients received CRT (50.4 Gy at 1.8 Gy/fraction plus 5.4-10.8 Gy boost; 5-fluorouracil, 1000 mg/m(2), Days 1-4 and 29-32, mitomycin C, 10 mg/m(2), Days 1 and 29). Median follow-up was 51 (range, 3-235) months. HIV-positive patients were significantly younger (mean age, 47 vs. 57 years, p<0.001) and predominantly male (92% vs. 29%, p<0.001). CRT could be completed in all patients with a reduction of chemotherapy and/or RT-interruption in 28% and 8%, respectively, in HIV-positive patients, and in 9% and 11%, respectively, in HIV-negative patients. Acute Grade 3/4-toxicity occurred in 44% vs. 49% (p=0.79). Initial complete response (84% vs. 93%, p=0.41), 5-year rates of local control (65% vs. 78%, p=0.44), cancer-specific (78% vs. 90%, p=0.17) and overall survival (71% vs. 77%, p=0.76) were not significantly different.\nQuestion: Concurrent chemoradiotherapy with 5-fluorouracil and mitomycin C for anal carcinoma: are there differences between HIV-positive and HIV-negative patients in the era of highly active antiretroviral therapy?",
    "gt": "HIV-positive patients with anal cancer can be treated with standard CRT, with the same tolerability and toxicity as HIV-negative patients. Long-term local control and survival rates are not significantly different between these groups.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Ureteral stents are used to reduce urologic complications after renal transplantation. However, they predispose to infection. The optimal time to keep them in the urinary tract has not yet been defined. The aim of this study was to evaluate the effect of early removal at the end of 2 weeks on urinary tract infections and early urologic complications (within 3 months), such as ureteroneocyctostomy leakage as well as ureteral anastomosis stricture or obstruction. We retrospectively analyzed the medical records of 48 patients who underwent renal transplantation using a ureteral stent. The patients were divided into two groups according to the time of stent removal: at the end of 2 weeks (group A; n = 10) versus at a later time (group B; n = 38). The urologic complication rate was 0% in group A and the urinary tract infection rate, 2%. The urologic complication rate was 0% in group B and the urinary tract infection rate, 35%.\nQuestion: Is removal of the stent at the end of 2 weeks helpful to reduce infectious or urologic complications after renal transplantation?",
    "gt": "Early removal of the stent at the end of 2 weeks after renal transplantation is decreased the rate of urinary tract infections.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this study was to examine the relationship between the maternal level of antiphospholipid antibodies (aPA) measured by anticardiolipin antibodies (aCL) and fetal growth retardation (SGA). A nested case control design was carried out in a prospective cohort study of 1552 para I and para II women. The study group consisted of all 138 women who gave birth to a SGA-child (defined as birthweight<10th percentile). A control group of 276 women was randomly selected from mothers of non-SGA children. Levels of aPA were measured in banked sera drawn from the women in the 33rd week of pregnancy and compared between cases and controls. There were 3 (2.5%) sera with aPA above 97.5 percentile among the cases and 3 (1.2%) among the controls. This difference was not statistically significant.\nQuestion: Can maternal antiphospholipid antibodies predict the birth of a small-for-gestational age child?",
    "gt": "Antiphospholipid antibody measurements obtained at 33 weeks of gestation cannot be used to assess the risk of birth of a small for gestational age infant among parous women.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Cytoblocks (CBs), or cell blocks, provide additional morphological detail and a platform for immunocytochemistry (ICC) in cytopathology. The Cellient(™) system produces CBs in 45 minutes using methanol fixation, compared with traditional CBs, which require overnight formalin fixation. This study compares Cellient and traditional CB methods in terms of cellularity, morphology and immunoreactivity, evaluates the potential to add formalin fixation to the Cellient method for ICC studies and determines the optimal sectioning depth for maximal cellularity in Cellient CBs. One hundred and sixty CBs were prepared from 40 cytology samples (32 malignant, eight benign) using four processing methods: (A) traditional; (B) Cellient (methanol fixation); (C) Cellient using additional formalin fixation for 30 minutes; (D) Cellient using additional formalin fixation for 60 minutes. Haematoxylin and eosin-stained sections were assessed for cellularity and morphology. ICC was assessed on 14 cases with a panel of antibodies. Three additional Cellient samples were serially sectioned to determine the optimal sectioning depth. Scoring was performed by two independent, blinded reviewers. For malignant cases, morphology was superior with Cellient relative to traditional CBs (P < 0.001). Cellularity was comparable across all methods. ICC was excellent in all groups and the addition of formalin at any stage during the Cellient process did not influence the staining quality. Serial sectioning through Cellient CBs showed optimum cellularity at 30-40 μm with at least 27 sections obtainable.\nQuestion: Automated Cellient(™) cytoblocks: better, stronger, faster?",
    "gt": "Cellient CBs provide superior morphology to traditional CBs and, if required, formalin fixation may be added to the Cellient process for ICC. Optimal Cellient CB cellularity is achieved at 30-40 μm, which will impact on the handling of cases in daily practice.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The presence of posttraumatic stress disorder (PTSD) in trauma survivors has been linked with family dysfunction and symptoms in their children, including lower self-esteem, higher disorder rates and symptoms resembling those of the traumatized parent. This study aims to examine the phenomenon of intergenerational transfer of PTSD in an Australian context. 50 children (aged 16-30) of 50 male Vietnam veterans, subgrouped according to their fathers' PTSD status, were compared with an age-matched group of 33 civilian peers. Participants completed questionnaires with measures of self-esteem, PTSD symptomatology and family functioning. Contrary to expectations, no significant differences were found between the self-esteem and PTSD symptomatology scores for any offspring groups. Unhealthy family functioning is the area in which the effect of the veteran's PTSD appears to manifest itself, particularly the inability of the family both to experience appropriate emotional responses and to solve problems effectively within and outside the family unit.\nQuestion: The adjustment of children of Australian Vietnam veterans: is there evidence for the transgenerational transmission of the effects of war-related trauma?",
    "gt": "Methodological refinements and further focus on the role of wives/mothers in buffering the impact of veterans' PTSD symptomatology on their children are indicated. Further effort to support families of Veterans with PTSD is also indicated.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate the effect of a humidity detector device on the quality of life of patients with urinary incontinence IU. Quasi-experimental study: a series of ten cases followed for a month. The devices were placed and the questionnaires filled in before and after using it for at least ten hours a day during a month. Health related quality of life was assessed through the questionnaires for IU convalidated and adapted to our specific environment: Urogenital Inventory Distress (UDI) and Incontinence Impact Questionary (IIQ). An improvement of 58 points by a four option Likert scale was considered a positive impact in the quality of life (IIQ). The scores obtained in UDI and IIQ are described before and after use the device and paried T test and Wilcoxon sign test were carried out to compare the scores obtained in each instance. The capacity to detect a difference of 58 points on the UDI scale was calculated (minimum relevant difference). A binomial test was undertaken to ascertain a probability of achieving an increase in the above mentioned index which would exceed the clinical relevance threshold. Average increase in IIQ improvement: x = 5.48 (Std Error = 20.43) 95% CI = -34.56 to 45.56. Average increase in UDI improvement: x = -11.87 (Std Error = 20.70) 95% IC = -52.45 to 28.70. The power of the analysis to detect as relevant a difference of a 588 point increase in IIQ 71.1% and probability of obtaining a relevant improvement in the questionnaire IIQ 10% (IC 95%) 0% to 39.4%.\nQuestion: Do the incontinent patients improve their equality of life using a humidity detector device?",
    "gt": "A negative impact in the Quality of Life due to frequent changes of incontinence pads.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We assessed whether testicular growth arrest is related to varicocele size in adolescents. We also determined whether adolescents with a varicocele and testes of equal size treated nonoperatively are at significant risk for growth arrest and, if so, whether this risk is related to varicocele size. We retrospectively reviewed the records of boys with a varicocele. Testis volume was measured with calipers and computed into cc as (length x width x breadth) x 0.521. Testicular growth arrest was defined as left testis at least 15% smaller than the right testis. Varicocele size was graded 1-barely palpable, 2-palpable but not visible, 3a-visible and, 1 to 1.5 times the size of the ipsilateral testis, 3b-1.5 to 2 times the size of the ipsilateral testis and 3c-greater than 2 times the size of the ipsilateral testis. Boys with a grade 1 varicocele and those treated with previous inguinal or testicular surgery were excluded from study. Repair was recommended for testicular growth arrest or discomfort. Data were analyzed with chi-square and Fisher's exact test. The records of 124 boys 7 to 18 years old (mean age 13) with a varicocele were reviewed. Seven patients were excluded from analysis, yielding a total of 117 boys. Testicular growth arrest was observed at initial visit in 10 of 33 (30.3%) grade 2, 18 of 37 (48.6%) grade 3a, 14 of 31 (45.2%) grade 3b and 6 of 16 (37.5%) grade 3c cases (p not significant), or a total of 38 of 84 (45.2%) grade 3 cases (p<0.01) plus grade 2. Followup ranged from 1 to 5 years. Of the cases of equal sized testes at presentation growth arrest was observed in 3 of 16 (18.8%) grade 2, 2 of 11 (18.2%) grade 3a, 4 of 14 (28.6%) grade 3b and 3 of 9 (33.3%) grade 3c (p not significant), or a total of 9 of 34 (26.5%) grade 3 cases (p not significant) plus grade 2. Overall, testicular growth arrest was found in 13 of 33 (39%) grade 2 and 47 of 84 (56%) grade 3 varicoceles (p<0.01).\nQuestion: Testicular growth arrest and adolescent varicocele: does varicocele size make a difference?",
    "gt": "Boys with a varicocele are at significant risk for testicular growth arrest, irrespective of varicocele size, and those with a grade 3 varicocele have a higher risk of testicular growth arrest than those with a grade 2 varicocele. Of boys with testes of equal size at diagnosis growth arrest is observed during adolescence in approximately 25% irrespective of varicocele size.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Roux-en-Y gastric bypass (RYGBP) either laparoscopic or open has been increasingly employed in the treatment of patients with morbid obesity. Laparoscopic approach is believed to be superior over open approach in terms of shorter hospital stay and easier recovery. We aimed to assess feasibility and safety of open RYGBP with short stay in comparison with laparoscopic RYGBP. One hundred and ninety consecutive patients were assigned to open (n=103) or laparoscopic (n=87) RYGBP. The first 20 patients of the laparoscopic arm were excluded due to procedure learning curve. Patients were treated by a multidisciplinary team focused on successfully RYGBP with short stay (1 day). Short stay was reached by 90% of patients operated with open approach and 81% by laparoscopy (P=0.070). Discharge in the second day was reached by 97% of patients in both groups. Procedure length [(median (IQR)] was faster for open RYGBP [103 (70-180 min) vs. 169 (105-248 min); P<0.0001]. Thirty-day readmission rate was similar between groups (3% vs. 7%; P=0.266). There was no death in either group.\nQuestion: Hospital discharge in the day following open Roux-en-Y gastric bypass: is it feasible and safe?",
    "gt": "Short stay (1 day) following open gastric bypass was a feasible and safe procedure. This approach might have economic impact and might increase patient acceptance for open RYGBP.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Acromegaly is characterized not only by disabling symptoms, but also by relevant co-morbidities. Insulin resistance, leading to glucose intolerance is one of the most important contributory factors to the cardiovascular mortality in acromegaly. We analysed the records of 220 naïve patients with acromegaly diagnosed at our Department in the years 1995-2007. Diagnosis of active acromegaly was established on the basis of widely recognized criteria. In each patient glucose and insulin concentrations were assessed when fasting and during the 75 g OGTT. Normoglycaemia existed in 46% of acromegalic patients. Among glucose tolerance abnormalities we found impaired fasting glucose in 19%, impaired glucose tolerance in 15% and overt diabetes mellitus in 20%. There was no statistically significant differences in gender, duration of the disease, basal plasma GH, IGF-1 or fasting insulin concentrations between normoglycaemic patients and those with impairments in glucose tolerance. The groups showed statistically significant differences with respect to age at diagnosis (p<0.01). There was no significant correlation between GH, IGF-1 concentrations and fasting plasma glucose. There was no correlation between the duration of the disease and fasting plasma glucose. We found a statistically significant correlation between plasma GH, IGF-1 concentrations and HOMA, QUICKI and insulinAUC.\nQuestion: Abnormalities in glucose homeostasis in acromegaly. Does the prevalence of glucose intolerance depend on the level of activity of the disease and the duration of the symptoms?",
    "gt": "The prevalence of diabetes mellitus among acromegalics is much higher than in the general population. The occurrence of glucose tolerance impairments does not depend on the duration of the disease. In patients with acromegaly insulin resistance and hyperinsulinemia are positively correlated with the level of activity of the disease.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Obese and morbidly obese patients undergoing lumbar spinal fusion surgery are a challenge to the operating surgeon. Minimally invasive transforaminal lumbar interbody fusion (MIS-TLIF) and open-TLIF have been performed for many years with good results; however, functional outcomes after lumbar spine surgery in this subgroup of patients remain poorly understood. Furthermore, whether index MIS-TLIF or open-TLIF for the treatment of degenerative disc disease or spondylolisthesis in morbidly obese results in superior postoperative functional outcomes remains unknown. A total of 148 (MIS-TLIF: n = 40, open-TLIF: n = 108) obese and morbidly obese patients undergoing index lumbar arthrodesis for low back pain and/or radiculopathy between January 2003 and December 2010 were selected from a multi-institutional prospective data registry. We collected and analyzed data on patient demographics, postoperative complications, back pain, leg pain, and functional disability over 2 years. Patients completed the Oswestry Disability Index (ODI), Medical Outcomes Study Short-Form 36 (SF-36), and back and leg pain numerical rating scores before surgery and then at 12 and 24 months after surgery. Clinical outcomes and complication rates were compared between both patient cohorts. Compared with preoperative status, Visual Analog Scale (VAS) back and leg pain, ODI, and SF-36 physical component score/mental component score were improved in both groups. Both MIS-TLIF and open-TLIF patients showed similar 2-year improvement in VAS for back pain (MIS-TLIF: 2.42 ± 3.81 vs. open-TLIF: 2.33 ± 3.67, P = 0.89), VAS for leg pain (MIS-TLIF: 3.77 ± 4.53 vs. open-TLIF: 2.67 ± 4.10, P = 0.18), ODI (MIS-TLIF: 11.61 ± 25.52 vs. open-TLIF: 14.88 ± 22.07, P = 0.47), and SF-36 physical component score (MIS-TLIF: 8.61 ± 17.72 vs. open-TLIF: 7.61 ± 15.55, P = 0.93), and SF-36 mental component score (MIS-TLIF: 4.35 ± 22.71 vs. open-TLIF: 5.96 ± 21.09, P = 0.69). Postoperative complications rates between both cohorts were also not significantly divergent between (12.50% vs. 11.11%, P = 0.51).\nQuestion: A prospective, multi-institutional comparative effectiveness study of lumbar spine surgery in morbidly obese patients: does minimally invasive transforaminal lumbar interbody fusion result in superior outcomes?",
    "gt": "MIS-TLIF is a safe and viable option for lumbar fusion in morbidly obese patients and, compared with open-TLIF, resulted in similar improvement in pain and functional disability. Postoperative complications rates between both cohorts were also not significantly divergent.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The evidence supporting the survival benefit of multiple arterial grafts in the general coronary bypass surgery (CABG) population is compelling. Alternatively, results of studies comparing 2 versus 1 internal thoracic artery (ITA) grafts in diabetics have reported conflicting survival data. The use of radial versus ITA as the second arterial conduit has not been studied. We obtained complete death follow-up in 1516 consecutive diabetic [64+/-10 years (mean+/-SD). Insulin/no insulin: There were 540 (36%)/976 (64%)] primary isolated CABG patients all with>or=1 ITA grafts. The series included 626 ITA/radial (41%) and 890 ITA/vein (59%) patients. Using separate radial-use propensity models, we matched one-to-one 475 (76%) ITA/radial to 475 (53%) unique ITA/vein patients; each including 166 insulin and 309 no insulin patients. Unadjusted survival was markedly better for (1) ITA/radial (94.3%, 86.7% and 70.4% at 1, 5 and 10 years, respectively) versus ITA/vein (91.8%, 74.5% and 53.8%; p<0.0001) and (2) for no insulin (94.2%, 82.8% and 65.5%) versus insulin (90.4%, 73.1% and 49.2%; p<0.0001). In matched patients, 11-year Kaplan-Meier analysis showed essentially identical ITA/radial and ITA/vein survival for all diabetics combined (p=0.53; log rank) and for the no insulin (p=0.76) cohort. Lastly, a trend for better ITA/radial survival in insulin dependent diabetics after the second postoperative year did not reach significance (p=0.13).\nQuestion: Does radial use as a second arterial conduit for coronary artery bypass grafting improve long-term outcomes in diabetics?",
    "gt": "Using radial as a second arterial conduit as opposed to vein grafting did not confer a survival benefit in diabetics. This unexpected result is perhaps related to relatively diminished radial graft patency and/or the augmented radial vasoreactivity characteristic of diabetics. These findings indicate that the radial survival advantage demonstrated in the general CABG population lies primarily in non-diabetics in whom this advantage may be underestimated.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Prenatal smoking is robustly associated with increased risk of conduct problems in offspring. Observational studies that provide detailed phenotypic description are critical for generating testable hypotheses about underlying processes through which the effects of prenatal smoking may operate. To this end, we use a developmental framework to examine the association of exposure with (1) oppositional defiant disorder and attention-deficit/hyperactivity disorder in young boys and (2) the pattern of delinquent behavior at adolescence. Using diagnostic measures and repeated measures of delinquency, we compare exposed and nonexposed boys from the youngest cohort of the Pittsburgh Youth Study (N = 448). Exposed boys were significantly more likely to (1) develop oppositional defiant disorder and comorbid oppositional defiant disorder-attention-deficit/hyperactivity disorder but not attention-deficit/hyperactivity disorder alone and (2) to have an earlier onset of significant delinquent behavior.\nQuestion: Is prenatal smoking associated with a developmental pattern of conduct problems in young boys?",
    "gt": "The early emergence and developmental coherence of exposure-related conduct problems is striking and is consistent with a behavioral teratological model. Phenotypically, exposure-related conduct problems appear to be characterized by socially resistant and impulsively aggressive behavior. Whether prenatal smoking plays an etiological role in or is a risk marker for the development of conduct problems, exposed offspring are at increased risk of an early-starter pathway to conduct problems.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Most of the studies on cardiovascular disease (CVD) risk factors in menopause have focused on serum lipid(lipoprotein) abnormalities and were conducted in populations which were not well controlled for several important influential factors. Two homogenous groups of 30 apparently healthy Caucasian premenopausal women and 3-5 years postmenopausal women who were nonobese, nonsmoking and not using estrogen were compared in a well-controlled cross-sectional design. Fasting serum ferritin and plasma total homocysteine (tHcy) were evaluated concomitantly to classical serum lipid(lipoprotein) risk factors. Relationships between risk factors and the influence of other contributing variables such as diet and body weight were also examined. Serum total cholesterol (p<0.01), low-density lipoproteins (LDL; p<0.05) and triglycerides (p<0.05) of postmenopausal women were greater than that of their menstruating counterparts, even though they ate a CVD-preventive diet, had similar body weight and body fat distribution. Their serum ferritin was almost 3-fold greater (p<0.0001) but was still within normal limits, except for the 38.5% of postmenopausal women who exhibited values above the 80 mug/l limit that has been associated with sharp increases in the rate of heart disease in either gender. Serum ferritin was low in one third of the postmenopausal group (as low as in the premenopausal control group, whose dietary iron intake was slightly below the nutritional recommendation). The mean plasma tHcy of the postmenopausal group was almost twice as elevated (p<0.0001). Both ferritin and tHcy were found to be linked to serum cholesterol. The correlation between tHcy and triglycerides was also significant.\nQuestion: Is serum ferritin an additional cardiovascular risk factor for all postmenopausal women?",
    "gt": "Early menopause is not associated with blood iron overload and CVD risk factor in an important proportion of women.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The Active Healthy Kids the Netherlands (AHKN) Report Card consolidates and translates research and assesses how the Netherlands is being responsible in providing physical activity (PA) opportunities for children and youth (<18 years). The primary aim of this article is to summarize the results of the 2016 AHKN Report Card. Nine indicators were graded using the Active Healthy Kids Global Alliance report card development process, which includes a synthesis of the best available research, surveillance, policy and practice findings, and expert consensus. Grades assigned were: Overall Physical Activity Levels, D; Organized Sport Participation, B; Active Play, B; Active Transportation, A; Sedentary Behaviors, C; Family and Peers, B; School, C; Community and the Built Environment, A; Government Strategies and Investments, INC.\nQuestion: Is our Youth Cycling to Health?",
    "gt": "Sedentary behavior and overall PA levels are not meeting current guidelines. However, the Dutch youth behaviors in sports, active transportation, and active play are satisfactory. Several modifiable factors of influence might be enhanced to improve these indicators or at least prevent regression. Although Dutch children accumulate a lot of daily PA through cycling, it is not enough to meet the current national PA guidelines of 60 minutes of moderate-to-vigorous PA per day.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: As our healthcare system moves toward bundling payments, orthopaedic trauma surgeons will be increasingly benchmarked on perioperative complications. We therefore sought to determine financial risks under bundled payments by identifying adverse event rates for (1) orthopaedic trauma patients compared with general orthopaedic patients and (2) based on anatomic region and (3) to identify patient factors associated with complications. Prospective. Multicenter.PATIENTS/ A total of 146,773 orthopaedic patients (22,361 trauma) from 2005 to 2011 NSQIP data were identified. Minor and major adverse events, demographics, surgical variables, and patient comorbidities were collected. Multivariate regressions determined significant risk factors for the development of complications. The complication rate in the trauma group was 11.4% (2554/22,361) versus 4.1% (5137/124,412) in the general orthopaedic group (P = 0.001). When controlling for all variables, trauma was a risk factor for developing complications [odds ratio (OR): 1.69, 95% confidence interval (CI): 1.57-1.81]. After controlling for several patient factors, hip and pelvis patients were 4 times more likely to develop any perioperative complication than upper extremity patients (OR: 3.79, 95% CI: 3.01-4.79, P = 0.01). Lower extremity patients are 3 times more likely to develop any complication versus upper extremity patients (OR: 2.82, 95% CI: 2.30-3.46, P = 0.01).\nQuestion: Adverse Events in Orthopaedics: Is Trauma More Risky?",
    "gt": "Our study is the first to show that orthopaedic trauma patients are 2 times more likely than general orthopaedic patients to sustain complications, despite controlling for identical risk factors. There is also an alarming difference in complication rates among anatomic regions. Orthopaedic trauma surgeons will face increased financial risk with bundled payments.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Whether the isolated VSD (i-VSD) is associated with aneuploidy to the same degree as a more severe heart anomaly is unclear. Our objective was to determine the likelihood of aneuploidy in pregnancies at a tertiary referral center when an i-VSD is detected before 24 weeks. A retrospective chart review of all detailed anatomy ultrasounds before 24 weeks performed at the University of Kansas Medical Center from 08/23/2006 to 06/07/2012 was conducted. A complete evaluation of the fetal heart was accomplished using gray scale and spectral/color Doppler examinations. The outcomes of each pregnancy were reviewed for any diagnoses of aneuploidy. Odds ratios were calculated. A total of 4078 pregnancies with complete obstetric and neonatal data were reviewed. The prevalence of an i-VSD was 2.7% (112/4078). The odds ratio of aneuploidy when an i-VSD was present was (OR: 36.0, 95% CI: 5.0, 258.1). This odds ratio remained large when either an abnormal or unknown serum screen was present.\nQuestion: Is an isolated ventricular septal defect detected before 24 weeks on ultrasound associated with fetal aneuploidy?",
    "gt": "The presence of an i-VSD present before 24 weeks does increase the risk of fetal aneuploidy. Whether a normal serum screen or first trimester screen for aneuploidy negates the association of an i-VSD with aneuploidy still remains undetermined.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Despite significant risk for venous thromboembolism, severely injured trauma patients often are not candidates for prophylaxis or treatment with anticoagulation. Long-term inferior vena cava (IVC) filters are associated with increased risk of postphlebitic syndrome. Retrievable IVC filters potentially offer a better solution, but only if the filter is removed; our hypothesis is that the most of them are not. This retrospective study queried a level I trauma registry for IVC filter insertion from September 1997 through June 2004. One IVC filter was placed before the availability of retrievable filters in 2001. Since 2001, 27 filters have been placed, indicating a change in practice patterns. Filters were placed for prophylaxis (n = 11) or for therapy in patients with pulmonary embolism or deep vein thrombosis (n = 17). Of 23 temporary filters, only 8 (35%) were removed.\nQuestion: Are temporary inferior vena cava filters really temporary?",
    "gt": "Surgeons must critically evaluate indications for IVC filter insertion, develop standard criteria for placement, and implement protocols to ensure timely removal of temporary IVC filters.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Macrophage death in advanced lesion has been confirmed to play an important role in plaque instability. However, the mechanism underlying lesion macrophage death still remains largely unknown. Immunohistochemistry showed that caspase-1 activated in advanced lesion and co-located with macrophages and TUNEL positive reaction. In in-vitro experiments showed that ox-LDL induced caspase-1 activation and this activation was required for ox-LDL induced macrophages lysis, IL-1β and IL-18 production as well as DNA fragmentation. Mechanism experiments showed that CD36 and NLRP3/caspase-1/pathway involved in ox-LDL induced macrophage pyroptosis.\nQuestion: Oxidized low density lipoprotein induced caspase-1 mediated pyroptotic cell death in macrophages: implication in lesion instability?",
    "gt": "Our study here identified a novel cell death, pyroptosis in ox-LDL induced human macrophage, which may be implicated in lesion macrophages death and play an important role in lesion instability.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The objective of this study was to quantify the effects of radiation-induced cancer risks in patients with Bosniak category IIF lesions undergoing CT versus MRI surveillance. We developed a Markov-Monte Carlo model to determine life expectancy losses attributable to radiation-induced cancers in hypothetical patients undergoing CT versus MRI surveillance of Bosniak IIF lesions. Our model tracked hypothetical patients as they underwent imaging surveillance for up to 5 years, accounting for potential lesion progression and treatment. Estimates of radiation-induced cancer mortality were generated using a published organ-specific radiation-risk model based on Biological Effects of Ionizing Radiation VII methods. The model also incorporated surgical mortality and renal cancer-specific mortality. Our primary outcome was life expectancy loss attributable to radiation-induced cancers. A sensitivity analysis was performed to assess the stability of the results with variability in key parameters. The mean number of examinations per patient was 6.3. In the base case, assuming 13 mSv per multiphase CT examination, 64-year-old men experienced an average life expectancy decrease of 5.5 days attributable to radiation-induced cancers from CT; 64-year-old women experienced a corresponding life expectancy loss of 6.9 days. The results were most sensitive to patient age: Life expectancy loss attributable to radiation-induced cancers increased to 21.6 days in 20-year-old women and 20.0 days in 20-year-old men. Varied assumptions of each modality's (CT vs MRI) depiction of lesion complexity also impacted life expectancy losses.\nQuestion: Microsimulation model of CT versus MRI surveillance of Bosniak IIF renal cystic lesions: should effects of radiation exposure affect selection of imaging strategy?",
    "gt": "Microsimulation modeling shows that radiation-induced cancer risks from CT surveillance for Bosniak IIF lesions minimally affect life expectancy. However, as progressively younger patients are considered, increasing radiation risks merit stronger consideration of MRI surveillance.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The vast majority of pancreatic cancers occurs sporadically. The discovery of frequent variations in germline gene copy number can significantly influence the expression levels of genes that predispose to pancreatic adenocarcinoma. We prospectively investigated whether patients with sporadic pancreatic adenocarcinoma share specific gene copy number variations (CNVs) in their germline DNA. DNA samples were analyzed from peripheral leukocytes from 72 patients with a diagnosis of sporadic pancreatic adenocarcinoma and from 60 controls using Affymetrix 500K array set. Multiplex ligation-dependent probe amplification (MLPA) assay was performed using a set of self-designed MLPA probes specific for seven target sequences. We identified a CNV-containing DNA region associated with pancreatic cancer risk. This region shows a deletion of 1 allele in 36 of the 72 analyzed patients but in none of the controls. This region is of particular interest since it contains the YTHDC2 gene encoding for a putative DNA/RNA helicase, such protein being frequently involved in cancer susceptibility. Interestingly, 82.6% of Sicilian patients showed germline loss of one allele.\nQuestion: Germline copy number variation in the YTHDC2 gene: does it have a role in finding a novel potential molecular target involved in pancreatic adenocarcinoma susceptibility?",
    "gt": "Our results suggest that the YTHDC2 gene could be a potential candidate for pancreatic cancer susceptibility and a useful marker for early detection as well as for the development of possible new therapeutic strategies.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Homocystinuria due to cystathionine beta-synthase deficiency and familial hypercholesterolemia are inherited disorders of metabolism that are associated with premature development of cardiovascular disease. This study addresses the possibility that different patterns of carotid wall damage and cerebral blood flow hemodynamics are present in these two metabolic diseases. Twelve patients with homocystinuria due to cystathionine beta-synthase deficiency (mean age, 24 years), 10 patients with homozygous familial hypercholesterolemia (mean age, 26 years), and 11 healthy control subjects (mean age, 26 years) underwent a vascular examination by noninvasive methods. B-mode ultrasound imaging was used to obtain measurements of intima-media thickness of common carotid, bifurcation, and internal carotid arteries as an index of atherosclerosis. Cerebral blood flow velocity was estimated from vascular examination of the middle cerebral artery by transcranial Doppler. Systolic, diastolic, and mean velocities were measured. Pulsatility index, a possible indicator of vascular resistance in the cerebral circulation, was also calculated. Mean maximum intima-media thickness was 1.4 mm in patients with familial hypercholesterolemia, 0.6 mm in patients with homocystinuria, and 0.6 mm in control subjects. The difference between hypercholesterolemic and homocystinuric patients or control subjects was statistically significant (P<.001). Diastolic blood flow velocities were significantly reduced in the middle cerebral arteries of hypercholesterolemic patients compared with homocystinuric patients or control subjects (P<.05), whereas systolic or mean velocities did not differ. The pulsatility index, a possible indicator of vascular resistance in the cerebral circulation, was significantly higher in hypercholesterolemic patients compared with homocystinuric patients or healthy control subjects (P<.01). A direct relation was demonstrated between pulsatility index of the middle cerebral artery and mean maximum intima-media thickness of carotid arteries on the same side (P<.001).\nQuestion: Premature carotid atherosclerosis: does it occur in both familial hypercholesterolemia and homocystinuria?",
    "gt": "Familial hypercholesterolemia is responsible for diffuse and focal thickening of carotid arteries and possibly also for hyperlipidemic endothelial dysfunction extending to small resistance arteries and leading to a disturbed cerebral blood flow. Patients with homocystinuria due to homozygosis for cystathionine beta-synthase deficiency seldom have plaques in their carotid arteries. They are similar to healthy control subjects with regard to both intima-media thickness and blood flow velocity in the middle cerebral artery. Therefore, it is unlikely that typical atherosclerotic lesions precede thrombotic events in homocystinuria. However, it is possible that arterial dilatations caused by medial damage lead to thrombosis in homocystinuric patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Urinalysis is the third major test in clinical laboratory. Manual technique imprecision urges the need for a rapid reliable automated test. We evaluated the H800-FUSIOO automatic urine sediment analyzer and compared it to the manual urinalysis technique to determine if it may be a competitive substitute in laboratories of central hospitals. 1000 urine samples were examined by the two methods in parallel. Agreement, precision, carryover, drift, sensitivity, specificity, and practicability criteria were tested. Agreement ranged from excellent to good for all urine semi-quantitative components (K>0.4, p = 0.000), except for granular casts (K = 0.317, p = 0.000). Specific gravity results correlated well between the two methods (r = 0.884, p = 0.000). RBCS and WBCs showed moderate correlation (r = 0.42, p = 0.000) and (r = 0.44, p = 0.000), respectively. The auto-analyzer's within-run precision was>75% for all semi-quantitative components except for proteins (50% precision). This finding in addition to the granular casts poor agreement indicate the necessity of operator interference at the critical cutoff values. As regards quantitative contents, RBCs showed a mean of 69.8 +/- 3.95, C.V. = 5.7, WBCs showed a mean of 38.9 +/- 1.9, C.V. = 4.9). Specific gravity, pH, microalbumin, and creatinine also showed good precision results with C.Vs of 0.000, 2.6, 9.1, and 0.00 respectively. In the between run precision, positive control showed good precision (C.V. = 2.9), while negative control's C.V. was strikingly high (C.V. = 127). Carryover and drift studies were satisfactory. Manual examination of inter-observer results showed major discrepancies (<60% similar readings), while intra-observer's results correlated well with each other (r = 0.99, p = 0.000).\nQuestion: Urinalysis: The Automated Versus Manual Techniques; Is It Time To Change?",
    "gt": "Automation of urinalysis decreases observer-associated variation and offers prompt competitive results when standardized for screening away from the borderline cutoffs.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To examine 5-year survival from haematological malignancies in children, adolescents and young adults in Australia and determine if there has been any improvement in survival for the older age groups compared with children (the age-related \"survival gap\"). Population-based study of all Australian children (aged 0-14 years), adolescents (15-19 years) and young adults (20-29 years) diagnosed with acute lymphoblastic leukaemia (ALL), acute myeloid leukaemia (AML), Hodgkin lymphoma (HL) and non-Hodgkin lymphoma (NHL) between 1982 and 2004, with follow-up to 2006. 5-year survival from ALL, AML, HL and NHL analysed for four periods of diagnosis (1982-1989, 1990-1994, 1995-1999 and 2000-2004). During 1982-2004, 13 015 people aged<or = 29 years were diagnosed with primary leukaemia or lymphoma in Australia. For those with ALL, 5-year survival for adolescents improved from 40% (1982-1989) to 74% (2000-2004); the improvement for young adults was smaller (31% to 47%), and both these groups still had lower survival than children, whose 5-year survival improved from 74% to 88%. There was a larger narrowing of the gap for AML: for cases diagnosed in 2000-2004, 5-year survival was similar for young adults (63%), adolescents (74%) and children (69%). For lymphoma cases diagnosed in 2000-2004, 5-year survival in all age groups was greater than 95% for HL and greater than 81% for NHL, although children fared better than adolescents and young adults.\nQuestion: Survival from haematological malignancy in childhood, adolescence and young adulthood in Australia: is the age-related gap narrowing?",
    "gt": "These Australian population-based data confirm an improvement in survival from haematological malignancies across all three age groups, but an age-related survival gap remains for adolescents and young adults compared with children, especially for young adults with ALL. Greater participation of adolescents and young adults in clinical trials and more detailed data collection are needed to provide evidence about optimal treatment regimens in these age groups.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Nipple-sparing mastectomy (NSM) preserves the native skin envelope, including the nipple-areolar skin, and has significant benefits including improved aesthetic outcome and psychosocial well-being. Patients with prior breast scars undergoing NSM are thought to be at increased risk for postoperative complications, such as skin and/or nipple necrosis. This study describes our experience performing NSM in patients who have had prior breast surgery and aims to identify potential risk factors in this subset of patients. A retrospective review of all patients undergoing nipple sparing mastectomy at The University of Utah from 2005 to 2011 was performed. Fifty-two patients had prior breast scars, for a total of 65 breasts. Scars were categorized into 4 groups depending on scar location: inframammary fold, outer quadrant, periareolar, and circumareolar. Information regarding patient demographics, social and medical history, treatment intent, and postoperative complications were collected and analyzed. Eight of the 65 breasts (12%) developed a postoperative infection requiring antibiotic treatment. Tobacco use was associated with an increased risk of infection in patients with prior breast scars (odds ratio [OR], 7.95; 95% confidence interval [CI], 1.37-46.00; P = 0.0206). There was a 13.8% rate of combined nipple and skin flap necrosis and receipt of chemotherapy (OR, 5.00; CI, 1.11-22.46; P = 0.0357) and prior BCT (OR, 12.5; CI, 2.2-71.0; P = 0.004) were found to be associated with skin flap or NAC necrosis.\nQuestion: Nipple Sparing Mastectomy in Patients With Prior Breast Scars: Is It Safe?",
    "gt": "Nipple-sparing mastectomy is a safe and viable option for patients with a prior breast scar. Our results are comparable to the published data in patients without a prior scar. Caution should be exercised with patients who have a history of tobacco use or those requiring chemotherapy because these patients are at increased risk for infection and NAC/skin flap necrosis, respectively, when undergoing NSM in the setting of a prior breast scar.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To compare the strength of the association between depression and mortality between elderly and younger individuals with diabetes mellitus. A survival analysis conducted in a longitudinal cohort study of persons with diabetes mellitus to test the association between depression and mortality in older (≥ 65) and younger (18-65) adults. Managed care. Persons aged 18 and older with diabetes mellitus who participated in the Wave 2 survey of the Translating Research Into Action for Diabetes (TRIAD) Study (N = 3,341). The primary outcome was mortality risk, which was measured as days until death using linked data from the National Death Index. Depression was measured using the Patient Health Questionnaire. After controlling for age, sex, race and ethnicity, income, and other comorbidities, mortality risk in persons with diabetes mellitus was 49% higher in those with depression than in those without, although results varied according to age. After controlling for the same variables, mortality risk in persons aged 65 and older with depression was 78% greater than in those without. For those younger than 65, the effect of depression on mortality was smaller and not statistically significant.\nQuestion: Depression and all-cause mortality in persons with diabetes mellitus: are older adults at higher risk?",
    "gt": "This analysis suggests that the effect of depression on mortality in persons with diabetes mellitus is most significant for older adults. Because there is evidence in the literature that treatment of depression in elderly adults can lead to lower mortality, these results may suggest that older adults with diabetes mellitus should be considered a high-priority population for depression screening and treatment.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Natriuretic peptides (NP) are well-established markers of heart failure (HF). During the past 5 years, analytical and clinical recommendations for measurement of these biomarkers have been published in guidelines. The aim of this follow-up survey was to investigate how well these guidelines for measurement of NP have been implemented in laboratory practice in Europe. Member societies of the European Federation of Clinical Chemistry and Laboratory Medicine were invited in 2009 to participate in a web-based audit questionnaire. The questionnaire requested information on type of tests performed, decision limits for HF, turn-around time and frequency of testing. There was a moderate increase (12%) of laboratories measuring NP compared to the initial survey in 2006. The most frequently used HF decision limits for B-type NP (BNP) and N-terminal BNP (NT-proBNP) were, respectively, 100 ng/L and 125 ng/L, derived from the package inserts in 55%. Fifty laboratories used a second decision limit. Age or gender dependent decision limits were applied in 10% (8.5% in 2006). The vast majority of laboratories (80%) did not have any criteria regarding frequency of testing, compared to 33% in 2006.\nQuestion: Do laboratories follow heart failure recommendations and guidelines and did we improve?",
    "gt": "The implementation of NP measurement for HF management was a slow process between 2006 and 2009 at a time when guidelines had just been established. The decision limits were derived from package insert information and literature. There was great uncertainty concerning frequency of testing which may reflect the debate about the biological variability which was not published for most of the assays in 2009.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether access to a computer generated electrocardiogram (ECG) report can reduce errors of interpretation by senior house officers (SHOs) in an accident and emergency department. Ten SHOs were asked to interpret 50 ECGs each: 25 with computer generated reports, 25 without. Their answers, and the computer generated reports, were compared with a \"gold standard\" produced by two experienced clinicians. The primary outcome measure was the proportion of major errors of interpretation. The computer reading system made two major errors (4%, 95% confidence interval (CI) 1.1% to 13.5%) compared with the gold standard. Access to the computer report did not significantly reduce major errors among SHOs (46 (18.4%) with report v 56 (22.4%) without, odds ratio 0.64, 95% CI 0.36% to 1.14%, p=0.13) or improve the proportion completely correct (104 (41.6%) with report v 91 (36.4%) without, odds ratio 1.43, 95% CI 0.88 to 2.33, p=0.15).\nQuestion: Do computer generated ECG reports improve interpretation by accident and emergency senior house officers?",
    "gt": "SHOs have a high error rate when interpreting ECGs, which is not significantly reduced by access to a computer generated report. Junior doctors should continue to seek expert senior help when they have to interpret a difficult ECG.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Respondent-driven sampling (RDS) is an increasingly used peer chain-recruitment method to sample \"hard-to-reach\" populations for whom there are no reliable sampling frames. Implementation success of RDS varies; one potential negative factor being the number of seeds used. We conducted a sensitivity analysis on estimates produced using data from an RDS study of gay, bisexual and other men who have sex with men (GBMSM) aged ≥16 years living in Vancouver, Canada. Participants completed a questionnaire on demographics, sexual behavior and substance use. For analysis, we used increasing seed exclusion criteria, starting with all participants and subsequently removing unproductive seeds, chains of ≤1 recruitment waves, and chains of ≤2 recruitment waves. We calculated estimates for three different outcomes (HIV serostatus, condomless anal intercourse with HIV discordant/unknown status partner, and injecting drugs) using three different RDS weighting procedures: RDS-I, RDS-II, and RDS-SS. We also assessed seed dependence with bottleneck analyses and convergence plots. Statistical differences between RDS estimators were assessed through simulation analysis. Overall, 719 participants were recruited, which included 119 seeds and a maximum of 16 recruitment waves (mean chain length = 1.7). The sample of>0 recruitment waves removed unproductive seeds (n = 50/119, 42.0%), resulting in 69 chains (mean length = 3.0). The sample of>1 recruitment waves removed 125 seeds or recruits (17.4% of overall sample), resulting in 37 chains (mean length = 4.8). The final sample of>2 recruitment waves removed a further 182 seeds or recruits (25.3% of overall sample), resulting in 25 chains (mean length = 6.1). Convergence plots and bottleneck analyses of condomless anal intercourse with HIV discordant/unknown status partner and injecting drugs outcomes were satisfactory. For these two outcomes, regardless of seed exclusion criteria used, the crude proportions fell within 95% confidence intervals of all RDS-weighted estimates. Significant differences between the three RDS estimators were not observed.\nQuestion: Does size really matter?",
    "gt": "Within a sample of GBMSM in Vancouver, Canada, this RDS study suggests that when equilibrium and homophily are met, although potentially costly and time consuming, analysis is not negatively affected by large numbers of unproductive or lowly productive seeds.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The purpose of the present paper was to investigate whether screening for abdominal aortic aneurysm (AAA) causes health-related quality of life to change in men or their partners. A cross-sectional case-control comparison was undertaken of men aged 65-83 years living in Perth, Western Australia, using questionnaires incorporating three validated instruments (Medical Outcomes Study Short Form-36, EuroQol EQ-5D and Hospital Anxiety and Depression Scale) as well as several independent questions about quality of life. The 2009 men who attended for ultrasound scans of the abdominal aorta completed a short prescreening questionnaire about their perception of their general health. Four hundred and ninety-eight men (157 with an AAA and 341 with a normal aorta) were sent two questionnaires for completion 12 months after screening, one for themselves and one for their partner, each being about the quality of life of the respondent. Men with an AAA were more limited in performing physical activities than those with a normal aorta (t-test of means P = 0.04). After screening, men with an AAA were significantly less likely to have current pain or discomfort than those with a normal aorta (multivariate odds ratio: 0.5; 95% confidence interval (CI): 0.3-0.9) and reported fewer visits to their doctor. The mean level of self-perceived general health increased for all men from before to after screening (from 63.4 to 65.4).\nQuestion: Is screening for abdominal aortic aneurysm bad for your health and well-being?",
    "gt": "Apart from physical functioning, screening was not associated with decreases in health and well-being. A high proportion of men rated their health over the year after screening as being either the same or improved, regardless of whether or not they were found to have an AAA.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The concerns for hyperoxia-related brain tissue injury are well known to the medical community. The cerebro-vasodilatory properties of sevoflurane may create relative cerebral tissue \"hyperoxia\" during inhalational induction as compared to a propofol-based intravenous induction of anesthesia. The objective for this case series discussion was to identify any differences in cerebral tissue oxygenation secondary to induction of anesthesia with sevoflurane versus propofol. METHODS/ After institutional review board approval, the computer data of tissue cerebral oximetry of pediatric patients (1-18 years age group) undergoing non-cardiac surgeries was comparatively analyzed for changes over time between the groups of children who received sevoflurane induction versus propofol induction of anesthesia. \"Hyperoxia\" (\"hyperoxygenation\") was defined as significant percent changes from the baseline values as recorded in tissue cerebral oximetry. In this case series, seven patients underwent inhalational (INH) induction with high concentrations (8%) sevoflurane with nitrous oxide in 33% oxygen and four patients underwent intravenous (i.v.) induction with 2 mg/kg propofol and nitrous oxide in 33% oxygen. As compared to propofol, significant cerebral tissue \"hyperoxia\" occurred with sevoflurane induction (p = 0.003). This did not resolve over time.\nQuestion: Inhalational induction with \"vasoparalytic\" sevoflurane: are we \"hyperoxygenating\" while anesthetizing developing brains?",
    "gt": "As compared to intravenous induction with propofol, inhalational induction with \"vasoparalytic\" sevoflurane \"hyperoxygenates\" developing brains. This observation requires validation in larger trials to conclude appropriate effect on our practice of pediatric anesthesia and pediatric patient safety under anesthesia.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Edema surrounding the medial collateral ligament (MCL) is seen on MR imaging in patients with MCL injuries and in patients with radiographic osteoarthritis in the non-traumatic knee. Because we noted MCL edema in patients without prior trauma or osteoarthritis, we studied the association between intra-articular pathology and MCL edema in patients without knee trauma. We evaluated the MR examinations of 247 consecutive patients (121 male, 126 female with a mean age of 44 years) without recent trauma for the presence of edema surrounding the MCL, meniscal and ACL tears, medial meniscal extrusion, medial compartment chondromalacia, and osteoarthritis. The percentages of patients illustrating MCL edema with and without each type of pathology were compared using Fisher's exact test to determine if there was a statistically significant association. We found MCL edema in 60% of 247 patients. MCL edema was present in 67% of patients with medial meniscal tears, 35% with lateral meniscal tears, 100% with meniscal extrusion of 3 mm or more, 78% with femoral chondromalacia, 82% with tibial chondromalacia, and 50% with osteoarthritis. The percentage of patients with edema increased with the severity of the chondromalacia. These associations were all statistically significant (p<0.02). The mean age of those with MCL edema was 49.7 years compared with 34.9 years without MCL edema ( p<0.001). Patient gender and ACL tear did not correlate with MCL edema. Nine (4%) of the 247 patients had MCL edema without intra-articular pathology. None of these 9 patients had MCL tenderness or joint laxity on physical examination.\nQuestion: Is intra-articular pathology associated with MCL edema on MR imaging of the non-traumatic knee?",
    "gt": "We confirmed that MCL edema is associated with osteoarthritis, but is also associated with meniscal tears, meniscal extrusion, and chondromalacia. In addition, MCL edema can be seen in patients without intra-articular pathology, recent trauma or MCL abnormality on physical examination.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study reports 21 patients with Stage I-III low-grade non-Hodgkin's lymphoma who were treated with comprehensive lymphatic irradiation (CLI) at the University of Florida between 1966 and 1992. Sites clinically involved with disease were treated with 30 Gy, whereas clinically uninvolved sites were treated with 25 Gy. Median follow-up for the group was 14 years (24.5 years for Stage III patients). Overall absolute survival rates at 5, 10, and 15 years were 84%, 68%, and 34%. Cause-specific survival rates at 5, 10, and 15 years were 84%, 68%, and 56%. Freedom-from-relapse rates at 5, 10, and 15 years were 75%, 58%, and 58%, with no relapses noted after 10 years. Bulky disease (>6 cm) was a significant indicator of poor prognosis for cause-specific survival (p = .01).\nQuestion: Is comprehensive lymphatic irradiation for low-grade non-Hodgkin's lymphoma curative therapy?",
    "gt": "These data support findings from other institutions suggesting a role for CLI as potentially curative therapy with acceptable toxicity and a short treatment time for patients with Stages I and II and limited Stage III disease.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Upper GI (UGI) studies are routinely ordered to screen for malrotation before routine placement of gastrostomy (G) tubes. However, the usefulness of this study is unknown. A retrospective review of children with surgically placed G-tubes over a 2 year period (2011-2013) was performed. Patients with concomitant fundoplications were excluded. Three hundred ninety-three patients underwent G-tube placement. Of these, 299 patients (76%) had preoperative UGI, and 11 patients (3.7%) were identified with malrotation on UGI. Five (1.7%) patients underwent a Ladd's procedure. The remaining 6 either had malrotation associated with gastroschisis (n=5) or were lost to follow-up (n=1). Children<1 year did not have different rates of malrotation compared to older children (4.3% vs. 3.2%, p=0.617). Likewise, children with neurologic impairment (NI) had similar rates of malrotation compared to neurologically normal (NN) children (2.6% vs. 3.8%, p=0.692). The only significant difference in malrotation rate was between those with congenital gastrointestinal anomalies (24%) and those without (1.5%) (p<0.001).\nQuestion: Routine gastrostomy tube placement in children: Does preoperative screening upper gastrointestinal contrast study alter the operative plan?",
    "gt": "Preoperative screening UGI before routine G-tube placement led to an unexpected diagnosis of malrotation in only 1.7%. Given the added radiation risk associated with an UGI, our data suggest that an UGI is unnecessary prior to routine G-tube placement. A larger prospective study is warranted to validate these results.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Previous studies showed conflicting and inconsistent results regarding the effect of anatomic location of the melanoma on sentinel lymph node (SLN) positivity and/or survival. This study was conducted to evaluate and compare the effect of the anatomic locations of primary melanoma on long-term clinical outcomes. All consecutive cutaneous melanoma patients (n=2,079) who underwent selective SLN dissection (SLND) from 1993 to 2009 in a single academic tertiary-care medical center were included. SLN positive rate, disease-free survival (DFS), and overall survival (OS) were determined. Kaplan-Meier survival, univariate, and multivariate analyses were performed to determine predictive factors for SLN status, DFS, and OS. Head and neck melanoma (HNM) had the lowest SLN-positive rate at 10.8% (16.8% for extremity and 19.3% for trunk; P=0.002) but had the worst 5-year DFS (P<0.0001) and 5-year OS (P<0.0001) compared with other sites. Tumor thickness (P<0.001), ulceration (P<0.001), HNM location (P=0.001), mitotic rate (P<0.001), and decreasing age (P<0.001) were independent predictive factors for SLN-positivity. HNM with T3 or T4 thickness had significantly lower SLN positive rate compared with other locations (P≤0.05). Also, on multivariate analysis, HNM location versus other anatomic sites was independently predictive of decreased DFS and OS (P<0.001). By Kaplan-Meier analysis, HNM was associated significantly with the worst DFS and OS.\nQuestion: Is head and neck melanoma different from trunk and extremity melanomas with respect to sentinel lymph node status and clinical outcome?",
    "gt": "Primary melanoma anatomic location is an independent predictor of SLN status and survival. Although HNM has a decreased SLN-positivity rate, it shows a significantly increased risk of recurrence and death as compared with other sites.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To test the hypothesis that iodinated contrast media may induce an elevation in serum potassium level. Protocol A: After intravenous infusion of contrast media into six rabbits, alterations of potassium ion concentrations were measured. Protocol B: Fresh rabbit blood was mixed in vitro with contrast media, and the fluctuations in potassium were monitored over a 30-minute period. Protocol C: Similar to protocol B, except that blood from humans with no reaction to contrast media was used. For protocol A, blood potassium levels increased above baseline levels. The elevations were statistically significant (P<.05). For protocol B, diatrizoate and ioxaglate caused a gradual increase in blood potassium levels, but iopamidol did not. In protocol C, all three contrast media caused statistically significant elevation in potassium levels. The release of potassium was statistically significant at 5 minutes (P<.05 for diatrizoate and ioxaglate, and P<.01 for iopamidol). The mean release rates (+/- standard deviation) by means of linear regression analysis were 0.0190 mmol/min +/- 0.0112 with diatrizoate, 0.0159 mmol/min +/- 0.0057 with iopamidol, and 0.0088 mmol/min +/- 0.0033 with ioxaglate.\nQuestion: Do iodinated contrast media increase serum potassium levels?",
    "gt": "Iodinated contrast media increase blood potassium levels causing release of potassium into intravascular spaces. This potassium release may play some role in contrast medium-induced adverse reactions.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Fifty-nine patients with late-stage AMD (74.3 ± 7.3 years) and 49 age-, sex-, and education-matched control subjects were compared for the presence of AD according to the guidelines of the National Institute of Neurological and Communicative Disorders and Stroke and the Alzheimer's Disease and Related Disorders Association (NINCDS-ADRDA). Detailed neuropsychological tests were performed for all subjects. Neuropsychiatric tests scores were lower in the AMD group than the control group. The frequency of AD was higher in patients with AMD (40.7% in AMD and 20.4% in control group, P = 0.03), and particularly higher in late dry (nonvascular) AMD (d-AMD) patients (71.4% in d-AMD and 31.1% in late wet (vascular) AMD, P = 0.007). d-AMD patients performed worse than controls on all tests. There was also an association between age, sex, and low education and neuropsychiatric tests scores (P<0.01). However, there was no association between visual acuity and neuropsychiatric tests scores.\nQuestion: Is Alzheimer disease related to age-related macular degeneration?",
    "gt": "The increased frequency of AD in patients with AMD is significant. This study demonstrated the importance of cognitive assessment in patients with AMD, particularly in the d-AMD type.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Several studies have investigated plasma androgen levels in women with recurrent miscarriage (RM) with conflicting results on whether an association between hyperandrogenaemia and RM exists. However, none of these studies included sensitive androgen measurements using a large data set. We therefore investigated the free androgen index (FAI) in a large number of women with RM in order to ascertain whether hyperandrogenaemia is a predictor of subsequent pregnancy outcome. We studied 571 women who attended the Recurrent Miscarriage Clinic in Sheffield and presented with>or =3 consecutive miscarriages. Serum levels of total testosterone and sex hormone-binding globulin were measured in the early follicular phase and FAI was then deduced. The prevalence of hyperandrogenaemia in RM was 11% and in a subsequent pregnancy, the miscarriage rate was significantly higher in the raised FAI group (miscarriage rates of 68% and 40% for FAI>5 and FAI<or = 5 respectively, P = 0.002).\nQuestion: Does free androgen index predict subsequent pregnancy outcome in women with recurrent miscarriage?",
    "gt": "An elevated FAI appears to be a prognostic factor for a subsequent miscarriage in women with RM and is a more significant predictor of subsequent miscarriage than an advanced maternal age (>or =40 years) or a high number (>or =6) of previous miscarriages in this study.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We sought to determine if a small muscle mass index (MMI) is actually detrimental for insulin sensitivity when studying a large group of postmenopausal women displaying various body composition statuses and when age and visceral fat mass (VFM) are taken into account. A cross-sectional study was conducted in 99 healthy postmenopausal women with a BMI of 28±4 kg/m(2). Fat mass and total fat-free mass (FFM) were obtained from DXA and VFM and MMI were estimated respectively by the equation of Bertin and by: Total FFM (kg)/height (m)(2). Fasting plasma insulin and glucose were obtained to calculate QUICKI and HOMA as an insulin sensitivity index. Total MMI and VFM were both significantly inversely correlated with QUICKI and positively with HOMA even when adjusted for VFM. A stepwise linear regression confirmed Total MMI and VFM as independent predictors of HOMA and plasma insulin level.\nQuestion: Is a small muscle mass index really detrimental for insulin sensitivity in postmenopausal women of various body composition status?",
    "gt": "A small muscle mass might not be detrimental for the maintenance of insulin sensitivity and could even be beneficial in sedentary postmenopausal women. The impact of muscle mass loss on insulin sensitivity in older adults needs to be further investigated.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Loneliness and low mood are associated with significant negative health outcomes including poor sleep, but the strength of the evidence underlying these associations varies. There is strong evidence that poor sleep quality and low mood are linked, but only emerging evidence that loneliness and poor sleep are associated. To independently replicate the finding that loneliness and poor subjective sleep quality are associated and to extend past research by investigating lifestyle regularity as a possible mediator of relationships, since lifestyle regularity has been linked to loneliness and poor sleep. Using a cross-sectional design, 97 adults completed standardized measures of loneliness, lifestyle regularity, subjective sleep quality and mood. Loneliness was a significant predictor of sleep quality. Lifestyle regularity was not a predictor of, nor associated with, mood, sleep quality or loneliness.\nQuestion: An investigation of the relationship between subjective sleep quality, loneliness and mood in an Australian sample: can daily routine explain the links?",
    "gt": "This study provides an important independent replication of the association between poor sleep and loneliness. However, the mechanism underlying this link remains unclear. A theoretically plausible mechanism for this link, lifestyle regularity, does not explain the relationship between loneliness and poor sleep. The nexus between loneliness and poor sleep is unlikely to be broken by altering the social rhythm of patients who present with poor sleep and loneliness.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To optimize a dual-energy computed tomographic protocol with sinogram-affirmed iterative reconstruction algorithms for improving small nodules detection. The raw data of a dual-energy computed tomographic arterial acquisition of a cirrhotic patient were reconstructed with a standard filtered back projection (B20f) and 3 iterative (I26, I30, I31) kernels with different strength (S3-S5). The 80-kilovolt (peak) (kVp) and the linear blended (DE_0.5) images (80-140 kVp) were analyzed. For each series, 8-subcentimeter low-contrast lesions were simulated within the liver. Four radiologists performed a detectability test and rated the image quality (5-point scales) in all images. The sensitivity increased from 31% (B20f) to 87.5% with sinogram-affirmed iterative reconstruction S5 kernels without a difference between 80-kVp and DE_0.5 series (W test, P = 0.062). The highest image quality rating was 3.8 (B20 DE_0.5), without difference from DE_0.5 I30-S5 and I26-S3.\nQuestion: Can sinogram-affirmed iterative reconstruction improve the detection of small hypervascular liver nodules with dual-energy CT?",
    "gt": "Iterative reconstructions increase the sensitivity for detecting abdominal lesions, even in the 80-kVp series. The kernel I30-S5 was considered the best.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Pneumonia is the leading cause of infectious death amongst children globally, with the highest burden in Africa. Early identification of children at risk of treatment failure in the community and prompt referral could lower mortality. A number of clinical markers have been independently associated with oral antibiotic failure in childhood pneumonia. This study aimed to develop a prognostic model for fast-breathing pneumonia treatment failure in sub-Saharan Africa. We prospectively followed a cohort of children (2-59 months), diagnosed by community health workers with fast-breathing pneumonia using World Health Organisation (WHO) integrated community case management guidelines. Cases were followed at days 5 and 14 by study data collectors, who assessed a range of pre-determined clinical features for treatment outcome. We built the prognostic model using eight pre-defined parameters, using multivariable logistic regression, validated through bootstrapping. We assessed 1,542 cases of which 769 were included (32% ineligible; 19% defaulted). The treatment failure rate was 15% at day 5 and relapse was 4% at day 14. Concurrent malaria diagnosis (OR: 1.62; 95% CI: 1.06, 2.47) and moderate malnutrition (OR: 1.88; 95% CI: 1.09, 3.26) were associated with treatment failure. The model demonstrated poor calibration and discrimination (c-statistic: 0.56).\nQuestion: Can We Predict Oral Antibiotic Treatment Failure in Children with Fast-Breathing Pneumonia Managed at the Community Level?",
    "gt": "This study suggests that it may be difficult to create a pragmatic community-level prognostic child pneumonia tool based solely on clinical markers and pulse oximetry in an HIV and malaria endemic setting. Further work is needed to identify more accurate and reliable referral algorithms that remain feasible for use by community health workers.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To analyze physician work production over a 5-year period to discover trends in productivity. Surgical workforce calculations over the past 25 years have projected major oversupply as well as looming shortages. Recent studies indicate that demand for surgical services will increase over the next two decades as the population ages and develops age related chronic diseases. This study examines actual physician productivity to determine whether there is capacity for increased work output in response to projected increases in demand. Physician productivity data as measured by relative value units were obtained from the Medical Group Management Association Physician Compensation Reports for a 5-year period. Surgeons were compared with nonsurgeons and across subspecialties. Surgeon and nonsurgeon productivity in terms of relative value units remained relatively stable over the study period; surgical:nonsurgical productivity per provider was 1.30-1.46:1.\nQuestion: Surgical work output: is there room for increase?",
    "gt": "Surgeons produce a significant amount of the total work in multi-specialty medical groups. These results may indicate that the surgical and general surgical workforce has reached a plateau with respect to clinical productivity. Predicted increases in demand for procedure-based work to care for the aging population are likely to be difficult to meet with the available workforce.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The GlideScope video-guided laryngoscope is an alternative standard of care for rescue laryngoscopies when direct laryngoscopy is unsuccessful. During postoperative checks by an anesthesiologist, it was noticed that patients who reported sore throat often required GlideScope laryngoscopy. Consequently, it is difficult to determine whether postoperative sore throats are caused by irritation inflicted by multiple laryngoscopic attempts or the actual utilization of the GlideScope itself. The goal of this study was to determine whether the use of the GlideScope leads to a greater or lesser incidence of sore throat when compared with traditional laryngoscope blades used for intubation. Eligible patients scheduled for elective inpatient surgeries requiring endotracheal tube intubation were enrolled into this single-blinded prospective cohort study. χ(2) Test, Fisher exact test, and t tests were used to compare differences across the primary end point and other demographic categories. Operating rooms and postanesthesia recovery unit, Albany Medical Center, Albany, NY. There were a total of 151 patients with American Society of Anesthesiologists grades 1 to 3 included in the study. Eighty-one patients were randomized to a control group that received traditional laryngoscopy via Macintosh/Miller blades and 70 patients received video-guided intubation via the GlideScope. The incidence of postoperative sore throat was recorded via a yes/no questionnaire within 24 hours after extubation. Secondary parameters such as provider type, sex, and perceived difficulty were also recorded. There was no significant difference in the proportion of patients reporting sore throat by type of blade used (Mac/Miller 36.3% vs GlideScope 32.4%, P = .619). For secondary outcomes, women were significantly more likely to report sore throat as compared with men (men 24.3% vs women 43.2%, P = .015), and the provider type was significantly associated with the occurrence of postoperative sore throat (attendings 26.8% vs certified registered nurse anesthetists 52.3% vs third-year clinical anesthesia residents 30%, P = .012).\nQuestion: Does the incidence of sore throat postoperatively increase with the use of a traditional intubation blade or the GlideScope?",
    "gt": "Use of the GlideScope videolaryngoscopy was not significantly associated with increased occurrence of postoperative sore throat when compared with traditional intubation techniques. Our results may enable more trainees to acquire intubation skills with the GlideScope during an initial intubation attempt in patients with American Society of Anesthesiologist grades 1 to 3, with optimization of patient satisfaction in respect to postoperative sore throats. In addition, a provider's choice of intubation technique based on either Macintosh/Miller blades or the GlideScope does not significantly impact a patient's risk of postoperative sore throat.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To identify the factors that contribute to the under-resourcing of Aboriginal health and to explore the impact that funding arrangements have on the implementation of Aboriginal health policy. Qualitative study based on 35 in-depth interviews with a purposive sample of frontline health professionals involved in health policy and service provision in the Northern Territory. Participants described three factors that contributed to the under-resourcing of Aboriginal health: inefficient funding arrangements, mainstream programs being inappropriate for Aboriginal Australians, and competing interests determining the allocation of resources. Insufficient capacity within the healthcare system undermines the multilevel implementation process whereby organisations need to have the capacity to recognise new policy ideas, assess their relevance to their existing work and strategic plan and to be able to incorporate the relevant new ideas into day-to-day practice.\nQuestion: Efficient funding: a path to improving Aboriginal healthcare in Australia?",
    "gt": "Insufficient resources for Aboriginal health were found to be a barrier to implementing Aboriginal health policy. Inadequate resources result from the cumbersome allocation of funding rather than simply the amount of funding provided to Aboriginal healthcare. Monitoring government performance and ensuring the efficient allocation of funds would allow us to develop the delivery system for Aboriginal healthcare and therefore provide greater opportunities to capitalise on current interventions and future efforts.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Overdose is a significant cause of death among heroin users. Frequently, other heroin users are present when an overdose occurs, which means the victim's life could be saved. There is a lack of studies that, based on heroin users own stories, examine their views, assessments, and responses to witnessed overdoses. The study is based on qualitative interviews with thirty-five heroin users who witnessed someone else's overdose. The heroin users generally had a positive attitude towards assisting peers who had overdosed. A number of factors and circumstances, however, contribute to witnesses often experiencing resistance to or ambivalence about responding. The witness's own high, the difficulty in assessing the seriousness of the situation, an unwillingness to disturb someone else's high, uncertainty about the motive behind the overdose and whether the victim does or does not want assistance as well as fear of police involvement, were common factors that acted as barriers to adequate responses in overdose situations.\nQuestion: Wasted, overdosed, or beyond saving--to act or not to act?",
    "gt": "The fact that being high makes it difficult to respond to overdoses, using traditional methods, argues for simpler and more effective response techniques. This can include intranasal naloxone programs for heroin users. The findings regarding the uncertainty about the intention of the overdose victim and the sensitivity to the experience of a good high argue for more up-front communication and discussion amongst using peers so that they can make their intentions clear to each other. Issues like this can be addressed in overdose education interventions. Overdose prevention measures also need to address the fact that fear of the police acts as a barrier to call emergency services.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We propose a simple and inexpensive in vitro crystallization assay of measuring turbidity by spectrophotometry in synthetic urine. We validated our method by investigating the effect of potassium (K) citrate on the crystallization of calcium oxalate monohydrate (CaOx), calcium phosphate, and magnesium ammonium phosphate using synthetic urine. The crystallization of CaOx was studied using turbidimetric measurements of solution produced by mixing calcium chloride and sodium oxalate at 37 °C, pH 5.7. The turbidity of the crystal suspension was measured immediately with double-beam spectrophotometer as the absorbance of light at 660 nm wavelength. The rates of crystal formation and aggregation were obtained by measuring optical density (OD) over 30 min. The obtained results were compared to CaOx crystal concentration with and without citrate assessed by optical microscopy. The sensitivity of spectrophotometry in measuring turbidity was confirmed by the linear correlation between the crystal concentration and OD readings at 660 nm seen on the standard curve. Under similar experimental conditions, the results were comparable to the ones obtained by optical microscopy. The OD readings over 30 min revealed an instant decrease in the number of crystals, with maximum aggregation noted at 18 min. Addition of K-citrate at 1.25 mg/ml led to initial less crystal formation (OD = 0.236 nm vs. OD = 0.527 nm), with a maximum aggregation reached at 18 min. Overall, citrate addition decreased nucleation with a small change in the aggregation (OD = 0.316 vs. OD = 0.359).\nQuestion: Urinary turbidity as a marker of crystallization: is spectrophotometric assessment useful?",
    "gt": "Spectrophotometric measurement of urinary turbidity is feasible and sensitive in assessing the potential clinical usefulness of different medications in inhibiting crystallization in urine.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: With ever increasing demands on emergency services it is necessary to consider how to enhance the recruitment and retention of emergency nurses in public hospitals. Personality is known to influence occupational choice, yet there is a lack of research exploring how personality may influence the workforce decisions of emergency nurses. A standardised personality test instrument, the NEO™-PI-3, was used in a survey design inclusive of demographic questions to measure personality characteristics. Data were collected from 72 emergency nurses working at an Australian Emergency Department between July and October 2012. The personality scores of emergency nurses were compared against general population norms in each of five personality domains and their 30 associated facets. Participants scored higher than population norms in the domains of Extraversion (p<.001), Openness to experience (p<.001) and Agreeableness (p = .001), and in twelve facets, including excitement-seeking (p<.001) and competence (p = .003).\nQuestion: The personality of emergency nurses: is it unique?",
    "gt": "The personality profile of this sample of emergency nurses is different to the population norm. Assessment of personality and knowledge of its influence on specialty selection may assist in improving retention and recruitment in emergency nursing.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Whether and when to transfuse in anemia of prematurity is highly controversial. Some authors suggest transfusions simply if the hemoglobin (Hb) level is below a defined normal range. Others propose the use of clinical or laboratory parameters in anemic patients to decide whether to transfuse or not. A decreasing amount of circulating Hb should cause a compensatory increase in cardiac output (CO) and an increase in arterial serum lactate. In 56 anemic preterm infants (not in respiratory or hemodynamic failure) we analyzed CO after the first week of life using a Doppler sonographic method. At the same time serum lactate levels, Hb levels and oxygen saturation were registered. Nineteen of these patients were given transfusion when they demonstrated clinical signs of anemia by tachycardia>180/min, tachypnea, retractions, apneas and centralization (group 2). The remaining 37 patients were not transfused (group 1). Serum lactate, CO, heart rate (HR), oxygen delivery, respiratory rate, capillary refill and Hb were analyzed in both groups and in group 2 before and 12-24 h after transfusion. Data between groups 1 and 2 and in group 2 before and after transfusion were compared. In the 56 patients studied no linear correlation between Hb and CO or between Hb and serum lactate was found. Nor could any correlation be demonstrated between the other variables studied. Examining the subgroups separately, a negative linear correlation was demonstrated between serum lactate and oxygen delivery in group 2. No other significant correlations were detected. However, when the pre- and post-transfusion data were compared in group 2 (increase of Hb from 9.45 (SD 3.44) to 12.5 (SD 3.8) g/100 ml), the CO decreased from 281.3 (SD 162.6) to 224 (SD 95.7) ml/kg per min (p<0.01) and serum lactate decreased significantly from 3.23 mmol/l (SD 2.07) before to 1.71 (SD 0.83) after transfusion. Oxygen delivery was 35.8 (+/- 0.19) ml/kg per min group 1, 27.8 (+/- 0.05) pre- and 43.4 (+/- 0.07) post-transfusion in group 2 (p<0.01).\nQuestion: Do cardiac output and serum lactate levels indicate blood transfusion requirements in anemia of prematurity?",
    "gt": "CO measurements and serum lactate levels add little information to the decision-making process for blood transfusions, as neither CO nor serum lactate levels correlate with HB levels in an otherwise asymptomatic population of preterm infants. In infants where the indication for blood transfusion is made based on traditionally accepted clinical criteria, serum lactate is an additional laboratory indicator of impaired oxygenation, as it correlates significantly with oxygen delivery. A significant lower oxygen delivery in patients in whom blood transfusion is indicated and an increase in oxygen induced by transfusion demonstrate the value of these criteria in identifying preterm infants who benefit from transfusion.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Given the paucity of literature on the time course of recovery of erectile function (EF) after radical prostatectomy (RP), many publications have led patients and clinicians to believe that erections are unlikely to recover beyond 2 years after RP. We sought to determine the time course of recovery of EF beyond 2 years after bilateral nerve sparing (BNS) RP and to determine factors predictive of continued improved recovery beyond 2 years. EF was assessed prospectively on a 5-point scale: (i) full erections; (ii) diminished erections routinely sufficient for intercourse; (iii) partial erections occasionally satisfactory for intercourse; (iv) partial erections unsatisfactory for intercourse; and (v) no erections. From 01/1999 to 01/2007, 136 preoperatively potent (levels 1-2) men who underwent BNS RP without prior treatment and who had not recovered consistently functional erections (levels 1-2) at 24 months had further follow-up regarding EF. Median follow-up after the 2-year visit was 36.0 months. Recovery of improved erections at a later date: recovery of EF level 1-2 in those with level 3 EF at 2 years and recovery of EF level 1-3 in those with level 4-5 EF at 2 years. The actuarial rates of further improved recovery of EF to level 1-2 in those with level 3 EF at 2 years and to level 1-3 in those with level 4-5 EF at 2 years were 8%, 20%, and 23% at 3, 4, and 5 years postoperatively, and 5%, 17%, and 21% at 3, 4, and 5 years postoperatively, respectively. Younger age was predictive of greater likelihood of recovery beyond 2 years.\nQuestion: Time course of recovery of erectile function after radical retropubic prostatectomy: does anyone recover after 2 years?",
    "gt": "There is continued improvement in EF beyond 2 years after BNS RP. Discussion of this prolonged time course of recovery may allow patients to have a more realistic expectation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Some men with premature ejaculation (PE) and normal erectile function record contradictory response/s to The Sexual Health Inventory for Men (SHIM) and may be incorrectly categorized as suffering from erectile dysfunction (ED). The aim of this study was to evaluate the frequency of false positive SHIM diagnosis of ED in men with lifelong PE. SHIM, stopwatch intravaginal ejaculation latency time (IELT). A prospective observational study of men with normal erectile function and lifelong PE, diagnosed using the ISSM definition of lifelong PE, was conducted. The SHIM was self-administered at Visit 1. Mean per subject stopwatch IELT was determined from four subsequent intercourse attempts. Seventy-eight subjects with a mean age of 33.2 +/- 8.3 years and a geometric mean IELT of 15.9 +/- 2.3 seconds were enrolled. The mean SHIM score for all subjects was 20.4 +/- 6.0. Fifty-two subjects (66.7%) have SHIM scores of>21 (mean 24.3 +/- 1.1), consistent with normal erectile function, and a geometric mean IELT of 18.3 +/- 2.2 seconds. Twenty-six subjects (33.3%) had SHIM scores<22 (mean 12.7 +/- 3.7), consistent with a false positive diagnosis of ED, and a geometric mean IELT of 10.5 +/- 2.3 seconds. The incidence of false positive SHIM diagnosis of ED (SHIM<22) was inversely related to the IELT. Although the geometric mean IELT for subjects with SHIM scores<22 was significantly less than that of all subjects and subjects with SHIM scores>21, there were no significant differences between the geometric mean IELT or the IELT distribution of all subjects vs. the normal erectile function IELT (SHIM>21) cohort.\nQuestion: Screening for erectile dysfunction in men with lifelong premature ejaculation--Is the Sexual Health Inventory for Men (SHIM) reliable?",
    "gt": "This study demonstrates a 33.3% false positive SHIM diagnosis of ED in men with PE. This is likely to limit subject recruitment in clinical trials by exclusion of subjects with low-range IELTs but is unlikely to result in significantly different baseline IELTs or IELT distributions.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Diabetes or insulin resistance, overweight, arterial hypertension, and dyslipidaemia are recognized risk factors for cardiovascular (CV) disease. However, their predictive value and hierarchy in elderly subjects remain uncertain. We investigated the impact of cardiometabolic risk factors on mortality in a prospective cohort study of 331 elderly high-risk subjects (mean age+/-SD: 85+/-7 years). Two-year total mortality was predicted by age, diabetes, low BMI, low diastolic blood pressure (DBP), low total and HDL cholesterol, and previous CV events. The effect of diabetes was explained by previous CV events. In non-diabetic subjects, mortality was predicted by high insulin sensitivity, determined by HOMA-IR and QUICKI indices. In multivariate analyses, the strongest mortality predictors were low BMI, low HDL cholesterol and previous myocardial infarction. Albumin, a marker of malnutrition, was associated with blood pressure, total and HDL cholesterol, and HOMA-IR. The inflammation marker CRP was associated with low total and HDL cholesterol, and high HOMA-IR.\nQuestion: Cardiometabolic determinants of mortality in a geriatric population: is there a \"reverse metabolic syndrome\"?",
    "gt": "In very old patients, low BMI, low DBP, low total and HDL cholesterol, and high insulin sensitivity predict total mortality, indicating a \"reverse metabolic syndrome\" that is probably attributable to malnutrition and/or chronic disorders. These inverse associations limit the relevance of conventional risk factors. Previous CV events and HDL cholesterol remain strong predictors of mortality. Future studies should determine if and when the prevention and treatment of malnutrition in the elderly should be incorporated into conventional CV prevention.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The primary purpose of this study is to explore primary care physicians' (PCPs') knowledge, attitudes and self-reported activities provided to patients for smoking cessation. The secondary purpose is to identify the relationships between physician-related characteristics and knowledge, attitudes and self-reported activities for smoking cessation. A national cross-sectional web survey was conducted in Italy from April through September 2012. 722 PCPs completed the questionnaire. The great majority indicated the correct proportion of smokers among patients with lung cancer, the smoking abstention required for risk reduction after smoking cessation, and tobacco as a known major risk factor for chronic obstructive pulmonary disease (COPD), whereas 28.7% knew the Fagerstrom test for the assessment of nicotine dependence. Almost all PCPs reported that they ask all patients if they smoke, inform about the dangers of smoking and recommend to quit smoking, whereas prescription of recommended drugs for smoking cessation varied from 37.7% for nicotine replacement therapy to 4.9% for varenicline.\nQuestion: Are primary care physicians prepared to assist patients for smoking cessation?",
    "gt": "Despite a positive attitude, Italian PCPs are not prepared to deliver effective interventions for smoking cessation in their patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It is unclear whether proactive telephone support enhances smoking cessation beyond the provision of nicotine replacement therapy alone. We randomly assigned 330 low-income women smokers to receive either free nicotine patches (control condition) or free nicotine patches with up to 16 weeks of proactive telephone support (experimental condition). All participants were assessed by telephone at baseline and at 2 weeks, 3 months, and 6 months post-baseline to determine smoking status. Results revealed a significant effect for the telephone support at 3 months, with 43% of experimental versus 26% of control condition women reporting 30-day point prevalent abstinence (P = 0.002). The difference was no longer significant at 6 months. A metaanalysis conducted with five randomized studies revealed a slight but non-significant long-term benefit of proactive telephone support when added to the provision of free nicotine patches for smoking cessation.\nQuestion: Does extended proactive telephone support increase smoking cessation among low-income women using nicotine patches?",
    "gt": "This is the second study to demonstrate a short-term effect for proactive telephone support added to free nicotine replacement therapy; however, neither the current study, nor the metaanalysis including the four other published trials, confirmed a longer-term benefit.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To describe the successful implementation of an evidence-based, integrated quality improvement mental health program in a primary care setting. Intermountain Healthcare (IHC) has aligned resources around a conceptual framework that emphasizes clinic and community accountability, family and consumer health focused on recovery rather than disease, and enhanced decision making through partnerships and automation. The mental health integration system includes an integrated team led foremost by the patient and family with vital defined roles for primary care providers, care managers, psychiatrists, advanced practice registered nurses, support staff, and the National Alliance for the Mentally Ill. Pharmacists have assumed training functions on the team and have the potential to play more vital roles.\nQuestion: Can mental health integration in a primary care setting improve quality and lower costs?",
    "gt": "The IHC experience demonstrates that mental health services can be effectively integrated into everyday practice in a primary care setting. Clinical and financial burden can be decreased for the health care team, patients, and family.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Clinically valid cardiac evaluation via treadmill stress testing requires patients to achieve specific target heart rates and to successfully complete the cardiac examination. A comparison of the standard Bruce protocol and the ramped Bruce protocol was performed using data collected over a 1-y period from a targeted patient population with a body mass index (BMI) equal to or greater than 30 to determine which treadmill protocol provided more successful examination results. The functional capacity, metabolic equivalent units achieved, pressure rate product, and total time on the treadmill as measured for the obese patients were clinically valid and comparable to normal-weight and overweight patients (P<0.001). Data gathered from each protocol demonstrated that the usage of the ramped Bruce protocol achieved more consistent results in comparison across all BMI groups in achieving 80%-85% of their age-predicted maximum heart rate.\nQuestion: Comparison of Bruce treadmill exercise test protocols: is ramped Bruce equal or superior to standard bruce in producing clinically valid studies for patients presenting for evaluation of cardiac ischemia or arrhythmia with body mass index equal to or greater than 30?",
    "gt": "This study did not adequately establish that the ramped Bruce protocol was superior to the standard Bruce protocol for the examination of patients with a BMI equal to or greater than 30.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The association between chronic idiopathic urticaria (CIU) and autoimmune thyroiditis (AT) is known, as well as major prevalence of antithyroid antibodies in the allergical subjects and other autoimmune diseases. We have evaluated the effects of l-thyroxine on clinical symptoms of CIU in AT patients suggesting the hypothesis of a new thyroid-stimulating hormone (TSH) role in immune system. In 20 female patients with CIU + AT, both hypothyroid and euthyroid, we have investigated the therapeutic effects of l-thyroxine dosed to suppress the TSH. Free-T3, Free-T4, TSH, antithyroperoxidase and antithyroglobulin antibodies, total immunoglobulin (Ig)E, Rheuma test and eritro-sedimentation rate were monitored during treatment. In 16 patients a strong decrease of urticaria symptoms has happened after 12 weeks. The TPO Ab and HTG Ab clearly decreased in 14 patients. Furthermore, in two patients with rheumatoid arthritis and in two patients with pollen allergy a strong decrease of rheuma test titer and total IgE has happened.\nQuestion: Improvement of chronic idiopathic urticaria with L-thyroxine: a new TSH role in immune response?",
    "gt": "The reason of AT is associated to CIU and others allergical and autoimmune diseases is poorly known. The exclusive hormonal therapy reduces the symptoms of CIU and inflammatory response in many chronic diseases associated to AT. We suggest a stimulatory effect of TSH able to produce considerable changes of the immune response and immune tolerance in patients with AT causing target organs damage. The causal mechanism involves immune, nervous and endocrine system, sharing a common set of hormones, cytokines and receptors, in a unique totally integrated loop (the neuro-immuno-endocrine axis).",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study explores active learning algorithms as a way to reduce the requirements for large training sets in medical text classification tasks. Three existing active learning algorithms (distance-based (DIST), diversity-based (DIV), and a combination of both (CMB)) were used to classify text from five datasets. The performance of these algorithms was compared to that of passive learning on the five datasets. We then conducted a novel investigation of the interaction between dataset characteristics and the performance results. Classification accuracy and area under receiver operating characteristics (ROC) curves for each algorithm at different sample sizes were generated. The performance of active learning algorithms was compared with that of passive learning using a weighted mean of paired differences. To determine why the performance varies on different datasets, we measured the diversity and uncertainty of each dataset using relative entropy and correlated the results with the performance differences. The DIST and CMB algorithms performed better than passive learning. With a statistical significance level set at 0.05, DIST outperformed passive learning in all five datasets, while CMB was found to be better than passive learning in four datasets. We found strong correlations between the dataset diversity and the DIV performance, as well as the dataset uncertainty and the performance of the DIST algorithm.\nQuestion: Active learning for clinical text classification: is it better than random sampling?",
    "gt": "For medical text classification, appropriate active learning algorithms can yield performance comparable to that of passive learning with considerably smaller training sets. In particular, our results suggest that DIV performs better on data with higher diversity and DIST on data with lower uncertainty.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: With the development of high-performance computer programs, transcutaneous electrogastrography has experienced a renaissance in the last few years and is widely recommended as a non-invasive diagnostic tool to evaluate functional gastric disorders. We assessed the clinical value of electrogastrography in symptomatic and asymptomatic patients after a variety of procedures of the upper gastrointestinal (GI) tract. Electrogastrography tracings were recorded with a commercially available data logger using a recording frequency of 4 Hz. A standard meal was given between a 60 min preprandial and a 60 min postprandial period. The following parameters were analyzed pre- and postprandially utilizing Fourier and spectral analysis: Regular gastric activity (2-4 cycles/minute), bradygastria (0.5-2 cycles/minute), tachygastria (4-9 cycles/minute), dominant frequency and power of the dominant frequency. Nineteen asymptomatic healthy volunteers served as a control group. Forty-nine patients, who had undergone upper intestinal surgery, were included in the study (cholecystectomy n = 10, Nissen fundoplication n = 10, subtotal gastrectomy n = 8, truncal vagotomy, and gastric pull-up as esophageal replacement n = 6). Twenty of these patients complained of epigastric symptoms post-operatively, while 12 of these 20 patients also had a scintigraphic gastric emptying study with Tc99m labeled semisolid meal. Preprandial gastric electric activity was between 2 and 4 cycles/minute in 60-90% of the study time in healthy volunteers. In all study groups the prevalence and power of normal electric activity increased significantly after the test meal (p<0.001). After cholecystectomy, Nissen fundoplication, subtotal gastrectomy or vagotomy and gastric pull-up pre- and postprandial gastric electric activity showed a greater variability compared to normal volunteers (p<0.05), but no typical electrogastrography pattern could be identified for the different surgical procedures. There was no significant difference in the electrogastrography pattern between asymptomatic and symptomatic patients and patients with normal or abnormal scintigraphic gastric emptying curves.\nQuestion: Transcutaneous electrogastrography: a non-invasive method to evaluate post-operative gastric disorders?",
    "gt": "There is no specific electrogastrography pattern to differentiate between typical surgical procedures or epigastric symptoms. To date, electrogastrography does not contribute to the diagnosis and analysis of gastric motility disorders after upper intestinal surgery.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether the behavioral participation in muscle-strengthening activity (MSA) or the strength outcome produces the largest reduction in all-cause mortality risk. The 1999-2002 National Health and Nutritional Examination Survey was used, with follow-up of up to 12.6 years (mean, 9.9 years) (N=2773 adults aged ≥50 years). Participants were placed into 4 groups based on 2 dichotomously categorized variables: lower-extremity strength (LES) of the knee extensors (top quartile) and adherence to MSA guidelines (≥2 MSA sessions per week). Approximately 21% of the population died during follow-up. Compared with individuals not meeting MSA guidelines and not in top quartile for LES, the adjusted hazard ratios (HRs) and 95% CIs were as follows: (1) meets MSA guidelines but not in top quartile for LES (HR=0.96; 95% CI, 0.63-1.45; P=.84), (2) in top quartile for LES but does not meet MSA guidelines (HR=0.54; 95% CI, 0.42-0.71; P<.001), and (3) in top quartile for LES and meets MSA guidelines (HR=0.28; 95% CI, 0.12-0.66; P=.005). Further analyses revealed that individuals in the top quartile for LES who also met MSA and moderate to vigorous physical activity guidelines were at even further reduced risk for premature all-cause mortality (HR=0.23; 95% CI, 0.08-0.61; P=.005).\nQuestion: Determining the Importance of Meeting Muscle-Strengthening Activity Guidelines: Is the Behavior or the Outcome of the Behavior (Strength) a More Important Determinant of All-Cause Mortality?",
    "gt": "These results demonstrate that muscle strength seems to be more important than the behavioral participation in MSA for reducing the risk of premature all-cause mortality.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: In recent years, due to a high persistence, biomagnification in food webs, presence in remote regions, and potential toxicity, perfluorochemicals (PFCs) have generated a considerable interest. The present study was aimed to determine the levels of perfluorooctane sulfonate (PFOS), perfluorooctanoic acid (PFOA), and other PFCs in drinking water (tap and bottled) and river water samples from Tarragona Province (Catalonia, Spain). Municipal drinking (tap) water samples were collected from the four most populated towns in the Tarragona Province, whereas samples of bottled waters were purchased from supermarkets. River water samples were collected from the Ebro (two samples), Cortiella, and Francolí Rivers. After pretreatment, PFC analyses were performed by HPLC-MS. Quantification was done using the internal standard method, with recoveries between 68% and 118%. In tap water, PFOS and PFOA levels ranged between 0.39 and 0.87 ng/L (0.78 and 1.74 pmol/L) and between 0.32 and 6.28 ng/L (0.77 and 15.2 pmol/L), respectively. PFHpA, PFHxS, and PFNA were also other detected PFCs. PFC levels were notably lower in bottled water, where PFOS could not be detected in any sample. Moreover, PFHpA, PFHxS, PFOA, PFNA, PFOS, PFOSA, and PFDA could be detected in the river water samples. PFOS and PFOA concentrations were between<0.24 and 5.88 ng/L (<0.48 and 11.8 pmol/L) and between<0.22 and 24.9 ng/L (<0.53 and 60.1 pmol/L), respectively. Assuming a human water consumption of 2 L per day, the daily intake of PFOS and PFOA by the population of the area under evaluation was calculated (0.78-1.74 and 12.6 ng, respectively). It was found that drinking water might be a source of exposure to PFCs as important as the dietary intake of these pollutants.\nQuestion: Levels of perfluorochemicals in water samples from Catalonia, Spain: is drinking water a significant contribution to human exposure?",
    "gt": "The contribution of drinking water (tap and bottled) to the human daily intake of various PFCs has been compared for the first time with data from dietary intake of these PFCs. It was noted that in certain cases, drinking water can be a source of exposure to PFCs as important as the dietary intake of these pollutants although the current concentrations were similar or lower than those reported in the literature for surface water samples from a number of regions and countries.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We sought to determine whether location of the second internal thoracic artery (ITA) graft used for bilateral ITA grafting affects mortality and morbidity of patients with 3-system coronary artery disease and to identify factors associated with second ITA location. From January 1972 to June 2006, 3611 patients with 3-system coronary artery disease underwent bilateral ITA grafting with one graft anastomosed to the left anterior descending system and the second to either the circumflex (n=2926) or right coronary artery (n=685) system. Follow-up was 9.2+/-7.2 years. Propensity score methodology was used to obtain risk-adjusted outcome comparisons between patients with the second ITA to circumflex versus right coronary artery. Hospital mortality (0.34% versus 0.58%; P=0.4), stroke (0.96% versus 0.88%; P=0.8), myocardial infarction (1.3% versus 0.73%; P=0.2), renal failure (0.44% versus 0.29%; P=0.6), respiratory insufficiency (3.5% versus 3.8%; P=0.7), and reoperation for bleeding (3.4% versus 3.2%; P=0.8) were similar in patients who received the second ITA to circumflex or right coronary artery and remained similar after propensity score adjustment. Late survival (86% versus 87% at 10 years) was also similar. Despite this, there was a gradual decline in ITA to right coronary artery grafting.\nQuestion: Does location of the second internal thoracic artery graft influence outcome of coronary artery bypass grafting?",
    "gt": "Contrary to prevailing wisdom that the second ITA graft should be anastomosed to the next most important left-sided coronary artery in 3-system coronary artery disease, it may be placed to either the circumflex or right coronary artery system with similar early and late outcomes.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess the incidence and type of biliary complications in liver transplantation after biliary reconstruction with or without a biliary tutor. A prospective, non-randomized study of 128 consecutive patients undergoing elective liver transplantation was performed. Retransplantations, emergency transplantations, hepaticojejunostomy and patients who died within 3 months of causes other than biliary complications were excluded. Group I (n = 64) underwent termino-terminal choledochocholedochostomy with a Kehr tube and group II (n = 64) underwent choledochocholedochostomy without Kehr tube. Complications, therapeutic procedures, reoperations and survival free of biliary complications were analyzed. The overall rate of biliary complications was 15% (17% in group I and 14% in group II). Types of complication (overall and in groups I and II, respectively) consisted of fistulas 4% (6% vs. 3%), stenosis 8% (4% vs. 12%), and Kehr dysfunction 3%. The mean number of therapeutic procedures, including endoscopic retrograde cholangiopancreatography, percutaneous transhepatic cholangiography, trans-Kehr cholangiography and drainage of collections, was 2.1 vs. 2 per complicated patient. The overall reoperation rate was 5% (2% vs. 9%) (p<0.05). One-year survival free of biliary complications was 85% vs. 82% (Log Rank = 0.5).\nQuestion: Biliary reconstruction in liver transplantation: is a biliary tutor necessary?",
    "gt": "No statistically significant differences were found in complications after choledocho-choledocho anastomosis with or without a biliary tutor. However, the patient group that did not receive a biliary tutor required more complex procedures for treatment of complications, as well as a greater number of reoperations.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this study was to determine the effectiveness of Kinesio taping (KT) application added to the exercise treatment of subacromial impingement syndrome (SIS). Thirty-eight (25 female, 13 male) patients with SIS were randomly divided into therapeutic KT (n=19) and sham KT (n=19) groups. All patients received the same exercise therapy in addition to therapeutic or sham KT at 3-day intervals for 12 days. The groups were compared according to pain, range of motion (ROM), muscle strength and DASH and Constant scores before treatment and at the 5th and 12th treatment days. Within group comparisons showed significant improvements in both groups at the 5th and 12th day evaluations (p<0.05). In comparisons between the groups, pain with movement and DASH scores in the therapeutic group were significantly lower at the 5th day (p<0.01). There were significant improvements in night pain, pain with movement, DASH score, shoulder external rotation muscle strength, and pain free shoulder abduction ROM in the therapeutic group at the 12th day (p<0.05). Passive shoulder flexion ROM increased more in the sham group at the 12th day (p<0.05).\nQuestion: Does Kinesio taping in addition to exercise therapy improve the outcomes in subacromial impingement syndrome?",
    "gt": "The addition of KT application to the exercise program appears to be more effective than the exercise program alone for the treatment of SIS.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Accelerated coronary artery disease (ACAD), a serious consequence after heart transplantation, is characterized by diffuse, concentric myointimal proliferation in the arteries. Increasing evidence supports the existence of a local renin-angiotensin system and the role of angiotensin-II in smooth muscle cell proliferation. We investigated the effect of angiotensin-II blocker candesartan and angiotensin-converting enzyme (ACE) inhibitor enalapril on experimental ACAD in a rat model. After heterotopic cardiac transplantation (Fisher to Lewis), recipients received 20 mg/kg/day candesartan or 40 mg/kg/day enalapril per os. Two groups of animals received additional pre-treatment with candesartan or enalapril 7 days before transplantation, and treatment was continued after grafting. All study groups including the controls received 3 mg/kg/day of sub-cutaneous cyclosporine for immunosuppression. A syngeneic group (Lewis to Lewis), serving as extra control, did not receive any treatment. Eighty days after grafting, we assessed the extent of ACAD in large and small arteries, using digitizing morphometry and expressed as mean vascular occlusion (MVO). In enalapril and candesartan pre- and post-treated animals, we observed significant reduction of MVO of intramyocardial arteries compared with the cyclosporine group (p<0.005), to levels similar to the syngeneic transplants. MVO of epicardial arteries in enalapril and candesartan pre- or posttreated animals did not significantly differ from cyclosporine controls (p>0.05).\nQuestion: Do vascular compartments differ in the development of chronic rejection?",
    "gt": "Our results support the hypothesis of 2 proliferative compartments in the development of ACAD, with differing receptor or enzyme distribution: the compartment of small, intramyocardial arteries in which ACAD can be reduced by ACE or AT(1) blockade, and that of large, epicardial arteries in which inhibition fails.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To examine the health consequences of exposure to income inequality. Secondary analysis employing data from several publicly available sources. Measures of individual health status and other individual characteristics are obtained from the March Current Population Survey (CPS). State-level income inequality is measured by the Gini coefficient based on family income, as reported by the U.S. Census Bureau and Al-Samarrie and Miller (1967). State-level mortality rates are from the Vital Statistics of the United States, other state-level characteristics are from U.S. census data as reported in the Statistical Abstract of the United States. We examine the effects of state-level income inequality lagged from 5 to 29 years on individual health by estimating probit models of poor/fair health status for samples of adults aged 25-74 in the 1995 through 1999 March CPS. We control for several individual characteristics, including educational attainment and household income, as well as regional fixed effects. We use multivariate regression to estimate the effects of income inequality lagged 10 and 20 years on state-level mortality rates for 1990, 1980, 1970, and 1960. Lagged income inequality is not significantly associated with individual health status after controlling for regional fixed effects. Lagged income inequality is not associated with all cause mortality, but associated with reduced mortality from cardiovascular disease and malignant neoplasms, after controlling for state fixed-effects.\nQuestion: Is exposure to income inequality a public health concern?",
    "gt": "In contrast to previous studies that fail to control for regional variations in health outcomes, we find little support for the contention that exposure to income inequality is detrimental to either individual or population health.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To analyze outcomes in simultaneous kidney-pancreas transplantation (SKPT) recipients who retain C-peptide production at the time of SKPT. This retrospective analysis of SKPTs from January 2002 through January 2007 compared outcomes between patients with absent or low C-peptide levels (<2.0 ng/mL, group A) with those having levels>or =2.0 ng/mL (group B). Among 74 SKPTs, 67 were in group A and seven in group B (mean C-peptide level 5.7 ng/mL). During transplantation, group B subjects were older (mean age 51 vs 41 years, P = .006); showed a later age of onset of diabetes (median 35 vs 13 years, P = .0001); weighed more (median 77 vs 66 kg, P = .24); had a greater proportion of African-Americans (57% vs 13%, P = .004); and had a longer pretransplant duration of dialysis (median 40 vs 14 months, P = .14). With similar median follow-up of 40 months, death-censored kidney (95% group A vs 100% group B, P = NS) and pancreas (87% group A vs 100% group B, P = NS) graft survival rates were similar, but patient survival (94% group A vs 71% group B, P = .03) was greater in group A. At 1-year follow-up, there were no significant differences in rejection episodes, surgical complications, infections, readmissions, hemoglobin A1C or C-peptide levels, serum creatinine, or MDRD GFR levels.\nQuestion: Do pretransplant C-peptide levels influence outcomes in simultaneous kidney-pancreas transplantation?",
    "gt": "Diabetic patients with measurable C-peptide levels before transplant were older, overweight, more frequently African-American and had a later age of onset of diabetes, longer duration of pretransplant dialysis, and reduced patient survival compared to insulinopenic patients undergoing SKPT. The other outcomes were similar.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Tracheal stenosis and dehiscence of anastomosis due to excessive tension are well-known problems after long-segment tracheal resections. The aim of this study was to evaluate the efficacy of the W-plasty technique to prevent these two complications. Animals were divided into a study and a control group. Each group consisted of 6 animals. In the control group, we performed a 5-cm tracheal segment resection, and then reconstruction was performed with an interrupted technique with 6/0 Prolene sutures. In the study group, we used the W-plasty technique with 6/0 Prolene interrupted sutures. The animals were sacrificed on the 30th day postoperatively and tracheal resection including the entire anastomosis site was performed. The traction and pullout test was applied to each specimen and all the specimens were analysed histopathologically. The intraluminal diameter and the thickness of the tracheal wall at the level of anastomoses were measured by using a micrometer. The pattern of the reaction and localization were recorded. The traction and pullout test results were 131.6 +/- 4.3 g and 187.5 +/- 6.4 g in the control and the study group, respectively, which was a significant difference (p = 0.004). The intraluminal diameters were 3.3 +/- 1.2 mm and 4.3 +/- 0.9 mm in the control and study group, respectively (p = 0.134). In contrast to the control group, early inflammatory and late fibroblastic reactions were negative in the study group.\nQuestion: W-plasty technique in tracheal reconstruction: a new technique?",
    "gt": "Considering the outcomes of this study, we think that the W-plasty technique has much more advantages than the standard techniques in terms of anastomosis durability and development of stenosis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: In order to treat children with Attention-deficit/Hyperactivity Disorder (ADHD) with a once-a-day stimulant several galenic approaches have been tried. The long acting methylphenidate (MPH, Medikinet-Retard) is a preparation with a two-step dynamic to release MPH (step one: acute; step two: prolonged). The efficacy of Medikinet-Retard, a new long-acting methylphenidate preparation, is analyzed based on the assessment of parents in the afternoon. In a multicenter drug treatment study (placebo controlled, randomized, double-blind) 85 children (normal intelligence, age 6 to 16 years, diagnosis of ADHD according to DSM-IV) were investigated over 4 weeks with weekly visits. Forty-three children received Medikinet-Retard and forty-two children placebo. The weekly dose titration depending on body weight and symptomatology allowed a final maximum of 60 mg. The effects on ADHD as perveived by the parents were assessed weekly with a German symptom checklist for ADHD according to DSM-IV and ICD-10 (FBB-HKS). The differences between baseline and last week of treatment were compared statistically between groups. There was a large and statistically significant positive drug effect on ADHD symptomatology. The effect size of these differences was d = 1.2 (total score). Effects were found on inattention, hyperactivity and impulsity on the respective subscales. The efficacy of Medikinet-Retard was evaluated by the parents on an average as good. The rate of responders was four-times higher in the verum-group. The correlations of the changed scores in the parent ratings with the respective change scores in the teacher ratings were in the medium range.\nQuestion: Does a morning dose of Methylphenidate Retard reduce hyperkinetic symptoms in the afternoon?",
    "gt": "This is the first study with a German long-acting methylphenidate preparation (Medikinet-Retard). According to data based on parents' assessments, the drug showed very good clinical efficacy and safety in children with ADHD. Its two step galenic release of methylphenidate seems to be appropriate for a once-a-day (morning) stimulant in schoolchildren.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: An adult trial reported the efficacy of recombinant human erythropoietin in critically ill patients with a 19% decrease in red blood cell transfusion. Our aim was to evaluate the relevance of this prophylactic treatment in children hospitalized in a pediatric intensive care unit (PICU). Cohort study from January 1995 to December 2004. University hospital PICU. Children between 1 month and 18 yrs of age. We searched through a prospective databank for all children hospitalized in the PICU for>or =4 days (potential recipients of erythropoietin, as proposed in the adult trial) and transfused with red blood cells after day 7 following PICU entry (in whom erythropoietin might prevent anemia, according to results of the adult trial). We found that 799 of 2,578 children (31%) were hospitalized for>or =4 days. The study group comprised 787 patients who were hospitalized for>or =4 days in the PICU and for whom full records were available. One hundred eighty-three children in this study group were transfused during their stay in the PICU (median age, 7 months; weight, 6.60 kg). Hemoglobin levels before transfusion (mean +/- sd) were 7.7 +/- 1.5 g/dL. These transfused children represented 23% of the study group and 7% of the total PICU admissions. Forty-seven children (6% of the study group, 2% of the total PICU admissions) were transfused with red blood cells after 7 days of hospitalization and could have benefited from a prophylactic treatment with erythropoietin. Relative risk to benefit of a prophylactic treatment by erythropoietin was higher in cases of mechanical ventilation (relative risk, 1.18) and inotropic treatment (relative risk, 1.72) and if the main diagnosis involved dermatological (relative risk, 3.03) or oncologic disease (relative risk, 3.94).\nQuestion: Is a prophylactic treatment by erythropoietin relevant to reduce red blood cell transfusion in the pediatric intensive care unit?",
    "gt": "If we applied the results of the adult trial to our PICU, we would have to treat 31% of the children with prophylactic erythropoietin and thereby expect a reduction of one red blood cell transfusion for every 17 treated patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Numerous correlational studies have examined whether perceptions of vulnerability or worry are better predictors of health-related behavior. The aim of this experimental study was to explore some of the potential causal relationships involved: Are the effects of a brief smoking cessation intervention (for women attending for cervical smear tests) on intention to stop smoking mediated by perceived vulnerability or worry about cervical cancer? A mediation analysis of an experimental study. Perceived vulnerability to and worry about cervical cancer, and intention to stop smoking in the next month. Questionnaires were completed by 172 (71%) women at 2-week follow-up. Compared with women in the control group, those in the intervention group had higher perceptions of vulnerability, worry, and intention to stop smoking. Personal vulnerability (p<.01) and comparative vulnerability (p<.05) were significant mediators of the relationship between study group and intention to stop smoking. Worry about cervical cancer was not related to intention.\nQuestion: Do perceptions of vulnerability and worry mediate the effects of a smoking cessation intervention for women attending for a routine cervical smear test?",
    "gt": "Worry may be a less important construct in relation to disease prevention behaviors such as smoking cessation. More experimental studies comparing different behaviors are needed to determine the causal relationship between worry and outcomes.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The ACGME requires the assessment of resident competency in 6 domains. Global evaluations covering all 6 competencies are routinely used. Evaluators may be overly influenced by resident affability and availability, thereby resulting in a halo effect. We hypothesized that the Interpersonal Skills and Communications (ICS) and Professionalism (PR) competencies would unduly influence other competency scores. General surgery resident evaluations are performed by staff and peers on a rotational basis using competency-based questions. Each question is scored using a 5-point Likert scale. Mean individual composite scores for each competency were calculated and then correlated with other mean composite competency scores. Data from patient evaluations were similarly analyzed. A final correlation of competency scores to ABSITE scores, as an objective, standardized measure of a specific competency, Medical knowledge (MK) was also performed. Results were available for 37 residents (PGY 1-5). There was a significant association between ICS scores and higher scores in MK (r = 0.52, p = 0.004), PR (r = 0.826, p<0.0001) and patient care (PC) (r = 0.619, p<0.0001). No correlation, however, was found between patient evaluations of residents and their faculty/peer-based ICS scores. We found no association between ICS scores and improved patient evaluations. Lastly, we found no association between ICS or MK scores and ABSITE scores.\nQuestion: Are the communication and professionalism competencies the new critical values in a resident's global evaluation process?",
    "gt": "It was difficult to ascertain whether residents with better ICS scores had higher PR, PC, and MK scores because of the halo effect, improper completion of evaluations, or whether those residents were truly performing better clinically. External measures of resident performance did not correlate with faculty/peer evaluations of ICS and PR. Residency programs should consider adopting a more standardized way to objectively evaluate residents.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate the effectiveness of lignocain 2% and oxymetazoline 0.025% compared to oxymetazoline 0.025% alone when administered prior to fibreoptic nasendoscopy in paediatric patients. Prospective, randomized controlled, double-blind study. A group of 56 children, undergoing nasendoscopy to determine adenoidal size, were randomized into two groups and received either lignocain 2% and oxymetazoline 0.025% or oxymetazoline 0.025% alone prior to fibreoptic nasendoscopy. A tertiary care Paediatric Hospital. The endoscopist recorded the ease of performance of the procedure, cooperation of patient and quality of the view achieved using a visual analogue scale (VAS). The pain and anxiety levels of the child were recorded before, during and immediately after the procedure, using a VAS. The duration of performing the procedure was recorded from insertion of the endoscope into the nostril until removal. All 56 children were able to undergo the endoscopy and the full anxiety and pain assessment was done. Three children were excluded because they have undergone nasendoscopies before. Of the 53 patients included, 27 children received solution A (oxymetazoline 0.025%) and 26 children received solution B (oxymetazoline 0.025% and lignocain 2%). There was no statistical difference between the two groups regarding the duration of the endoscopy, quality of view, ease of performance and cooperation of the patients. The median pain and anxiety scores were not significantly different between the two groups.\nQuestion: Is topical local anaesthesia necessary when performing paediatric flexible nasendoscopy?",
    "gt": "This study concludes that the use of a decongestant (oxymetazoline) for paediatric nasendoscopy is just as effective as the use of oxymetazoline with lignocain. Pain and anxiety is not increased in the absence of lignocain.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Hydrocephalus is a common pediatric problem. Ventriculoperitoneal shunts (VPS) are the most frequent operative procedures used to treat hydrocephalic children. The peritoneal end is usually placed in the general peritoneal cavity. We present an alternative site of peritoneal end placement in the suprahepatic space in an attempt to reduce the abdominal complications. All patients with a diagnosis of congenital hydrocephalus were included in the study. In group 1, the lower end of the VPS was placed in the suprahepatic space. Patients were evaluated for abdominal complications like pseudocyst formation, intestinal obstruction and blockage of the lower end of the VPS. The data were compared with those patients in whom the peritoneal end was placed in the general peritoneal cavity (group 2). The total number of patients in groups 1 and 2 was 133 and 175, respectively. Complications in group 1 were dislodgement of the shunt in the general peritoneal cavity in 28 (21.05%), suprahepatic pseudocyst formation in 2 (1.5%) and blocked lower end in 2 patients (1.5%). In group 2, complications noted were pseudocyst formation in 5 (2.8%), blocked lower end in 25 (14.2%), intestinal obstruction in 9 (5.1%), inguinoscrotal migration in 10 (5.7%) and perforation of viscera in 6 patients (3.4%). The overall follow-up period ranged from 1 to 7 years.\nQuestion: Placement of the peritoneal end of a ventriculoperitoneal shunt in the suprahepatic space: does it improve prognosis?",
    "gt": "Placement of the lower end of the shunt in the suprahepatic space can be advantageous to placing it in the general peritoneal cavity. The procedure is simple and results can be rewarding.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether criminals go to the hospital when they are shot. Such information is needed to check on the accuracy of using hospital emergency room data to estimate non-fatal gunshot wounds. Five jails across the US. A survey of inmates being booked into jail, administered by in-house health care staff. Over 90% of over 300 criminals who had been wounded sometime before their incarceration reported going to a hospital for treatment after being shot. These results are consistent with previous findings from one jail.\nQuestion: Do criminals go to the hospital when they are shot?",
    "gt": "Jail inmates who had previously been shot were likely to have been treated in a hospital. This limited finding is consistent with the proposition that hospital/emergency department data may miss only a small percentage of gunshot wounds to criminals.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Poststroke depression (PSD) is the most common neuropsychiatric consequence of stroke. A large number of studies have focused on the pathogenesis of PSD, but only a few aimed to characterize its psychopathology; these studies yielded results that are difficult to compare because of the different methods utilized. The current study aimed to characterize the symptom profile of PSD in an attempt to better understand the disease and allow a more accurate diagnosis. The study sample comprised 64 patients divided into three groups: stroke patients without diagnosis of depression (n = 33), stroke patients diagnosed with PSD (PSD group, n = 14) and patients diagnosed with major depression (MD) but with no clinical comorbidity (MD group, n = 17). All patients were diagnosed using the Structured Clinical Interview for DSM-IV Axis I Disorders (SCID-I). The initial diagnostic interview was complemented by the Mini Mental State Examination (MMSE), the Rankin Scale, and four scales for the assessment of the intensity of symptoms of anxiety and depression: the Beck Depression Inventory (BDI), the Hospital Anxiety and Depression General Scale (HADS), the Hamilton Depression Rating Scale (HAM-D) and the Hamilton Rating Scale for Anxiety (HAM-A). The Star Plot, a graphical method of data visualization, was used to analyze the results. The t test was used for independent samples (two-tailed analysis). As measured by the BDI, HAM-D and HAM-A scales and HADS depression subscale, the average total scores of symptoms for the sample of patients diagnosed with MD without clinical comorbidity was significantly higher than that of the PSD patients (p<0.05). Similar results were obtained by plotting the BDI data on Star Plot. The PSD patients showed mild typical depressive symptoms such as less depressed mood, anhedonia, disinterest, guilt, negative thoughts, depreciation, suicidal ideation and anxiety, when evaluated by the HAM-A scale. Moreover, the somatic symptoms of depression did not lead to increased diagnosis of major depression in stroke patients.\nQuestion: Is poststroke depression a major depression?",
    "gt": "The results indicate that the PSD clinical picture comprised, in general, symptoms of mild/moderate intensity, especially those considered as pillars for the diagnosis of depression: depressed mood, loss of pleasure and lack of interest. Given the imprecision of boundaries that separate the clinical forms of depression from subclinical and nonpathological forms, or even from the concepts of demoralization and adjustment disorders, we situate PSD in a complex biopsychosocial context in which a better understanding of its psychopathological profile could provide diagnostic and therapeutic alternatives best suited to the difficult reality experienced by stroke patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  }
]