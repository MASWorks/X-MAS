[
    {
        "query": "Answer the question based on the following context: To examine further the relationship between diabetes mellitus (DM), genotype and prostate cancer aggressiveness. Specifically, we sought to evaluate for effect modification between DM, a newly discovered prostate cancer susceptibility locus on chromosome 17q12 (single nucleotide polymorphism rs4430796) and prostate cancer features. In 593 genotyped men treated with radical prostatectomy (RP), we examined RP features stratified by DM and rs4430796 carrier status. Despite a significantly higher body mass index among patients with DM, individual pathological features were similar between men with and without DM. Using a dominant model, 17q12 carriers were less likely to have DM and more likely to have a RP Gleason score of>or=7. However, the presence or absence of DM did not modify the relationship between 17q12 susceptibility alleles and pathological features.\nQuestion: Does diabetes mellitus modify the association between 17q12 risk variant and prostate cancer aggressiveness?",
        "gt": "Among 17q12 risk allele carriers, there was no significant relationship between DM and adverse tumour features. However, there were relatively few men with DM (7%) in our RP cohort, particularly compared with its 21% prevalence in the USA population aged>60 years. It is unclear whether this reflects selection bias, genetic protection from prostate cancer among patients with DM, or both. Despite these limitations, the present data suggest that DM alone does not appear to modify any association between 17q12 risk alleles with prostate cancer features.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study evaluated supply and demand trends for orthopedic postgraduate year 1 (PGY1) positions from 1984 to 2011 for the purpose of estimating national intercandidate competition over time. National Resident Matching Program (NRMP) data for orthopedic surgery from 1984 to 2011 were collected. Proxy variables including (total number of orthopedic applicants/number of orthopedic PGY1 positions), (number of US senior applicants to orthopedics/number of orthopedic PGY1 positions), (number of US seniors matching into orthopedics/number of US senior orthopedic applicants), (total number of matched orthopedic applicants/total number of orthopedic applicants), and (total number of US applicants who fail to match into orthopedics/total number of US senior applicants into orthopedics) as well as average United States Medical Licensing Examination Step 1 scores were used to gauge the level of competition between candidates and were compared over time. Academic medical center in the Midwestern United States. Medical professors and medical students. The NRMP data suggested that the number of positions per applicant decreased or remained stable since 1984 and that the percentage of applicants who did not match was no higher now than in the past. This finding was primarily because of the relative decrease in the ratio of applicants to available PGY1 positions, which stems from the number of positions increasing more rapidly than the number of applicants.\nQuestion: Is orthopedics more competitive today than when my attending matched?",
        "gt": "The NRMP data from 1984 to 2011 supported our hypothesis that intercandidate competition intensity for orthopedic PGY1 positions has not increased over time. The misconception that orthopedics is becoming more competitive likely arises from the increased number of applications submitted per candidate and the resulting relative importance placed on objective criteria such as United States Medical Licensing Examination Step 1 scores when programs select interview cohorts.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Our goal was to evaluate whether active management of labor lowers cesarean section rates, shortens the length of labor, and overcomes any negative effects of epidural analgesia on nulliparous labor. We randomly assigned 405 low-risk term nulliparous patients to either an active management of labor (n = 200) or our usual care control protocol (n = 205). Patients who were undergoing active management of labor were diagnosed as being in labor on the basis of having painful palpable contractions accompanied by 80% cervical effacement, underwent early amniotomy, and were treated with high-dose oxytocin for failure to progress adequately in labor. The cesarean section rate in the active management of labor group was lower than that of controls but not significantly so (active management, 7.5%; controls, 11.7%; p = 0.36). The length of labor in the active management group was shortened by 1.7 hours (from 11.4 to 9.7 hours, p = 0.001). Fifty-five percent of patients received epidural analgesics; a reduction in length of labor persisted despite the use of epidural analgesics (active management 11.2 hours vs control 13.3 hours, p = 0.001). A significantly greater proportion of active management patients were delivered by 12 hours compared with controls (75% vs 58%, p = 0.01); this difference also persisted despite the use of epidural analgesics (66% vs 51%, p = 0.03).\nQuestion: Active management of labor: does it make a difference?",
        "gt": "Patients undergoing active management had shortened labors and were more likely to be delivered within 12 hours, differences that persisted despite the use of epidural analgesics. There was a trend toward a reduced rate of cesarean section.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Long axis strain (LAS) has been shown to be a fast assessable parameter representing global left ventricular (LV) longitudinal function in cardiovascular magnetic resonance (CMR). However, the prognostic value of LAS in cardiomyopathies with reduced left ventricular ejection fraction (LVEF) has not been evaluated yet. In 146 subjects with non-ischemic dilated cardiomyopathy (NIDCM, LVEF \u226445\u00a0%) LAS was assessed retrospectively from standard non-contrast SSFP cine sequences by measuring the distance between the epicardial border of the left ventricular apex and the midpoint of a line connecting the origins of the mitral valve leaflets in end-systole and end-diastole. The final values were calculated according to the strain formula. The primary endpoint of the study was defined as a combination of cardiac death, heart transplantation or aborted sudden cardiac death and occurred in 24 subjects during follow-up. Patients with LAS values>\u2009-5\u00a0% showed a significant higher rate of cardiac events independent of the presence of late gadolinium enhancement (LGE). The multivariate Cox regression analysis revealed that LVEDV/BSA (HR: 1.01, p\u2009<\u20090.05), presence of LGE (HR: 2.51, p\u2009<\u20090.05) and LAS (HR: 1.28, p\u2009<\u20090.05) were independent predictors for cardiac events. In a sequential cox regression analysis LAS offered significant incremental information (p\u2009<\u20090.05) for the prediction of outcome in addition to LGE and LVEDV/BSA. Using a dichotomous three point scoring model for risk stratification, including LVEF<35\u00a0%, LAS>\u2009-10\u00a0% and the presence of LGE, patients with 3 points had a significantly higher risk for cardiac events than those with 2 or less points.\nQuestion: Left ventricular long axis strain: a new prognosticator in non-ischemic dilated cardiomyopathy?",
        "gt": "Assessment of long axis function with LAS offers significant incremental information for the prediction of cardiac events in NIDCM and improves risk stratification beyond established CMR parameters.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Earlier studies have given conflicting results regarding the effect of exposure to tobacco smoke on atopic sensibilization. A cross-sectional study of present and former smoking habits in relation to atopic disorders from data on 6909 young and middle-aged adults (16-49 years) and their 4472 children (3-15 years) from the Swedish Survey of Living Conditions in 1996-97. The prevalence of allergic asthma and allergic rhino-conjunctivitis decreased, in a dose-response manner (P = 0.03 and P = 0.004, respectively), with increasing exposure to tobacco smoke in the adult study population. This pattern was little changed when potential confounders (sex, age, education, domicile, country of birth) were entered into a multivariate analysis: the adjusted odds ratio (OR) for allergic rhino-conjunctivitis was 0.5 (0.4-0.7) for those who smoked at least 20 cigarettes a day and OR 0.7 (0.6-0.9) for those smoking 10-19 cigarettes, compared with those who reported that they never had smoked Former smokers had a tendency for a slightly lower risk: OR 0.9 (0.8-1.0). In a multivariate analysis, children of mothers who smoked at least 15 cigarettes a day tended to have lower odds for suffering from allergic rhino-conjunctivitis, allergic asthma, atopic eczema and food allergy, compared to children of mothers who had never smoked (ORs 0.6-0.7). Children of fathers who had smoked at least 15 cigarettes a day had a similar tendency (ORs 0.7-0.9).\nQuestion: Does tobacco smoke prevent atopic disorders?",
        "gt": "This study demonstrates an association between current exposure to tobacco smoke and a low risk for atopic disorders in smokers themselves and a similar tendency in their children. There is a need for further studies with a prospective design to certify the causal direction of this association. Smoking habits and atopic disorder in parents should not be considered independent variables in epidemiological studies of the connection between exposure to tobacco smoke and atopy in children.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Portal vein embolization is used in the treatment of hepatocellular cancer, with the purpose of enhancing resectability. However, regeneration is restricted due to hepatocellular injury following chemotherapeutics (e.g. doxorubicin). The aim of this study was to investigate whether hyperbaric oxygenation (HBO) can alleviate the hepatotoxicity of chemotherapy and improve regeneration in the injured liver. Rats were allocated to four experimental groups. Group I rats were subjected to right portal vein ligation (RPVL); rats in groups II and III were administered doxorubicin prior to RPVL, with group III rats being additionally exposed to HBO sessions postoperatively; group IV rats was sham-operated. All rats were sacrificed on postoperative day 7, and liver injury was assessed by measuring alanine aminotransferase (ALT) and aspartate aminotransferase (AST) levels. Protein synthetic ability was determined based albumin levels and liver regeneration by the mitotic index (MI). The AST and ALT values of group II rats were significantly higher than those of group I, but not those of group III. Rats treated with doxorubicin and HBO (groups II and III) showed slightly but not significant differences in albumin levels than those subjected to only RPVL or sham-operated. The MI was significantly increased in groups I, II, and III, with the MI of group III rats significantly higher than those of group I rats.\nQuestion: Can hyperbaric oxygenation decrease doxorubicin hepatotoxicity and improve regeneration in the injured liver?",
        "gt": "Based on our results, we conclude that HBO treatment has the potential to diminish doxorubicin-related hepatotoxicity and improve regeneration in the injured liver.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patient dissatisfaction has been previously associated with motor block in shoulder surgery patients receiving brachial plexus block. For elective minor wrist and hand surgery, we tested whether a regional block accelerating the early return of upper extremity motor function would improve patient satisfaction compared with a long-acting proximal brachial plexus block. A total of 177 patients having elective 'minor' wrist and hand surgery under awake regional block randomly received adrenalized infraclavicular lidocaine 2% 10 ml+ropivacaine 0.75% 20 ml ('long acting', n=90), or adrenalized infraclavicular lidocaine 1.5% 30 ml+long-acting distal median, radial, and ulnar nerve blocks selected according to the anticipated area of postoperative pain ('short acting', n=87). A blinded observer questioned patients on day 1 for numerically rated (0-10) subjective outcomes. With 95% power, there was no evidence for a 1-point satisfaction shift in the short acting group: satisfaction was similarly high for both groups [median (inter-quartile range)=10 (8-10) vs 10 (8-10), P=0.71], and also demonstrated strong evidence for equivalence [mean difference (95% confidence interval)=-0.18 (-0.70 to 0.35)]. There was no difference between the groups for weakness- or numbness-related dissatisfaction (low for both groups), or for numerically rated or time to first pain. Surgical anaesthesia success was similar between the groups (short acting, 97% vs 93%, P=0.50), although more patients in the short acting group had surgery initiated in \u226425 min (P=0.03).\nQuestion: Does motor block related to long-acting brachial plexus block cause patient dissatisfaction after minor wrist and hand surgery?",
        "gt": "Patient satisfaction is not improved after elective minor wrist and hand surgery with a regional block accelerating the early return of motor function. For this surgery, motor block related to a long-acting brachial plexus block does not appear to cause patient dissatisfaction. Clinical Trial Registration number. ACTRN12610000749000, https://www.anzctr.org.au/registry/trial_review.aspx?ID=335931.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A Danish population based matched case-control study of perinatal risk factors in children with infantile autism has provided some interesting and surprising observations regarding infantile autism and children born after assisted conception. The cases (461) consisted of all children born between 1990 and 1999 and diagnosed with infantile autism in the Danish Psychiatric Central Register before February 2001. Matched controls were identified in the Danish Civil Registration System. The main exposure measures included obstetric risk factors for infantile autism. We found a 59% decreased risk for developing infantile autism among children conceived after assisted conception (odds ratio [OR]0.41, 95% [0.19-0.89]) and a 63% decreased risk after adjusting for known risk factors for assisted conception and infantile autism (OR 0.37, 95% [0.14-0.98]).\nQuestion: Do children born after assisted conception have less risk of developing infantile autism?",
        "gt": "We found that children born after assisted conception had a lower risk of developing infantile autism then their matched controls. Our observations could possibly be explained by the mother's health status before and during early pregnancy. Our findings require further investigation in larger studies.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Stigmatizing attitudes toward people with disabilities can jeopardize such individuals' well-being and recovery through denial of employment and community isolation. By shaping social norms that define group membership, the construct of individualism may partially explain differences in stigmatizing attitudes across cultures. Further, widespread globalization has brought intensely individualistic social practices to certain segments of non-Western cultures. This paper examines whether the construct of individualism can help to explain cross-cultural differences in stigmatizing attitudes observed between American and Chinese employers. Employers (N = 879) from Beijing, Hong Kong, and Chicago provided information on their attitudes toward hiring people with disabilities, and path analyses were conducted to examine potential mediating relationships. Path analyses indicated that vertical individualism, along with perceived responsibility for acquiring a condition, partially mediated the relationship between culture and employers' negative attitudes about job candidates with disabilities.\nQuestion: Does individualism help explain differences in employers' stigmatizing attitudes toward disability across Chinese and American cities?",
        "gt": "These results suggested that greater espousal of competitive and individualist values may drive stigmatizing attitudes across cultures.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We report the radiographic and clinical response rate of stereotactic body radiation therapy (SBRT) compared with conventional fractionated external beam radiation therapy (CF-EBRT) for renal cell carcinoma (RCC) bone lesions treated at our institution. Forty-six consecutive patients were included in the study, with 95 total lesions treated (50 SBRT, 45 CF-EBRT). We included patients who had histologic confirmation of primary RCC and radiographic evidence of metastatic bone lesions. The most common SBRT regimen used was 27 Gy in 3 fractions. Median follow-up was 10 months (range, 1-64 months). Median time to symptom control between SBRT and CF-EBRT were 2 (range, 0-6 weeks) and 4 weeks (range, 0-7 weeks), respectively. Symptom control rates with SBRT and CF-EBRT were significantly different (P = .020) with control rates at 10, 12, and 24 months of 74.9% versus 44.1%, 74.9% versus 39.9%, and 74.9% versus 35.7%, respectively. The median time to radiographic failure and unadjusted pain progression was 7 months in both groups. When controlling for gross tumor volume, dose per fraction, smoking, and the use of systemic therapy, biologically effective dose \u226580 Gy was significant for clinical response (hazard ratio [HR], 0.204; 95% confidence interval [CI], 0.043-0.963; P = .046) and radiographic (HR, 0.075; 95% CI, 0.013-0.430; P = .004). When controlling for gross tumor volume and total dose, biologically effective dose \u226580 Gy was again predictive of clinical local control (HR, 0.140; 95% CI, 0.025-0.787; P = .026). Toxicity rates were low and equivalent in both groups, with no grade 4 or 5 toxicity reported.\nQuestion: Local control rates of metastatic renal cell carcinoma (RCC) to the bone using stereotactic body radiation therapy: Is RCC truly radioresistant?",
        "gt": "SBRT is both safe and effective for treating RCC bone metastases, with rapid improvement in symptoms after treatment and more durable clinical and radiographic response rate. Future prospective trials are needed to further define efficacy and toxicity of treatment, especially in the setting of targeted agents.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Our objective was to clarify the clinical outcome of renal transplantation based on residual daily urine output (RDUO). We retrospectively analyzed a prospective database of 276 patients who underwent renal transplantation (Tx) between January 2008 and December 2012. Patients had pre-transplantation daily urine output measurement of 24-h proteinuria and were clinically re-evaluated the day before transplantation. We included patients with no daily urine output and those with residual daily urine output. Real bladder capacity was not measured. We excluded patients with a history of lower urinary tract malformation, those treated by trans-ileal conduit or enterocystoplasty, and those with early graft thrombosis or graft primary non-function. Sex ratio, age at Tx, pre-Tx MHC antibodies levels, donor age, and cold ischemia duration were not significantly different between the 2 groups. Dialysis duration was longer in group I (p<0.001). The dialysis duration was correlated with the volume of residual urine output (r=0.12, p<0.0001). We found 14 (19.4%) urological complications in Group I (11 urinary leaks and 3 urethral stenosis) and 13 (6.4%) in Group II (5 urinary leaks and 8 stenosis). This difference was significant (p=0.0013 and relative risk [RR]=2.2). Absence of residual daily urine output was a risk factor of post-transplantation urinary leak (p<0.0001: RR=2.95). At 3 years, graft survival was 74.7% and 94.6%, respectively, in Group I and II (p=0.003).\nQuestion: Does daily urine output really matter in renal transplantation?",
        "gt": "The absence of residual daily urine output seems to be a major risk factor for urological complications. Taking into account recipient residual daily urine output should modify surgical strategy during renal transplantation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Appropriateness criteria for the treatment of Crohn\u2019s disease (CD) and ulcerative colitis (UC) have been developed by expert panels. Little is known about the acceptance of such recommendations by care providers. The aim was to explore how treatment decisions of practicing gastroenterologists differ from those of experts, using a vignette case study and a focus group. Seventeen clinical vignettes were drawn from clinical indications evaluated by the expert panel. A vignette case questionnaire asking for treatment options in 9 or 10 clinical situations was submitted to 26 practicing gastroenterologists. For each vignette case, practitioners\u2019 answers on treatments deemed appropriate were compared with panel decisions. Qualitative analysis was performed on focus group discussion to explore acceptance and divergence reasons. Two hundred thirty-nine clinical vignettes were completed, 98 for CD and 141 for UC.Divergence between proposed treatments and panel recommendations was more frequent for CD (34%) than for UC (27%). Among UC clinical vignettes, the main divergences with the panel were linked to 5-aminosalicylate (5-ASA) failure assessment and to situations in which stopping treatment was the main decision. For CD, the propositions of care providers diverged from the panel in mild to moderate active disease, for which practitioners were more prone to an accelerated step-up than the panel\u2019s recommendations.\nQuestion: Acceptance of inflammatory bowel disease treatment recommendations based on appropriateness ratings: do practicing gastroenterologists agree with experts?",
        "gt": "In about one-third of vignette cases, inflammatory bowel disease treatment propositions made by practicing gastroenterologists diverged from expert recommendations. Practicing gastroenterologists may experience difficulty in applying recommendations in daily practice.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We present a four-membered Greek family. The father was diagnosed with familial NF1 and the mother with generalized epilepsy, being under hydantoin treatment since the age of 18 years. Their two male children exhibited NFNS characteristics. The father and his sons shared R1947X mutation in the NF1 gene. The two children with NFNS phenotype presented with NF1 signs inherited from their father and fetal hydantoin syndrome-like phenotype due to exposure to that anticonvulsant during fetal development.\nQuestion: Is Neurofibromatosis Type 1-Noonan Syndrome a Phenotypic Result of Combined Genetic and Epigenetic Factors?",
        "gt": "The NFNS phenotype may be the result of both a genetic factor (mutation in the NF1 gene) and an epigenetic/environmental factor (e.g. hydantoin).",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although socioeconomic patterns of smoking across the different stages of the tobacco epidemic have been well researched, less is known about these patterns among immigrant populations. This paper aims to assess the smoking prevalence and its socioeconomic gradients among three immigrant populations. Three cross-sectional studies, using structured face-to-face interviews, were conducted in three representative (for socioeconomic status) samples of 385 Turkish, 316 Moroccan, and 1072 Surinamese first-generation immigrants aged 35-60 years in Amsterdam, The Netherlands. Information gathered included information about smoking behaviour, educational level and background characteristics. The associations between educational level and smoking rates were assessed using logistic regression analyses stratified by age and sex, for each ethnic group separately. The prevalence of smoking differed per group, being highest among Turkish and Surinamese men (63% and 55%, respectively), followed by Moroccan men and Turkish and Surinamese women (30%, 32% and 27%, respectively). Higher smoking rates were found among women with higher educational levels, except for Surinamese women aged 35-44 years. However, among Turkish and Moroccan men aged 35-44 years and Surinamese men, smoking rates were higher in lower socioeconomic groups.\nQuestion: Smoking in immigrants: do socioeconomic gradients follow the pattern expected from the tobacco epidemic?",
        "gt": "The prevalence figures and educational associations suggest that the socioeconomic gradient changes in earlier stages of the epidemic in immigrant populations than in the Western host populations, particularly in men. This provides indications to suggest that smoking prevention measures in male immigrant groups need to be tailored to lower socioeconomic groups in particular throughout the tobacco epidemic, and to higher socioeconomic groups among women.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Description of the three-year course of mental illness after supplying permanent housing to homeless individuals. 109-male and 20 female homeless individuals were assessed at the assignment of permanent housing and at one and three year follow-up using the Structured Clinical Interview for DSM-IV. A high percentage (86 %) was able to maintain or even improve the index housing situation. Only minor changes were observed in mental illness severity and global functioning. Symptoms improved slightly over the three year period. High degrees of alcohol consumption and mental illness severity increased the risk of deterioration of the housing arrangement.\nQuestion: Is supplying homeless individuals with permanent housing effective?",
        "gt": "Supplying homeless individuals with permanent housing is an effective measure but insufficient for improving mental illness. Combined measures of social and medical interventions from one provider are suggested for effective support of homeless people.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this study was to determine, on the basis of the late fate of the intact aortic arch with abnormal tissue after aortic root replacement, whether the intact aortic arch should be replaced prophylactically at the time of aortic root replacement for annuloaortic ectasia in Marfan syndrome. A retrospective review was performed in 85 patients with Marfan syndrome who underwent aortic root replacement for annuloaortic ectasia with or without aortic dissection (mean age 37 years, range 19-61 years). These 85 patients were divided into four groups according to the postoperative condition of the residual aorta. In group I (n = 47), the patients underwent aortic root replacement for annuloaortic ectasia with or without localized dissection in the ascending aorta. In these patients the residual aorta, including the aortic arch, was therefore intact. In group II (n = 10), the aortic arch was intact, although the descending thoracic aorta was dissected because of the preoperative type B dissection. In groups III and IV, the patients had type A dissection involving the transverse arch associated with annuloaortic ectasia. In group III (n = 13), residual dissection existed in the descending thoracic aorta after concomitant total arch replacement. In group IV (n = 15), the aortic arch and the descending thoracic aorta were dissected. There were 5 early deaths (3 in group I, 1 in group II, and 1 in group III). Subsequent operations were required in 10, 5, 6, and 7 cases in groups I, II, III, and IV, respectively. Regarding the aortic arch, only 2 of 53 survivors of the initial hospitalization with an intact aortic arch (groups I and II) underwent subsequent total arch replacement for the onset of dissection in the aortic arch, and 4 of 14 survivors of the initial hospitalization with a residual dissecting arch (group III) needed subsequent total arch replacement. Actuarial freedom from arch repair among patients with an intact aortic arch (91% at 15 years) was significantly higher than that among patients with a residual dissecting arch (49% at 15 years, P =.0078).\nQuestion: Should the transverse aortic arch be replaced simultaneously with aortic root replacement for annuloaortic ectasia in Marfan syndrome?",
        "gt": "The incidence of new dissection in the residual intact arch after aortic root replacement was extremely low. Therefore prophylactic replacement of the intact arch does not appear to be necessary at aortic root replacement for annuloaortic ectasia in Marfan syndrome.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate prospectively pubertal and predicted adult height progression until final height (FH) or near FH in girls with apparent idiopathic precocious puberty who were not treated. The decision not to treat at the time of initial evaluation was based on evidence of slowly progressive puberty as shown by bone age (BA) advancement<2 years above the chronologic age, whatever the hypothalamic pituitary ovarian axis activation, or no evidence of hypothalamic pituitary ovarian axis activation, whatever the BA advancement. During follow-up, patients who showed a significant decrease in predicted FH were treated with gonadotropin-releasing hormone agonist. Twenty-six girls with idiopathic precocious puberty were studied at a mean chronologic age of 7.4 +/- 0.9 years during a follow-up period of 6.6 +/- 2.2 years until FH or near FH. During the first 2 years of follow-up, most of the patients (group 1, n = 17; 65% of the cases) showed no substantial changes in predicted FH. They never required treatment, and menarche occurred at a mean chronologic age of 11.9 +/- 0.6 years. Their mean FH (or near FH) at 160.7 +/- 5.7 cm was close to their target height (161.3 +/- 4.7 cm). On the other hand, after a mean follow-up period of 1.4 +/- 0.8 years, 9 patients (group 2) had acceleration of bone maturation and deterioration of their predicted FH (from 162.1 +/- 6. 2 cm to 155.3 +/- 5.6 cm; P<.01), which was at that time significantly lower than their target height (P<.05) (mean target height = 159.8 +/- 4.6 cm). They received a gonadotropin-releasing hormone agonist for 2.1 +/- 0.7 years, resulting in a restoration of growth prognosis (mean FH or near FH = 160.2 +/- 6.7 cm).\nQuestion: Do all girls with apparent idiopathic precocious puberty require gonadotropin-releasing hormone agonist treatment?",
        "gt": "This study demonstrates that not all patients with apparent idiopathic precocious puberty require medical treatment, notably when there is no evidence of hypothalamo-pituitary ovarian activation or no significantly advanced BA to impair height potential. Most show a slowly progressing puberty. However, careful follow-up of these patients is necessary up to at least 9 years of age, because until then height prediction may deteriorate, necessitating gonadotropin-releasing hormone agonist treatment in one third of the cases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In recent years, Performance Based Financing (PBF); a form of result based financing, has attracted a global attention in health systems in developing countries. PBF promotes autonomous health facilities, motivates and introduces financial incentives to motivate health facilities and health workers to attain pre-determined targets. To achieve this, the Tanzanian government through the Christian Social Services Commission initiated a PBF pilot project in Rungwe district, Mbeya region. Kilimanjaro Christian Medical Center was given the role of training health workers on PBF principles in Rungwe. The aim of this study was to explore health care providers' perception on a three years training on PBF principles in a PBF pilot project at Rungwe District in Mbeya, Tanzania. This was an explorative qualitative study, which took place at Rungwe PBF pilot area in October 2012. Twenty six (26) participants were purposively selected. Six took part in- depth interviews (IDIs) and twenty (20) in the group discussions. Both the IDIs and the GDs explored the perceived benefit and challenges of implementing PBF in their workplace. Data were manually analyzed using content analysis approach. Overall informants had positive perspectives on PBF training. Most of the health facilities were able to implement some of the PBF concepts in their work places after the training, such as developing job descriptions for their staff, creating quarterly business plans for their facilities, costing for their services and entering service agreement with the government, improved record keeping, customer care and involving community as partners in running their facilities. The most common principle of paying individual performance bonuses was mentioned as a major challenge due to inadequate funding and poor design of Rungwe PBF pilot project.\nQuestion: Does training on performance based financing make a difference in performance and quality of health care delivery?",
        "gt": "Despite poor design and inadequate funding, our findings have shown some promising results after PBF training in the study area. The findings have highlighted the potential of PBF to act as leverage for initiating innovative and proactive actions, which may motivate health personnel performance and quality of care in the study setting with minimal support. However, key policy issues at the national level should be addressed in order to exploit this opportunity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the functional and cosmetic results and patient satisfaction after triple incision plasty for phimosis in children. The study included 197 boys who had a triple incision for phimosis (mean age 5.8 years, range 0.25-18). The indications for preputial surgery were recurrent balanoposthitis, ballooning during micturition and severe phimotic stenosis. The results after surgery were assessed using a questionnaire about the child's/parent's satisfaction, and an outpatient follow-up examination for functional and cosmetic preputial appearance. Of 128 parents/children responding, 108 (84%) were satisfied with the function and 102 (80%) reported a good cosmetic outcome. Triple incision as preputioplasty would be recommended to other parents by 119 (93%) respondents. Ninety-one (71%) of the parents feared disadvantages in their son's later life if the child had been circumcised. The outpatient examination showed an excellent functional and cosmetic outcome in 71 (77%) of the children.\nQuestion: Triple incision to treat phimosis in children: an alternative to circumcision?",
        "gt": "Triple incision is a simple, fast and safe technique for preputial relief, with good functional and cosmetic results, and was well accepted by the patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the potential of a simple and widely available technique as two-dimensional (2D) echocardiography to identify patients with ischemic cardiomyopathy and low likelihood of functional recovery after coronary revascularization. Two-dimensional echocardiography and radionuclide ventriculography (RNV) were performed before coronary revascularization in 94 patients with ischemic cardiomyopathy. Left ventricular ejection fraction (LVEF) was measured by RNV. Regional wall motion abnormalities, wall motion score index, end-diastolic wall thickness (EDWT), left ventricular (LV) volumes and LV sphericity index were assessed in the echocardiographic images. RNV was repeated 9-12 months after revascularization to assess LVEF change; an improvement>or=5% was considered clinically significant. Nine hundred and ninety-nine segments were severely dysfunctional; 149 out of 999 (15%) had an EDWT<or=6 mm. A severe enlargement of the end-diastolic volume index (EDVI) (>or=100 ml/ml) and of the end-systolic volume index (>or=80 ml) was present in 32 (34%) and 21 (22%) patients, respectively. A spherical shape of the LV was observed in 35 (37%) patients. LVEF after revascularization increased in 30 out of 94 patients (32%) from 30+/-8% to 39+/-9% (P<0.0001). On multivariate analysis, the EDVI was the only predictor of no recovery in LVEF [odds ratio, 1.06, confidence interval (CI), 1.04-1.1, P<0.0001]. The cut-off value of EDVI>or=90 ml/ml accurately identified patients that virtually never recover. Post-operatively, LVEF increased in three out of 42 (7%, 95% CI 0-15%) patients with EDVI>or=90 ml/ml as compared to 27 out of 52 (52%) patients with EDVI<90 ml/ml (P<0.0001).\nQuestion: Does resting two-dimensional echocardiography identify patients with ischemic cardiomyopathy and low likelihood of functional recovery after coronary revascularization?",
        "gt": "In patients with ischemic cardiomyopathy and severe LV enlargement, improvement of LVEF after revascularization is unlikely to occur. Conversely, in patients with relatively preserved LV size, a higher likelihood of functional recovery may be anticipated.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Rib fractures are a frequent traumatic injury associated with a relatively high morbidity. Currently, the treatment of rib fractures is symptomatic. Since it has been reported that pulsed ultrasounds accelerates repair of limb fractures, we hypothesized that the application of pulsed ultrasounds will modify the course of healing in an animal model of rib fracture. We studied 136 male Sprague-Dawley rats. Animals were randomly assigned to different groups of doses (none, 50, 100, and 250 mW/cm(2) of intensity for 3 minutes per day) and durations (2, 10, 20, and 28 days) of treatment with pulsed ultrasounds. In every subgroup, we analyzed radiologic and histologic changes in the bone callus. In addition, we examined changes in gene expression of relevant genes involved in wound repair in both control and treated animals. Histologic and radiologic consolidation was significantly increased by pulsed ultrasound treatment when applied for more than 10 days. The application of 50 mW/cm(2) was the most effective dose. Only the 100 and 250 mW/cm(2) doses were able to significantly increase messenger RNA expression of insulin-like growth factor 1, suppressor of cytokine signaling-2 and -3, and vascular endothelial growth factor and decrease monocyte chemoattractant protein-1 and collagen type II-alpha 1.\nQuestion: Pulsed ultrasounds accelerate healing of rib fractures in an experimental animal model: an effective new thoracic therapy?",
        "gt": "Our findings indicate that pulsed ultrasound accelerates the consolidation of rib fractures. This study is the first to show that pulsed ultrasound promotes the healing of rib fractures. From a translational point of view, this easy, cheap technique could serve as an effective new therapeutic modality in patients with rib fractures.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Congenital diaphragmatic hernia (CDH) remains a significant cause of death in newborns and, despite improved outcomes with multimodality therapies, optimal timing of repair remains undefined. We sought to evaluate the influence of surgical timing on patient outcomes and hypothesized that delayed repair does not improve survival in CDH. Prospectively collected data from 1,385 CDH Registry infants without preoperative extracorporeal membrane oxygen therapy (ECMO) were evaluated. Patients were stratified by timing of repair: Day of life (DOL) 0-3 (group 1), 4-7 (group 2), or>8 (group 3), and the effect of surgical timing on mortality was determined by logistic regression and risk-adjusted for severity of illness. The unadjusted odds ratio (OR) for mortality increased significantly with delayed repair (group 2, 1.73 [95% CI, 1.00-2.98; group 3, 3.42 [95% CI, 1.97-5.96]). However, when adjusted for severity of illness, delay in repair did not predict increased mortality (group 2, 1.2 [95% CI, 0.7-2.2]; group 3, 1.4 [95% CI, 0.8-2.6]), nor did it portend an increased need for postoperative ECMO (group 2, 1.1 [95% CI, 0.5-2.4]; group 3, 0.5 [95% CI, 0.2-1.4]).\nQuestion: A risk-stratified analysis of delayed congenital diaphragmatic hernia repair: does timing of operation matter?",
        "gt": "After adjustment for known risk factors, the timing of CDH repair in low-risk infants does not seem to influence mortality. However, specific clinical parameters guiding timing of elective CDH repair remain unknown.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Pretreatment urinary, bowel, and sexual dysfunction may increase the toxicity of prostate cancer treatments or preclude potential benefits. Using patient-reported baseline dysfunction from a prospective cohort study, we determined the proportion of patients receiving relatively contraindicated ('mismatched') treatments. Baseline obstructive uropathy and bowel dysfunction relatively contraindicate brachytherapy (BT) and external beam radiation therapy (EBRT), respectively, because they increase patients' vulnerability to treatment-related toxicity. Baseline sexual dysfunction renders moot the intended benefit of nerve-sparing radical prostatectomy (NSRP), which is to preserve sexual function. We categorized patients' clinical circumstances by increasing complexity and counted the mismatches in each, expecting weaker or multiple contraindications to increase mismatched treatments. Of 438 eligible patients, 389 (89%) reported preexisting dysfunction, and more than one-third received mismatched treatments. Mismatches did not significantly increase with clinical complexity, and watchful waiting was very infrequent, even when all treatment options were contraindicated. Patient age and comorbidity, but not preexisting dysfunction, were associated with treatment choice. As expected, mismatched BT and EBRT led to worsened urinary and bowel symptoms, respectively, and NSRP did not improve outcomes after baseline sexual dysfunction.\nQuestion: Treatment 'mismatch' in early prostate cancer: do treatment choices take patient quality of life into account?",
        "gt": "Pretreatment dysfunction does not appear to reliably influence treatment choices, and patients receiving mismatched treatments had worse outcomes. Further study is needed to determine why mismatched treatments were chosen, including the role of incomplete patient-physician communication of baseline dysfunction, and whether using a validated questionnaire before treatment decision-making would bypass this difficulty. Treatment mismatch may be a useful outcome indicator of the quality of patient-centered decisions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In the past, many surgeons could practise their craft with little or no knowledge of patent law. But in the world of robotic and computerized surgery, this is increasingly a myopic approach, because the principle means of protecting high-tech surgical instruments is through the application of patent law. The issue is: does the Brookhill-Wilk patent, which covers the performance of remote robotic surgery, impede the growth of cybersurgery? Review of the Brookhill-Wilk patent and relevant law. Patent law, which first took its form in the Middle Ages, attempts to balance the rewarding of innovation with the stifling of market growth. Using US patent law as a model, it would appear that the Brookhill-Wilk patent, a particular example of a medical process patent, could inhibit the growth of cybersurgery, as potential sums of money could be demanded by the patent holder from anyone who practises cybersurgery. However, two recent US Supreme Court cases appear to have seriously undermined the validity of a number of medical process patents, including the Brookhill-Wilk patent.\nQuestion: Are the Brookhill-Wilk patents impediments to market growth in cybersurgery?",
        "gt": "Based on recent changes in patent law, it is not expected that Brookhill-Wilk patent will hinder the growth of cybersurgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Long-term lamivudine therapy is required for patients with chronic hepatitis B, because hepatitis reappears frequently after it has withdrawn. However, hepatitis B virus (HBV) mutants resistant to lamivudine emerge frequently accompanied by breakthrough hepatitis. Effects of entecavir were evaluated in 19 patients who had developed breakthrough hepatitis during lamivudine therapy for longer than 5 years. This study is a subgroup analysis of a previously reported study. Entecavir, in either 0.5 or 1.0 mg/day doses, was given to 10 and nine patients for 52 weeks, respectively, and then all received 1.0 mg/day entecavir for an additional 68-92 weeks. There were no differences in biochemical and virological responses in the two groups of patients with respect to the two different initial doses of entecavir. Serum levels of alanine aminotransferase were normalized in 17 (90%) patients, and hepatitis B e antigen (HBeAg) disappeared from the serum in two (14%) of the 14 patients who were HBeAg-positive before. Furthermore, a decrease in histological activity index score greater than 2 points was achieved in nine of the 11 (82%) patients in whom annual liver biopsies were performed during 3 years while they received entecavir. HBV mutants resistant to entecavir emerged in five of the 19 (26%) patients, and hepatitis flare occurred in two of them (40%).\nQuestion: Efficacy of entecavir treatment for lamivudine-resistant hepatitis B over 3 years: histological improvement or entecavir resistance?",
        "gt": "Entecavir in the long term would be useful for histological improvement of breakthrough hepatitis induced by lamivudine-resistant HBV mutants in patients with chronic hepatitis B. However, the relatively high rate of entecavir resistance is a concern, and other strategies need to be considered when available.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is extensive evidence that major depression, and particularly melancholia, is characterized by hypothalamic-pituitary-adrenal (HPA) axis hyperactivity as well as systemic immune activation, which may be accompanied by increased interleukin-1 beta production. Interleukin-1 beta is known to enhance HPA axis activity during an immune response. This study investigated whether interleukin-1 beta production is related to HPA axis activity in depressed subjects. The subjects were 28 inpatients with major or minor depression and 10 normal comparison subjects. The authors measured 1) the subjects' cortisol levels after an overnight 1-mg dexamethasone suppression test (DST) and 2) mitogen-stimulated supernatant interleukin-1 beta production by peripheral blood mononuclear cells. Statistically significant positive correlations between interleukin-1 beta production and post-DST cortisol values were found in the study group as a whole and in the depressed and normal subgroups separately.\nQuestion: Interleukin-1 beta: a putative mediator of HPA axis hyperactivity in major depression?",
        "gt": "It is suggested that constituents of the immune response (such as interleukin-1 beta) in major depression may contribute to HPA axis hyperfunction in that illness.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the relationship between CD4 status and the P24 antigen level and survival in children infected with the human immunodeficiency virus. Cohort, case-control. Clinical Center at the National Institutes of Health, Bethesda, Md. One hundred forty-seven children infected with the human immunodeficiency virus enrolled in antiretroviral therapy protocols at the National Cancer Institute were reviewed and the relationships between CD4 counts, P24 antigenemia, and death were analyzed. None.MEASUREMENTS/ The presence of a very low CD count, less than 21% of the lower limit of normal values for age (equivalent to 0.05 x 10(9)/L in an adult), was associated with a significantly increased risk of death within 2 years. Although the risk of death was highest for children with CD4 counts below this level and who had detectable P24 antigen levels, P24 antigenemia by itself contributed little to the prognostic value of the CD4 count alone. However, it was also notable that a group of children with low CD4 counts also experienced prolonged survival.\nQuestion: CD4 status and P24 antigenemia. Are they useful predictors of survival in HIV-infected children receiving antiretroviral therapy?",
        "gt": "The association between low CD4 counts and death suggests that the age-adjusted CD4 count should be used as a marker to guide therapeutic intervention. At the same time, the presence of a very low CD4 count alone should not be considered a reason for therapeutic nihilism.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Since 2011, all acute general surgical admissions have been managed by the consultant-led emergency general surgery service (EGS) at our institution. We aim to compare EGS management of acute biliary disease to its preceding model. Retrospective review of prospectively collated databases was performed to capture consecutive emergency admissions with biliary disease from 1st February 2009 to 31st January 2013. Patient demographics, surgical intervention, use of diagnostic radiology, histological diagnosis, complications and hospital length of stay (LOS) were retrieved. A total of 566 patients were included (pre-EGS 254 vs. EGS 312). In the EGS period, the number of patients having surgery on index admission increased from 43.7 to 58.7 % (p<0.001) as did use of intra-operative cholangiography from 75.7 to 89.6 % (p = 0.003). The conversion to open cholecystectomy rate also was reduced from 14.4 to 3.3 % (p<0.001). Overall, a 14 % reduction in use of multiple (>1) imaging modalities for diagnosis was noted (p = 0.003). There was a positive trend in reduction of bile leaks but no significant difference in the overall morbidity and mortality. Time to theatre was reduced by 1 day [pre-EGS 2.7 (IQR 1.5-5.0) vs. EGS 1.7 (IQR 1.2-2.6) p<0.001]. The overall hospital LOS was reduced by 1.5 days [pre-EGS 5.0 (IQR 3-7) vs. EGS 3.5 (IQR 2-5) p<0.001].\nQuestion: Emergency Management of Gallbladder Disease: Are Acute Surgical Units the New Gold Standard?",
        "gt": "Since the advent of EGS, more judicious use of diagnostic radiology, reduced complications, reduced LOS, reduced time to theatre and an increased rate of definitive management during the index admission were demonstrated.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Seeds of annual halophytes such as Suaeda maritima experience fluctuating salinity, hydration, hypoxia and temperature during dormancy. Germination then occurs in one flush of 2-3 weeks after about 5 months of winter dormancy during which time the seeds can remain in saline, often waterlogged soil. The aim of this study was to investigate the effect of simulated natural conditions during dormancy on germination and to compare this with germination following the usual conditions of storing seeds dry. The effects of hydration, salinity, hypoxia and temperature regimes imposed during dormancy on germination were investigated. Also looked at were the effects of seed size on germination and the interaction between salinity during dormancy and salinity at the time of germination. Various pre-treatments were imposed on samples of seeds that had been stored dry or wet for different periods of time during the 5 months of natural dormancy. Subsequent germination tests were carried out in conditions that simulated those found in the spring when germination occurs naturally. Various salinities were imposed at germination for a test of interaction between storage salinity and salinity at germination. A temperature of about 15 degrees C was needed for germination and large seeds germinated earlier and better than small seeds. Cold seawater pre-treatment was necessary for good germination; the longer the saline pre-treatment during the natural dormancy period the better the germination. There appeared to be no effect of any specific ion of the seawater pre-treatment on germination and severe hypoxia did not prevent good germination. A short period of freezing stimulated early germination in dry-stored seed. Storage in cold saline or equivalent osmotic medium appeared to inhibit germination during the natural dormancy period and predispose the seed to germinate when the temperature rose and the salinity fell. Seeds that were stored in cold wet conditions germinated better in saline conditions than those stored dry.\nQuestion: Do conditions during dormancy influence germination of Suaeda maritima?",
        "gt": "The conditions under which seeds of S. maritima are stored affect their subsequent germination. Under natural conditions seeds remain dormant in highly saline, anoxic mud and then germinate when the temperature rises above about 15 degrees C and the salinity is reduced.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To test the reproducibility of the finding that early intensive care for whiplash injuries is associated with delayed recovery. We analyzed data from a cohort study of 1,693 Saskatchewan adults who sustained whiplash injuries between July 1, 1994 and December 31, 1994. We investigated 8 initial patterns of care that integrated type of provider (general practitioners, chiropractors, and specialists) and number of visits (low versus high utilization). Cox models were used to estimate the association between patterns of care and time to recovery while controlling for injury severity and other confounders. Patients in the low-utilization general practitioner group and those in the general medical group had the fastest recovery even after controlling for important prognostic factors. Compared with the low-utilization general practitioner group, the 1-year rate of recovery in the high-utilization chiropractic group was 25% slower (adjusted hazard rate ratio [HRR] 0.75, 95% confidence interval [95% CI]0.54-1.04), in the low-utilization general practitioner plus chiropractic group the rate was 26% slower (HRR 0.74, 95% CI 0.60-0.93), and in the high-utilization general practitioner plus chiropractic combined group the rate was 36% slower (HRR 0.64, 95% CI 0.50-0.83).\nQuestion: Early aggressive care and delayed recovery from whiplash: isolated finding or reproducible result?",
        "gt": "The observation that intensive health care utilization early after a whiplash injury is associated with slower recovery was reproduced in an independent cohort of patients. The results add to the body of evidence suggesting that early aggressive treatment of whiplash injuries does not promote faster recovery. In particular, the combination of chiropractic and general practitioner care significantly reduces the rate of recovery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Individuals referred to cardiac rehabilitation programs (CRPs) after stroke have demonstrated postprogram improvements in cardiovascular fitness (VO2peak). However, the effect of CRPs on other physiological/quality-of-life outcomes and effect of time from stroke on these results has not been investigated. The objectives of the present study are (1) to evaluate the effects of a CRP in participants with motor impairment after stroke and (2) to explore the effects of elapsed time from stroke on physiological/quality-of-life outcomes. The CRP included 24 weeks of resistance and aerobic training. Primary outcomes in 120 participants, 25.4\u00b142.3 (mean\u00b1standard deviation) months after stroke, included 6-minute walk distance (6MWD), VO2peak, timed repeated sit-to-stand performance, and affected-side isometric knee extensor strength (IKES). Secondary measures included gait characteristics (cadence, step lengths, and symmetry), walking speed, balance (Berg Balance Scale), affected-side range of motion (ROM), elbow flexor and grip strength, anaerobic threshold, and perceptions of participation/social reintegration. After adjusting for multiple comparisons, participants demonstrated significant improvements (all P<.001) in 6MWD (283.2\u00b1126.6 to 320.7\u00b1141.8 m), sit-to-stand performance (16.3\u00b19.5 to 13.3\u00b17.1 seconds), affected-side IKES (25.9\u00b110.1 to 30.2\u00b111 kg as a percentage of body mass), and VO2peak (15.2\u00b14.5 to 17.2\u00b14.9 mL\u00b7kg\u00b7min(-1)). Participants also demonstrated post-CRP improvements in secondary outcomes: anaerobic threshold, balance, affected-side hip/shoulder ROM, grip and isometric elbow flexor strength, participation, walking speed, cadence (all P<.001), and bilateral step lengths (P<.04). In a linear regression model, there was a negative association between the change in 6MWD and time from stroke (\u03b2=-42.1; P=.002) independent of baseline factors.\nQuestion: Outcomes in people after stroke attending an adapted cardiac rehabilitation exercise program: does time from stroke make a difference?",
        "gt": "A CRP yields improvements over multiple domains of recovery; however, those who start earlier demonstrate greater improvement in functional ambulation independent of baseline factors. These data support the use of adapted CRPs as a standard of care practice after conventional stroke rehabilitation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess in vitro the cariogenic and erosive potentials of Brazilian liquid oral paediatric medicines. Twenty-three paediatric medicines available on the Brazilian market were evaluated. The sample consisted of antihistamines, antitussives, bronchodilators and mucolytics. Duplicates of each bottle were analyzed for sugar concentration using normal-phase- high-performance liquid chromatography (HPLC). Quantification of sugars and sorbitol was calculated using the peak heights of commercial standards as references. pH measurements were determined using a digital pH meter. Titratable acidity was assessed by diluting three aliquots of each medicine, and increments of 0.1N NaOH were titrated until neutrality was reached. Viscosity was determined using a viscosemeter. Sugars were detected in 56.5% of the medicines. Sucrose was identified in 10 medicines, with concentrations ranging from 11.36 g% to 85.99 g%. Glucose was detected in five medicines, with concentrations varying from 4.64 g% to 40.19 g%; fructose in six medicines, with concentrations ranging from 5.09 g% to 46.71 g%. Twelve medicines exhibited sorbitol, with values ranging from 5.39 g% to 46.09 g%. Most tested medicines were acidic, with pH values ranging between 2.6 and 5.7. Only two medicines (Fluimucil and Polaramine) presented pH 6.4 and 6.0, respectively. Titratable acidity mean values ranged between 0.28 and 16.33 mL. Viscosity values varied between 2.8 cP and 412.3 cP.\nQuestion: Are paediatric medicines risk factors for dental caries and dental erosion?",
        "gt": "Many paediatric medicines showed high sugar concentration, pH values below the critical value and high titratable acidity values, all of which increase the medicines' cariogenic and erosive potentials.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to investigate whether the relation between responsibility for domestic work and psychological distress was influenced by perception of gender inequality in the couple relationship and relative socioeconomic position. In the Northern Swedish Cohort, all pupils who studied in the last year of compulsory school in a northern Swedish town in 1981 have been followed regularly until 2007. In this study, participants living with children were selected (n = 371 women, 352 men). The importance of relative socioeconomic position and perception of gender inequality in the couple relationship in combination with domestic work for psychological distress was examined through logistic regression analysis. Two combinations of variables including socioeconomic position ('having less than half of the responsibility for domestic work and partner higher socioeconomic position' and 'having more than half the responsibility for domestic work and equal socioeconomic position') were related to psychological distress. There were also higher ORs for psychological distress for the combinations of having 'less than half of the responsibility for domestic work and gender-unequal couple relationship' and 'more than half the responsibility for domestic work and gender-unequal couple relationship'. Having a lower socioeconomic position than the partner was associated with higher ORs for psychological distress among men.\nQuestion: Domestic work and psychological distress--what is the importance of relative socioeconomic position and gender inequality in the couple relationship?",
        "gt": "This study showed that domestic work is a highly gendered activity as women tend to have a greater and men a smaller responsibility. Both these directions of inequality in domestic work, in combination with experiencing the couple relationship as gender-unequal, were associated with psychological distress There is a need for more research with a relational approach on inequalities in health in order to capture the power relations within couples in various settings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Selective serotonin reuptake inhibitors (SSRIs) have been suspected of cardiac teratogenicity, but reports have been inconsistent. Our aim was to investigate the rate of nonsyndromic congenital heart defects in newborns exposed in utero to SSRIs compared with unexposed controls. This prospective study of women who gave birth at our tertiary center from 2000 to 2007 yielded 235 women who reported first-trimester SSRI use during pregnancy. All newborns born during the study period and found to have a persistent cardiac murmur on day 2 or 3 of life were referred for examination by a pediatric cardiologist and by echocardiography. The findings were compared between the newborns who were exposed to SSRIs and those who were not. Nonsyndromic congenital heart defects were identified by echocardiography in 8 of 235 (3.40%) newborns exposed in utero to SSRIs and in 1083 of 67,636 (1.60%) non-exposed newborns. The difference in prevalence between the two groups was significant (relative risk, 2.17; 95% confidence interval, 1.07-4.39). The prevalence rates for paroxetine and fluoxetine exposure were 4.3% and 3.0%, respectively. All cardiac defects in the study group were mild: ventricular septal defect (6), bicuspid aortic valve (1) and right superior vena cava to coronary sinus (1).\nQuestion: Are selective serotonin reuptake inhibitors cardiac teratogens?",
        "gt": "Newborns exposed in utero to SSRIs, have a twofold higher risk of mild nonsyndromic heart defects than unexposed infants. The data suggest that women who require SSRI treatment during pregnancy can be reassured that the fetal risk is low and possible cardiac malformations will probably be mild. Late-targeted ultrasound and fetal echocardiography at 22 to 23 weeks' gestation are recommended in this patient group.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patient notes are used for a variety of purposes in health care. Medical students are taught the structure of patient notes early in training. Review of patient notes are then used to assess synthesis and integration of patient information. It is critical that the information in the note accurately and completely represents the student-patient encounter. The authors reviewed videotapes of students in three standardized-patient based scenarios and compared what occurred during the physical examination with the subsequent documentation in the patient note. In all, 207 encounter-note pairs were reviewed. Only 8 (4%) of the notes completely and accurately represented what occurred during the encounter. Problems with underdocumentation, overdocumentation, and inaccurate documentation of physical findings were seen for all three patient scenarios.\nQuestion: Do students do what they write and write what they do?",
        "gt": "These findings highlight the need to teach and assess both data gathering skills and written documentation of findings in medical training.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Individuals with celiac disease (CD) are at increased risk of sepsis. The aim of this study was to examine whether CD influences survival in sepsis of bacterial origin. Nationwide longitudinal registry-based study. Through data on small intestinal biopsies from Sweden's 28 pathology departments, we identified 29,096 individuals with CD (villous atrophy, Marsh stage III). Each individual with CD was matched with five population-based controls. Among these, 5,470 had a record of sepsis according to the Swedish Patient Register (1,432 celiac individuals and 4,038 controls). Finally we retrieved data on mortality in sepsis patients through the Swedish Cause of Death Registry. CD was associated with a 19% increase in overall mortality after sepsis (95% confidence interval (CI) = 1.09-1.29), with the highest relative risk occurring in children (adjusted hazard ratio (aHR) = 1.62; 95%CI = 0.67-3.91). However, aHR for death from sepsis was lower (aHR = 1.10) and failed to reach statistical significance (95%CI = 0.72-1.69). CD did not influence survival within 28 days after sepsis (aHR = 0.98; 95%CI = 0.80-1.19).\nQuestion: Does Celiac Disease Influence Survival in Sepsis?",
        "gt": "Although individuals with CD seem to be at an increased risk of overall death after sepsis, that excess risk does not differ from the general excess mortality previously seen in celiac patients in Sweden. CD as such does not seem to influence short-term or sepsis-specific survival in individuals with sepsis and therefore is not an independent risk factor for poor prognosis in sepsis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine reciprocal associations between substance use (cigarette smoking, use of alcohol, marijuana, and other illegal drugs) and suicidal ideation among adolescents and young adults (aged 11-21 at wave 1; aged 24-32 at wave 4). Four waves public-use Add Health data were used in the analysis (N=3342). Respondents were surveyed in 1995, 1996, 2001-2002, and 2008-2009. Current regular smoking, past-year alcohol use, past-year marijuana use, and ever use of other illegal drugs as well as past-year suicidal ideation were measured at the four waves (1995, 1996, 2001-2002, and 2008-2009). Fixed effects models with lagged dependent variables were modeled to test unidirectional associations between substance use and suicidal ideation, and nonrecursive models with feedback loops combining correlated fixed factors were conducted to examine reciprocal relations between each substance use and suicidal ideation, respectively. After adjusting for the latent time-invariant effects and lagged effects of dependent variables, the unidirectional associations from substance use to suicidal ideation were consistently significant, and vice versa. Nonrecursive model results showed that use of cigarette or alcohol increased risk of suicidal ideation, while suicidal ideation was not associated with cigarette or alcohol use. Reversely, drug use (marijuana and other drugs) did not increase risk of suicidal ideation, but suicidal ideation increased risk of illicit drug use.\nQuestion: Suicidal ideation and substance use among adolescents and young adults: a bidirectional relation?",
        "gt": "The results suggest that relations between substance use and suicidal ideation are unidirectional, with cigarette or alcohol use increasing risk of suicidal ideation and suicidal ideation increasing risk of illicit drug use.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Mobile C-arm imaging is commonly used in operating rooms worldwide. Especially in orthopaedic surgery, intraoperative C-arms are used on a daily basis. Because of new minimally-invasive surgical procedures a development in intraoperative imaging is required. The purpose of this article is investigate if the choice of mobile C-arms with flat panel detector technology (Siemens Cios Alpha and Ziehm Vision RFD) influences image quality and dose using standard, commercially available test devices. For a total of four clinical application settings, two zoom formats, and all dose levels provided, the transmission dose was measured and representative images were recorded for each test device. The data was scored by four observers to assess low contrast and spatial resolution performance. The results were converted to a relative image quality figure allowing for a direct image quality and dose comparison of the two systems. For one test device, the Cios Alpha system achieved equivalent (within the inter-observer standard error) or better low contrast resolution scores at significantly lower dose levels, while the results of the other test device suggested that both systems achieved similar image quality at the same dose. The Cios Alpha system achieved equivalent or better spatial resolution at significantly lower dose for all application settings except for Cardiac, where a comparable spatial resolution was achieved at the same dose.\nQuestion: Does the choice of mobile C-arms lead to a reduction of the intraoperative radiation dose?",
        "gt": "The correct choice of a mobile C-arm is very important, because it can lead to a reduction of the intraoperative radiation dose without negative effects on image quality. This can be a big advantage to reduce intraoperative radiation not only for the patient but also for the entire OR-team.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The proportion of patients with idiopathic chronic pancreatitis (ICP) that have an autoimmune origin is unknown. Three forms of ICP have been described: pseudotumoral, duct-destructive, and usual chronic pancreatitis. The aim of this study was to identify autoimmune stigmata in the 3 forms. All patients who underwent exploration for ICP were included. The following data were recorded: examination by an internal medicine specialist, autoantibodies and immunoglobulin screening, and pancreatic duct imaging. Sixty patients were included (pseudotumoral, n = 11; duct-destructive, n = 27; usual, n = 22). There were no significant differences among the 3 types with regard to sex ratio, age, frequency of acute pancreatitis, or obstructive jaundice. Pancreatic calcifications were seen only in the usual form (81%; P = .0001). Autoimmune disease was present in 10 patients: ulcerative colitis in 5 patients, primary sclerosing cholangitis in 2 patients, and Sj\u00f6gren's syndrome, Hashimoto's thyroiditis, and Graves' disease in 1 patient each. Autoimmune diseases were not more frequent in patients with pseudotumoral (36%) or duct-destructive (19%) forms than in those with the usual form (5%, P = .06). Immunoglobulin G4 levels were increased in 2 of 6 in the pseudotumoral, 1 of 9 in the duct-destructive, and 0 of 12 patients in the usual group. Combining clinical and biochemical autoimmune parameters, 24 patients (40%) had at least 1 autoimmune marker or disease.\nQuestion: Is idiopathic chronic pancreatitis an autoimmune disease?",
        "gt": "Clinical or biochemical autoimmune stigmata are present in 40% of patients with ICP. Autoimmune mechanisms may be frequent in idiopathic pancreatitis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Formal efforts to improve patient education are associated with fewer disease complications in a number of conditions. The possible relationship between knowledge about ulcerative colitis and its cancer risk, and the development of colorectal cancer using a previously developed and validated instrument-the Crohn's and colitis knowledge (CCKNOW) score-were investigated. The 24 item CCKNOW questionnaire was mailed to patients known to have developed colorectal cancer as a complication of ulcerative colitis (cases) and to colitics from the Leicestershire inflammatory bowel disease patient database who had not developed cancer (controls). The mean (SD) CCKNOW scores for cases was 8.21 (3.02) and for controls was 8.27 (4.3). These scores did not differ significantly between cases and controls (difference 0.06, 95% confidence interval (CI) -1.7 to 1.5, p=0.9). There were four times as many members of the National Association of Crohn's and Colitis (NACC) in the control group compared with the cancer group and patients who are members of NACC achieve statistically significantly higher scores than non-members (11.6 v 7.8, p=0.05, 95% CI -0.1 to 7.6). However, after adjusting for NACC membership, the CCKNOW score did not appear to be associated with having developed cancer (odds ratio 1.04, 95% CI 0.92 to 1.18, p=0.5).\nQuestion: Does patient knowledge affect the colorectal cancer risk in ulcerative colitis?",
        "gt": "The CCKNOW scores were comparable in cases and controls. Thus, in a retrospective study, no evidence has been demonstrated of an association between patient knowledge and the risk of developing colorectal cancer in patients with ulcerative colitis. However, knowledge may have been increased in cases as a direct result of having had colorectal cancer as a complication of ulcerative colitis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The opinion on the use of retrograde ureteropyelography (RUPG) prior to routine pyeloplasty for an ureteropelvic (UPJ) obstruction has been divided. This study analyses the efficacy of a preoperative RUPG and determines if a dorsal lumbotomy (DL) approach offers any advantage in this situation. This is a retrospective analysis of application of RUPG prior to pyeloplasty in children with ages ranging from 42 days to 16.2 years who underwent surgery at the Children's Hospital at Westmead between 2009 and 2013. We identified a total of 95 children with isolated UPJ obstruction, with 59 (62.1%) boys and 36 (37.8%) girls. Overall, open pyeloplasties were performed in 89 (42 DL: 47 loin incision) and the rest (n = 6) laparoscopically. Preoperative RUPG was performed in 58 (61%) and it provided additional information in 11 (18.9%) patients for whom the surgical approach was modified. Hospital stay, operative time, and time to full diet were shorter with the DL approach (p<0.05).\nQuestion: Does the surgical approach change the need for a retrograde pyelogram prior to pyeloplasty?",
        "gt": "The current study suggests that RUPG is avoidable if the approach for pyeloplasty is through the conventional loin incision. The short-term advantages might rationalize the use of RUPG if a DL incision is employed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We report our 5-year experience of continuous flow left ventricular assist device (LVAD) implantation without the use of anti-platelet therapy. Between February 2006 and September 2011, 27 patients (26 men; 1 woman) were implanted with a continuous flow LVAD (HeartMate II, Thoratec Corporation, Pleasanton, CA, USA). The mean age was 55.7 \u00b1 9.9 years. The mean duration of support was 479 \u00b1 436 (1-1555) days with 35.4 patient-years on support. Twenty-one patients were implanted as a bridge to transplantation and 6 for destination therapy. The anticoagulation regimen was fluindione for all patients, with aspirin for only 4 patients. At the beginning of our experience, aspirin was administered to 4 patients for 6, 15, 60 and 460 days. Due to gastrointestinal (GI) bleeding and epistaxis, aspirin was discontinued, and since August 2006, no patients have received anti-platelet therapy. At 3 years, the survival rate during support was 76%. The most common postoperative adverse event was GI bleeding (19%) and epistaxis (30%) (median time: 26 days) for patients receiving fluindione and aspirin. The mean International Normalized Ratio (INR) was 2.58 \u00b1 0.74 during support. Fifteen patients have been tested for acquired Von Willebrand disease. A diminished ratio of collagen-binding capacity and ristocetin cofactor activity to Von Willebrand factor antigen was observed in 7 patients. In the postoperative period, 2 patients presented with ischaemic stroke at 1 and 8 months. One of these 2 patients had a previous history of carotid stenosis with ischaemic stroke. There were no patients with haemorrhagic stroke, transient ischaemic attack or pump thrombosis. The event rate of stroke (ischaemic and haemorrhagic) per patient-year was 0.059 among the patients without aspirin with fluindione regimen only.\nQuestion: Is anti-platelet therapy needed in continuous flow left ventricular assist device patients?",
        "gt": "A fluindione regimen without aspirin in long-duration LVAD support appears to not increase thromboembolic events and could lead to a diminished risk of haemorrhagic stroke.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the inter-rater reliability of results from Global Trigger Tool (GTT) reviews when one of the three reviewers remains consistent, while one or two reviewers rotate. Comparison of results from retrospective record review performed as a cross-sectional study with three review teams each consisting of two non-physicians and one physician; Team I (three consistent reviewers), Team II (one of the two non-physician reviewers or/and the physician from Team I are replaced for different review periods) and Team III (three consistent reviewers different from reviewers in Team I and Team II). Medium-sized hospital trust in Northern Norway. A total of 120 records were selected as biweekly samples of 10 from discharge lists between 1 July and 31 December 2010 for a 3-fold review. Replacement of review team members was tested to assess impact on inter-rater reliability and adverse events measurment. Inter-rater reliability assessed with the Cohen kappa coefficient between different teams regarding the presence and severity level of adverse events. Substantial inter-rater reliability regarding the presence and severity level of adverse events was obtained between Teams I and II, while moderate inter-rater reliability was obtained between Teams I and III.\nQuestion: Is inter-rater reliability of Global Trigger Tool results altered when members of the review team are replaced?",
        "gt": "Replacement of reviewers did not influence the results provided that one of the non-physician reviewers remains consistent. The experience of the consistent reviewer can result in continued consistency in interpretation with the new reviewer through discussion of events. These findings could encourage more hospital to rotate reviewers in order to optimize resources when using the GTT.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the effect of immediate postpartum curettage on rapid resolution of clinical and laboratory indices in pre-eclampsia and eclampsia women. A randomized controlled study, comprised of 420 pre-eclamptic or eclamptic women with singleton pregnancy 24 weeks gestation and more. Patients were divided into two groups: 220 patients underwent immediate postpartum curettage and 200 patients as a control group. The clinical and laboratory prenatal parameters showed no statistical significant differences between both groups. The follow-up for the postnatal clinical and laboratory data showed significant improvement for the mean arterial blood pressure in the curettage group over 6, 12, and 24 h after delivery and significant improvement in the platelet count as well. The average time required for MAP to reach 105 mmHg or less was significantly shorter (P<0.05) in the curettage group (40 \u00b1 3.15 h) than the control group (86 \u00b1 5.34 h). Two patients in the curettage group developed convulsions versus 11 patients in the control group within the first 24 h after delivery. No maternal mortalities were reported in both groups.\nQuestion: Does immediate postpartum curettage of the endometrium accelerate recovery from preeclampsia-eclampsia?",
        "gt": "Immediate postpartum curettage is a safe and effective procedure and can accelerate recovery from pre-eclampsia or eclampsia.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The uneven distribution of allied health professionals (AHPs) in rural and remote Australia and other countries is well documented. In Australia, like elsewhere, service delivery to rural and remote communities is complicated because relatively small numbers of clients are dispersed over large geographic areas. This uneven distribution of AHPs impacts significantly on the provision of services particularly in areas of special need such as mental health, aged care and disability services. This study aimed to determine the relative importance that AHPs (physiotherapists, occupational therapists, speech pathologists and psychologists - \"therapists\") living in a rural area of Australia and working with people with disability, place on different job characteristics and how these may affect their retention. A cross-sectional survey was conducted using an online questionnaire distributed to AHPs working with people with disability in a rural area of Australia over a 3-month period. Information was sought about various aspects of the AHPs' current job, and their workforce preferences were explored using a best-worst scaling discrete choice experiment (BWSDCE). Conditional logistic and latent class regression models were used to determine AHPs' relative preferences for six different job attributes. One hundred ninety-nine AHPs completed the survey; response rate was 51 %. Of those, 165 completed the BWSDCE task. For this group of AHPs, \"high autonomy of practice\" is the most valued attribute level, followed by \"travel BWSDCE arrangements: one or less nights away per month\", \"travel arrangements: two or three nights away per month\" and \"adequate access to professional development\". On the other hand, the least valued attribute levels were \"travel arrangements: four or more nights per month\", \"limited autonomy of practice\" and \"minimal access to professional development\". Except for \"some job flexibility\", all other attributes had a statistical influence on AHPs' job preference. Preferences differed according to age, marital status and having dependent children.\nQuestion: Should I stay or should I go?",
        "gt": "This study allowed the identification of factors that contribute to AHPs' employment decisions about staying and working in a rural area. This information can improve job designs in rural areas to increase retention.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: YKL-40 (human cartilage glycoprotein-39, or 38-kDa heparin-binding glycoprotein) is a mammalian member of a protein family that includes bacterial chitinases. YKL-40 mRNA is expressed by human liver and may play a role in tissue remodelling. The aims were to assess whether circulating YKL-40 is released or extracted in the hepatosplanchnic system and to localize YKL-40 in liver tissue. Plasma YKL-40 was determined by radioimmunoassay in 25 patients with liver diseases (alcoholic cirrhosis (n = 20), chronic active hepatitis (n = 2), cirrhosis of unknown aetiology (n = 2), and fatty liver (n = 1) and in 18 subjects with normal liver function during a haemodynamic investigation with catheterization of liver vein and the femoral artery. Immunohistochemical studies of the localization of YKL-40 in cryostal liver biopsy specimens were obtained from eight other patients with alcoholic liver disease. Plasma YKL-40 was significantly increased in patients with alcoholic cirrhosis (median, 523 micrograms/l; P<0.001) compared with controls (106 micrograms/l), and plasma YKL-40 in the hepatic vein was higher (P<0.01) than that of the artery in both the patients and controls, showing release of YKL-40 from the hepatosplanchnic area. The release rate of YKL-40 from the hepatosplanchnic area was higher in patients with liver disease than in controls (11.0 versus 2.1 micrograms/min, P<0.05). Furthermore, the highest plasma YKL-40 levels were found in patients with a moderate or severe degree of liver fibrosis, and immunohistochemical studies showed positive staining for YKL-40 antigen in areas of the liver biopsy with fibrosis.\nQuestion: Plasma YKL-40: a new potential marker of fibrosis in patients with alcoholic cirrhosis?",
        "gt": "The increased plasma YKL-40 in patients with alcoholic cirrhosis may reflect the remodelling of liver fibrosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the importance of intraoperative management of recipient hemodynamics for immediate versus delayed graft function. The retrospective study of 1966 consecutive renal transplants performed in our department between June 1980 and December 2009 analyzed several perioperative hemodynamic factors: central venous pressure (CVP), mean arterial pressure (MAP) as well as volumes of fluids, fresh frozen plasma (FFP), albumin, and whole blood transfusions. We examined their influence on renal graft function parameters: immediate diuresis, serum creatinine levels, acute rejection, chronic transplant dysfunction, and graft survival. Mean CVP was 9.23 \u00b1 2.65 mm Hg and its variations showed no impact on graft function. We verified a twofold greater risk of chronic allograft dysfunction among patients with CVP \u2265 11 mm Hg (P<.001). Mean MAP was 93.74 \u00b1 13.6 mm Hg; graft survivals among subjects with MAP \u2265 93 mm Hg were greater than those of patients with MAP<93 mm Hg (P = .04). On average, 2303.6 \u00b1 957.4 mL of saline solutions were infused during surgery. Patients who received whole blood transfusions (48%) showed a greater incidence of acute rejection episodes (ARE) (P = .049) and chronic graft dysfunction (P<.001). Patients who received FFP (55.7%), showed a higher incidence of ARE (P<.001). Only 4.6% of patients (n = 91) received human albumin with a lower incidence of ARE (P = .045) and chronic graft dysfunction (P = .024). Logistic binary regression analysis revealed that plasma administration was an independent risk factor for ARE (P<.001) and chronic dysfunction (P = .028). Volume administration (\u2265 2500 mL) was also an independent risk factor for chronic allograft dysfunction (P = .016). Using Cox regression, we verified volume administration \u2265 2500 mL to be the only independent risk factor for graft failure (P<.001).\nQuestion: Do intraoperative hemodynamic factors of the recipient influence renal graft function?",
        "gt": "MAP \u2265 93 mm Hg and perioperative fluid administration<2500 mL were associated with greater graft survival. Albumin infusion seemed to be a protective factor, while CVP \u2265 11 mm Hg, whole blood, and FFP transfusions were associated with higher rates of ARE and chronic graft dysfunction.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Choledocholithiasis commonly occurs in patients with symptomatic cholelithiasis. Although the recently developed multidetector computed tomography (MDCT) scan enhances the ability to diagnose choledocholithiasis, this technique is considered to have some limitations for evaluating the common bile duct (CBD).AIM: The purpose of this study was to evaluate the necessity for performing endoscopic ultrasound (EUS) as an add-on test to detect choledocholithiasis in patients who were diagnosed with gallstone disease without choledocholithiasis based on MDCT. Three hundred twenty patients with gallstone disease and no evidence of CBD stones according to MDCT underwent EUS between March 2006 and April 2011. If CBD stones were suspected based on the EUS results or clinical symptoms, a final diagnosis was obtained by endoscopic retrograde cholangiopancreatography (ERCP). The patients' medical records were retrospectively analyzed based on clinical symptoms, biochemical findings, and results of the imaging studies. CBD stones were not detected with MDCT in 41 (12.8 %) out of 320 patients with gallstone disease. The causes for these discrepancies could be attributed to small stone size (n = 19, 46.3 %), isodensity (n = 18, 43.9 %), impacted stones (n = 1, 2.4 %), and misdiagnosis (n = 3, 7.3 %). If EUS were used as a triage tool, unnecessary diagnostic ERCP and its complications could be avoided for 245 (76.6 %) patients.\nQuestion: Is endoscopic ultrasound needed as an add-on test for gallstone diseases without choledocholithiasis on multidetector computed tomography?",
        "gt": "MDCT may not be a primary technique for detecting CBD stones. EUS should be performed instead as an add-on test to evaluate the CBD for patients with gallstone-related disease. In particular, EUS should be routinely recommended for patients with abnormal liver enzyme levels, pancreatitis, and dilated CBD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study is to evaluate the risk of accepting cardiac donors after an episode of cardiopulmonary resuscitation. Since 1997, 13 resuscitated donor hearts (10 M, 3 F, age 15-54 years) after sudden cardiac arrest have been transplanted. The retrospective analysis was used. Allografts after resuscitation episode were implanted in 13 patients (6 M, 7 F, age 31-65 years). 11 patients were on the urgency list and two of them required periodically intravenous inotropic therapy. Two patients (P.A, B.J) died in the first 24 hours after procedure (cause of death: pulmonary embolism, extensive cardiac ischemia). During follow up (6-48 months, avg. 25.1 +/- 15.9 months) none of the 11 patients died. All patients are NYHA functional class I or I/II. Total time of cardiopulmonary resuscitation did not influence the time of reperfusion (p>0.05). Analysis of cardiac index Cl (l/min/m2) at 2, 4, 6, 8, 12, 24, 72 hours after heart transplantation showed correct values during following days. Echocardiographic and invasive examinations (8 patients) do not show any abnormalities.\nQuestion: Does the episode of cardiopulmonary resuscitation in cardiac donors increase the risk of heart transplantation?",
        "gt": "These results suggest that acceptance of cardiac donors after cardiopulmonary resuscitation may not increase the risk of heart transplantation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Pneumothorax is defined as air in pleural space. The etiology of spontaneous pneumothorax (SP) is still under investigation and, despite many studies, remains uncertain. The aim of this study was to investigate the effects of the lunar cycle and daily weather changes on SP development. The data of patients admitted to our clinic with SP were analysed retrospectively. The daily atmospheric pressure, relative ratio of humidity and temperature in degrees Celsius of each day were obtained. The mean values for each day, from the first to the 29th day, of the synodic lunar cycle (SLC) were calculated for the five-year study period. The attacks were allocated to the appropriate day of an ideal 29-day SLC, irrespective of the calendar date. A total of 131 patients who were admitted to our hospital with SP (130 males and 1 female with an average age of 32.4\u00b112.2) were included in this study. The number of patients with SP showed a statistically significant correlation with mean atmospheric pressure (p=0.005), relative humidity (p=0.007) and outdoor temperature (p=0.02) but not with the SLC.\nQuestion: Do Atmospheric Changes and the Synodic Lunar Cycle Affect the Development of Spontaneous Pneumothorax?",
        "gt": "SP is significantly influenced by weather-related factors. Changes in atmospheric pressure, humidity and outdoor temperature had obvious effects on the development of SP. However, the SLC had no effect on SP.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: With the increased occurrence of methicillin-resistant staphylococcus aureus infections, linezolid treatment might be administered more often. New rare adverse events are likely to follow. A 65-year-old man (weight, 91 kg; height, 185 cm) presented to the emergency department at the University of Virginia-affiliated Salem Veterans Affairs Medical Center, Salem, Virginia, after a recent (8 weeks) kidney transplantation with a 24-hour history of fatigue, chills, arthralgias, increased urinary frequency, and onset of tongue discoloration. Two days before admission, he completed a 14-day course of linezolid 600 mg PO BID for ampicillin-resistant enterococcal urinary tract infection. He was afebrile on admission and the dorsal aspect of his tongue was blackened centrally, browner peripherally, with normal pink mucosa on the periphery. Based on the Naranjo probability scale, the calculated score for tongue discoloration as a drug-related adverse event was 7 out of a maximum score of 13 points, designating it as a probable cause. The patient's tongue discoloration improved moderately during the hospital stay and resolved 6 months after the discontinuation of linezolid.\nQuestion: Tongue discoloration in an elderly kidney transplant recipient: Treatment-related adverse event?",
        "gt": "We report a rare association of linezolid and tongue discoloration in an elderly kidney transplant recipient that improved with discontinuation. We present this case to increase clinicians' awareness of the potential adverse event.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The role of combined endobronchial ultrasound-guided transbronchial needle aspiration (EBUS-TBNA) and endoscopic ultrasound-guided fine needle aspiration (EUS-FNA) with a single bronchoscope is poorly understood. The purpose of the present study was to elucidate the roles of EBUS-TBNA and EUS-FNA with a single bronchoscope in the preoperative hilar and mediastinal staging of non-small cell lung cancer (NSCLC). A total of 150 patients with potentially resectable known or suspected NSCLC were enrolled in our prospective study. EBUS-TBNA was performed, followed by EUS-FNA, with an EBUS bronchoscope for N2 and N3 nodes\u22655 mm in the shortest diameter on ultrasound images, in a single session. EBUS-TBNA was performed for 257 lymph nodes and EUS-FNA for 176 lymph nodes. Of the 150 patients, 146 had a final diagnosis of NSCLC. Of these 146 patients, 33 (23%) had N2 and/or N3 nodal metastases. The sensitivity of EBUS-TBNA, EUS-FNA, and the combined approach per patient was 52%, 45%, and 73%, respectively (EBUS-TBNA vs the combined approach, P=.016, McNemar's test). The corresponding negative predictive value was 88%, 86%, and 93%. Two patients (1%) developed severe cough from EBUS-TBNA.\nQuestion: Endoscopic ultrasound-guided fine needle aspiration and endobronchial ultrasound-guided transbronchial needle aspiration: Are two better than one in mediastinal staging of non-small cell lung cancer?",
        "gt": "The combined endoscopic approach with EBUS-TBNA and EUS-FNA is a safe and accurate method for preoperative hilar and mediastinal staging of NSCLC, with better results than with each technique by itself.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the relationship between leg length and glucose tolerance in pregnancy. The leg length and leg-to-height percentage were prospectively determined on 161 glucose-tolerant women during pregnancy and 61 women with gestational diabetes mellitus (GDM). Women with GDM were a mean of 2.8 cm shorter than women who were glucose tolerant, due entirely to their leg lengths being a mean of 3.2 cm shorter. With respect to the 2-h result on the glucose tolerance test (GTT), there were negative correlations for height (r = -0.161, P = 0.017), leg length (r = -0.266, P<0.0005), and the leg-to-height percentage (r = -0.294, P<0.0005). The correlation between the leg-to-height percentage and the 2-h result on the GTT remained significant after adjustment for age (r = -0.252, P<0.0005) and for age and BMI (r = -0.224, P = 0.001).\nQuestion: Gestational diabetes: Is there a relationship between leg length and glucose tolerance?",
        "gt": "Women with GDM are shorter than glucose-tolerant women and have a lower leg-to-height percentage. Consideration of short stature as a risk factor for GDM is not valid without taking into account the leg-to-height percentage.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study examined whether heightened cardiovascular reactivity and low socioeconomic status had synergistic effects on the progression of carotid atherosclerosis in a population of eastern Finnish men. Data from the Kuopio Ischemic Heart Disease Risk Factor Study were used to measure 4-year progression of intima-media thickness in 882 men according to cardiovascular reactivity and socioeconomic status. Associations were examined in relation to risk factors and were stratified by baseline levels of atherosclerosis and prevalent ischemic heart disease. The effect of reactivity on atherosclerotic progression depended on socioeconomic status. Men who had heightened cardiovascular responsiveness to stress and were born into poor families, received little education, or had low incomes had the greatest atherosclerotic progression.\nQuestion: Does low socioeconomic status potentiate the effects of heightened cardiovascular responses to stress on the progression of carotid atherosclerosis?",
        "gt": "An understanding of associations between individual risk factors and disease should be based on etiologic hypotheses that are conceived at the population level and involve fundamental social and economic causes of disease. This study demonstrates how examining the interaction of an individual biological predisposition will low socioeconomic status over the life course is etiologically informative for understanding the progression of atherosclerotic vascular disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The literature is inconsistent as to whether HIV-infected patients have higher rates of surgical complication rates than HIV-uninfected patients. This inconsistency reflects the failure to control for confounding variables in many of the previous studies. A retrospective cohort study of records of HIV-infected individuals who underwent surgical procedures between 1990 and 1995 was matched with the records of HIV-uninfected control patients. We performed a logistic regression analysis to determine the independent effects of HIV infection and other potential risk factors for surgical complications. The crude rates of death and infectious and hematologic complications were higher among HIV-infected patients than among uninfected patients. Although the crude risk of having any complication was higher among the HIV-infected (odds ratio [OR]=2.47, p=0.015), the adjusted risk was not (OR=0.72 [p<0.613]). Variables significantly associated with complications were American Society of Anesthesiology (ASA) risk class (OR=2.7), age (OR=1.06 per year), and weight (OR=0.96 per kg).\nQuestion: Is HIV infection a risk factor for complications of surgery?",
        "gt": "HIV sero-status was not found to be an independent risk factor for complications of surgery. The most important risk factor for complication of surgery in HIV-infected patients is ASA risk class.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare the diagnostic accuracy of standard (st) and long-term video (lt) EEG in elderly patients with suspected non-convulsive seizures. Over a 12-month period, we prospectively included all elderly (over-65) hospitalized patients having undergone lt-EEG for suspected non-convulsive seizures (n=43). st-EEG was defined as the first 20min of each lt-EEG. We recorded the patients' clinical and imaging characteristics and final diagnosis and assessed the respective diagnostic values of st-EEG and lt-EEG. Epileptiform discharges were detected on standard EEG in only 7% of patients and in 28% of patients on Lt-EEG (p=0.004). Non-convulsive seizures were recorded in 1 case vs. 4, respectively. Nine of 40 negative standard EEG showed later epileptiform activities. The median time to occurrence of the first epileptiform activities was 46.5min (interquartile range: 36.5-239.75min). Epileptiform activity occurred during sleep only in 33% patients with a negative st-EEG. Dementia was associated with a positive lt-EEG (p:0.047).\nQuestion: Is long-term electroencephalogram more appropriate than standard electroencephalogram in the elderly?",
        "gt": "Lt-EEG was clearly superior to standard EEG for detecting epileptiform activity in elderly when suspecting non convulsive seizures.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Sixteen patients with 19 renal artery stents underwent CT angiography. A biphasic protocol was performed including arteriographic acquisition at standard 120 kVp and a late-arterial scan at 100 kVp (n=9) or 80 kVp (n=7). Images were reconstructed under various algorithms. Signal-to-noise and contrast-to-noise ratios (SNR, CNR) were determined within stent, aorta and renal arteries. Image quality and the presence of restenosis were assessed. Volume CT dose-index was recorded and dose reduction (DR%) between phases was calculated. Ten patients presented with Hounsfield values>250 HU in all segments, phases and reconstructions and were further evaluated. The 120 kVp protocol performed better in all vessels and reconstruction algorithms. SNR at 120 kVp (B31f) did not differ significantly compared to 100 kVp (B31f). CNR within stent was borderline compromised at 100 kVp (p=0.042). All but two image sets (at 80 kVp) were considered diagnostic. Minor loss of subjective image quality was noticed at 100 kVp. No difference in assessment of restenosis was observed between 120 kVp and the diagnostic low-exposure scans. Mean DR% was estimated 45% at 100 kVp and 77% at 80 kVp.\nQuestion: MDCT angiography assessment of renal artery in-stent restenosis: can we reduce the radiation exposure burden?",
        "gt": "Renal MDCT angiography and stent-restenosis assessment are feasible at 100 kVp with minor loss of image quality and almost half radiation exposure.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It is still unclear whether the inlay thickness is an important factor influencing the fracture risk of ceramic inlays. As high tensile stresses increase the fracture risk of ceramic inlays, the objective of the present finite element method (FEM) study was to biomechanically analyze the correlation between inlay thickness (T) and the induced first principal stress. Fourteen ceramic inlay models with varying thickness (0.7-2.0 mm) were generated. All inlays were combined with a CAD model of a first mandibular molar (tooth 46), including the PDL and a mandibular segment which was created by means of the CT data of an anatomical specimen. Two materials were defined for the ceramic inlays (e.max(\u00ae) or empress(\u00ae)) and an occlusal force of 100 N was applied. The first principal stress was measured within each inlay and the peak values were considered and statistically analyzed. The stress medians ranged from 20.7 to 22.1 MPa in e.max(\u00ae) and from 27.6 to 29.2 MPa in empress(\u00ae) inlays. A relevant correlation between the first principal stress and thickness (T) could not be detected, neither for e.max(\u00ae) (Spearman: r=0.028, p=0.001), nor for empress(\u00ae) (Spearman: r=0.010, p=0.221). In contrast, a very significant difference (p<0.001) between the two inlay materials (M) was verified.\nQuestion: Ceramic inlays: is the inlay thickness an important factor influencing the fracture risk?",
        "gt": "Under the conditions of the present FEM study, the inlay thickness does not seem to be an important factor influencing the fracture risk of ceramic inlays. However, further studies are necessary to confirm this.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Reactive oxygen species have been shown to be initiators/promotors of tumorigenesis. Because evidence supports the role of increased oxidative stress in solid tumors, we sought to establish this relationship in neuroblastoma (NB). The aim of the study was to investigate the extent of oxidative DNA damage and antioxidative status in a progressive animal model of human NB. Tumors were induced in the left kidneys of nude mice by the injection of cultured human NB cells (10(6)). Blood was collected from tumor-bearing mice and controls at 2, 4, and 6 weeks. Peripheral blood leukocyte oxidative DNA damage was determined using single-cell gel electrophoresis (comet assay), and plasma antioxidant capacity was assessed by the Trolox equivalent antioxidant capacity method. Levels of oxidative DNA damage in peripheral blood leukocytes of NB-bearing mice were increased by 166%, 110%, and 87% as compared with healthy controls at 2, 4, and 6 weeks, respectively. Plasma total antioxidant values for tumor-bearing mice were not significantly different from control mice.\nQuestion: Oxidative status in neuroblastoma: a source of stress?",
        "gt": "Our results indicate an increase of oxidative stress in an animal model of human NB, especially in the early stages of growth. Yet, we did not observe an appreciable response in plasma antioxidant activity. Because an altered redox status has been implicated in tumor maintenance and progression, these findings support the notion of a complex oxidant-antioxidant imbalance contributing to NB growth.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The authors reviewed their institutional experience with pure low-grade oligodendroglioma (LGO), correlating outcomes with several variables of possible prognostic values. Sixty-nine patients with WHO-classified LGOs were treated between 1992 and 2006 at the McGill University Health Center. Clinical, pathological, and radiological records were carefully reviewed. Demographic characteristics; the nature and duration of presenting symptoms; baseline neurological function; extent of resection; Karnofsky Performance Scale score; preoperative radiological findings including tumor size, location, and absence/presence of enhancement; and pathological data including chromosome arms 1p/19q codeletion and O-methylguanine-DNA methyltransferase promoter gene methylation status were all compiled. The timing and dose of radio- and/or chemotherapy, date of tumor progression, pathological finding at disease progression, treatment at time of disease progression, and status at the last follow-up were also recorded. The median follow-up period was 6.1 years (range 1.3-16.3 years). The majority (78%) of patients presented with seizures; contrast enhancement was initially seen in 16 patients (25%). All patients had undergone an initial surgical procedure: gross-total resection in 27%, partial resection in 59%, and biopsy only in the remaining 13%. Fifteen patients received adjuvant radiotherapy. Data on O-methylguanine-DNA methyltransferase promoter gene methylation status was available in 47 patients (68%) and in all but 1 patient for 1p/19q status. Survival at 5, 10, and 15 years was 83, 63, and 29%, respectively. Multivariate analysis showed that seizures at presentation and the absence of contrast enhancement were the only independent favorable prognostic factors for survival. The 5-, 10-, and 15-year progression-free survival rates were 46, 7.7, and 0%, respectively.\nQuestion: Low-grade oligodendroglioma: an indolent but incurable disease?",
        "gt": "This retrospective review confirms the indolent but progressively fatal nature of LGOs. Contrast enhancement was the most evident single prognostic factor. New treatment strategies are clearly needed in the management of this disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Fibromyalgia (FM) is a form of non-articular rheumatism characterised by chronic widespread musculoskeletal aching. Although some works have investigated the possible role of oxidative stress in the pathophysiology of FM, none has analysed a significant number of oxidative markers in the same patients. Consequently, we have performed an exhaustive study of the oxidative/antioxidative status in FM patients and healthy controls, as well as the relationship with FM clinical parameters. In 45 female patients and 25 age-matched controls, we investigated the oxidative (lipid and protein peroxidation, and oxidative DNA damage) and antioxidative status (total antioxidant capacity (TAC), and antioxidant enzyme activities and compounds). Functional capacity and musculoskeletal pain were assessed by Fibromyalgia Impact Questionnaire (FIQ) and Visual Analogue Scale (VAS), respectively. The physical (PCS-12) and mental (MCS-12) health status was evaluated by SF-12. A significant increase in oxidative DNA damage and protein carbonyl content was found in FM patients vs. controls, as well as in antioxidant compounds such as copper and ceruloplasmin. Patients had diminished levels of TAC and zinc. Enzyme activities of superoxide dismutase, glutathione peroxidase, and catalase were lower in FM patients. Significant correlations were observed in patients between oxidative DNA damage and MCS-12, and zinc and PCS-12.\nQuestion: Is fibromyalgia-related oxidative stress implicated in the decline of physical and mental health status?",
        "gt": "These findings reveal an imbalance between oxidants and antioxidants in FM patients. The lower antioxidant enzyme activities may lead to oxidative stress through the oxidation of DNA and proteins, which may affect the health status of FM patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study was designed to determine whether digital intubation is a valid option for definitive airway control by emergency physicians. Digital intubation was performed by 18 emergency medicine residents and 4 staff emergency medicine physicians on 6 different cadavers. Placement was confirmed by direct laryngoscopy. The total time for all attempts used, as well as the number of attempts, was recorded. Each participant attempted intubation on all 6 cadavers. For 5 of the 6 cadavers, successful intubation occurred 90.9% of the time (confidence interval [CI], 85.5%-96.3%) for all participants. The average number of attempts for these 5 cadavers was 1.5 (CI, 1.4-1.7), and the average time required for success or failure was 20.8 seconds (CI, 16.9-24.8). The sixth cadaver developed soft tissue damage and a false passage near the vocal cords resulting in multiple failed attempts.\nQuestion: Is digital intubation an option for emergency physicians in definitive airway management?",
        "gt": "Although the gold standard for routine endotracheal intubation remains to be direct laryngoscopy, its effectiveness in certain situations may be limited. We believe that digital intubation provides emergency physicians with another option in securing the unprotected airway.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the relationship between hospital admissions for falls and hip fracture in elderly people and area characteristics such as socio-economic deprivation. Ecological study of routinely collected hospital admissions data for falls and hip fracture in people aged 75 years or over for 1992-1997, linked at electoral ward level with characteristics from census data. In total, 42,293 and 17,390 admissions were identified for falls and hip fracture, respectively, from 858 electoral wards in Trent. Rate ratios (RRs) for hospital admissions for falls and hip fracture were calculated by the electoral wards' Townsend score divided by quintiles. RRs were estimated by negative binomial regression and adjusted for the ward characteristics of age, gender, ethnicity, rurality, proportion of elderly people living alone and distance from hospital. There was a small but statistically significant association at electoral ward level between hospital admissions for falls and the Townsend score, with the most deprived wards having a 10% higher admission rate for falls compared with the most affluent wards (adjusted RR 1.10, 95% CI 1.01-1.19). No association was found between hospital admission for hip fracture and deprivation (adjusted RR 1.05, 95% CI 0.95-1.16).\nQuestion: Do rates of hospital admission for falls and hip fracture in elderly people vary by socio-economic status?",
        "gt": "There is some evidence of an association at electoral ward level between hospital admissions for falls and socio-economic deprivation, with higher rates in deprived areas. No such association was found for hip fracture. Further work is required to assess the impact of interventions on reducing inequalities in hospital admission rates for falls in elderly people.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Carotid angioplasty and stenting has been proposed as a treatment option for carotid occlusive disease in patients at high risk, including those 80 years of age or older or with contralateral carotid occlusion. We analyzed 30-day mortality and stroke risk rates of carotid endarterectomy (CEA) in patients aged 80 years or older with concurrent carotid occlusive disease. From a retrospective review of 1000 patients undergoing 1150 CEA procedures to treat symptomatic and asymptomatic carotid lesions over 13 years, we identified 54 patients (5.4%) aged 80 years or older with concurrent contralateral carotid occlusion. These patients were compared with 38 patients (3.8%) aged 80 years or older with normal or diseased patent contralateral carotid artery and 81 patients (8.1%) younger than 80 years with contralateral carotid occlusion. All CEA procedures involved either standard CEA with patching or eversion CEA, and were performed by the same surgeon, with the patients under deep general anesthesia and cerebral protection involving continuous perioperative electroencephalographic monitoring for selective shunting. Shunting criteria were based exclusively on electroencephalographic abnormalities consistent with cerebral ischemia. The 30-day mortality and stroke rate in patients aged 80 years or older with concurrent contralateral carotid occlusion was zero.\nQuestion: Octogenarians with contralateral carotid artery occlusion: a cohort at higher risk for carotid endarterectomy?",
        "gt": "The concept of high-risk CEA needs to be revisited. Patients with two of the criteria considered high risk in the medical literature, that is, age 80 years or older and contralateral carotid occlusion, can undergo CEA with no greater risks or complications. Until prospective randomized trials designed to evaluate the role of carotid angioplasty and stenting have been completed, CEA should remain the standard treatment in such patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Defocus curves are used to evaluate the subjective range of clear vision of presbyopic corrections such as in eyes implanted with accommodating intraocular lenses (IOLs). This study determines whether letter sequences and/or lens presentation order ought to be randomised when measuring defocus curves. Defocus curves (range +2.00DS to -2.00DS) were measured on 18 pre-presbyopic subjects (mean age 24.1+/-4.2 years) for six combinations of sequential or randomised positive or negative lens progression and non-randomised or randomised letter sequences. The letters were presented on a computerised logMAR chart at 6m. Overall there was a statistically significant difference between the six combinations (ANOVA, p<0.05) attributable to the combination of non-randomised letters with non-randomised lens progression from negative to positive defocus (p<0.01). There was no statistically significant difference in defocus curve measurements if both letters and lens order were randomised compared to if only one of these variables was randomised (p>0.05). Non-randomised letters, with a sequential lens progression from negative to positive, was significantly different to all other combinations when compared individually (Student's T-test, p<0.003 on all comparisons), and was confirmed as the sole source of the overall significant difference. There was no statistically significant difference if both lens presentation order and letter sequences were randomised compared to if only one or the other of these variables was randomised.\nQuestion: Is randomisation necessary for measuring defocus curves in pre-presbyopes?",
        "gt": "Non-randomised letters and non-randomised lens progression on their own did not affect the subjective amplitude of accommodation as measured by defocus curves, although their combination should be avoided.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patient recruitment into clinical trials is a major challenge, and the elderly, socially deprived and those with multiple comorbidities are often underrepresented. The idea of paying patients an incentive to participate in research is controversial, and evidence is needed to evaluate this as a recruitment strategy. In this study, we sought to assess the impact on clinical trial recruitment of a \u00a3100 incentive payment and whether the offer of this payment attracted more elderly and socially deprived patients. A total of 1,015 potential patients for five clinical trials (SCOT, FAST and PATHWAY 1, 2 and 3) were randomised to receive either a standard trial invitation letter or a trial invitation letter containing an incentive offer of \u00a3100. To receive payment, patients had to attend a screening visit and consent to be screened (that is, sign a consent form). To maintain equality, eventually all patients who signed a consent form were paid \u00a3100. The \u00a3100 incentive offer increased positive response to the first invitation letter from 24.7% to 31.6%, an increase of 6.9% (P\u2009<\u20090.05). The incentive offer increased the number of patients signing a consent form by 5.1% (P\u2009<\u20090.05). The mean age of patients who responded positively to the invitation letter was 66.5\u2009\u00b1\u20098.7 years, whereas those who responded negatively were significantly older, with a mean age of 68.9\u2009\u00b1\u20099.0 years. The incentive offer did not influence the age of patients responding. The incentive offer did not improve response in the most socially deprived areas, and the response from patients in these areas was significantly lower overall.\nQuestion: Does offering an incentive payment improve recruitment to clinical trials and increase the proportion of socially deprived and elderly participants?",
        "gt": "A \u00a3100 incentive payment offer led to small but significant improvements in both patient response to a clinical trial invitation letter and in the number of patients who consented to be screened. The incentive payment did not attract elderly or more socially deprived patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Using administrative data (Truven MarketScan\u00ae Research Databases), patients diagnosed with T2DM between 2007 and 2014 with \u2a7e6months continuous enrolment pre- and post-diagnosis were evaluated. Pretreatment was defined as OAD use at least 3months prior to T2DM diagnosis. Time-to-insulin initiation and healthcare costs were compared by OAD pretreatment status. Of the 866,605 patients studied, 241,856 (27.9%) were pretreated prior to T2DM diagnosis. Mean follow-up was 2.9years for pretreatment and 3.1years for those without pretreatment. Monthly diabetes-related pharmacy costs were significantly higher among pretreated patients ($66 versus $36, p<0.0001), as were overall monthly pharmacy costs ($255 versus $198, p<0.0001). Pretreated patients had lower mean monthly costs, both total ($625 versus $671, p<0.0001) and diabetes-related ($207 versus $214, p=0.0012). After multivariable adjustment, mean monthly diabetes-related total healthcare costs were higher among pretreated patients (+$60) but total all-cause monthly healthcare costs were significantly lower (-$354) (both p<0.05). Pretreatment was associated with a lower insulin initiation probability for 2years, after which probability was similar; the adjusted hazard ratio for pretreatment in a time-to-insulin model was 0.96 (95% CI, 0.94-0.97).\nQuestion: Evaluation of patients with type 2 diabetes mellitus receiving treatment during the pre-diabetes period: Is early treatment associated with improved outcomes?",
        "gt": "Pretreatment with OADs is associated with a modest delay in initiating insulin therapy and lower total healthcare costs. The clinical and pharmacoeconomic benefits of pretreatment should be elucidated in a prospective study.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To identify patients with ureteropelvic junction (UPJ) obstruction who will benefit from endoscopic Acucise incision of the stenosis and to compare the open Hynes-Anderson pyeloplasty with this minimally invasive technique. In a prospective trial, 22 patients with primary and secondary UPJ obstruction were treated by Acucise endopyelotomy, and 18 patients were treated by Hynes-Anderson pyeloplasty. Preoperative and postoperative renal scans were used to determine the degree of obstruction and intravenous urography, ultrasound scanning, or both to assess the degree of dilation. There was a vast difference in the cure rate of the two groups: Hynes-Anderson pyeloplasty cured 94.5% of the patients, while in the Acucise group, the cure rate was only 32%. There was some improvement in another 22% of the patients, but the renal scan curve remained obstructed. The remaining 45% of patients failed to show any improvement.\nQuestion: Retrograde acucise endopyelotomy: is it worth its cost?",
        "gt": "Acucise endopyelotomy will improve or cure only patients with good renal function and mild dilation of the pelvicaliceal system. Patients with severe dilation should be treated by Hynes-Anderson pyeloplasty.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: An increased platelet activation status is present in patients with preeclampsia. Our purpose was (1) to establish by means of flow cytometry whether platelets circulate in an activated state during the first and second trimesters of pregnancy and (2) to establish whether early platelet activation predicts the onset of preeclampsia. Consecutively, 244 pregnant women were included in a prospective study design. Platelets in whole blood samples from the pregnant women in the first trimester, the second trimester, and after delivery were labeled with the following antibodies associated with platelet activation: anti-CD62P (P-selectin, alpha-granule secretion), anti-CD63 (GP53, lysosomal secretion), anti-CD31 (GPIIa', platelet endothelial cell adhesion molecule-1). The surface antigen exposure was determined by double-label flow cytometry with anti-CD42b (GPIb, a platelet-specific monoclonal glycoprotein) to select platelets and platelet-derived materials. Preeclampsia was defined as a diastolic blood pressure>or = 90 mm Hg and proteinuria>or = 0.3 gm in a 24-hour urine sample (International Society for Study of Hypertension in Pregnancy criteria). Seventeen of 244 patients had preeclampsia (6.9%). Only first-trimester CD63 expression had an area under the curve>0.5 by receiver-operator characteristic curve analysis and was selected as a possible predictor of preeclampsia. We found a sensitivity of 47% and a specificity of 76% with use of a percentage of activated platelets above 2% as a positive test. Likelihood ratios were 1.94 for positive likelihood and 0.69 for negative likelihood. Univariate logistic regression analysis results were odds ratio 2.8 (95% confidence interval 1.0 to 7.6). Multivariate logistic regression analysis results were odds ratio 2.9 (95% confidence interval 0.92 to 8.9). However, the odds ratio of first antenatal diastolic blood pressure was two to four times higher than the odds ratio of first-trimester CD63 expression. The combination of first-trimester CD63 and first antenatal diastolic blood pressure increases the positive likelihood ratio from 1.94 to 9.4, with a sensitivity of 41%, a specificity of 96%, and a negative likelihood ratio of 0.62.\nQuestion: Can flow cytometric detection of platelet activation early in pregnancy predict the occurrence of preeclampsia?",
        "gt": "Increased first-trimester CD63 expression is an independent risk factor for development of preeclampsia. CD63 expression might be useful to identify a subgroup of patients with a high risk for development of preeclampsia, especially in combination with first-trimester antenatal diastolic blood pressure. This method of patient selection may enable more efficient intervention studies in patients at risk than do the selection methods used so far.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study was to compare the types of therapeutic neck dissection in patients with differentiated thyroid carcinoma. Sixty-one patients with lymph node metastasis in the neck, treated between 1997 and 2001, were studied retrospectively. A comparative study was made of a selective lateral neck dissection group and a radical or modified radical neck dissection group for recurrence, disease free survival (DFS), and overall survival (OS). Type of dissection was not related to DFS (P=0.92), OS (P=0.33), and local recurrence ratio (P=0.56). The factors affecting local recurrence were the age over 45 years (P=0.02), tumor size (0.005), and the presence of distant metastasis (P=0.04). The factors affecting DFS and OS were tumor size (0.003), thyroid capsule invasion (0.004).\nQuestion: Is the type of dissection in lateral neck metastasis for differentiated thyroid carcinoma important?",
        "gt": "Determination of the type of therapeutic neck dissection depends on patient and tumor characteristics. Selective lateral neck dissection can be applied safely in selected cases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The lean phenotype of cystathionine beta-synthase-deficient homocystinuria and the positive association of plasma total cysteine (tCys) with body mass index (BMI) suggest that total homocysteine (tHcy) and tCys are associated with body composition. We aimed to study associations of tCys and tHcy with body composition in the general population. Using data from 7038 Hordaland Homocysteine Study participants, we fitted regression models and dose-response curves of tCys and tHcy with BMI. In 5179 participants, we investigated associations of tCys and tHcy with fat mass and lean mass and examined whether changes in these aminothiols predicted body composition 6 y later. tCys showed positive associations with BMI (partial r = 0.28, P<0.001), and fat mass (partial r = 0.25, P<0.001), independent of diet, exercise, and plasma lipids. Women in the highest tCys quintile had fat mass 9 kg (95% CI: 8, 10 kg; P<0.001) greater than that of women in the lowest quintile. The corresponding values for men were 6 kg (95% CI: 5, 7 kg; P<0.001; P<0.001 in both sexes, ANOVA across quintiles). The rise in tCys over 6 y was associated with greater fat mass at follow-up (P<0.001), but there was no effect on lean mass. tHcy was not associated with lean mass, and it became significantly inversely associated with BMI and fat mass only after adjustment for tCys. The association between tHcy and lean mass was not significant.\nQuestion: Homocysteine, cysteine, and body composition in the Hordaland Homocysteine Study: does cysteine link amino acid and lipid metabolism?",
        "gt": "tCys concentrations show a strong positive association with BMI, mediated through fat mass. The link between cysteine and lipid metabolism deserves further investigation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In cardiac hypertrophy, ECG T-wave changes imply an abnormal sequence of ventricular repolarization. We investigated the hypothesis that this is due to changes in the normal regional differences in action potential duration. We assessed the contribution of potassium- and calcium-dependent currents to these differences. Both the altered sequence of ventricular repolarization and the underlying cellular mechanisms may contribute to the increased incidence of ventricular arrhythmias in hypertrophy. Rats received daily isoproterenol injections for 7 days. Myocytes were isolated from basal subendocardial (endo), basal midmyocardial (mid), and apical subepicardial (epi) regions of the left ventricular free wall. Action potentials were stimulated with patch pipettes at 37 degrees C. The ratio of heart weight to body weight and mean cell capacitance are increased by 22% and 18%, respectively, in hypertrophy compared with controls (P<.001). Normal regional differences in action potential duration at 25% repolarization (APD25) are reduced in hypertrophy (control: endo, 11.4+/-0.9 ms; mid, 8.2+/-0.9 ms; epi, 5.1+/-0.4 ms; hypertrophy: endo, 11.6+/-0.9 ms; mid, 10.4+/-0.8 ms; epi, 7.8+/-0.6 ms). The regional differences in APD25 are still present in 3 mmol/L 4-aminopyridine. Hypertrophy affects APD75 differently, depending on the region of origin of myocytes (ANOVA P<.05). APD75 is shortened in subendocardial myocytes but is prolonged in subepicardial myocytes (control: endo, 126+/-7 ms; epi, 96+/-10 ms; hypertrophy: endo, 91+/-6 ms; epi, 108+/-7 ms). These changes in APD75 are altered by intracellular calcium buffering.\nQuestion: Effects of hypertrophy on regional action potential characteristics in the rat left ventricle: a cellular basis for T-wave inversion?",
        "gt": "Normal regional differences in APD and the changes observed in hypertrophy are only partially explained by differences in I(tol). In hypertrophy, the normal endocardial/epicardial gradient in APD75 appears to be reversed. This may explain the T-wave inversion observed and will have implications for arrhythmogenesis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The effect on resident behaviors of adding a wander garden to an existing dementia facility was investigated. 34 male residents were observed for 12 months before and after opening the garden. Behaviors were assessed using the Cohen-Mansfield Agitation Inventory Short Form (CMAI), incident reports, as needed medications (pro re nata [PRN]), and surveys of staff and residents' family members as indices of affect. Final CMAI scores and total PRNs employed were lower than baseline values with a trend for residents who used the garden more often to have less agitated behavior. Verbal inappropriate behaviors did not change significantly whereas physical incidents increased. Staff and family members felt that the wander garden decreased inappropriate behaviors and improved mood and quality of life of the dementia residents.\nQuestion: Does a wander garden influence inappropriate behaviors in dementia residents?",
        "gt": "Study design characteristics and garden management may have affected behaviors both positively and negatively. Additional studies are needed to explore the benefits of wander gardens for dementia residents.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Research on \u03b2-cell autoimmunity in cystic fibrosis (CF)-related diabetes (CFRD) is still rare. We aimed to analyze the frequency of \u03b2-cell autoimmunity and the influence on age at diabetes onset, insulin requirement, type of insulin therapy, and hypoglycemic or ketoacidotic events in patients with CFRD compared with antibody-negative patients with CFRD in the Diabetes Patienten Verlaufsdokumentation (DPV) registry. We analyzed data of 837 patients with CFRD in the German/Austrian DPV database by multivariable mixed-regression modeling. In our cohort, 8.5% of patients with CFRD (n = 72) were found to be \u03b2-cell antibody positive. There was a female preponderance in this patient group: 65.3 vs. 57.6%. Diabetes onset (median [interquartile range]) was earlier (14.00 [10.15-15.90]vs. 16.10 [13.50-21.20] years; P<0.005), and insulin dose/kg body weight was higher (0.95 [0.61-1.15] vs. 0.67 [0.33-1.04]IU/kg; P<0.05). There were also differences in the type of insulin treatment. Insulin pump therapy was used significantly more often in patients with CFRD with \u03b2-cell autoimmunity (18.2 vs. 6.4%; P<0.05). The differences for multiple daily injections (ICT) and conventional therapy (CT) were not significant (ICT: 67.7 vs. 79.0%; CT: 15.2 vs. 14.6). Oral antidiabetic agents were rarely used in both groups. Rate of severe hypoglycemia with coma and rate of ketoacidosis were higher in antibody-positive patients (hypoglycemia with coma: 8.0 vs. 1.4, P<0.05; ketoacidosis: 9.3 vs. 0.9, P<0.05).\nQuestion: Does \u03b2-Cell Autoimmunity Play a Role in Cystic Fibrosis-Related Diabetes?",
        "gt": "Presence of \u03b2-cell autoantibodies in our cohort of patients with CFRD (8.5%) appeared to be greater than in the general population and was associated with female sex, earlier onset of diabetes, and higher insulin requirement. Insulin pump therapy was used significantly more often in patients with \u03b2-cell antibodies. Severe hypoglycemia and ketoacidosis were significantly more frequent in CFRD with \u03b2-cell autoimmunity compared with \u03b2-cell antibody-negative patients with CFRD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Neoadjuvant chemoradiation for rectal cancers may result in complete clinical response (cCR) in some patients. The aim of this study was to analyze the long-term outcomes of such patients in a tertiary cancer center. Patients with rectal cancer who had a cCR to neoadjuvant chemoradiation were divided into two groups: Group A (n=23) did not undergo surgery, and Group B (n=10) underwent elective surgery. The recurrence patterns and survival outcomes were compared between the two groups. After a median follow-up of 72 months (range 12-180), seven patients (30%) in Group A developed an isolated local recurrence. In Group B, after a median follow-up of 37 months (range 12-180) there were no local recurrences. The median disease-free and overall survival was 36 months (range 6-168) and 66 months (range 12-180) in Group A and 36 months (range 12-180) and 37 months (range 18-180) in Group B respectively.\nQuestion: Complete clinical response to neoadjuvant chemoradiation in rectal cancers: can surgery be avoided?",
        "gt": "Our results suggest that surgery could be avoided in selected patients with rectal cancer who have a cCR to neoadjuvant chemoradiation. However, until the safety of a non-surgical approach is proven in a prospective randomized trial, it cannot be recommended outside a clinical protocol study.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Some studies suggest that epidural analgesia prolongs labor and increases the incidence of cesarean section, especially if it is administered before 5 cm cervical dilation. The purpose of the current study was to determine whether early administration of epidural analgesia affects obstetric outcome in nulliparous women who are in spontaneous labor. Informed consent was obtained from 344 healthy nulliparous women with a singleton fetus in a vertex presentation, who requested epidural analgesia during spontaneous labor at at least 36 weeks' gestation. Each patient was randomized to receive either early or late epidural analgesia. Randomization occurred only after the following conditions were met: (1) the patient requested pain relief at that moment, (2) a lumbar epidural catheter had been placed, and (3) the cervix was at least 3 cm but less than 5 cm dilated. Patients in the early group immediately received epidural bupivacaine analgesia. Patients in the late group received 10 mg nalbuphine intravenously. Late-group patients did not receive epidural analgesia until they achieved a cervical dilation of at least 5 cm or until at least 1 h had elapsed after a second dose of nalbuphine. Ten of the 344 patients were excluded because of a protocol violation or voluntary withdrawal from the study. Early administration of epidural analgesia did not increase the incidence of oxytocin augmentation, prolong the interval between randomization and the diagnosis of complete cervical dilation, or increase the incidence of malposition of the vertex at delivery. Also, early administration of epidural analgesia did not result in an increased incidence of cesarean section or instrumental vaginal delivery. Seventeen (10%) of 172 women in the early group and 13 (8%) of 162 women in the late group underwent cesarean section (relative risk for the early group 1.22; 95% confidence interval 0.62-2.40). Patients in the early group had lower pain scores between 30 and 150 min after randomization. Infants in the late group had lower umbilical arterial and venous blood pH and higher umbilical venous blood carbon dioxide tension measurements at delivery.\nQuestion: Does early administration of epidural analgesia affect obstetric outcome in nulliparous women who are in spontaneous labor?",
        "gt": "Early administration of epidural analgesia did not prolong labor, increase the incidence of oxytocin augmentation, or increase the incidence of operative delivery, when compared with intravenous nalbuphine followed by late administration of epidural analgesia, in nulliparous women who were in spontaneous labor at term.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Health care-associated infections (HAI) result in 100,000 deaths/year. Alcohol use disorders (AUD) increase the risk of community-acquired infections and HAI. Small studies have shown that AUD increase the risk of HAI and surgical site infections (SSI). We sought to determine the risk of HAI and SSI in surgical patients undergoing elective inpatient joint replacement, coronary artery bypass grafting, laparoscopic cholecystectomy, colectomy, and hernia repair. The Nationwide Inpatient Sample was analyzed (years 2007 and 2008). HAI were defined as health care-associated pneumonia, sepsis, SSI, and urinary tract infection. Primary outcomes were risk of HAI and SSI in patients with AUD. Secondary outcomes were mortality and hospital length of stay in patients with HAI and SSI, alpha = 10(-6). There were 1,275,034 inpatient admissions analyzed; 38,335 (3.0%) cases of HAI were documented, and 5,756 (0.5%) cases of SSI were identified. AUD was diagnosed in 11,640 (0.9%) of cases. Multivariable analysis demonstrated that AUD was an independent predictor of developing HAI: odds ratio (OR) 1.70, p<10(-6), and this risk was independent of type of surgery. By multivariable analysis, the risk of SSI in patients with AUD was also higher: OR 2.73, p<10(-6). Hospital mortality in patients with HAI or SSI was not affected by AUD. However, hospital length of stay was longer in patients with HAI who had AUD (multivariable analysis 2.4 days longer, p<10(-6)). Among patients with SSI, those with AUD did not have longer hospital length of stay.\nQuestion: Health care-associated infections in surgical patients undergoing elective surgery: are alcohol use disorders a risk factor?",
        "gt": "Patients with AUD who undergo a variety of elective operations have an increased risk of infectious postoperative morbidity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Recently there has been growing interest in how neighbourhood features, such as the provision of local facilities and amenities, influence residents' health and well-being. Prior research has measured amenity provision through subjective measures (surveying residents' perceptions) or objective (GIS mapping of distance) methods. The latter may provide a more accurate measure of physical access, but residents may not use local amenities if they do not perceive them as 'local'. We believe both subjective and objective measures should be explored, and use West Central Scotland data to investigate correspondence between residents' subjective assessments of how well-placed they are for everyday amenities (food stores, primary and secondary schools, libraries, pharmacies, public recreation), and objective GIS-modelled measures, and examine correspondence by various sub-groups. ArcMap was used to map the postal locations of 'Transport, Health and Well-being 2010 Study' respondents (n = 1760), and the six amenities, and the presence/absence of each of them within various straight-line and network buffers around respondents' homes was recorded. SPSS was used to investigate whether objective presence of an amenity within a specified buffer was perceived by a respondent as being well-placed for that amenity. Kappa statistics were used to test agreement between measures for all respondents, and by sex, age, social class, area deprivation, car ownership, dog ownership, walking in the local area, and years lived in current home. In general, there was poor agreement (Kappa<0.20) between perceptions of being well-placed for each facility and objective presence, within 800 m and 1000 m straight-line and network buffers, with the exception of pharmacies (at 1000 m straight-line) (Kappa: 0.21). Results varied between respondent sub-groups, with some showing better agreement than others. Amongst sub-groups, at 800 m straight-line buffers, the highest correspondence between subjective and objective measures was for pharmacies and primary schools, and at 1000 m, for pharmacies, primary schools and libraries. For road network buffers under 1000 m, agreement was generally poor.\nQuestion: Do residents' perceptions of being well-placed and objective presence of local amenities match?",
        "gt": "Respondents did not necessarily regard themselves as well-placed for specific amenities when these amenities were present within specified boundaries around their homes, with some exceptions; the picture is not clear-cut with varying findings between different amenities, buffers, and sub-groups.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The discrepancy between high rates of sensitivity, specificity, and accuracy for intraductal ultrasonography (IDUS) in extrahepatic bile duct carcinoma and the failure to depict different wall layers as defined by the TNM classification have not yet been elucidated sufficiently. In a prospective study, endosonographic images were correlated with histomorphology including immunohistochemistry. Using IDUS, we examined fresh resection specimens of patients who had undergone pancreato-duodenectomy. For histological analysis, the formalin-fixed and paraffin-embedded specimens were stained by hematoxylin-eosin, elastica-van-Gieson, and immunohistochemically by smooth muscle-actin. To confirm our hypothesis, further cases from the archives were analyzed histopathologically and immunohistochemically. The various wall layers of the extrahepatic bile duct as described by the International Union Against Cancer are neither histomorphologically nor immunohistochemically consistently demonstrable. Especially, a clear differentiation between tumor invasion beyond the wall of the bile duct (T2) and invasion of the pancreas (T3) by histopathological means is often not possible. Endosonographic images using high-resolution miniprobes similarly confirm the difficulty in imaging various layers in the bile duct wall.\nQuestion: Endosonographic and histopathological staging of extrahepatic bile duct cancer: time to leave the present TNM-classification?",
        "gt": "Most adaptations made by the sixth edition of the TNM classification accommodate to the endosonographic and most of the histopathological findings as demonstrated in our study. In contrast to the new edition, however, our findings suggest to combine T2- and T3-staged tumors into one single class leading to clarification, and improved reproducibility of histopathological staging.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Previous studies reporting the impact of osteoarthritis (OA) on pain and function after hip arthroscopy largely predate resection of femoroacetabular impingement (FAI).QUESTIONS/ We determined (1) functional improvement after resection of FAI impingement lesions in patients with preoperative radiographic joint space narrowing, and (2) identified preoperative predictors of pain, function, and failure rates in these patients. Between September 2004 and April 2008, we treated 210 patients (227 hips) with FAI and a minimum 12-month followup (mean, 27 months). Group FAI consisted of 154 patients (169 hips) without radiographic joint space narrowing, whereas Group FAI-OA consisted of 56 patients (58 hips) with preoperative radiographic joint space narrowing. We collected Harris hip scores (HHS), Short Form-12 (SF-12), and pain scores on a visual analog scale (VAS) preoperatively and postoperatively. Score improvements were better for Group FAI compared with Group FAI-OA. The overall failure rate was greater for Group FAI-OA (52%) than for Group FAI (12%). Although patients with less than 50% joint space narrowing or greater than 2 mm joint space remaining on preoperative radiographs had improved scores throughout the study, we observed no score improvements at any time with advanced preoperative joint space narrowing. Greater joint space narrowing, advanced MRI chondral grade, and longer duration of preoperative symptoms predicted lower scores.\nQuestion: Does arthroscopic FAI correction improve function with radiographic arthritis?",
        "gt": "FAI correction with milder degrees of preoperative radiographic joint space narrowing resulted in improvements in pain and function at short-term followup. Patients with advanced radiographic joint space narrowing do not improve and we believe should not be considered for arthroscopic FAI correction.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although observational studies suggest that inflammatory markers are associated with autonomic nervous system function, the causal relationship of this is not clear. We tested the hypothesis that acute inflammation will temporarily attenuate vagal reactivation as measured by heart rate recovery after exercise. In this double-blind randomized study, 24 healthy subjects were assigned to receive either an influenza vaccine (n = 15) as a model to generate a systemic inflammatory response or a sham vaccine (n = 9). Heart rate recovery after exercise testing was used as an index of parasympathetic nervous function and was calculated as the difference between maximal heart rate during the test and heart rate 1 and 2 min after cessation of exercise. Both blood analysis and treadmill exercise stress tests were conducted before and 48 h after each vaccination. Inflammatory marker, log C-reactive protein (1.9 +/- 1.2 to 2.8 +/- 1.4, p<0.05) was significantly increased after the influenza vaccine. Heart rate recovery 1 was significantly attenuated 48 h after the influenza vaccination (23.4 +/- 6.4 to 20.5 +/- 4.9, p<0.05) but not sham vaccination.\nQuestion: Does an acute inflammatory response temporarily attenuate parasympathetic reactivation?",
        "gt": "These findings show that acute inflammation is associated with a temporary deterioration in cardiac autonomic nervous system function in healthy subjects.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cardiovascular fitness (VO(2max)) and physical activity are both related to risk of metabolic disease. It is unclear, however, whether the metabolic effects of sedentary living are the same in fit and unfit individuals. The purpose of this study was, therefore, to describe the association between physical activity and the metabolic syndrome and to test whether fitness level modifies this relationship. Physical activity was measured objectively using individually calibrated heart rate against energy expenditure. VO(2max) was predicted from a submaximal exercise stress test. Fat mass and fat-free mass (FFM) were calculated using impedance biometry. A metabolic syndrome score was computed by summing the standardized values for obesity, hypertension, hyperglycemia, insulin resistance, hypertriglyceridemia, and the inverse level of HDL cholesterol and was expressed as a continuously distributed outcome. To correct for exposure measurement error, a random subsample (22% of cohort) re-attended for three repeat measurements in the year following the first assessment. The relationship of VO(2max) (ml O2.kg(FFM)(-1).min(-1)) and the metabolic syndrome score was of borderline significance after adjusting for age, sex, physical activity, and measurement error (beta = -0.58, P = 0.06). The magnitude of the association between physical activity (kJ.d(-1).kg(FFM)(-1)) and the metabolic syndrome was more than three times greater than for VO(2max) (standardized beta = -1.83, P = 0.0042). VO(2max), however, modified the relationship between physical activity energy expenditure and metabolic syndrome (P = 0.036).\nQuestion: Does the association of habitual physical activity with the metabolic syndrome differ by level of cardiorespiratory fitness?",
        "gt": "This study demonstrates a strong inverse association between physical activity and metabolic syndrome, an association that is much steeper in unfit individuals. Thus, prevention of metabolic disease may be most effective in the subset of unfit inactive people.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Reports on the specificity of breast MRI are heterogeneous, depending on the respective setting of the performed study. To retrospectively estimate the sensitivity and especially the specificity of breast MRI in the non-screening setting as an adjunct to mammography sorted by breast density and to estimate the accuracy of breast MRI in cases rated BI-RADS 0 and 3 mammographically. A total of 216 consecutive patients with referral to breast MRI and previously acquired mammography were enrolled in this analysis. Negative findings were followed up with a mean time of 26.7 months. The loss to follow-up was 10.8%. The single breast was regarded as the study subject (n=399, 364 cases were eligible for calculation of diagnostic accuracy). BI-RADS 1 and 2 were rated as benign, 4 and 5 as malignant. BI-RADS 0 and 3 were analyzed separately. The 95% confidence intervals (CIs) were calculated from the normally approximated binomial distribution and taken to represent significant differences for the two imaging modalities if they did not overlap. Among the study population, 62 malignant neoplasms were detected. For cases rated BI-RADS 1, 2, 4, and 5 (n=251), the sensitivity of breast MRI was 95.7% (95% CI 89.9-100.0%) and 74.5% (95% CI 62.0-87.0%) for mammography, respectively. The specificity of breast MRI was 96.1% (95% CI 93.4-98.8%) and 92.2% (95% CI 88.5-95.9%) for mammography, respectively. The diagnostic accuracy of breast MRI did not depend on breast density. In cases rated BI-RADS 0, n=57 (3, n=56), breast MRI achieved a sensitivity of 100% (90.9%) and a specificity of 98.1% (88.9%). There was a significant (P<0.01) accumulation of dense breast tissue (ACR IV) in breasts rated BI-RADS 0 in mammography. Breast MRI missed three malignant lesions, two of them being smaller than 3 mm.\nQuestion: Breast MRI as an adjunct to mammography: Does it really suffer from low specificity?",
        "gt": "There is no rationale to criticize the low specificity of breast MRI when used as an adjunct to mammography. The independency of the diagnostic accuracy of breast MRI from breast density makes it a worthwhile choice in mammographic BI-RADS 0 cases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Increasing evidence suggests a close association between early sexual maturation (SM) and obesity in girls and female adults. Earlier maturing girls are more likely to be obese than nonearly maturers. However, limited research has been conducted in boys. To examine the influence of early SM on fatness in boys and compare it with girls, and to test the hypothesis that the associations differ by gender because of the differences in growth and SM patterns in boys and girls. Cross-sectional study. One thousand five hundred one girls and 1520 boys (aged 8-14 years) who participated in the Third National Health and Nutrition Examination Survey survey (1988-1994) and had complete anthropometry (weight, height, skinfold thickness) and SM data. Based on each individual's age and SM status (Tanner stages: genitalia stages for boys and breast stages for girls), the subjects were classified as: 1) early maturers (those who reached a certain Tanner stage earlier than the median age for that stage), and 2) the others (average and later maturers). Overweight was defined as a body mass index (BMI)>or =85th percentile, and obesity>or =95th percentile. Logistic regression analysis was to test how early maturation affected the risks for overweight and obese. Using multiple linear regression models, the associations between fatness (BMI and skinfold thickness) and SM were systematically examined. Covariates including age, ethnicity, residence, family income, energy intake, and physical activity were adjusted. Early SM was positively associated with overweight and obesity in girls, but the associations were reverse for boys. The prevalence of overweight in early maturers versus the others was 22.6% versus 31.6% in boys and 34.4% versus 23.2% in girls; the figures for obesity were 6.7% versus 14.8% and 15.6% versus 8.1%, respectively. Odd ratios and 95% confidence intervals for obesity were 0.4 (0.2, 0.8) for boys and 2.0 (1.1, 3.5) for girls, and covariates were adjusted. Most significant differences in overweight and obesity among ethnic groups disappeared after controlling for SM. Fatness (BMI and skinfold thickness) was associated with SM stages and with early maturation in boys and girls, but the associations were in opposite directions. Compared with their counterparts, early maturing boys were thinner, whereas early maturing girls were fatter.\nQuestion: Is obesity associated with early sexual maturation?",
        "gt": "Obesity is associated with sexual maturation in both boys and girls, but the association differs. There is positive association in girls, but a negative one in boys. Maturation status should be taken into consideration when assessing child and adolescent obesity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To identify the antibiotic prescriptions and evaluate their suitability for the infectious conditions treated at a Primary Care Centre. A prospective observation study. La Mina Primary Care Centre. Sant Adri\u00e0 de Bes\u00f2s (Barcelona). The on-demand visits of patients over 14 to the General Medicine and Emergency clinics between June 1991 and May 1992 provided the data through a simple multi-stage random sample. On the basis of the clinical notes, these variables were recorded: age, gender, diagnosis, the antibiotic prescribed and its manner of administration. The indication and choice of treatment was assessed in line with previously established criteria, as well as whether the antibiotic was first-choice in Primary Care. Infections treated in hospital or by specialists, non-bacterial cutaneous infections and Conjunctivitis were excluded. Out of 2,523 people examined, 474 presented infectious conditions (18.8%); the most common of these were infections of the upper respiratory tract (46.4%) and acute Bronchitis (17.3%). An antibiotic was prescribed in 206 cases (43.3%). The most used antibiotics were: Amoxicillin (41.5%), Penicillin (19.0%), Cloxacillin (11.2%), Erythromycin (10.2%) and Pipemidic Acid (7.8%). They were orally taken in 89.4% of cases. 92.3% of the antibiotics were first-choice. Overall fitness of treatment was 86.3% (56.5% unnecessary and non-prescribed treatment; and 29.7% necessary and using the recommended antibiotic). The least suitable treatment was observed for cases of acute Bronchitis without any risk factors.\nQuestion: Are antibiotics correctly prescribed in primary care?",
        "gt": "Prescriptions are adjusted to the recommendations on antibiotic policy in Primary Care, although less suitable treatment was observed for acute Bronchitis. The importance of applying a methodology based on objective criteria, in order to make a qualitative analysis in studies on the use of medication, is highlighted.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Among patients with peptic ulcer disease, the prevalence of Helicobacter pylori has been reported to range from 80% to 90%. Thus empirical cost-effective therapy has been suggested. We surveyed patients with peptic ulcer disease in Rochester, NY. From two teaching hospitals all patients who had duodenal ulcers (DU) and/or gastric ulcers (GU) on esophagogastroduodenoscopy (EGD) with antral biopsy for histology for H. pylori and for rapid urease (CLO) test were included in the study. We examined a total of 160 patients with DU and 145 patients with GU, age range 18-92 yr, obtaining clinical data, race, medication profile, and history of use of nonsteroidal antiinflammatory drugs (NSAIDs). An ulcer was defined if the lesion with loss of mucosal integrity was>or = 0.5 cm, with apparent depth. H. pylori was considered present if CLO test and/or histology were positive for H. pylori. To confirm the reliability of nonuse of NSAIDs, we randomly checked blood samples of 90 such patients from the ambulatory clinic for the presence of salicylates. To identify the sensitivity of the CLO test, we performed a serology test for H. pylori antibody in 100 subjects to compare the CLO test results. Also, 500 CLO test results were compared to the histology results for H. pylori. Among 160 DU patients, 16 were NSAID users with negative H. pylori and excluded from the prevalence study. Of the remaining 144 patients with DU, H. pylori was present in 88 patients (61%). When these data were analyzed according to race, H. pylori was present in 54 (52%) of 104 whites compared to 34 of 40 (85%) nonwhites (blacks, Hispanics, Asians) (p<0.01). Among 145 GU patients 18 were NSAID users with negative H. pylori and excluded from the prevalence analysis. Of the remaining 127 patients with GU, H. pylori was present in 87 patients (61%). Among them, H. pylori was present in 46 of 87 (53%) whites, whereas 31 of 40 nonwhites (78%) were H. pylori-positive (p<0.01). Antral histology and CLO test for H. pylori were in agreement in 92% of cases. Serology and CLO test for H. pylori were in agreement in 87% of cases. None of the randomly screened patients, including 16 ulcer patients with negative H. pylori, showed presence of salicylate in blood.\nQuestion: Prevalence of Helicobacter pylori in peptic ulcer patients in greater Rochester, NY: is empirical triple therapy justified?",
        "gt": "In greater Rochester, NY, where the majority of our patients with EGD were whites, the prevalence of H. pylori among ulcer patients was lower compared to other regions, particularly among whites. This suggests that an additional causative factor or factors for peptic ulcers may be present. Hence, empirical antibiotic therapy of ulcer patients without confirming the presence of H. pylori may not be justified.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The pain-relieving efficacy of antagonists of histamine 1 (H1) receptors that are widely found in the ureter and that cause contractions in renal colic was presented in comparison with a placebo. Eighty-six patients who presented to the emergency service because of renal colic accompanied by nausea, and who had urinary system stones detected were included in the study. The patients were separated into 2 groups by double-blind, random assignment. The 45 patients in group 1 received 50 mg intramuscular (IM) dimenhydrinate. The 41 patients in group 2 received 2 mL IM saline solution as a placebo. The visual analogous scale (VAS) values were detected at referral of the patients and at 10, 20, and 30 minutes of therapy to detect the pain intensity. Verbal descriptive scale (VDS) was used for evaluation of nausea and vomiting before and after the therapy. VAS values were statistically quite low in group 1 at 10, 20, and 30 minutes of therapy. VDS scores were also statistically significantly low in group 1 at 30 minutes of treatment.\nQuestion: Histamine 1 receptor antagonist in symptomatic treatment of renal colic accompanied by nausea: two birds with one stone?",
        "gt": "Dimenhydrinate, which is an ethanolamine group H1 receptor blocker, appeared to be effective compared with the placebo in relieving renal colic pain and nausea and vomiting symptoms in patients. Comparative studies with other analgesics will be useful for determining how to use this agent for analgesic purposes in renal colic.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We hypothesize that oxygen consumption (V\u0307o2) estimation in patients with respiratory symptoms is inaccurate and can be improved by considering arterial blood gases or spirometric variables. For this retrospective study, we included consecutive subjects who underwent cardiopulmonary exercise testing. Resting V\u0307o2 was determined using breath-by-breath testing methodology. Using a training cohort (n = 336), we developed 3 models to predict V\u0307o2. In a validation group (n = 114), we compared our models with 7 available formulae. Our first model (V\u0307o2 = -184.99 + 189.64 \u00d7 body surface area [BSA, m(2)] + 1.49 \u00d7 heart rate [beats/min]+ 51.51 \u00d7 FIO2 [21% = 0; 30% = 1] + 30.62 \u00d7 gender [male = 1; female = 0]) showed an R(2) of 0.5. Our second model (V\u0307o2 = -208.06 + 188.67 \u00d7 BSA + 1.38 \u00d7 heart rate + 35.6 \u00d7 gender + 2.06 \u00d7 breathing frequency [breaths/min]) showed an R(2) of 0.49. The best R(2) (0.68) was obtained with our last model, which included minute ventilation (V\u0307o2 = -142.92 + 0.52 \u00d7 heart rate + 126.84 \u00d7 BSA + 14.68 \u00d7 minute ventilation [L]). In the validation cohort, these 3 models performed better than other available equations, but had wide limits of agreement, particularly in older individuals with shorter stature, higher heart rate, and lower maximum voluntary ventilation.\nQuestion: Can we better estimate resting oxygen consumption by incorporating arterial blood gases and spirometric determinations?",
        "gt": "We developed more accurate formulae to predict resting V\u0307o2 in subjects with respiratory symptoms; however, equations had wide limits of agreement, particularly in certain groups of subjects. Arterial blood gases and spirometric variables did not significantly improve the predictive equations.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Hepatitis C virus (HCV) has emerged as a major public health problem among injection drug users. In this analysis we examine whether disinfection of syringes with bleach has a potentially protective effect on anti-HCV seroconversion. We conducted a nested case-control study comparing 78 anti-HCV seroconverters with 390 persistently anti-HCV seronegative injection drug users. These data come from the Second Collaborative Injection Drug Users Study, a prospective cohort study that recruited injection drug users from five U.S. cities between 1997 and 1999. We used conditional logistic regression to determine the effect of bleach disinfection of syringes on anti-HCV seroconversion. Participants who reported using bleach all the time had an odds ratio (OR) for anti-HCV seroconversion of 0.35 (95% confidence interval = 0.08-1.62), whereas those reporting bleach use only some of the time had an odds ratio of 0.76 (0.21-2.70), when compared with those reporting no bleach use.\nQuestion: Does bleach disinfection of syringes protect against hepatitis C infection among young adult injection drug users?",
        "gt": "These results suggest that bleach disinfection of syringes, although not a substitute for use of sterile needles or cessation of injection, may help to prevent HCV infection among injection drug users.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Topical capsaicin application was shown to reduce infarct size in experimental animal models. We hypothesized that cardioprotective properties of topical capsaicin application could be related to its hypothermic effect. In the first arm of the study, anesthetized rats received capsaicin cream (Caps group) or vehicle (Control group, Ctrl) applied either 15 or 30\u00a0min prior to a 30-min coronary artery occlusion followed by 2-h reperfusion. Core body temperature was allowed to run its course, and was monitored via rectal probe. At the end of the protocol, hearts were excised and risk zone and infarct size were measured. In an additional set of animals, hearts were excised immediately after a 15-min application of capsaicin/vehicle, and were used to measure phosphorylated Akt and Erk1/2 with western blots. In the second arm of the study Ctrl (n\u2009=\u20096) and Caps-treated (n\u2009=\u20095) animals were subjected to the same protocol as rats in the first arm, but core body temperature was maintained at 36\u00a0\u00b0C. In the first arm of the study, capsaicin produced a rapid decrease in rectal temperature ranging from 0.22 to 1.78\u00a0\u00b0C at pre-occlusion, with a median level of 0.97\u00a0\u00b0C. A capsaicin-induced temperature decrease of>0.97\u00a0\u00b0C was associated with a 31.2\u00a0% smaller infarct compared to the control group. Capsaicin treatment induced an increase in the levels of phosphorylated Akt and Erk1/2 at the end of capsaicin cream application. No increase in the phosphorylation of downstream p70S6 was observed. Levels of phosphorylated Akt- and Erk1/2 did not correlate with temperature changes after treatment. In the second arm of the study, in which body core temperature was maintained at 36\u00a0\u00b0C, no change in the infarct size was observed in the capsaicin vs. control group.\nQuestion: Capsaicin-induced cardioprotection. Is hypothermia or the salvage kinase pathway involved?",
        "gt": "In the current study we for the first time demonstrated that the capsaicin induced cardioprotective effect might be related to mild hypothermia, caused by capsaicin topical application. The salvage kinase pathway appears not to be critical for capsaicin-induced cardioprotection.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Tracheal drug administration is a route for drug delivery during cardiopulmonary resuscitation when intravenous access is not immediately available. However, tracheal adrenaline (epinephrine) injection has been recently shown to be associated with detrimental decrease in blood pressure. This was attributed to exaggerated early beta2 mediated effects unopposed by alpha-adrenergic vasoconstriction. We hypothesized that endobronchial adrenaline administration is associated with better drug absorption, which may abolish the deleterious drop of blood pressure associated with tracheal drug administration. To determine haemodynamic variables after endobronchial adrenaline administration in a non-arrest canine model. Prospective, randomized, laboratory study. Adrenaline (0.02, 0.05, 0.1 mg/kg) diluted with normal saline was injected into the bronchial tree of five anaesthetized dogs. Injection of 10-ml saline served as control. Heart rate, blood pressure and arterial blood gases were monitored for 60 min after drug instillation. The protocol was repeated after 1 week. Adrenaline at a dose of 0.02 mg/kg produced only a minor initial decrease in diastolic (from 90 +/- 5 to 78 +/- 3 mmHg, P=0.05), and mean blood pressure (from 107 +/- 4 to 100 +/- 3 mmHg, P=0.05), in all dogs. This effect lasted less then 30 s following the drug administration. In contrast, higher adrenaline doses (0.05 and 0.1 mg/kg) produced an immediate increase in diastolic (from 90 +/- 5 to 120 +/- 7 mmHg; and from 90 +/- 5 to 170 +/- 6 mmHg, respectively), and mean blood pressure (from 107 +/- 4 to 155 +/- 10 mmHg; and from 107 +/- 4 to 219 +/- 6 mmHg, respectively). All adrenaline doses resulted in an immediate increase in systolic blood pressure and pulse. Endobronchial administration of saline (control) affected none of the haemodynamic variables.\nQuestion: Endobronchial adrenaline: should it be reconsidered?",
        "gt": "In a non-arrest model, endobronchial adrenaline administration, as opposed to the effect of tracheal adrenaline, produced only a minor decrease in diastolic and mean blood pressure. We suggest that endobronchial adrenaline administration should be investigated further in a CPR low-flow model when maintaining adequate diastolic pressure may be crucial for survival.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare the efficacy of Valsalva maneuver and pneumatic compression techniques in detecting lower extremity deep venous and saphenofemoral insufficiency. Eighty-one extremities evaluated in 43 patients who had undergone Doppler ultrasound examination of the lower extremity venous system were included in the study. Valsalva maneuver and pneumatic cuff techniques were used to elicit reflux in the standing position. Reflux was investigated with spectral Doppler in the superficial femoral vein, popliteal vein, the proximal segment of the great saphenous vein close to its junction with the femoral vein and in its caudal segment at the medial aspect of the knee. The same measurements were repeated after rapid deflation of the pneumatic cuff, which was applied to the calf and was initially inflated to 200 mmHg. Retrograde flow exceeding 1000 msec was regarded as insufficiency. The results of the two techniques at each venous segment were compared with the McNemar test. Deep venous and/or saphenofemoral insufficiency were detected in 61 of the 81 extremities. The cuff deflation technique was superior at the popliteal vein and caudal segment of the great saphenous vein. The Valsalva maneuver was superior at the superficial femoral vein. The statistical results did not change when the McNemar test was repeated for reflux exceeding 2000 msec.\nQuestion: Doppler ultrasound diagnosis of lower extremity deep vein insufficiency: Valsalva maneuver or pneumatic cuff?",
        "gt": "Combined application of Valsalva maneuver and pneumatic cuff techniques will lead to more accurate evaluation and increased detection of lower extremity venous insufficiency.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A network of Stop Smoking Services has been set up within the National Health Service (NHS) in England. The services deliver a combination of behavioural support and medication. It is important to establish the degree of variability in quit rates attributable to differences between individual practitioners, to gauge the scope for improvement by training and professional support. The aim of the present analysis was to examine how far short-term quit rates depend on the practitioner delivering the intervention after adjusting for potential confounding variables. Observational study using routinely collected data. Thirty-one NHS Stop Smoking Services in England. Data from 46,237 one-to-one treatment episodes (supported quit attempts) delivered by specialist practitioners. Three-level logistic regression models were fitted for carbon monoxide (CO)-validated short-term (4-week) quit rates. Models adjusted for age, gender, exemption from prescription charges, medication and intervention setting for each treatment episode, number of clients for each practitioner and economic deprivation at the level of the Stop Smoking Service. Secondary analyses included (i) the heaviness-of-smoking index (HSI) as predictor and (ii) 4-week quit rates whether or not confirmed by CO. Differences between individual specialist practitioners explained 7.6% of the variance in CO-verified quit rates after adjusting for client demographics, intervention characteristics and practitioner and service variables (P\u2009<\u20090.001). HSI had little impact on this figure; in quits not necessarily validated by CO, practitioners explained less variance.\nQuestion: Does it matter who you see to help you stop smoking?",
        "gt": "Individual stop smoking practitioners appear to differ to a significant degree in effectiveness. It is important to examine what underlies these differences in order to improve selection, training and professional development.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is an expectation that interns can perform the core procedural skill of male catheterisation; however, it is unclear if our medical graduates are competent to do so, because there is no formal practical skills exit assessment in our current programme.AIM: We sought to investigate the level of experience, the self-reported confidence, and measured competency of our pre-intern (PRINT) students to perform the procedural skill of male catheterisation. We asked 100/147 (68%) PRINT students to complete a questionnaire to elucidate their experience and confidence prior to being practically assessed on a plastic manikin, using a faculty member validated 26-item checklist. Students were also invited to attend focus groups to help identify factors that had contributed to their practical performance. Between 2010 and 2012, 100/147 (68%) PRINT students completed a questionnaire prior to being formatively assessed. The mean score for self-reported confidence was 78.3/100 (95% CI 74.8-81.8), and the mean performance score was 85.6/100 (95% CI 83.2-87.9); however, the correlation coefficient between the confidence score and performance score was weak (r = 0.18). Three focus groups were conducted, with a total of 12/100 (12%) students attending. Although students reported that they had sound knowledge of the skill, the lack of opportunity to perform the skill in the clinical setting had led to mediocre performance outcomes.\nQuestion: Pre-interns: ready to perform?",
        "gt": "We found no significant correlation among the level of experience, the self-reported ability and actual performance when students were assessed under direct observation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the proportion of patients who received a blood transfusion after joint replacement, and to devise a simple method to ensure patients were transfused based on strict clinical and haematological need. Prospective audit over 2 years. The study group was 151 patients who underwent total hip and knee arthroplasty in a typical district general hospital (Kettering) over a 2-year period. They were divided into three consecutive groups. Current practice was audited (producing the first group of 62 patients) and transfusion rates were compared to regional figures. Local guidelines were drawn up. A form was introduced on which the indications for any transfusion had to be documented prior to transfusion of the blood. This was designed to encourage transfusion only on strong clinical grounds or an haemoglobin (Hb) level<8 g/dl. Transfusion practice was then re-audited (producing the second group of 44 patients) to assess whether practice had improved. A year later, all relevant staff were reminded by letter of the guidelines. The process was then re-audited (producing the third group of 45 patients) again to determine whether practice remained improved or not. In the first audit (current practice) of 62 patients, the overall transfusion rate was 71%, with a higher rate in the hip replacement group (84%) ordered mainly by anaesthetic staff. Ward staff were reluctant not to transfuse patients whose Hb level fell below 10 g/dl. In the second audit, the transfusion rate fell by nearly 50% to 37%, with almost identical figures for knee and hip replacement. In the third audit of 45 patients, a year later, the transfusion rate was 40% overall.\nQuestion: Are we overusing blood transfusing after elective joint replacement?",
        "gt": "Patients were being transfused routinely, generally without good clinical evidence of benefit to the patient. The audit process was successful in instituting change for the better in blood transfusion practice for elective joint replacement. The improved practice can be largely maintained provided staff are regularly reminded of appropriate guidelines and encouraged to transfuse for clinical need only. For absolute adherence to guidelines, we would recommend a compulsory form system be introduced for transfusion in the per-operative period, to ensure blood transfusion is only given when absolutely necessary.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to compare the distribution of virulence-associated genotypes of Helicobacter pylori in two Colombian populations with contrasting gastric cancer risk but with similar H. pylori infection prevalence. Gastric biopsies were taken from 241 subjects from the high gastric cancer risk area of Pasto and from 93 subjects from the low risk area of Tumaco. Four gastric biopsies from each patient were fixed in 10% buffered formalin for histopathologic analysis, and one was frozen immediately in liquid nitrogen and used for genotyping. CagA and vacA genotypes were determined by multiplex polymerase chain reaction and reverse hybridization on a line probe assay. In patients from the population with high risk for gastric cancer, statistically significant higher relative frequencies of cagA positive and vacA s1 and ml genotypes were found as compared to the population from the low risk area.\nQuestion: Virulence-associated genotypes of Helicobacter pylori: do they explain the African enigma?",
        "gt": "Although H. pylori infection has been recognized as a cause of gastric cancer in humans, some large populations with high prevalence of infection have low gastric cancer rates. This so-called \"African enigma\" so far remains unexplained. Our findings suggest that virulence-associated genes of H. pylori may partially explain the African enigma. Other factors, including human genetic polymorphisms and diet, are also suspected to play a major role. Further investigations are needed to test this hypothesis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It is unclear if disparities described in diabetes primary care extend to subspecialty diabetes care. This retrospective observational study examined disparities in diabetes outcomes in a subspecialty practice by assessing glycemic improvement in type 2 diabetes patients during the first year of enrollment. Electronic data were gathered on 3,945 subjects. The outcome was the proportion of white and minority (Asian, black, and Hispanic) subjects achieving a hemoglobin A1C (A1C) level of \u22647% after the first year of care. Logistic regression was used to identify factors associated with odds of achieving A1C \u22647%. Minority patients had greater diabetes duration, more social disadvantages and missed appointments, and worse control at presentation than whites. The proportion of patients reaching target A1C rose from 37 to 52% among white patients and from 28 to 40% among minority patients. Significant differences between whites and minorities in the rates of patients reaching A1C \u22647% were found only among those with higher initial A1C (iA1C) levels (32% vs. 20.9%; P = .002 in third iA1C quartile, and 28.2% vs. 17.9%; P = .0003 in fourth iA1C quartile). The interaction between race/ethnicity and the top two iA1C quartiles remained significant in the fully adjusted model.\nQuestion: Do ethnic disparities extend to subspecialty diabetes care?",
        "gt": "Reaching an A1C level of \u22647% depends strongly upon the glycemic level at initial presentation to specialty care, not race. However, minority patients with the highest baseline A1C levels do not improve to the same degree as white patients, and therefore should be targeted for more intensive diabetes care management.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The critical shortage of surgeons and access to surgical care in Africa is increasingly being recognized as a global health crisis. Across Africa, there is only one surgeon for every 250,000 people and only one for every 2.5 million of those living in rural areas. Surgical diseases are responsible for approximately 11.2% of the total global burden of disease. Even as the importance of treating surgical disease is being recognized, surgeons in sub-Saharan Africa are leaving rural areas and their countries altogether to practice in more desirable locations. The Pan-African Academy of Christian Surgeons (PAACS) was formed in 1997 as a strategic response to this profound need for surgical manpower. It is training surgical residents through a 5-year American competency-based model. Trainees are required to be of African origin and a graduate of a recognized medical school. To date, PAACS has established six training programs in four countries. During the 2009-2010 academic year, there were 35 residents in training. A total of 18 general surgeons and one pediatric surgeon have been trained. Two more general surgeons are scheduled to finish training in 2011. Four graduates have gone on to subspecialty training, and the remaining graduates are practicing general surgery in rural and underserved urban centers in Angola, Guinea-Conakry, Ghana, Cameroon, Republic of Congo, Kenya, Ethiopia, and Madagascar.\nQuestion: Is it possible to train surgeons for rural Africa?",
        "gt": "The PAACS has provided rigorous training for 18 African general surgeons, one of whom has also completed pediatric surgery training. To our knowledge, this is the only international rural-based surgical training program in Africa.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A publication on behalf of the European Society of Urological Oncology questioned the need for removing the seminal vesicles during radical prostatectomy in patients with prostate specific antigen less than 10 ng/ml except when biopsy Gleason score is greater than 6 or there are greater than 50% positive biopsy cores. We applied the European Society of Urological Oncology algorithm to an independent data set to determine its predictive value. Data on 1,406 men who underwent radical prostatectomy and seminal vesicle removal between 1998 and 2004 were analyzed. Patients with and without seminal vesicle invasion were classified as positive or negative according to the European Society of Urological Oncology algorithm. Of 90 cases with seminal vesicle invasion 81 (6.4%) were positive for 90% sensitivity, while 656 of 1,316 without seminal vesicle invasion were negative for 50% specificity. The negative predictive value was 98.6%. In decision analytic terms if the loss in health when seminal vesicles are invaded and not completely removed is considered at least 75 times greater than when removing them unnecessarily, the algorithm proposed by the European Society of Urological Oncology should not be used.\nQuestion: Is it necessary to remove the seminal vesicles completely at radical prostatectomy?",
        "gt": "Whether to use the European Society of Urological Oncology algorithm depends not only on its accuracy, but also on the relative clinical consequences of false-positive and false-negative results. Our threshold of 75 is an intermediate value that is difficult to interpret, given uncertainties about the benefit of seminal vesicle sparing and harm associated with untreated seminal vesicle invasion. We recommend more formal decision analysis to determine the clinical value of the European Society of Urological Oncology algorithm.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate donor graft function, intraoperative blood consumption, and oxygenation and hemodynamic stability in patients undergoing lung transplantation. Prospective pilot study. University hospital. Forty-three patients undergoing lung transplantation from January 1999 to June 2001. Hemodynamic monitoring, early extubation, and noninvasive ventilation criteria. The 31 nonearly extubated patients showed a lower PaO(2)/fraction of inspired oxygen (F(I)O(2)), a higher mean pulmonary arterial pressure, extravascular lung-water index (EVLWI) and vasoactive drug support (norepinephrine), and more blood products consumption than 12 early extubated patients at the end of surgery. Seven of 12 early extubated patients did not show any signs of respiratory failure after tracheal extubation; they were alert and able to perform deep breathing exercise and coughing. In the other 5 patients, hypoxemia, hypercapnia, and an increase of respiratory rate>30 breaths/min were observed. The intermittent application of noninvasive pressure ventilation by face mask avoided endotracheal intubation.\nQuestion: Is very early extubation after lung transplantation feasible?",
        "gt": "The use of a short-acting anesthetic drug, appropriate intraoperative extubation criteria, epidural analgesia, and postoperative noninvasive ventilation make early extubation of lung-transplanted patients possible and effective.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: If glucose transport proteins (Glut) are elevated in tumors they may be good targets for tumor imaging. For targeting, the overexpression of Glut should be a general characteristic of tumors. Moreover agents which bind to Glut should accumulate selectively in tumors. To test this, we quantitated Glut in isolated membranes from three human tumor xenografts, two murine tumor models and normal murine tissues using direct binding studies. Additionally, the biodistribution of two compounds which bind to Glut, 7-[[(2-(3-(125I-p-hydroxyphenyl)propionyl)aminoethyl)amino]carbonyl]-7-+ ++desacetyl-forskolin([125I]HPP forskolin) and [3H]cytochalasin B, were studied in a tumor model which overexpressed Glut. There were multiple classes of binding sites for [3H]cytochalasin B and a percentage of these sites were competitive with D-glucose but not L-glucose. The rank potency and IC50 values for [3H]cytochalasin B binding were: 2-deoxy-D-glucose (4.5 mM)>or = D-glucose (7 mM)>mannose (25 mM)>galactose (35 mM)>rhamnose (1-3 mM)>sorbitol (1-3 mM) and were similar to reported values for transport. The average density of Glut in four tumor models and normal tissues was between 0.7 and 4 pmole/mg protein, but Kd values were not significantly different (69 nM). In LX-1 human lung tumor xenograft (LX-1) Glut were 10-to-20-fold higher than other tissues (21.6 +/- 0.6 pmole/mg protein, p<0.01). Immunostaining of Glut-1 was more prominent in LX-1 than other xenograft tumors, consistent with the binding data. Glut density was highest in poorly vascularized regions suggesting that Glut upregulation was related to a biofeedback mediated event. Iodine-125 HPP-forskolin and [3H]cytochalasin B did not localize in LX-1 tumors.\nQuestion: Targeting of glucose transport proteins for tumor imaging: is it feasible?",
        "gt": "Glut overexpression was not a common characteristic of the five tumors tested. Iodine-125 HPP-forskolin and [3H]cytochalasin B did not localize in LX-1 tumors, indicating that these agents did not target tumors with upregulated Glut. Results suggest that Glut are not a promising target for tumor imaging.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: to investigate whether patients with lichen planus (LP) are really prone to urolithiasis or not. We performed a prospective analysis of 40 patients diagnosed with lichen planus (LP) (group I), and 40 volunteers did not have LP before (group II). Participants were all checked for urolithiasis by radiological investigations. Blood samples were analyzed for biochemistry parameters including calcium and uric acid. 24-h urine samples were analyzed to investigate oxalate, citrate calcium, uric acid, magnesium, sodium and creatinine. Men/women ratio and mean age were similar between group I and II (p>0.05). A presence or history of urolithiasis was detected in 8 (20%) and 2 (%5) patients in group I and II, respectively (p<0.05). Hypocitraturia was the most common anomaly with 35% (n:14) in group I. The rate of hypocitraturia in group II was 12.5% (n:5) and the difference was statistically significantly different (p=0.036). In group I, hyperuricosuria and hyperoxaluria followed with rates of 27.5% (n:11) and 25% (n:10), respectively. The rate of hyperuricosuria and hyperoxaluria were both 5% (n:2) in group II and the differences were significant (p<0.05). Hyperuricemia was another importante finding in the patients with LP. It was detected in 13 (32.5%) patients in group I and in 1 (2.5%) participant in group II (p=0.001).\nQuestion: Are patients with lichen planus really prone to urolithiasis?",
        "gt": "According to our results, metabolic disorders of urolithiasis were highly detected in the patients with LP. However, similar to the etiology of LP, the exact reasons for these metabolic abnormalities in LP remain a mystery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Breast cancer is characterized by hormone dependency, and endocrine therapy is a key treatment in breast cancer. Recently, targeted therapies such as Trastuzumab treatment for HER2-positive breast cancer has been important. Triple-negative (TN) breast cancer is characterized by lack of expression of estrogen receptor (ER) and progesterone receptor (PgR), and the absence of HER2 protein overexpression, and so there is no targeted therapy for this subtype. In this study, we examined the biological and prognostic characteristics in TN breast cancer. Between January 1998 and September 2006, 1,552 patients with primary breast cancer were investigated retrospectively in this study and ER, PgR and HER2 status were evaluated in all cases. Furthermore, p53 overexpression and Ki67 values were examined immunohistochemically. Patient distribution according to ER, PgR or HER2 status was as follows: ER and PgR positive: 57.9%, and ER and PgR negative: 25.1%. With regards to the HER2 status, HER2 positive was 23.3%, and triple negative (TN) was 14.0%. TN breast cancer has a high proliferation rate, high nuclear grade and frequent p53 overexpression. Patients with TN tumors had a significantly poorer disease-free survival (DFS) than those with non-TN tumors. After recurrence the overall survival (OS) rate in TN cases was significantly lower than that of the non-TN cases. Multivariate analysis revealed that TN was a significant factor for DFS and OS after recurrence.\nQuestion: Is triple negative a prognostic factor in breast cancer?",
        "gt": "TN breast cancer is a rare subtype with a high proliferation rate and a high nuclear grade, p53 overexpression, and lower DFS/OS. To improve the prognosis of TN breast cancer, a new effective strategy needs to be developed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Recently, a number of studies have reported positive results from the nonoperative management of fistula-in-ano in infancy, although it has not been of use in all patients. The purpose of this study was to discern the effective treatment methods of fistula-in-ano in infants. A retrospective review was done of 310 children who required operative management for fistula-in-ano or perianal abscess between January 1991 and July 2000. Eighteen patients displayed an onset of symptoms at less than 1 year of age and a duration of symptoms longer than 12 months. The authors analyzed these patients' medical records. All patients were boys. The mean duration of the symptoms was 26.6 +/- 27.5 months. Fourteen patients had shown an onset of symptoms at less than 6 months of age. The longest duration was 10 years. The patients showed conservative periods of over 12 months because their parents did not want them to undergo surgery. The disease in these patients followed 2 patterns. One (6 patients) was an onset of symptoms followed by a silent fistula-in-ano state. The other (12 patients) was an onset of symptoms followed by an intermittent relapse of inflammation. All patients underwent fistulotomy, and none of them had recurrent fistula during the follow-up period.\nQuestion: Fistula-in-ano in infants: is nonoperative management effective?",
        "gt": "Although the advantages of a nonoperative management of fistula-in-ano in infants include the avoidance of general anesthesia and surgical intervention, the lesions cannot be cured by a period of conservation. Surgical management is more effective in respect to the time factor.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The evaluation of surgical risk is crucial in elderly patients. At present, there is little evidence of the usefulness of comprehensive geriatric assessment (CGA) as a part of the overall assessment of surgical elderly patients. We verified whether CGA associated with established surgical risk assessment tools is able to improve the prediction of postoperative morbidity and mortality in 377 elderly patients undergoing elective surgery. Overall mortality and morbidity were 2.4% and 19.9%, respectively. Multivariate analysis showed that impaired cognitive function (odds ratio [OR], 1.33; 95% confidence interval [CI], 1.15 to 4.22; P<.02) and higher Physiological and Operative Severity Score for the Enumeration of Mortality and Morbidity (OR, 1.11; 95% CI, 1.00 to 1.23; P<.04) are predictive of mortality. Higher comorbidity is predictive of morbidity (OR, 2.12; 95% CI, 1.06 to 4.22; P<.03) and higher American Society of Anesthesiologists (OR, 2.18; 95% CI, 1.31 to 3.63; P<.001) and National Confidential Enquiry into Patient Outcome of Death score (OR, 2.03; 95% CI, 1.03 to 4.00; P<.04).\nQuestion: Does comprehensive geriatric assessment improve the estimate of surgical risk in elderly patients?",
        "gt": "In elective surgical elderly patients, the morbidity and mortality are low. The use of CGA improves the identification of elderly patients at higher risk of adverse events, independent of the surgical prognostic indices.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To perform a frequency analysis of start minute digits (SMD) and end minute digits (EMD) taken from the electronic, computer-assisted, and manual anesthesia billing-record systems. Retrospective cross-sectional review. University medical center. This cross-sectional review was conducted on billing records from a single healthcare institution over a 15-month period. A total of 30,738 cases were analyzed. For each record, the start time and end time were recorded. Distributions of SMD and EMD were tested against the null hypothesis of a frequency distribution equivalently spread between zero and nine. SMD and EMD aggregate distributions each differed from equivalency (P<0.0001). When stratified by type of anesthetic record, no differences were found between the recorded and expected equivalent distribution patterns for electronic anesthesia records for start minute (P<0.98) or end minute (P<0.55). Manual and computer-assisted records maintained nonequivalent distribution patterns for SMD and EMD (P<0.0001 for each comparison). Comparison of cumulative distributions between SMD and EMD distributions suggested a significant difference between the two patterns (P<0.0001).\nQuestion: Are anesthesia start and end times randomly distributed?",
        "gt": "An electronic anesthesia record system, with automated time capture of events verified by the user, produces a more unified distribution of billing times than do more traditional methods of entering billing times.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The present study examines whether there is an association between anemia during the first trimester and the risk to develop preterm delivery (PTD), intrauterine growth restriction, and other obstetrical complications. The study population included all registered births between 2000 and 2010. Anemia was defined as hemoglobin<10 g/dl. A comparison of obstetrical characteristics and perinatal outcomes was performed between women with and without anemia. Multiple logistic regression models were used to control for confounders. The study population included 33,888 deliveries, of these 5.1% (1718) were with anemia during the first trimester. Women with anemia were significantly older, delivered earlier, and were more likely to be grand multiparous. There were significantly higher rates of PTD and low birth weight (LBW;<2500 g) among patients with anemia (12.3% vs. 9.3%; p<0.001 and 11.7% vs. 9.0%; p<0.001, respectively). On the contrary, no significant differences between the groups were noted regarding the rate of intrauterine growth restriction. Using a multivariable analysis, the significant association between anemia and PTD persisted (OR = 1.35; 95% CI 1.2-1.6, p<0.01).\nQuestion: Can anemia in the first trimester predict obstetrical complications later in pregnancy?",
        "gt": "Anemia during the first trimester is significantly and independently associated with an increased risk for subsequent PTD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Post-operative diaphragmatic hernias (PODHs) are serious complications following esophagectomy or total gastrectomy. The aim of this study was to describe and compare the incidence of PODHs at a high volume center over time and analyze the outcomes of patients who develop a PODH. A prospective database of all resectional esophagogastric operations performed for cancer between January 2001 and December 2015 was analyzed. Patients diagnosed with PODH were identified and data extracted regarding demographics, details of initial resection, pathology, PODH symptoms, diagnosis and treatment. Out of 631 patients who had hiatal dissection for malignancy, 35 patients developed of PODH (5.5\u00a0% overall incidence). Median age was 66 (range 23-87) years. The incidence of PODH in each operation type was: 2\u00a0% (4/221) following an open 2 or 3 stage esophagectomy, 10\u00a0% (22/212) following laparoscopic hybrid esophagectomy, 7\u00a0% (5/73) following MIO, and 3\u00a0% (4/125) following total gastrectomy. The majority of patients had colon or small bowel in a left-sided hernia. Of the 35 patients who developed a PODH, 20 (57\u00a0%) patients required emergency surgery, whereas 15 (43\u00a0%) had non-urgent repair. The majority of the patients had had suture repair (n\u00a0=\u00a024) or mesh repair (n\u00a0=\u00a07) of the diaphragmatic defect. Four patients were treated non-operatively. In hospital post-operative mortality was 20\u00a0% (4/20) in the emergency group and 0\u00a0% (0/15) in the elective group. Further hernia recurrence affected seven patients (n\u00a0=\u00a07/27, 26\u00a0%) and 4 of these patients (15\u00a0%) presented with multiple recurrences.\nQuestion: Diaphragmatic herniation following esophagogastric resectional surgery: an increasing problem with minimally invasive techniques?",
        "gt": "PODH is a common complication following hybrid esophagectomy and MIO. Given the high mortality from emergency repair, careful thought is needed to identify surgical techniques to prevent PODH forming when minimal access esophagectomy are performed. Upper GI surgeons need to have a low index of suspicion to investigate and treat patients for this complication.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Elastic nailing is a common method of fixation for tibial shaft fractures in skeletally immature individuals. Poor outcomes of titanium elastic nails for femoral shaft fractures have been associated with increasing patient age and weight, especially patients weighing>50 kg. Our objective is to determine if there is an upper weight or age limit to the safe and effective use of titanium elastic nails for tibial shaft fractures in the pediatric population. This is a retrospective cohort study of patients who underwent stabilization of a tibial shaft fracture with titanium elastic nails at a large tertiary-care pediatric trauma center. Data collected included patient demographics, injury characteristics, and radiographic data. Weight groups were stratified as \u2265 or<50 kg, and age groups as 14 years or older or less than 14 years old. Malunion was defined as 10 degrees of angulation in either the sagittal or coronal plane. Union was defined as bridging of \u22653 cortices on orthogonal radiographs. A significant difference in time to union was considered to be 3 weeks. Ninety-five patients were included with a mean age of 12.1 years (range, 6 to 16 y) and a mean weight of 50.2 kg (range, 21 to 122 kg). Malunion rate was similar between weight cohorts: 13.3% (6/45) in the \u226550-kg group and 10% (5/50) in the<50-kg group (P=0.61). Malunion rate was similarly comparable between age groups: 17.6% (6/34) in the 14 years and older group and 8.2% (5/61) in the less than 14-year-old group (P=0.17). There was no statistically significant difference in time to union between weight or age cohorts. In sum, we did not find a significant difference in the rate of malunion or time to healing between younger and older patients or between lighter and heavier patients.\nQuestion: Titanium Elastic Nailing for Pediatric Tibia Fractures: Do Older, Heavier Kids Do Worse?",
        "gt": "The use of titanium elastic nails for tibial shaft fractures, unlike for other long bone fractures, seems not to be precluded in older and heavier patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Feedback from multiple-choice question (MCQ) assessments is typically limited to a percentage correct score, from which estimates of student competence are inferred. The students' confidence in their answers and the potential impact of incorrect answers on clinical care are seldom recorded. Our purpose was to evaluate student confidence in incorrect responses and to establish how confidence was influenced by the potential clinical impact of answers, question type and gender. This was an exploratory, cross-sectional study conducted using a convenience sample of 104 Year\u00a03 dental students completing 20 MCQs on implant dentistry. Students were asked to select the most correct response and to indicate their confidence in it for each question. Identifying both correctness and confidence allowed the designation of uninformed (incorrect and not confident) or misinformed (incorrect but confident) responses. In addition to recording correct/incorrect responses and student confidence, faculty staff designated incorrect responses as benign, inappropriate or potentially harmful if applied to clinical care. Question type was identified as factual or complex. Logistic regression was used to evaluate relationships between student confidence, and question type and gender. Students were misinformed more often than uninformed (22% versus 8%), and misinformed responses were more common with complex than factual questions (p\u00a0<\u00a00.05). Students were significantly more likely to be confident of correct than incorrect benign, incorrect inappropriate or incorrect harmful answers (p\u00a0<\u00a00.001), but, contrary to expectations, confidence did not decrease as answers became more harmful.\nQuestion: Does student confidence on multiple-choice question assessments provide useful information?",
        "gt": "Recording student confidence was helpful in identifying uninformed versus misinformed responses, which may allow for targeted remediation strategies. Making errors of calibration (confidence and accuracy) more visible may be relevant in feedback for professional development.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is increased risk for the occurrence of deep venous thrombosis (DVT) and renovascular thrombosis after kidney transplantation. A disruption of the blood homeostasis caused by surgery and leading to clotting and bleeding malfunctions is widely accepted. However, other causes such as inherited or acquired disorders of the clotting system may further increase the risk of thrombosis. Here, we summarize and review data on possible causes, incidence and ways to prevent the occurrence of DVT and/or renovascular thrombosis after kidney transplantation. The incidence of DVT after kidney transplantation is 6.2-8.3% and approximately 25% of these patients suffer from pulmonary embolism. The DVT occurs primarily on the side of the transplant with an increased risk throughout the first 5 months after transplantation. Thereby, 2-12% of the patients develop renovascular thromboses, most of which are related directly to the surgery. However, inherited or acquired thrombophilia may also play an important role. A severe course is known for prothrombin gene G20210A polymorphism, which can result in graft loss. A great diversity of prophylactic treatments is available but adjustment to the underlying circumstances is crucial for a favourable outcome. Low-dose heparin prophylaxis for at least 2-3 weeks can be used as standard therapy to prevent the occurrence of DVT after kidney transplantation. However, this may not be sufficient for concurrent disorders of the blood homeostasis such as elevated levels of antiphospholipid antibodies, lupus anticoagulant, prothrombin gene G20210A polymorphism or a combined inherited thrombophilia. These patients may need a prophylactic anticoagulation with coumarins starting prior to transplantation and being continued for at least 1 year or even lifelong. Only randomized trials can answer the question concerning optimal duration and safety of coumarins in this setting.\nQuestion: Do we need screening for thrombophilia prior to kidney transplantation?",
        "gt": "DVT and/or renovascular thromboses are severe complications after kidney transplantation. Inherited and acquired thrombophilia, apart from surgery and abnormal anatomy itself, have to be considered and proper prophylactic treatment initiated.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: lt is estimated that epilepsy affects approximately 50 million people worldwide and about 40 million of them live in developing countries. Studies have indicated high rates of poor knowledge, negative attitude and poor first aid management skills of students with epilepsy among practicing teachers. However, there is paucity of such studies on trainee teachers to ascertain any similarities or differences (if any) and the effect of educational interventions. To determine the effect of a health education intervention on trainee teachers' knowledge, attitude and first aid management of epilepsy. The effect of a health education intervention in first aid management of epilepsy was assessed among 226 trainee teachers, attending the Federal College of Education (Technical), Akoka. This was done using a quasi-experimental study design. Data were analyzed using the SPSS version 15. The respondents had a median age of 22 years with a range of 18 to 56 years. The majority of them were females (68.6%), single (79.2%), Christians (81.9%), Yoruba (70.4%) and in first year (100 level) of their study (69.9%). The highest proportion was from the Accounting department (46.0%). A consistent increase in responses to items on knowledge, attitude and first aid management of epileptic seizure items from baseline to post-intervention was observed. For instance, the proportion of responses that epileptic seizures originate from the brain significantly (p = 0.025) increased from 62.5% at baseline to 74.1% after intervention. Generally, slightly more than two-fifths (44.2%) and about two thirds (61.9%) of the respondents were observed to have poor knowledge and negative attitude to epilepsy respectively at baseline. Overall, giving health education on epilepsy led to a reduction in the proportion of respondents with poor knowledge by 15.5% (increase of good knowledge by 29.6%), decrease of negative attitude by 16.4% and increase of good first aid management skill by 25.0%. The knowledge scores were significantly associated with age (p = 0.001), marital status (p = 0.003) and department (p = 0.004) while the attitude scores were significantly associated with teaching duration (p = 0.020). The knowledge was predicted by department (p = 0.001) while the attitude was predicted by teaching duration (p = 0.036).\nQuestion: Improving First Aid Management of Epilepsy by Trainee Teachers of the Federal College of Education (Technical), Akoka - Lagos, South West Nigeria--Can Health Education have an Effect?",
        "gt": "This study reveals that health education could improve the knowledge, attitude. and first aid management of students with epilepsy among trainee teachers. It is therefore proposed that an intervention programme on baseline knowledge of epilepsy and its first aid management be incorporated into the teacher-training curriculum, particularly those in health-related programmes, to address their deficiencies in knowledge, attitude and first aid management of students with epilepsy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Vasopressors are recommended for cardiopulmonary resuscitation (CPR) after cardiac arrest. In order to assess possible benefits regarding neurological recovery, vasopressin versus adrenaline and the combination of both was tested against placebo in a cardiac arrest model in rats. Under anaesthesia with halothane and N2O, cardiac arrest was initiated via transoesophageal electrical fibrillation. After 7 min of global ischaemia, CPR was performed by external chest compression combined with defibrillation. Animals were randomly assigned to three groups receiving adrenaline, vasopressin and a combination of both (n = 15 per group) versus placebo (n = 8). At 1, 3 and 7 days animals were tested according to a neurological deficit score (NDS). After 7 days of reperfusion, coronal brain sections were analysed by Nissl- and TUNEL-staining. Viable as well as TUNEL-positive neurons were counted in the hippocampal CA-1 sector. For statistical analysis, the log rank and the Kruskal-Wallis ANOVA test were used. All data are given as mean+/-S.D.; a p-value<0.05 was considered significant. Mean arterial blood pressure (MAP) measured in the aorta did not differ between the vasopressor groups, whereas placebo animals had significantly lower levels. Survival to 7 days revealed significant differences between the placebo (n = 0/8) and all vasopressor groups (adrenaline, 10/15; adrenaline/vasopressin, 8/15; vasopressin, 12/15). Histological deficit scoring by quantitative analysis of the Nissl- and TUNEL-staining showed no difference in the amount of viable and apoptotic neurons in the vasopressin group (viable: 33+/-18; apoptotic: 63+/-23) versus the adrenaline group (viable: 21+/-12; apoptotic: 67+/-17) and the adrenaline/vasopressin group (viable: 31+/-26; apoptotic: 61+/-27). Neurological deficit scoring did not show any differences between the vasopressor groups.\nQuestion: Vasopressors are essential during cardiopulmonary resuscitation in rats: Is vasopressin superior to adrenaline?",
        "gt": "Administration of arginine-vasopressin during CPR does not improve behavioural and cerebral histopathological outcome, compared to the use of adrenaline or the combination of both vasopressors, after cardiac arrest in rats.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of the study was to investigate whether changes in the level of oxidized LDL (oxLDL) over 2-years contribute to the development of subclinical macroangiopathy and/or microvascular complications in patients with DM1. Basic clinical and biochemical parameters and oxLDL level were measured in 70 patients at baseline and after 2 years of the study. In addition, an ultrasonographic study was performed to assess the carotid intima media thickness (IMT). Patients did not differ according to basic clinical and biochemical parameters at the beginning and after 2 years of the study. IMT increased (p=0.000001) whereas oxLDL level decreased (p=0.00001) in DM1 patients during 2 years. Multivariate regression analysis showed that oxLDL independently influences IMT in DM1 patients (\u03b2=0.454, R2=0.35). Further, positive correlations between oxLDL value and LDL-C concentration (r=0.585, p<0.05, n=70) and between oxLDL level and apo-B concentration have been established (r=0.610, p<0.05, n=70). Moreover, patients with chronic microvascular complications showed a higher value of IMT in comparison with patients without them (p=0.003).\nQuestion: Does oxidized LDL contribute to atherosclerotic plaque formation and microvascular complications in patients with type 1 diabetes?",
        "gt": "Our results provide the evidence that oxLDL accelerates atherosclerotic plaque formation and may contribute to the development of microvascular complications in DM1.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It has never been investigated whether first depression differs in patients who have experienced bereavement compared to patients who have not. Patients discharged with a diagnosis of a single depressive episode from a psychiatric in- or outpatient hospital setting were consecutively sampled from the Danish Psychiatric Central Research Register. Patients participated in an extensive interview including the Schedules for Clinical Assessment in Neuropsychiatry (SCAN) and the Interview of Recent Life Events (IRLE). Among 301 patients with a first depression, 26 patients (4.7%) had experienced death of a first degree relative (parent, sibling, child) or a near friend, 163 patients (54.2%) had experienced other moderate to severe stressful life events and 112 patients had not experienced stressful life events in a 6 months period prior to the onset of depression. Patients who had experienced bereavement did not differ from patients with other stressful life events or from patients without stressful life events in socio-demographic variables or in the phenomenology of the depression, psychiatric comorbidity, family history or response to antidepressant treatment.\nQuestion: Does bereavement-related first episode depression differ from other kinds of first depressions?",
        "gt": "Bereavement-related first episode depression does not differ from other kinds of first depression.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine for evidence of clustering in time, in space and in space/time in the occurrence of rheumatoid arthritis (RA). A population-based incidence register of RA in the East Anglian region of the UK: population size 413,000. In all 687 new cases of inflammatory joint disease registered between 1 January 1990 and 31 December 1994 were studied. Population data were obtained from postcode areas by age and sex. Time trend analysis was conducted over the first 36 months and observed and expected distributions compared. Spatial clustering was based on comparison of observed distribution using map grid references to random expectation based on simulation. A similar procedure was undertaken for time/space clustering. There was no evidence of a time trend. There was only modest evidence of spatial clustering with non-random distribution observed in one area but there was no evidence of time/space clustering.\nQuestion: Do new cases of rheumatoid arthritis cluster in time or in space?",
        "gt": "Although a viral aetiology is the strongest candidate for RA, no evidence of a localized event in time was associated with disease development in this population.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The therapy for native mitral valve endocarditis is in evolution. Antibiotics have significantly improved survival rates, but patients with complications of endocarditis may require surgical treatment. Between January 1985 and December 1995, 146 patients underwent surgical therapy (repair or replacement) for native mitral valve endocarditis. All patients had documented bacterial endocarditis. Univariate and multivariate analyses were performed to determine predictors of hospital death, long-term event-free survival, and probability of repair. Patients were evaluated in three groups: all patients, patients with acute endocarditis, and patients with chronic endocarditis. There were ten hospital deaths (6.8%). Patients undergoing repair had a lower hospital mortality rate (p = 0.008) then those having replacement. Event-free survival was improved after mitral valve repair in the overall group (p = 0.02) and in the group with healed (chronic) endocarditis (p = 0.05). Although the acute endocarditis group demonstrated an improved event-free survival rate after mitral valve repair versus replacement (74% versus 20% at 6 years), this did not reach statistical significance.\nQuestion: Is there an advantage to repairing infected mitral valves?",
        "gt": "We conclude that mitral valve repair is preferable to mitral valve replacement when possible, in patients with complications of endocarditis, as repair results in a lower hospital mortality and an improved long-term survival.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Helicobacter pylori (HP) infection can recur even after eradication by triple therapy. We hypothesize that maintenance acid suppression treatment after standard eradication therapy would be necessary to further reduce ulcer recurrence in Jordanian population. This is a retrospective study that was conducted at King Abdullah University Hospital (KAUH), a major University hospital, and tertiary care facility (>400 beds) located in North Jordan. Endoscopic and histologic results and medication history were reviewed for each patient who has prescribed eradication therapy for HP over the period from July 2003 until May 2006. Maintenance acid suppression treatment after standard eradication therapy markedly reduced the recurrence rate of peptic ulcer from 58.3% (with out maintenance acid suppression treatment) to 1.45% (with maintenance acid suppression treatment).\nQuestion: Is maintenance acid suppression necessary to reduce the rate of reinfection with Helicobacter pylori?",
        "gt": "Our results indicate that treatment of HP infection by eradication regimen (triple therapy only) is not enough to prevent recurrence of ulcer in the Jordanian population. Thus, we recommend maintenance acid suppression following standard H. pylori eradication regimen to maintain remission.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To analyze the impact of surgeon's experience on surgical margin status, postoperative continence and operative time after radical prostatectomy (RP) in a surgeon who performed more than 2000 open RP. We retrospectively analyzed 2269 patients who underwent RP by one surgeon from April 2004 to June 2012. Multivariable logistic models were used to quantify the impact of surgeon's experience (measured by the number of prior performed RP) on surgical margin status, postoperative continence and operative time. Negative surgical margin rate was 86 % for patients with pT2 stage, and continence rate at 3 years after RP was 94 %. Patients with negative surgical margin had lower preoperative PSA level (p = 0.02), lower pT stage (p<0.001) and lower Gleason score (p<0.001). The influence of the experience of the surgeon was nonlinear, positive and highly significant up to 750 performed surgeries (75-90 % negative surgical margin) (p<0.01). The probability of continence rises significantly with surgeon's experience (from 88-96 %) (p<0.05). A reduction in operative time (90-65 min) per RP was observed up to 1000 RP.\nQuestion: Surgical learning curve for open radical prostatectomy: Is there an end to the learning curve?",
        "gt": "In the present study, we showed evidence that surgeon's experience has a strong positive impact on pathologic and functional outcomes as well as on operative time. While significant learning effects concerning positive surgical margin rate and preserved long-term continence were detectable during the first 750 and 300 procedures, respectively, improvement in operative time was detectable up to a threshold of almost 1000 RP and hence is relevant even for very high-volume surgeons.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The most appropriate approach to the repair of large paraesophageal hernias remains controversial. Despite early results of excellent outcomes after laparoscopic repair, recent reports of high recurrence require that this approach be reevaluated. For this study, 60 primary paraesophageal hernias consecutively repaired at one institution from 1990 to 2002 were reviewed. These 25 open transabdominal and 35 laparoscopic repairs were compared for operative, short-, and long-term outcomes on the basis of quality-of -life questionnaires and radiographs. No difference in patient characteristics was detected. Laparoscopic repair resulted in lower blood loss, fewer intraoperative complications, and a shorter length of hospital stay. No difference in general or disease-specific quality-of-life was documented. Radiographic follow-up was available for 78% open and 91% laparoscopic repairs, showing anatomic recurrence rates of 44% and 23%, respectively (p = 0.11).\nQuestion: Should laparoscopic paraesophageal hernia repair be abandoned in favor of the open approach?",
        "gt": "Laparoscopic repair should remain in the forefront for the management of paraesophageal hernias. However, there is considerable room for improvement in reducing the incidence of recurrence.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The authors determined the usefulness of frozen section (FS) evaluation in the operative management of follicular lesions of the thyroid. Fine-needle aspiration (FNA) cannot reliably discriminate between benign and malignant follicular lesions of the thyroid. Accordingly, FS evaluation is used routinely to guide intraoperative management. One hundred twenty-five consecutive patients with follicular thyroid lesions who underwent surgical exploration at the Johns Hopkins Hospital were reviewed. Frozen sections were categorized in 104 of 120 patients (87%) as \"follicular lesion, defer to permanent section,\" rendering no useful clinical information. In only 4 of 120 patients (3.3%) did FS evaluation correctly modify the operative procedure. Notably, in six cases (5.0%), an incorrect FS evaluation misled the surgeon, resulting in four misguided operations.\nQuestion: Follicular lesions of the thyroid. Does frozen section evaluation alter operative management?",
        "gt": "Frozen section evaluation is of minimal diagnostic value for follicular thyroid lesions, rendering no additional information 87% of the time; it prolongs the operation, increases costs, and leads to misguided interventions. Until a more definitive diagnostic tool exists for follicular thyroid lesions, FS evaluation could be omitted, resection of the lobe with the nodule could be performed, and the definitive operative management could be based on the final permanent histology.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is a lack of evidence regarding the role of drainage in laparoscopic cholecystectomy (LC) for acutely inflamed gallbladder (AIGB), and drain insertion remains controversial. From December 2013 to November 2014, a total of 193 patients who needed LC due to AIGB at the four participating hospitals were entered in this study. After the operation, the patients were randomly assigned to undergo drain insertion (94 patients, 48.7%, group A) or not (99 patients, 51.3%, group B). The surgical outcomes between the two groups were prospectively reviewed. The study was registered at www.clinicaltrials.gov at the inception of enrollment (NCT02027402). Both groups were comparable in terms of patient demographics, operative time and postoperative hospital stay. In 18 cases (9.3%), postoperative morbidities such as bleeding, bile leakage, wound infection or an abscess occurred, and there was no significant difference between the two groups. The visual analog scale pain score measured at 24 h (3.9\u2009\u00b1\u20091.4 in group A and 3.3\u2009\u00b1\u20092.0 in group B, P\u2009=\u20090.014) and 48 h (2.1\u2009\u00b1\u20091.5 in group A and 1.5\u2009\u00b1\u20091.4 in group B, P\u2009=\u20090.006) was significantly higher in group A.\nQuestion: Is routine drain insertion after laparoscopic cholecystectomy for acute cholecystitis beneficial?",
        "gt": "Routine drain insertion does not prevent or reduce postoperative morbidities after LC for AIGB and can even cause prolonged postoperative pain. This prospective study suggests that routine drain use in LC for AIGB should be reconsidered.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Poor sleep may be associated with the cardiovascular disease (CVD) morbidity and mortality. It is less clear if poor sleep is associated with subclinical CVD. We evaluated cross-sectional associations between self-reported sleep disturbance and duration and calcification in the coronary arteries (CAC) and aorta (AC) in healthy mid-life women. 512 black and white women enrolled in the SWAN Heart Study, underwent a computed tomography protocol for measurement of CAC and AC and completed questionnaires about their sleep. Linear and partial proportional logit regression analyses adjusted for site, race, age, body mass index, and the Framingham risk score (model 1). Additional covariates of education, perceived health, hypnotic medication and alcohol use were evaluated (model 2), plus depressive symptoms (model 3). AC was related to higher levels of trouble falling asleep, waking earlier than planned, overall poor sleep quality, and cough/snoring and shorter sleep duration in linear regression analyses (model 1). Adjustments for additional covariates showed that poor sleep quality and waking earlier than planned remained associated with higher AC (models 2 and 3). CAC was unrelated to sleep characteristics.\nQuestion: Do reports of sleep disturbance relate to coronary and aortic calcification in healthy middle-aged women?",
        "gt": "Poor sleep quality is related to AC in middle-aged women. Sleep quality should routinely be assessed in mid-life women.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To correlate the periodontal status of 15 patients with primary Sj\u00f6gren's syndrome (SS) with their salivary levels of BAFF. The periodontal status of 15 patients who fulfilled the criteria for primary SS was compared with that of 15 controls with xerostomia who did not fulfill the criteria for primary SS but had similar symptoms of dry mouth. The level of BAFF was measured in paired samples of saliva and serum using in-house enzyme-linked immunosorbent assays. Periodontitis was assessed by the plaque index, the modified gingival index, the papillary bleeding index, and the periodontal pocket depth. Notwithstanding the better oral hygiene practices of the patients with primary SS compared with those of the xerostomia controls and the subsequent reduction of their plaque index scores, complications of periodontitis, such as bleeding, gingival hypertrophy, and periodontal pockets, were not improved. This failure to ameliorate the complications of periodontitis in patients with primary SS was associated with high levels of BAFF in their saliva compared with the levels in xerostomia controls (7.4 +/- 2.1 versus 1.0 +/- 0.4 ng/ml [P<0.002]). The levels of BAFF in saliva did not correlate with the levels in sera but did correlate with the periodontal pocket depth (P<0.002).\nQuestion: Is periodontal disease mediated by salivary BAFF in Sj\u00f6gren's syndrome?",
        "gt": "These findings are similar to the bone resorption observed in patients with rheumatoid arthritis. They suggest that the known effect of B cells in periodontitis would be partly mediated by salivary BAFF in patients with primary SS.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A substantial proportion of patients with clinical stage I non-small cell lung cancer (NSCLC) have more advanced disease on final pathologic review. We studied potentially modifiable factors that may predict pathologic upstaging. Data of patients with clinical stage I NSCLC undergoing resection were obtained from the National Cancer Database. Univariate and multivariate analyses were performed to identify variables that predict upstaging. From 1998 to 2010, 55,653 patients with clinical stage I NSCLC underwent resection; of these, 9,530 (17%) had more advanced disease on final pathologic review. Of the 9,530 upstaged patients, 27% had T3 or T4 tumors, 74% had positive lymph nodes (n>0), and 4% were found to have metastatic disease (M1). Patients with larger tumors (38 mm vs 29 mm, p<0.001) and a delay greater than 8 weeks from diagnosis to resection were more likely to be upstaged. Upstaged patients also had more lymph nodes examined (10.9 vs 8.2, p<0.001) and were more likely to have positive resection margins (10% vs 2%, p<0.001). Median survival was lower in upstaged patients (39 months vs 73 months). Predictors of upstaging in multivariate regression analysis included larger tumor size, delay in resection greater 8 weeks, positive resection margins, and number of lymph nodes examined. There was a linear relationship between the number of lymph nodes examined and the odds of upstaging (1 to 3 nodes, odds ratio [OR] 2.01;>18 nodes OR 6.14).\nQuestion: Pathologic Upstaging in Patients Undergoing Resection for Stage I Non-Small Cell Lung Cancer: Are There Modifiable Predictors?",
        "gt": "Pathologic upstaging is a common finding with implications for treatment and outcomes in clinical stage I NSCLC. A thorough analysis of regional lymph nodes is critical to identify patients with more advanced disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This paper provides evidence of environmental iodine deficiency in the Gippsland region. Quantitative study; water samples were collected from 18 water treatment plants and four rain water tanks across Gippsland and water iodine concentrations were measured. Gippsland region of Victoria, Australia. This paper reports on the iodine concentration of drinking water from sources across Gippsland and examines the contribution of iodine from water to the Gippsland diet. This study also briefly examines the relationship between the concentration of iodine in water and distance from the sea. The cut-off value for water iodine concentrations considered to be indicative of environmental iodine deficiency is<2 \u00b5g L(-1) . The mean iodine concentration of water from 18 Gippsland water treatment plants was 0.38 \u00b5g L(-1) and would therefore make negligible difference to the dietary intake of iodine. This finding also falls well below the suggested dietary intake of iodine from water estimated by the 22nd Australian Total Diet Study. Our study found no linear relationship between the water iodine concentration and distance from the sea.\nQuestion: Is Gippsland environmentally iodine deficient?",
        "gt": "As Gippsland has environmental iodine deficiency there is a greater probability that people living in this region are at higher risk of dietary iodine deficiency than those living in environmentally iodine sufficient regions. Populations living in areas known to have environmental iodine deficiency should be monitored regularly to ensure that problems of iodine deficiency, especially amongst the most vulnerable, are addressed promptly.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the influence of the surgical removal of partially impacted third molars (3Ms) and compare the effects of a 3-cornered laterally rotated flap (LRF) with primary closure (flap 1) and an envelope flap with secondary closure (flap 2) on the short-term periodontal status of the adjacent second molars (2Ms). We also assessed the postoperative complications after removal of the partially impacted 3M. A split mouth, randomized clinical study was designed. The study sample included patients with bilateral partially impacted 3Ms. The primary predictor variable was the type of flap design (flaps 1 and 2). The primary outcome variable was periodontal status (gingival recession [GR], probing depth [PD], plaque index [PI], and gingival index) of the 2Ms measured preoperatively and 90 days postoperatively. The secondary outcome variables were postoperative complications, including pain, facial swelling, alveolitis, and local wound infection. The other variables included gender, position of the 3Ms, and surgical difficulty. We performed descriptive, comparative, correlation, and multivariate analyses. The sample included 28 patients aged 18 to 28 years. The GR, PD, and PI values with the flap 2 design were greater than those with the flap 1 design (P<.05). Facial swelling with the flap 1 design was significantly greater than with the flap 2 design on the second postoperative day (P<.05). The pain levels with the flap 1 design were significantly greater than those with the flap 2 design on the first and second postoperative days (P<.05). According to the multivariate regression analyses, flap design was closely related to the periodontal status of the 2Ms and postoperative discomfort.\nQuestion: Does laterally rotated flap design influence the short-term periodontal status of second molars and postoperative discomfort after partially impacted third molar surgery?",
        "gt": "The results of the present clinical study have shown that the flap design in partially impacted 3M surgery considerably influences the early periodontal health of the 2Ms and postoperative discomfort. However, although the 3-cornered LRF design might cause more pain and swelling, it could be the method of choice for partially impacted 3M surgery because of the early periodontal healing.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The actual gold standard of Botulin A toxin (BoTx A) batches qualification is the mouse lethality assay. With this assay it is nevertheless impossible to set a therapeutic value unit. The goal of this research was to study the effects of BoTx A increasing concentrations on glutamatergic rat neurons. We studied the glutamate release with increasing concentrations of BoTx A. We also studied the BoTx A target cleavage with a western blot technique. Our results proved that it is possible to establish a dose-response - like curve of BoTx A effects on glutamate release. Moreover the cleavage of the target protein was visible for the same toxin concentrations that inhibited the glutamate release.\nQuestion: Measurement of botulinum toxin activity: towards a new cellular culture assay?",
        "gt": "This technique could be the first step toward a new way of setting a better pharmaceutical profile for toxin batches.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate whether the 'inverse care law' applies to New South Wales (NSW) hospital admissions--especially to older people with high socio-economic status (SES). Cross-sectional study analysing inequalities in public and private hospital admission rates by SES, defined in terms of age, sex and family income/size at the small geographic area level. Admissions to NSW public and private hospitals in 1999-2000 (1.8 million admissions against a NSW population of 6.4 million). Inequalities in hospitalisation rates were expressed as rate ratios across the most and least disadvantaged 20% of the NSW population. Public hospital admission rates for people aged 0-60 years were 24-35% higher for the most disadvantaged 20% of the NSW population than for the least disadvantaged 20%. For 70+ year-olds the direction of this difference was reversed--being 14% lower for the most disadvantaged 20% of the population (5% higher for public patients). For private hospitals this reversal prevailed for all age groups (23-49% lower). For all hospitals it was 16% and 27% lower for 60-69 and 70+ year-olds respectively, with higher admission rates for top SES 60+ year-olds most pronounced for renal dialysis, chemotherapy, colonoscopies and other diagnostic scopes, rehabilitation and follow-up, and cataract operations.\nQuestion: Hospital admissions by socio-economic status: does the 'inverse care law' apply to older Australians?",
        "gt": "While the 'inverse care law' did apply to 60+ year-olds, it did not apply either to younger NSW hospital users or to public patients in public hospitals.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The treatment of personality disorder is repeatedly reported as less successful than the treatment of patients without personality disorder. Most clinicians believe that anxiety disorder in tandem with a personality disorder often leads to longer treatment, worsens the prognosis, and thus increases treatment costs. Our study was designed to compare the short-term effectiveness of therapy in patients suffering from social phobia with and without personality disorder. The specific aim of the study was to assess the efficacy of a 6 week therapeutic program designed for social phobia (SSRIs and CBT) in patients suffering from social phobia with comorbid personality disorder (17 patients) and social phobia without comorbid personality disorder (18 patients). The patients were regularly assessed in weeks 0, 2, 4 and 6 using the CGI (Clinical Global Improvement) for severity, LSAS (Liebowitz Social Anxiety Scale), and in self-assessments BAI (Beck Anxiety Inventory) and BDI (Beck Depression Inventory). Patients in both groups improved their scores in most of the assessment instruments used. A combination of CBT and pharmacotherapy proved to be the most effective treatment for patients suffering with social phobia with or without comorbid personality disorder. Treatment efficacy in patients with social phobia without personality disorder was significantly better than in the group with social phobia comorbid with personality disorder for CGI and specific inventory for social phobia - LSAS. The scores on the subjective depression inventory (BDI) also showed significantly greater decrease over the treatment in the group without personality disorder. The treatment effect between groups did not differ in subjective general anxiety scales BAI.\nQuestion: Is there any influence of personality disorder on the short term intensive group cognitive behavioral therapy of social phobia?",
        "gt": "Our study showed that patients suffering from social phobia and comorbid personality disorder showed a smaller decrease in specific social phobia symptomatology during treatment compared than patients with social phobia without personality disorders. However, a significant decrease in symptomatology occurred in personality disorder patients as well.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Our study aimed at defining the role of tamsulosin as adjunctive therapy after extracorporeal shock wave lithotripsy (ESWL) in patients with stones in the kidney and ureter. A placebo-controlled, randomized, double-blind clinical trial prospectively performed between February 2008 and September 2009 on 150 patients with 4-20 mm in diameter renal and ureteral stones referred to our ESWL center. After ESWL, all patients randomly assigned to two groups (placebo and tamsulosin). The drugs administration was started immediately after ESWL and was continued for a maximum of 30 days. From 150 patients, 71 in control group and 70 in case group completed the study. Of 71 patients (60.56%) in control group, 43 patients became stone free; and other patients (39.44%) did not succeed in stone expulsion during 12 weeks after ESWL. In case group of 70 patients (71.4%), 50 patients became stone free. Time of stone passage in most of the patients happened between 20th and 30th day in control group (32.6%) and between 10th and 20th day (50%) in case group after ESWL. There is no statistically significant difference between stone passage in two groups (p = 0.116) and location of stone (p = 0.114), but there is statistically significant difference in time of stone passage from onset of treatment in case and control groups (p = 0.002).\nQuestion: Is there a role for tamsulosin after shock wave lithotripsy in the treatment of renal and ureteral calculi?",
        "gt": "At last, this study suggested that tamsulosin facilitate earlier clearance of fragments after ESWL.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We compared the results from a video-assisted thoracoscopic sympathectomy (VTS) at the T4 denervation level with those from a VTS at the T3 level for the treatment of palmar hyperhydrosis (PH). Seventy patients with PH were prospectively followed for VTS at the T3 or T4 denervation levels for 6 months. The end points of this study were: absence of PH, compensatory hyperhydrosis (CH), and quality-of-life assessment. Sixty-seven patients reported a complete resolution of PH after surgery. One failure occurred in the T3 group and 2 in the T4 group. When anhydrosis was obtained, we noticed totally dry hands in 26 patients in the T3 group and 6 patients in the T4 group. The other 27 patients in the T4 group and 8 in the T3 group maintained a small level of sweating and were also considered to be therapeutic successes. At 6 months, 25 patients in the T4 group had some degree of CH (71.42%) and all patients in the T3 group (100%), though the T4 group had a lower degree of severity of CH at the 6-month follow-up (P<0.05). After the operation, quality of life was improved similarly in both groups.\nQuestion: Is sympathectomy at T4 level better than at T3 level for treating palmar hyperhidrosis?",
        "gt": "VTS at either the T3 or T4 level provides an effective treatment for PH. VTS at the T4 level is associated with a less severe form of CH. Despite the occurrence of CH, patients' quality of life is significantly improved following VTS at the T3 or T4 levels. For this reason, the T4 resection can now be used as a treatment for PH.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Few Australian studies describe the epidemiology of penetrating trauma. This study describes the incidence and demographic features of penetrating injuries with emphasis on trends and severity analysis. Case analysis was performed utilizing data from the Liverpool Hospital Trauma Registry (1989-94), NSW Department of Health Hospital Separations (1991-93), and the NSW Bureau of Crime Statistics (1991-93) with reference to the Liverpool and Fairfield Local Government Areas (LGA). The Trauma Registry revealed 251 of penetrating trauma. The median age was 26 years (interquartile range 21-33). Ninety-one per cent of the victims were male. Fourteen per cent of patients had an Injury Severity Score (ISS)>15. Sixty-five per cent of cases were stab injuries and 20% gunshot injuries with the abdomen being the most commonly injured site. Twenty-one per cent of patients underwent laparotomy, 1.6% thoracotomy and 1.2% thoracotomy and laparatomy. There were 10 (4%) deaths. Trends in incidence of penetrating trauma and violent crime involving weapons were analysed. Static trends were observed for the annual incidence of penetrating trauma from the Liverpool Hospital Trauma Registry. Separations for penetrating trauma from Liverpool and Fairfield hospitals showed a slightly increasing trend. Violent crimes involving weapons in the Liverpool and Fairfield LGA showed a static trend. Nevertheless, separations for penetrating trauma and rates of violent crimes involving weapons were higher in south-western Sydney than metropolitan Sydney or NSW. Eight per cent of the LGA population are Vietnamese but this study identified 16% of victims as being Vietnamese.\nQuestion: Is penetrating injury on the increase in south-western Sydney?",
        "gt": "This study found no significant increase in penetrating trauma or violent crime predisposing to penetrating injury in south-western Sydney.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients with prostate cancer with a pre-operative prostate-specific antigen (PSA)>15 ng/ml who undergo radical retropubic prostatectomy (RRP) generally do not have a good outcome, yet may have organ-confined cancer and should be offered the option of surgery.AIM: To assess the outcome of patients who underwent RRP with a pre-operative PSA>15 ng/ml. Thirty-four patients, mean pre-operative PSA: 25.46 ng/ml (15.03-76.6) and mean Gleason score: 6.4 (5-9) were assessed. Two groups were identified. Group I: 41% (14/34) have no biochemical recurrence to mean follow up of 58 months (30-106). Mean PSA: 18.8 ng/ml (15.03-25.84). Mean Gleason score: 6.1 (5-7). Clinical stage: T1c in 80%. No patient had seminal vesicle or lymph node involvement. Group II: 59% (20/34) have biochemical recurrence or died (3) from their disease to mean follow up of 66 months (36-98). Mean PSA: 28.9 ng/ml (15.28-76.6). Mean Gleason score: 6.7 (5-9). Clinical stage: T1c in 25%. Eleven patients had seminal vesicle (8) involvement or positive lymph nodes (3) or both (2).\nQuestion: Should patients with a pre-operative prostate-specific antigen greater than 15 ng/ml be offered radical prostatectomy?",
        "gt": "RRP seems feasible in patients whose pre-operative PSA is between 15 and 25 ng/ml with stage T1c, Gleason score<or = 7 and negative lymph node frozen section.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: While a considerable body of research has explored the relationship between patient expectations and clinical outcomes, few studies investigate the extent to which patient expectations change over time. Further, the temporal relationship between expectations and symptoms is not well researched. We conducted a latent class growth analysis on patients (n = 874) with back pain. Patients were categorised in latent profile clusters according to the course of their expectations over 3 months. Nearly 80% of participants showed a pattern of stable expectation levels, these patients had either high, medium or low levels of expectations for the whole study period. While baseline levels of symptom severity did not discriminate between the three clusters, those in the groups with higher expectations experienced better outcome at 3 months. Approximately 15% of patients showed decrease in expectation levels over the study period and the remainder were categorised in a group with increasingly positive expectations. In the former clusters, decrease in expectations appeared to be concordant with a plateau in symptom improvement, and in the latter, increase in expectations occurred alongside an increase in symptom improvement rate.\nQuestion: Do recovery expectations change over time?",
        "gt": "The expectations of most people presenting to primary care with low back pain do not change over the first 3 months of their condition. People with very positive, stable expectations generally experience a good outcome. While we attempted to identify a causal influence of expectations on symptom severity, or vice versa, we were unable to demonstrate either conclusively.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine the significant differences in smoking, drug and alcohol use between adolescent boys and girls, and to raise the possible need to design and implement prevention programs from a gender perspective. A qualitative study using eight discussion groups of adolescents aged 14-18 years (n=56) and 6 semi-structured interviews with experts and professionals in drug prevention in the Community of Madrid. Categorical interpretive analysis was performed. The adolescents and prevention professional indicated differences between boys and girls in drug and alcohol use. The significances, reasons associated with the consumption and the patterns of consumption were perceived differently by each sex. To lose weight, calm down or an image of rebelliousness was related to girls who smoked, while boys smoked less because they did more sports. The perception of certain precocity of drug consumption was associated with the step from school to Higher Education Institutions. They found smoking associated with a good social image among their groups. Adolescents showed the ineffectiveness of the campaigns and prevention messages they received, incoherence of adults between messages and actions, and the attraction of all behaviours that are banned. Professionals observed the need to include a gender perspective in prevention programs, but did not know how to achieve it, mainly because it has been translated into different activities for each sex until now.\nQuestion: Is a gender differential intervention necessary in the prevention of adolescent drug use?",
        "gt": "The significant differences associated with smoking, drug and alcohol use observed in the adolescents should lead us to design and implement prevention programs that incorporate a gender perspective. It is perhaps from this strategy where drug and alcohol use among girls can be reduced.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It is unknown whether physical activity during pregnancy (PA) has long-term impact on the metabolic profile of the offspring. We investigated associations of PA with markers of the metabolic syndrome (MS) in 20y old offspring. Longitudinal study where 965 pregnant women during 1988-1989 had four dimensions of PA assessed by questionnaires in gestation week 30: PA at work; leisure time PA, daily amount of walking-biking and sport participation. The following MS markers were assessed in the offspring (n=439): body mass index (BMI), waist circumference, blood pressure, homeostasis model assessment insulin resistance as well as fasting plasma glucose, triglycerides, cholesterol (high-density lipoprotein (HDL), low-density lipoprotein and total cholesterol), insulin and leptin levels. Walking-biking PA in pregnancy is associated with unchanged or subtle, adverse changes of distinct MS markers among offspring including lower levels of HDL cholesterol (ratio 0.95 (95% CI 0.92 to 0.98) per 1 h increment in walking-biking), a higher diastolic blood pressure (difference 1.12 (95% CI 0.03 to 2.20) mm Hg/1 h increment) and a higher BMI (ratio 1.03 (95% CI 1.01 to 1.05) per 1 h increment). In separate analyses in males, these associations persisted and additional adverse associations were found for triglycerides, systolic blood pressure, waist circumference and leptin. No associations were detected with other measures of PA.\nQuestion: Does physical activity during pregnancy adversely influence markers of the metabolic syndrome in adult offspring?",
        "gt": "The study did not substantiate any protective effects of PA in pregnancy. In contrast, data suggested that high amounts of daily walking-biking in pregnancy may have adverse effects on levels of HDL cholesterol, diastolic blood pressure and BMI in young adult offspring.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Recent studies reported lower quality of care for black vs. white patients with community-acquired pneumonia and suggested that disparities persist at the individual hospital level. We examined racial differences in emergency department and intensive care unit care processes to determine whether differences persist after adjusting for case-mix and variation in care across hospitals. Prospective, observational cohort study. Twenty-eight U.S. hospitals. Patients with community-acquired pneumonia: 1738 white and 352 black patients. None. We compared care quality based on antibiotic receipt within 4 hrs and adherence to American Thoracic Society antibiotic guidelines, and intensity based on intensive care unit admission and mechanical ventilation use. Using random effects and generalized estimating equations models, we adjusted for case-mix and clustering of racial groups within hospitals and estimated odds ratios for differences in care within and across hospitals. Black patients were less likely to receive antibiotics within 4 hrs (odds ratio, 0.55; 95% confidence interval, 0.43-0.70; p<.001) and less likely to receive guideline-adherent antibiotics (odds ratio, 0.72; 95% confidence interval, 0.57-0.91; p = .006). These differences were attenuated after adjusting for casemix (odds ratio, 0.59; 95% confidence interval; 0.46-0.76 and 0.84; 95% confidence interval, 0.66 -1.09). Within hospitals, black and white patients received similar care quality (odds ratio, 1; 95% confidence interval, 0.97-1.04 and 1; 95% confidence interval, 0.97-1.03). However, hospitals that served a greater proportion of black patients were less likely to provide timely antibiotics (odds ratio, 0.84; 95% confidence interval, 0.78-0.90). Black patients were more likely to receive mechanical ventilation (odds ratio, 1.57; 95% confidence interval, 1.02-2.42; p = .042). Again, within hospitals, black and white subjects were equally likely to receive mechanical ventilation (odds ratio, 1; 95% confidence interval, .94-1.06) and hospitals that served a greater proportion of black patients were more likely to institute mechanical ventilation (odds ratio, 1.13; 95% confidence interval, 1.02-1.25).\nQuestion: Do hospitals provide lower quality of care to black patients for pneumonia?",
        "gt": "Black patients appear to receive lower quality and higher intensity of care in crude analyses. However, these differences were explained by different case-mix and variation in care across hospitals. Within the same hospital, no racial differences in care were observed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this paper is to determine the possible association between five different profiles of immunohistochemical expression related to clinical, histopathological and immunohistochemical known prognostic value variables for breast cancer. A total of 194 breast carcinoma tumour samples were studied. In this study five groups or immunohistochemical profiles were defined, based on expression of hormone receptors (oestrogen or progesterone) and/or Her2/neu (luminal-type A, luminal-type B, mixed profile, Her2/neu profile and triple-negative-type profile) and we studied whether there are differences between them with regard to clinical, histopathological and immunohistochemical variables that have a known prognostic significance. In the series we found 134 (69%) cases corresponding to a luminal immunophenotype, of which 98 (50.5%) were from the luminal A group and 36 (18.6%) from luminal B. Twenty-nine cases (15.9%) were triple-negative, 18 (9.3%) mixed and 13 (6.7%) Her2/neu type. It is worth noting the relationship between the triple-negative and Her2/neu immunophenotypes and the more poorly differentiated histological forms (62% and 60%, respectively) and between the luminal A group and well-differentiated tumours (p = 0.008). Expression of ki67 was high in the triple-negative group (73.9%) and low in the luminal A group (26.3%; p = 0.001). The expression of p53 was also greater for the Her2/neu (55.5%) and triple-negative (60.8%) groups (p = 0.0005) than for the others.\nQuestion: Immunohistochemical characterisation of breast cancer: towards a new clasification?",
        "gt": "The subgroups without hormone receptor expression, with Her2/neu overexpression or without (triple-negative group), have characteristics associated with variables of a poorer prognosis. The lack of progesterone receptor expression also seems to be associated with these.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Size can predict malignancy in adrenocortical tumors, but the same extrapolation for pheochromocytomas (PCC) is controversial. The goal of this study was to find a correlation between the tumor size and malignant potential of PCC and determine whether the \"Pheochromocytoma of the adrenal gland scaled score\" (PASS) proposed by Thompson can be applied to predict malignancy. A retrospective analysis of patients with PCC operated on from 1991 to 2007 revealed 98 PCC removed from 93 patients. Tumor size was available for 90 tumors. Six (6.4%) patients had proven malignancy. Five familial cases were excluded from the PASS analysis. Of the benign cases, none developed recurrence or metastasis. There were 54 (60%) tumors\u00a0>\u00a06\u00a0cm and 36 (40%) tumors\u00a0\u2264\u00a06\u00a0cm. All 12 PASS parameters were individually present in higher frequency in the>6-cm group; but the difference was not statistically significant except cellular monotony (p\u00a0=\u00a00.02). Overall, a PASS\u00a0\u2264\u00a04 was found in 57 patients. Mean PASS was statistically significantly higher in the>6-cm group (4.4 vs. 3.3, p\u00a0=\u00a00.04). Of the sporadic benign cases, 21 (41%) patients with tumor size\u00a0>\u00a06\u00a0cm had a PASS of>4, and none of them developed metastasis. PASS\u00a0\u2264\u00a04 was found in 25 (81%) PCC in the \u22646-cm group, and none developed metastases. PASS\u00a0\u2265\u00a04 was found in six (19%) patients in the \u22646-cm group, and none developed metastases. 68 patients completed 5-year follow-up, and the remaining had a mean follow-up of 28.7\u00a0months. No correlation was found between tumor size and PASS\u00a0>\u00a04 and PASS\u00a0\u2264\u00a04 (7.8\u00a0cm vs. 7.1\u00a0cm; p\u00a0=\u00a00.23).\nQuestion: Size of the tumor and pheochromocytoma of the adrenal gland scaled score (PASS): can they predict malignancy?",
        "gt": "Presently there is not enough evidence to indict a large (>6\u00a0cm) PCC as malignant. Furthermore, PASS cannot be reliably applied to PCC for predicting malignancy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Follicular fluid was collected from 58 patients undergoing oocyte retrieval for IVF. Ovulation was induced with GnRH analogues and gonadotropins. Follicular fluids of mature follicles (>17 mm) were aspirated and pooled for each patient. Follicular fluid steroid hormone levels (E2, P) and VEGF, inhibin A, inhibin B concentrations were studied. The serum levels of E2, P and VEGF were also assessed on the day of the oocyte retrieval. These parameters and characteristics of the cycles were compared between the pregnant (group 1) and non pregnant (group 2) patients. The serum and FF VEGF levels were found to be significantly lower in the group in whom the pregnancy was achieved (P<0.001). The FF inhibin A and FF inhibin B were found to be significantly higher in pregnant group (P<0.001). However, age, day 3 FSH, dosage of gonadotropin administered, fertilization rate, sperm count, motile and morphologically normal sperm percentage were not significantly different in the two groups. There was an negative correlation between VEGF and number of follicles, number of oocytes, FF inhibin A, FF inhibin B. The number of oocytes retrieved, the fertilization rate were positively correlated with FF inhibin B and FF inhibin A.\nQuestion: Follicular fluid concentrations of vascular endothelial growth factor, inhibin A and inhibin B in IVF cycles: are they markers for ovarian response and pregnancy outcome?",
        "gt": "This study demonstrated that decreased FF VEGF, serum VEGF and elevated FF inhibin A and B are associated with better ovarian response and high pregnancy rate.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Data shows vanadium protects pancreatic beta cells (BC) from diabetic animals. Whether this effect is direct or through the relief of glucose toxicity is not clear. This study evaluated the potential effect of oral vanadyl sulfate (vanadium) on glycemic status and pancreatic BC of normal and diabetic rats. Rats were divided into five groups of normal and diabetic. Diabetes was induced with streptozocin (40 mg/kg, i.v.). Normal rats used water (CN) or vanadium (1 mg/ml VOSO4, VTN). Diabetic rats used water (CD), water plus daily neutral protamine Hagedorn insulin injection (80 U/kg, ITD) or vanadium (VTD). Blood samples were taken for blood glucose (BG, mg/dL) and insulin (ng/dL) measurements. After two months, the pancreata of sacrificed rats were prepared for islet staining. Pre-treated normal BG was 88 \u00b1 2, and diabetic BG was 395 \u00b1 9. The final BG in CD, VTD, and ITD was 509 \u00b1 22, 138 \u00b1 14, and 141 \u00b1 14, respectively. Insulin in VTN (0.75 \u00b1 0.01) and VTD (0.78 \u00b1 0.01) was similar, higher than CD (0.51 \u00b1 0.07) but lower than CN (2.51 \u00b1 0.02). VTN islets compared to CN had larger size and denser central core insulin immunoreactivity with plentiful BC. CD and ITD islets were atrophied and had scattered insulin immunoreactivity spots and low BC mass. VTD islets were almost similar to CN.\nQuestion: Does the relief of glucose toxicity act as a mediator in proliferative actions of vanadium on pancreatic islet beta cells in streptozocin diabetic rats?",
        "gt": "Besides insulin-like activity, vanadium protected pancreatic islet BC, and the relief of glucose toxicity happening with vanadium had a little role in this action.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: At depths below 10 m, reefs are dominated by blue-green light because seawater selectively absorbs the longer, 'red' wavelengths beyond 600 nm from the downwelling sunlight. Consequently, the visual pigments of many reef fish are matched to shorter wavelengths, which are transmitted better by water. Combining the typically poor long-wavelength sensitivity of fish eyes with the presumed lack of ambient red light, red light is currently considered irrelevant for reef fish. However, previous studies ignore the fact that several marine organisms, including deep sea fish, produce their own red luminescence and are capable of seeing it. We here report that at least 32 reef fishes from 16 genera and 5 families show pronounced red fluorescence under natural, daytime conditions at depths where downwelling red light is virtually absent. Fluorescence was confirmed by extensive spectrometry in the laboratory. In most cases peak emission was around 600 nm and fluorescence was associated with guanine crystals, which thus far were known for their light reflecting properties only. Our data indicate that red fluorescence may function in a context of intraspecific communication. Fluorescence patterns were typically associated with the eyes or the head, varying substantially even between species of the same genus. Moreover red fluorescence was particularly strong in fins that are involved in intraspecific signalling. Finally, microspectrometry in one fluorescent goby, Eviota pellucida, showed a long-wave sensitivity that overlapped with its own red fluorescence, indicating that this species is capable of seeing its own fluorescence.\nQuestion: Red fluorescence in reef fish: a novel signalling mechanism?",
        "gt": "We show that red fluorescence is widespread among marine fishes. Many features indicate that it is used as a private communication mechanism in small, benthic, pair- or group-living fishes. Many of these species show quite cryptic colouration in other parts of the visible spectrum. High inter-specific variation in red fluorescence and its association with structures used in intra-specific signalling further corroborate this view. Our findings challenge the notion that red light is of no importance to marine fish, calling for a reassessment of its role in fish visual ecology in subsurface marine environments.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Late-life depression is associated with increased subcortical white matter hyperintensities. There is some evidence that they are associated with a poorer response to acute treatment. Neurological signs and neuropsychological dysfunction are further evidence of abnormalities in the brain, but they have not been studied in relation to therapy resistance. A prospective study of 24 normal controls and 75 consecutive elderly (aged 65 to 85) patients with DSM-III-R major depression entered a naturalistic study of treatment. Assessment of response to monotherapy and then lithium augmentation or ECT created three outcome groups. Investigations included magnetic resonance brain imaging, neuropsychological and neurological examination. Response to monotherapy within 12 weeks was shown by 42.7%, a further 37.3% responded to lithium augmentation or ECT within 24 weeks and 20% had responded poorly to all treatments at 24 weeks. Subcortical hyperintensities were significantly increased in the more resistant patients. These included confluent deep white matter, multiple (>5) basal ganglia lesions and pontine reticular formation lesions. Most of the neuropsychological impairment was restricted to the resistant groups and was of a subcortico-frontal type. Extrapyramidal, frontal and pyramidal neurological signs characterized the resistant groups. The combination of extrapyramidal signs, pyramidal tract signs and impairment of motor hand sequencing strongly predicted resistance to 12 weeks of antidepressant monotherapy with 89% sensitivity and 95% specificity.\nQuestion: Is subcortical disease associated with a poor response to antidepressants?",
        "gt": "In late-life depression a poor response to antidepressant monotherapy can be expected in those patients with a frontal lobe syndrome, extrapyramidal signs or if MRI T2-weighted lesions are present in both the basal ganglia and the pontine reticular formation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Studies show that stroke survivors typically have lower life satisfaction than persons who have not been diagnosed with stroke. To determine if significant differences in life satisfaction exist between stroke survivors with and without functional limitations and whether specific functional limitations, as well as participation in outpatient rehabilitation affect the odds of reported life satisfaction for stroke survivors. Chi square analysis was used to examine data from the 2013 BRFSS to determine the relationship of functional limitations as well as participation in rehabilitation services to life satisfaction for stroke survivors. Logistic regression analysis was used to determine what variables increased the odds of reported poor life satisfaction. Stroke survivors experiencing difficulty with cognition, depression and IADLs showed significantly lower life satisfaction than those who did not experience these functional limitations. Survivors exhibiting activity limitations had almost twice the odds of reporting poor life satisfaction and those experiencing limitations in cognition and IADLs had 2.88 times and 1.81 times the odds as others without these limitations of reporting poor life satisfaction, respectively. Participation in outpatient rehabilitation reduced the odds of reporting of poor life satisfaction by approximately one half.\nQuestion: Does type of disability and participation in rehabilitation affect satisfaction of stroke survivors?",
        "gt": "Rehabilitation focused on addressing these functional limitations would increase life satisfaction for persons diagnosed with stroke. Future research on specific types of cognitive and daily living limitations would assist policy makers and referral sources in making appropriate referrals to rehabilitation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The objective of this national survey was to describe the routine use of procedures and technologies in Canadian hospitals providing maternity care, and to determine the extent to which current use was consistent with the existing evidence and recommended guidelines for maternal and newborn care. Representatives of 572 hospitals providing maternity care across Canada were sent questionnaires in the spring and summer of 1993; 523 (91.4%) responded. The primary outcome measures consisted of the self-reported use of obstetric procedures and technologies (perineal shaves, enemas/suppositories, intravenous infusions, initial and continuous electronic fetal heart monitoring, episiotomy rates). Hospitals were grouped according to location, size (number of live births per year), and university affiliation status. The hospitals in the Prairie provinces, in Quebec, and in the Atlantic provinces were significantly less likely than those in Ontario to restrict their use of perineal shaves and enemas to women on admission in labor. Small hospitals were significantly more likely than large hospitals (>1000 live births) to restrict their use of intravenous infusions, and initial and continuous electronic fetal monitoring. The university-affiliated and nonteaching hospitals were significantly less likely than the university teaching hospitals to have episiotomy rates of less than 40 percent for primiparous women. Small hospitals were more likely than large hospitals to report episiotomy rates of less than 20 percent for multiparous women.\nQuestion: A national survey of use of obstetric procedures and technologies in Canadian hospitals: routine or based on existing evidence?",
        "gt": "Considerable variations occur in the routine use of obstetric procedures and technologies in Canadian hospitals providing maternity care, according to hospital location, size, and university affiliation status. Despite the existing evidence suggesting that the routine use of these practices and procedures is both unnecessary and potentially harmful, a significant number of Canadian hospitals continued to use them routinely in 1993.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Initial classification of diabetes of young may require revision to improve diagnostic accuracy of different forms of diabetes. The aim of our study was to examine markers of beta-cell autoimmunity in a cohort of young (0-25 years) patients with type 1 diabetes and compare the presentation and course of the disease according to the presence of pancreatic antibodies. Cross-sectional population-based study was performed covering 100% of pediatric (n\u2009=\u2009860) and 70% of 18-25 years old adult patients (n\u2009=\u2009349) with type 1 diabetes in Lithuania. No antibodies (GAD65, IA-2, IAA and ICA) were found in 87 (7.5%) cases. Familial history of diabetes was more frequent in those with antibodies-negative diabetes (24.1 vs. 9.4%, p\u2009<\u20090.001). Gestational age, birth weight and age at diagnosis was similar in both groups. Ketosis at presentation was more frequent in patients with autoimmune diabetes (88.1 vs. 73.5%, p\u2009<\u20090.05). HbA1c at the moment of investigation was 8.6 (3) vs. 8.7 (2.2)% in antibodies-negative and antibodies-positive diabetes groups, respectively, p\u2009>\u20090.05. In the whole cohort, neuropathy was found in 8.8% and nephropathy - in 8.1% of cases, not depending on autoimmunity status. Adjusted for age at onset, disease duration and HbA1c, retinopathy was more frequent in antibodies-negative subjects (13.8 vs. 7.8%, p\u2009<\u20090.05).\nQuestion: The course of diabetes in children, adolescents and young adults: does the autoimmunity status matter?",
        "gt": "Antibodies-negative pediatric and young adult patients with type 1 diabetes in this study had higher incidence of family history of diabetes, higher frequency of retinopathy, less frequent ketosis at presentation, but similar age at onset, HbA1c,\u00a0incidence of nephropathy and neuropathy compared to antibodies-positive patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adherence to drug treatment and health-related quality of life (HRQL) are two distinct concepts. Generally one would expect a positive relationship between the two. The purpose of this study was to assess the relationship between adherence and HRQL. HRQL was measured using the physical and mental summary measures of the RAND-12 (PHC-12, MHC-12), the SF-12 (PCS-12, MCS-12), HUI-2 and HUI-3. Adherence was assessed using Morisky's instrument. Three longitudinal datasets were used. One dataset included 100 hypertensive patients. Another dataset covered 199 high risk community-dwelling individuals. The third dataset consisted of 365 elderly patients. Spearman's correlation coefficients were used to assess association. Subgroup analyses by type of medication and inter-temporal analyses were also performed. Correlation between adherence and PHC-12 ranged from 0.08 (p = 0.26) to 0.22 (p<0.01). Correlations between adherence and MHC-12 ranged from 0.11 (p = 0.11) to 0.15 (p<0.01). Similar results were observed using HUI-2, HUI-3, and SF-12 as well as by type of medication and in the lagged analyses.\nQuestion: Is adherence to drug treatment correlated with health-related quality of life?",
        "gt": "Correlations between HRQL and adherence were positive but typically weak or negligible in magnitude.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Fetuin-A is a circulating inhibitor of ectopic calcification. Low plasma levels have been associated in some studies with increased vascular calcification, aortic stiffness and mortality in patients with Chronic Kidney Disease (CKD). However, there are other studies examining the association of fetuin-A with vascular parameters and mortality, which do not show these associations. These conflicting data may be explained by methodological differences. We compared plasma fetuin-A measurements made with two widely-used commercial fetuin-A ELISA kits (Biovendor, Modrice, Czech Republic; Epitope Diagnostics Inc., San Diego, US) in samples from patients with and without CKD. We evaluated the effect of differences in fetuin-A glycosylation status on assay specificity. Deming regression analysis showed poor agreement between methods (for CKD cohort: y=-0.05+2.52x, S(y|x)=0.099g/L, R(2)=0.694). The Epitope Diagnostics kit demonstrated significant positive bias and greater specificity for deglycosylated fetuin-A relative to the Biovendor assay.\nQuestion: Poor agreement between commercial ELISAs for plasma fetuin-A: An effect of protein glycosylation?",
        "gt": "The apparently contradictory nature of reports of the association of fetuin-A with biological variables may reflect differences in the specificity of different ELISA methods for glycosylated plasma fetuin-A.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to evaluate therapy response in patients undergoing cetuximab-CapIri-based chemoradiation for rectal cancer using dynamic magnetic resonance imaging (dMRI). The volumetric degree of tumor regression and contrast media perfusion were compared to the results of the histopathologic ypTN staging. 33 patients were examined using a 1.5-T scanner with repetitive 2D FLASH sequences after contrast media application. All patients were examined twice - before therapy and immediately before surgery. In all patients, the tumor volume decreased (mean 72 +/- 16%). In 25/33 patients, the slope of the contrast media enhancement curve decreased (mean 31 +/- 20%). In histopathologically proven downstaging after therapy, the decrease in slope was significantly higher than in the group without downstaging, and the decrease in slope was better for distinguishing between 'responder' and 'non-responder' than the decrease in volume.\nQuestion: Can dynamic MR imaging predict response in patients with rectal cancer undergoing cetuximab-based neoadjuvant chemoradiation?",
        "gt": "Using dMRI helps to identify responders undergoing cetuximab-based chemoradiation better than volume decrease alone.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether the time of dosing (morning or evening) affects the tolerability or efficacy of tamsulosin in the treatment of lower urinary tract symptoms. Data were analysed from an open-label, observational study in which patients were treated with 0.4 mg tamsulosin once daily for 12 weeks. Treatment effects were determined using the Benign Prostatic Hyperplasia Impact Index, the quality-of-life question of the International Prostate Symptom Score, a similarly phrased question about sexual satisfaction, the maximum urinary flow rate, the postvoid residual urine volume, and the overall efficacy and tolerability. The results were analysed statistically for differences between dosing times, using analysis of covariance for the quantitative variables and logistic regression for the qualitative variables. While no specific recommendation about the dosing time was given in the trial, the retrospective analysis showed that 4420 and 2087 patients received tamsulosin in the morning and evening, respectively. Both groups had similar values for all variables before treatment. The efficacy and tolerability of tamsulosin treatment was also similar in both groups; there were small advantages for morning dosing, which were statistically significant because there were many patients.\nQuestion: Does the time of administration (morning or evening) affect the tolerability or efficacy of tamsulosin?",
        "gt": "In contrast to other alpha-blockers, night-time dosing is not necessary to improve the tolerability or efficacy of tamsulosin.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There are sporadic reports, with different verdicts, of restorative proctectomy by laparoscopic transanal pull-through (LTPT) without the use of a minilaparotomy for a part of the procedure. This study aimed to explore the applicability and advantages of LTPT with colon pouch-anal anastomosis for low rectal cancer, and to evaluate the results. From January 2002 to July 2003, 10 of 12 patients (6 men and 4 women) undergoing a laparoscopic procedure for low rectal cancer (<6 cm from the anal verge) underwent LTPT. The mean age of these patients was 58 years. The results have been compared with those for 12 similar non-pull-through procedures performed during the same period. There was no operative mortality. An anastomotic leakage and a hemorrhagic gastropathy occurred in the LTPT group. During a mean follow-up period of 18 months (range, 12-26 months), there was no local relapse. Four patients manifested moderate incontinence. No significant differences in functional outcome were observed between the LTPT and control groups.\nQuestion: Restorative proctectomy with colon pouch-anal anastomosis by laparoscopic transanal pull-through: an available option for low rectal cancer?",
        "gt": "The authors' experience supports use of the LTPT procedure with colonic pouch-anal anastomosis for selected lower rectal cancers with indications for a laparoscopic approach as an appropriate and reproducible surgical treatment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients' preferences for cardiopulmonary resuscitation (CPR) relate to their perception about the likelihood of success of the procedure. There is evidence that the lay public largely base their perceptions about CPR on their experience of the portrayal of CPR in the media. The medical profession has generally been critical of the portrayal of CPR on medical drama programmes although there is no recent evidence to support such views. To compare the patient characteristics, cause and success rates of cardiopulmonary resuscitation (CPR) on medical television drama with published resuscitation statistics. Observational study. 88 episodes of television medical drama were reviewed (26 episodes of Casualty, Casualty, 25 episodes of Holby City, 23 episodes of Grey's Anatomy and 14 episodes of ER) screened between July 2008 and April 2009. The patient's age and sex, medical history, presumed cause of arrest, use of CPR and immediate and long term survival rate were recorded. Immediate survival and survival to discharge following CPR. There were a total of 76 cardio-respiratory arrests and 70 resuscitation attempts in the episodes reviewed. The immediate success rate (46%) did not differ significantly from published real life figures (p=0.48). The resuscitation process appeared to follow current guidelines. Survival (or not) to discharge was rarely shown. The average age of patients was 36 years and contrary to reality there was not an age related difference in likely success of CPR in patients less than 65 compared with those 65 and over (p=0.72). The most common cause of cardiac arrest was trauma with only a minor proportion of arrests due to cardio-respiratory causes such as myocardial infarction.\nQuestion: Resuscitation on television: realistic or ridiculous?",
        "gt": "Whilst the immediate success rate of CPR in medical television drama does not significantly differ from reality the lack of depiction of poorer medium to long term outcomes may give a falsely high expectation to the lay public. Equally the lay public may perceive that the incidence and likely success of CPR is equal across all age groups.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Ultrasonography (US) is used in rheumatology to assess small joints in inflammatory arthritis. Recently there has been some investigation into the utility of US in osteoarthritis (OA), however there has been little comparison of US to other imaging modalities in OA. This study aimed to compare the detection of osteophytosis and joint space narrowing (JSN) by US and conventional radiography (CR) in OA of the hand. with OA of the hand underwent US and CR examination of the small joints of both hands to identify osteophytosis and joint space narrowing. 1106 joints of 37 patients were imaged with US and CR. US detected osteophytosis in 448 joints, compared to CR that detected osteophytosis in 228 joints (approximately 30% fewer joints). Where osteophytosis was detected by US but not CR, this was usually proximal to the joint line. Joint space narrowing was detected in 450 joints by US, but only 261 joints by CR. The distribution of US and CR detected osteoarthritis changes in this cohort was consistent with population studies of radiographic hand OA, although metacarpophalangeal (MCP) involvement was higher than might be expected\nQuestion: Can ultrasonography improve on radiographic assessment in osteoarthritis of the hands?",
        "gt": "US detected more osteophytosis and joint space narrowing than CR in OA of the hand. Involvement of MCP joints was more common than would be expected from population radiographic studies. The increased detection of OA structural pathology by US may make this a useful tool for hand OA research.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Lung tissue is metabolically active and consumes oxygen. The oxygen content difference between arterial and mixed venous blood does not include the effect of pulmonary tissue oxygen uptake. Thus, oxygen consumption (VO2) of the lung should be reflected as a difference between VO2 measured by gas exchange and VO2 derived by the Fick principle. The purpose of this study was to measure in clinical conditions this difference (taken to represent the VO2 of the lung), and to evaluate the sources of error in lung VO2 estimation. Nine patients undergoing coronary artery bypass grafting were studied. VO2 was measured by indirect calorimetry (VO2gasex) and compared to Fick-derived VO2 (VO2Fick) after induction of anaesthesia, after closure of the chest, at admission to intensive care, after stabilization of haemodynamics and during weaning from mechanical ventilation. The Fick-derived VO2 was calculated from blood samples taken at the beginning and at the end of each 20 min measurement period, and the mean of 12 consecutive thermodilution cardiac output measurements taken during each 20 min measurement period. VO2gasex was higher than VO2Fick (P<0.01; in all except 4 of 45 measurements). The difference between the measured and the calculated VO2 was 33 +/- 25 ml/min (mean +/- SD, range -16-100 ml/min). This difference represented 14 +/- 3% (range 11-18%) of the whole body VO2. The VO2-difference was highest after the induction of anaesthesia (50 +/- 19 ml/min; range 20-41 ml/min, P<0.03) and lowest on arrival at the intensive care unit (10 +/- 16 ml/min; range -16-39 ml/min). Core temperature did not correlate with the oxygen consumption difference.\nQuestion: Calculated versus measured oxygen consumption during and after cardiac surgery. Is it possible to estimate lung oxygen consumption?",
        "gt": "A constant difference between measured and calculated VO2 can be detected in carefully controlled clinical conditions. The difference between the two methods is due to both lung oxygen consumption and errors in the measurement of VO2 thermodilution cardiac output, haemoglobin and blood oxygen contents. We suggest that the perioperative changes of the VO2-difference are due not only to variation of the measurements but also to changes in lung metabolic activity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate differences in second-, third-, and fourth-year medical students' knowledge of bloodborne pathogen exposure risks, as well as their attitudes toward, and intentions to comply with, Universal Precautions (UP). Cross-sectional survey. Surveys about students' knowledge, attitudes, and intentions to comply with UP were completed by 111 second-year (preclinical), 80 third-year, and 60 fourth-year medical students at Washington University School of Medicine in the spring of 1996. Preclinical students knew more than clinical students about the efficacy of hepatitis B vaccine, use of antiretroviral therapy after occupational exposure to human immunodeficiency virus, and nonvaccinated healthcare workers' risk of infection from needlestick injuries (P<.001). Students' perceived risk of occupational exposure to bloodborne pathogens and attitudes toward hepatitis B vaccine did not differ, but preclinical students agreed more strongly that they should double glove for all invasive procedures with sharps (P<.001). Clinical students agreed more strongly with reporting only high-risk needlestick injuries (P=.057) and with rationalizations against using UP (P=.008). Preclinical students more frequently reported contemplating or preparing to comply with double gloving, wearing protective eyewear, reporting all exposures, and safely disposing of sharps, whereas students with clinical experience were more likely to report compliance. Clinical students also were more likely to report having \"no plans\" to practice the first three of these precautions (P<.001).\nQuestion: Does clinical experience affect medical students' knowledge, attitudes, and compliance with universal precautions?",
        "gt": "Differences in knowledge, attitudes, and intentions to comply with UP between students with and without clinical experience may have important implications for the timing and content of interventions designed to improve compliance with UP.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Disease in the musculoskeletal system accounts for the largest proportion of chronic disease in Denmark, and the associated costs amount to billions of kroner every year. Prevention and treatment have focussed on exercise and training. Training in fitness centres is one of the most popular forms of exercise in Denmark and the number of users is increasing rapidly. We suspect that musculoskeletal problems are common among members of fitness centres, and that good communication between the centres and the health care sector would optimize treatment. The purpose of the present study is to describe the extent of musculoskeletal problems among members of fitness centres and the degree of communication between the centres and the health care sector. Information regarding age, sex, musculoskeletal complaints, possible treatment, and whether there had been any communication between health care providers and the fitness centres before or during the period of training was collected among members of five fitness centres in Denmark. 485 (94%) out of a total of 516 members participated in the study. 56% reported that they had one or more musculoskeletal problem when joining the centre. Out of these, 77% stated that musculoskeletal problems were the main or a contributing reason for joining the centre. More than half the participants with musculoskeletal complaints had received some kind of treatment within the previous year. However, communication between health care providers and fitness centres was uncommon.\nQuestion: Are fitness centres part of the health care sector?",
        "gt": "The fitness sector is growing rapidly and more than 50% of members suffer from musculoskeletal problems. Most of these also receive treatment for their problems but there is very little and almost no formal communication between the health care sector and the fitness centres.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The optimal medical or surgical therapy and outcome of enterococcal prosthetic joint infection are unknown. We performed a retrospective cohort study involving all patients with enterococcal total hip or knee arthroplasty infection treated at our institution from 1969 through 1999. The outcome for patients treated with combination systemic antimicrobial therapy (a cell wall-active agent and an aminoglycoside) versus monotherapy with a cell wall-active agent was analyzed. Fifty episodes of prosthetic joint infection due to enterococci occurred in 47 patients. The median duration of follow-up was 1253 days (range, 29-4610 days). The median age at the time of diagnosis was 70 years (range, 32-89 years). Fifty percent of episodes (25 of 50 episodes) occurred in male patients; 48% (24 of 50 episodes) involved total hip or knee arthroplasty. The estimate of 2-year survival free of treatment failure was 94% (95% confidence interval [CI], 83%-100%) for patients treated with 2-stage exchange, 76% (95% CI, 58%-100%) for patients treated with resection arthroplasty, and 80% (95% CI, 51.6%-100%) for patients treated with debridement and retention of the components (P=.9). The overall rate of 2-year survival free of treatment failure was 88% (95% CI, 77%-100%) for patients treated with monotherapy and 72% (95% CI, 54%-96%) for patients treated with combination therapy (P=.1). The development of cranial nerve VIII toxicity was significantly more common among patients receiving combination therapy (P=.002). Nephrotoxicity was more frequent in the combination therapy group (occurring in 26% of episodes; P=.09).\nQuestion: Outcome of enterococcal prosthetic joint infection: is combination systemic therapy superior to monotherapy?",
        "gt": "Enterococcal prosthetic joint infection is uncommon at our institution. Patients receiving combination therapy and those receiving monotherapy did not differ with respect to outcome. There were more cases of ototoxicity in the combination therapy group than there were in the monotherapy group.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Muscarinic antagonists such as tolterodine are the treatment of choice for overactive bladder (OAB). We determined the impact of concomitant stress incontinence (SI) on the therapeutic effects of tolterodine in patients with OAB with and without concomitant SI. Data from an open label, observational study involving 2,250 patients with OAB symptoms were analyzed for baseline frequency, urgency and incontinence, and alterations in these symptoms while on 12-week treatment with 2 mg tolterodine twice daily. Data are shown as the mean +/- SD. The statistical significance of differences in treatment effects was determined by multiple regression analysis, adjusting for gender, age and baseline symptom intensity. Concomitant I to III degree SI according to the Stamey grading was present in 31%, 15% and 2% of patients, respectively, and it was associated with increasing basal incontinence, although only III degree SI was associated with greater baseline frequency or urgency. In the overall group tolterodine decreased frequency, urgency and urge incontinence from 12.4 +/- 4.3 to 7.7 +/- 2.7, 8.4 +/- 5.1 to 2.0 +/- 3.0 and 3.4 +/- 4.2 to 0.8 +/- 2.0 episodes daily, respectively. On multiple linear regression analysis I and II degree SI had a minor, if any, effect on this improvement, while III degree SI was statistically associated with a smaller decrease in frequency (by 1.4 +/- 0.4 micturitions daily, p = 0.0002) and incontinence (by 2.1 +/- 0.3 episodes daily, p<0.0001) but with similar alterations in the number of urge episodes.\nQuestion: Does concomitant stress incontinence alter the efficacy of tolterodine in patients with overactive bladder?",
        "gt": "Concomitant I or II degree SI has little effect on the efficacy of tolterodine in OAB cases. Only patients with concomitant III degree SI have significantly less improvement.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The published articles examining obesity and CABG surgery contain conflicting results about the role of body mass index (BMI) as a risk factor for in-hospital mortality. We studied 16 218 patients who underwent isolated CABG in the Providence Health System Cardiovascular Study Group database from 1997 to 2003. The effect of BMI on in-hospital mortality was assessed by logistic regression, with BMI group (underweight, normal, overweight, and 3 subgroups of obesity) as a categorical variable or transformations, including fractional polynomials, of BMI as a continuous variable. BMI was not a statistically significant risk factor for mortality in any of these assessments. However, using cumulative sum techniques, we found that the lowest risk-adjusted CABG in-hospital mortality was in the high-normal and that overweight BMI subgroup patients with lower or higher BMI had slightly increased mortality.\nQuestion: Is obesity a risk factor for mortality in coronary artery bypass surgery?",
        "gt": "Body size is not a significant risk factor for CABG mortality, but the lowest mortality is found in the high-normal and overweight subgroups compared with obese and underweight.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Sustained efforts have not attenuated racial and ethnic disparities in unintended pregnancy and effective contraceptive use in the United States. The roles of attitudes toward contraception, pregnancy and fertility remain relatively unexplored. Knowledge of contraceptive methods and attitudes about contraception, pregnancy, childbearing and fertility were assessed among 602 unmarried women aged 18-29 at risk for unintended pregnancy who participated in the 2009 National Survey of Reproductive and Contraceptive Knowledge. The contribution of attitudes to racial and ethnic disparities in effective method use was assessed via mediation analysis, using a series of regression models. Blacks and Latinas were more likely than whites to believe that the government encourages contraceptive use to limit minority populations (odds ratio, 2.5 for each). Compared with white women, Latinas held more favorable attitudes toward pregnancy (2.5) and childbearing (coefficient, 0.3) and were more fatalistic about the timing of pregnancy (odds ratio, 2.3); blacks were more fatalistic about life in general (2.0). Only one attitude, skepticism that the government ensures contraceptive safety, was associated with contraceptive use (0.7), but this belief did not differ by race or ethnicity. Although blacks and Latinas used less effective methods than whites (0.3 and 0.4, respectively), attitudes did not explain disparities. Lower contraceptive knowledge partially explained Latinas' use of less effective methods.\nQuestion: Do racial and ethnic differences in contraceptive attitudes and knowledge explain disparities in method use?",
        "gt": "Providing basic information about effective methods might help to decrease ethnic disparities in use. Research should examine other variables that might account for these disparities, including health system characteristics and provider behavior.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Loss of voluntary contraction of the external anal sphincter is thought to be a factor in fecal incontinence. During anal manometry, computerized systems produce several parameters including fatigue rate (FR), which is the basis for calculating the fatigue rate index (FRI). Our aim was to evaluate FR and FRI and their clinical importance in patients suffering from fecal incontinence or severe constipation. All patients scheduled for an anal physiology work-up were included in the study. FR was determined by a computer program and FRI was calculated manually with the following equation: FRI (minutes) = [squeeze pressure (mm Hg) - resting pressure (mmHg)] / - FR (mmHg/min). FR and FRI were compared in patients suffering from fecal incontinence (group I) and severe constipation (group II). Furthermore, subgroups (<50 and>or = 50 years of age) were compared. Lastly, a possible relation between length of the high-pressure zone (HPZ) and FR and FRI was assessed. Between January 2000 and December 2004, 131 patients (96 with fecal incontinence, 35 with constipation) were studied. Both FR and FRI were similar between groups I and II; no significant differences were found when younger and older patients were compared within the same group. We also did not find any relation between HPZ length and either FR or FRI.\nQuestion: Anorectal manometry: are fatigue rate and fatigue rate index of any clinical importance?",
        "gt": "FR and FRI do not seem to be helpful in routine colorectal practice for evaluating the strength of the external anal sphincter.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Practice-based Internet communication allows patients to obtain health information, ask questions, and submit requests through a personalized Web site. While such online tools also bring great promise for educating patients with the goal of fostering behavior change, it is important to examine how individuals currently using such services differ from those who do not. The study used administrative information to characterize a population of patients communicating with a medical practice through the Internet during the end of 1999 and through 2000. Patient claims data generated during clinical encounters from January 1999 through May 2000 were examined to measure the relationship between patient demographics, frequency of visits, specific acute diagnoses, and specific chronic diagnoses and the use of online communication with the practice. Ten percent of patients, and 13.2% of patients 18 years or older, used the practice Web site. There were differences in use of the practice Web site by age and insurance status, but not by gender. Use of the practice Web site was similar or higher among patients having a diagnosis for a variety of acute and chronic conditions compared to those not having such a diagnosis. Patients with more clinic visits were more likely to use the Web-based service.\nQuestion: Using claims data to examine patients using practice-based Internet communication: is there a clinical digital divide?",
        "gt": "Patients using practice-based Internet communication and having significant health risks can be identified through the use of administrative data, presenting an opportunity to test online educational efforts to improve health.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Anti-beta(2)-Glicoprotein-1 antibodies (anti-beta(2)GPI-ab) have been related to recurrent miscarriage (RM) with conflicting results. The aim was to evaluate the role of anti-beta(2)-GPI-ab as unique biological marker in RM related to antiphospholipid (aPL). A cohort study that included 59 cases, divided in two groups, was designed: group 1 comprised 43 pregnant women with 'obstetric' antiphospholipid syndrome (APS) and group 2 included 16 cases with similar complaints but only having repeatedly anti-beta(2)-GPI-ab. Previous thrombosis and/or inherited thrombophilia were excluded. Lupus anticoagulant, anticardiolipin antibodies (aCA), anti-beta(2)-GPI-ab, and other autoantibodies were analyzed. Miscarriages, premature births, pre-eclampsia, live births, placental and systemic thromboses were studied. No differences in previous obstetric complications were detected (P = 1.00-0.164). After the treatment, differences in number of obstetric complications were not seen (P = 1.00). Live births were similar in two groups (88.4% and 93.7%; P = 1.00). Placental thrombosis was equal in both groups, 93.3% versus 80% (P = 1.00).\nQuestion: Are anti-beta-glycoprotein-I antibodies markers for recurrent pregnancy loss in lupus anticoagulant/anticardiolipin seronegative women?",
        "gt": "These results suggest that anti-beta(2)-GPI-ab may be considered a biological marker for obstetric APS.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The following study was conducted to identify risk factors for a postoperative CSF leak after vestibular schwannoma (VS) surgery. The authors reviewed a prospectively maintained database of all patients who had undergone resection of a VS at the Mayo Clinic between September 1999 and May 2013. Patients who developed a postoperative CSF leak within 30 days of surgery were compared with those who did not. Data collected included patient age, sex, body mass index (BMI), tumor size, tumor side, history of prior tumor treatment, operative time, surgical approach, and extent of resection. Both univariate and multivariate regression analyses were performed to evaluate all variables as risk factors of a postoperative CSF leak. A total of 457 patients were included in the study, with 45 patients (9.8%) developing a postoperative CSF leak. A significant association existed between increasing BMI and a CSF leak, with those classified as overweight (BMI 25-29.9), obese (BMI 30-39.9), or morbidly obese (BMI\u226540) having a 2.5-, 3-, and 6-fold increased risk, respectively. Patients undergoing a translabyrinthine (TL) approach experienced a higher rate of CSF leaks (OR 2.5, 95% CI 1.3-4.6; p=0.005), as did those who had longer operative times (OR 1.04, 95% CI 1.02-1.07; p=0.0006). The BMI, a TL approach, and operative time remained independent risk factors on multivariate modeling.\nQuestion: Are there modifiable risk factors to prevent a cerebrospinal fluid leak following vestibular schwannoma surgery?",
        "gt": "Elevated BMI is a risk factor for the development of a postoperative CSF leak following VS surgery. Recognizing this preoperatively can allow surgeons to better counsel patients regarding the risks of surgery as well as perhaps to alter perioperative management in an attempt to decrease the likelihood of a leak. Patients undergoing a TL approach or having longer operative times are also at increased risk of developing a postoperative CSF leak.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patient quality outcomes are a major focus of the health care industry. It is unknown what effect involvement in graduate medical education (GME) has on patient outcomes. The purpose of this study is to begin to examine whether GME involvement in postoperative care impacts patient quality outcomes. The retrospective cohort included all patients who underwent a nonemergent colectomy from January 1, 2007 to January 1, 2008 at a 2-hospital system. Data collected included patient demographics, patient quality outcomes, complications, and GME involvement. Patient quality outcomes were based on compliance with the Surgical Care Improvement Project (SCIP) guidelines. A total of 159 nonemergent colectomies were analyzed. The GME group accounted for 116 (73%) patients. A significant difference was found in several SCIP process-based measures of quality when comparing the GME group with the non-GME group. Postoperative antibiotics were more likely to be stopped within 24 hours (p = 0.010), and preoperative heparin and postoperative deep vein thrombosis (DVT) prophylaxis were more likely to be administered (p<0.001). Additionally, patients in the GME group showed improved quality outcomes as there were significantly fewer postoperative complications (p<0.001) and a shorter duration of stay (p = 0.008). The use of gastrointestinal prophylaxis was more common in the non-GME group (p = 0.002). No significant differences were observed between the 2 groups in respect to age, sex, diabetes, preoperative antibiotics, antibiotics, 1 hour before surgery, postoperative antibiotics, and continuation of home beta blockade.\nQuestion: Does participation in graduate medical education contribute to improved patient outcomes as outlined by Surgical Care Improvement Project guidelines?",
        "gt": "GME at teaching institutions has a positive impact on patient quality outcomes. At our institution, many of the SCIP measurable outcomes had improved compliance if an attending physician participated in the GME program.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In this study, we aimed to investigate the differences between a sample of migraineurs and non-migraineurs with regard to their stress symptoms, tendency to stress, coping styles and life satisfaction. This study was carried out on a migraineur group (n = 62, mean age: 37.5 +/- 11.3, range: 18 to 61 years) and a non-migraineur group (n = 58, mean age: 32.0 +/- 11.2, range: 18 to 61 years). Stress Audit (Symptoms), Stress Audit (Vulnerability), Turkish version of Ways of Coping Inventory Scales and Life Satisfaction were applied to the migraineur and non-migraineur groups. No significant differences were found between the groups in the scores of the stress symptoms except in the sub scores of the sympathetic system. There was no significant difference between the groups in the tendency to stress and life satisfaction (p>.05). For scores of the coping styles, the mean scores of the seeking social support subscale was higher in the control group than that of the migraineur group. However, migraineur women had higher mean scores in the submissive and the optimistic subscales.\nQuestion: Are migraineur women really more vulnerable to stress and less able to cope?",
        "gt": "We consider that, these outcomes may emphasize the necessity to be careful when using negative expressions about stress relating to migraineurs. Further comprehensive studies are required considering the multiple triggers of the disease in various cultural contexts.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess radiation dose to the thyroid in patients undergoing neurointerventional procedures and to evaluate dose reduction to the thyroid by lead shielding. A randomized patient study was undertaken to evaluate the dose reduction by thyroid lead shields and assess their practicality in a clinical setting. Sixty-five patients attending for endovascular treatment of arteriovenous malformations (AVMs) and aneurysms were randomized into one of 2 groups a) No Thyroid Shield and b) Thyroid Lead Shield. Two thermoluminescent dosimeters (TLDs) were placed over the thyroid gland (1 on each side) at constant positions on each patient in both groups. A thyroid lead shield (Pb eq. 0.5 mm) was placed around the neck of patients in the thyroid lead shield group after the neurointerventional radiologist had obtained satisfactory working access above the neck. The total dose-area-product (DAP) value, number and type of digital subtraction angiography (DSA) runs and fluoroscopy time were recorded for all patients. Of the 72 patients who initially attended for neurointerventional procedures, 7 were excluded due to failure to consent or because of procedures involving access to the external carotid circulation. Of the remaining 65 who were randomized, a further 9 were excluded due to; procedureabandonment, unfeasible shield placement or shield interference with the procedure. Patient demographics included mean age of 47.9 yrs (15-74), F:M=1.4:1. Mean fluoroscopy time was 25.9 min. Mean DAP value was 13,134.8 cGy x cm(2) and mean number of DSA runs was 13.4. The mean relative thyroid doses were significantly different (p<0.001) between the unshielded (7.23 mSv/cGy2 x 105) and shielded groups (3.77 mSv/cGy2 x 105). A mean thyroid dose reduction of 48% was seen in the shielded group versus the unshielded group.\nQuestion: Thyroid dose during neurointerventional procedures: does lead shielding reduce the dose?",
        "gt": "Considerable doses to the thyroid are incurred during neurointerventional procedures, highlighting the need for increased awareness of patient radiation protection. Thyroid lead shielding yields significant radiation protection, is inexpensive and when not obscuring the field of view, should be used routinely.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare personality traits of psychiatry residents with various characteristics. The authors administered Cloninger's personality inventory to residents at two schools. There were no trait differences between international medical graduates (IMGs) and U.S. medical graduates (USMGs) or those for whom psychiatry was a first or second choice.\nQuestion: Do the personalities of international and U.S. medical graduates in psychiatry differ?",
        "gt": "Perceived differences between IMG and USMG psychiatry residents appear unrelated to personality.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The authors examined whether patients with comorbid borderline personality disorder and posttraumatic stress disorder (PTSD) have a more severe clinical profile than patients with either disorder without the other. Outpatients with borderline personality disorder without PTSD (N=101), PTSD without borderline personality disorder (N=121), comorbid borderline personality disorder and PTSD (N=48), and major depression without PTSD or borderline personality disorder (N=469) were assessed with structured interviews for psychiatric disorders and for degree of impairment. Outpatients with diagnoses of comorbid borderline personality disorder and PTSD were not significantly different from outpatients with borderline personality disorder without PTSD, PTSD without borderline personality disorder, or major depression without PTSD or borderline personality disorder in severity of PTSD-related symptoms, borderline-related traits, or impairment.\nQuestion: Is comorbidity of posttraumatic stress disorder and borderline personality disorder related to greater pathology and impairment?",
        "gt": "The additional diagnosis of PTSD or borderline personality disorder does little to augment the pathology or dysfunction of patients who have either disorder without the other.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It has been suggested that the use of a short-stem prosthesis could conserve proximal bone by proximal load transfer. Proximal stress shielding should be reduced, a phenomenon that has been associated with bone resorption around traditional stems. Bone remodelling of a metaphyseal fixed stem (Nanos, Smith&Nephew Int.) was analysed by the dual-energy x-ray absorptiometry. This study included 36 patients undergoing the total hip replacement using the Nanos short stem in comparison to 36 patients operated by a traditional long-stemmed femoral stem (Alloclassic). In all cases a threaded cup was inserted. Both groups were not different in regard to the BMI or in regard to the quality of bone (BMI). The average age of the group of patients with the short-stem prosthesis was slightly younger (average 54.2 years [range: 29 to 75]) than the patient group with the long-stem prosthesis (average 61.1 years [range: 39 to 71]). A prospective clinical analysis was done by the Harris hip score (HHS) and the Sutherland score to evaluate the social quality of life. With a minimum follow-up of 12 months in all cases, radiological changes in regard to stem subsidence, periprosthetic osteolysis or linear radiolucencies were analysed. The changes of periprosthetic bone density were examined with DEXA in all patients 3 and 12 months postoperatively. No patients required reoperation because of loosening or subsidence of the short-stem prosthesis. The HHS improved from a mean of 43.1 (range: 9 to 51) to 96.5 points (range: 79 to 100) in the short-stem group and to 91.3 points (range: 61 to 100) in the group of patients with long-stemmed femoral component. Radiographic follow-up revealed no evidence of component loosening or migration of the short-stem. Along the greater trochanter an osteolysis of the bone structure was found in two cases. A decrease of the proximal periprosthetic bone density (Gruen zone I, -6.4%) and in zone VII (-7.2%) were measured. An increase of the BMD in the lateral inferior region (Gruen zone II, +9.7%) superior to the polished tip of the short stem was observed over a period of one year after implantation. At the polished tip of the prosthesis a significant change of bone density in zone III (+1.03%) and in zone V (+0.7%) could not be observed.\nQuestion: Is there a bone-preserving bone remodelling in short-stem prosthesis?",
        "gt": "The desired proximal load transfer of a short-stemmed implant in the metaphyseal region of the proximal femur could not be reached with this device. On the basis of the excellent clinical results of the patients operated with the Nanos short-stem prosthesis we conclude that the component induces bone ingrowth in the lateral/distal region of the proximal femur.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To study and compare the specific postoperative complications of thyroidectomy in a population with a BMI \u226525 with a population having a BMI below 25. A prospective study was carried out from September 2010 to January 2013. Postoperative calcemia, laryngeal mobility, bleeding or infectious complications, postoperative hospital stay, and operation time were studied and compared statistically by a \u03c7(2)-test or Student's t-test. A total of 240 patients underwent total thyroidectomy and 126 underwent a partial thyroidectomy. Of them, 168 patients had a BMI below 25 and 198 patients had a BMI \u226525. There was no statistically significant difference in the occurrence of early or permanent hypoparathyroidism, recurrent laryngeal nerve palsy, bleeding complications, or postoperative duration of hospital stay. There was, however, a significant operative time in patients with a BMI \u226525.\nQuestion: Thyroidectomy in patients with a high BMI: a safe surgery?",
        "gt": "Despite the longer operative time, thyroidectomy (total or partial) can be performed safely in patients with a BMI \u226525.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Venous blood is the usual sample for measuring various biomarkers, including 25-hydroxyvitamin D (25OHD). However, it can prove challenging in infants and young children. Hence the finger-prick capillary collection is an alternative, being a relatively simple procedure perceived to be less invasive. We elected to validate the use of capillary blood sampling for 25OHD quantification by liquid chromatography tandem-mass spectrometry (LC/MS-MS). Venous and capillary blood samples were simultaneously collected from 15 preschool-aged children with asthma 10days after receiving 100,000IU of vitamin-D3 or placebo and 20 apparently healthy adult volunteers. 25OHD was measured by an in-house LC/MS-MS method. The venous 25OHD values varied between 23 and 255nmol/l. The venous and capillary blood total 25OHD concentrations highly correlated (r(2)=0.9963). The mean difference (bias) of capillary blood 25OHD compared to venous blood was 2.0 (95% CI: -7.5, 11.5) nmol/l.\nQuestion: Assessing vitamin D nutritional status: Is capillary blood adequate?",
        "gt": "Our study demonstrates excellent agreement with no evidence of a clinically important bias between venous and capillary serum 25OHD concentrations measured by LC/MS-MS over a wide range of values. Under those conditions, capillary blood is therefore adequate for the measurement of 25OHD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To study which cut off point of DAS28 corresponds to fulfilment of the American Rheumatism Association (ARA) preliminary remission criteria, and clinical remission criteria in patients with rheumatoid arthritis (RA). All adult patients diagnosed with RA at Jyv\u00e4skyl\u00e4 Central Hospital 1997-98 were assessed for remission at 5 years. Remission was defined as (a) ARA remission; (b) clinical remission (defined as no tender or swollen joints and normal erythrocyte sedimentation rate). DAS28 was used to measure disease activity. A receiver operating characteristics curve analysis was performed to calculate a cut off point of DAS28 that best corresponds to the ARA remission criteria and the clinical remission criteria. 161 patients (mean age 57 years, 107 (66%) female, 98 (61%) with positive rheumatoid factor, and 51 (32%) with erosions) were studied. At 5 years, 19 (12%) patients met the ARA remission criteria, and 55 (34%) met the clinical remission criteria. The cut off value of DAS28 was 2.32 for the ARA remission criteria, and 2.68 for the clinical remission criteria. In patients with DAS28<2.32, 11/57 (19%) had tender joints, 6/57 (11%) had swollen joints, and 4/57 (7%) had both tender and swollen joints (66 joint count).\nQuestion: Is DAS28 an appropriate tool to assess remission in rheumatoid arthritis?",
        "gt": "In this study the DAS28 cut off point for the ARA remission was lower than in previous studies. The cut off point for DAS28 remission remains controversial. A substantial proportion of patients below the DAS28 cut off point for remission have tender or swollen joints, or both. DAS28 may not be an appropriate tool for assessment of remission in RA.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Questionnaire. Sisters/charge nurses were allocated patients in addition to being in charge of their ward for, on average, half of their shifts each week. Most of them did not have time to complete their managerial duties, which included supporting and supervising other staff on patient care issues. More than 50 per cent of the sisters/charge nurses did not have the time to attend clinical supervision.\nQuestion: Are ward sisters and charge nurses able to fulfil their role?",
        "gt": "Sisters/charge nurses treat clinical care--both delivering it directly themselves and advising other staff on its delivery--as a higher priority than their managerial and administrative duties; lack of time is a barrier to the successful fulfilment of their role.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Chronic pain is common in persons with multiple sclerosis (MS), but the co-morbidity of fibromyalgia (FM) has yet to be investigated in MS. Objectives of the study were to evaluate, among the various types of chronic pain, the frequency of FM in MS and its impact on MS patients' health-related quality of life (HRQoL). 133 MS patients were investigated for the presence and characterization of chronic pain within 1 month of assessment. A rheumatologist assessed the presence FM according to the 1990 ACR diagnostic criteria. Depression, fatigue, and HRQoL were also assessed by means of specific scales. Chronic pain was present in 66.2% of patients (musculoskeletal in 86.3%; neuropathic in 13.7%; absent in 33.8% [called NoP]). Pain was diagnosed with FM (PFM+) in 17.3% of our MS patients, while 48.9% of them had chronic pain not FM type (PFM-); the prevalence of neuropathic pain in these 2 sub-groups was the same. PFM+ patients were prevalently females and had a higher EDSS than NoP. The PFM+ patients had a more pronounced depression than in the NoP group, and scored the worst in both physical and mental QoL.\nQuestion: Chronic pain in multiple sclerosis: is there also fibromyalgia?",
        "gt": "In our sample of MS patients we found a high prevalence of chronic pain, with those patients displaying a higher disability and a more severe depression. Moreover, FM frequency, significantly higher than that observed in the general population, was detected among the MS patients with chronic pain. FM occurrence was associated with a stronger impact on patients' QoL.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The reuse of disposable laparoscopic instruments carries a risk of transmitting infectious diseases such as hepatitis and HIV. We evaluated the safety of reusing disposable trocars by studying the chances of their harboring infectious viruses after resterilization in an in vitro setting. Disposable laparoscopic trocars were exposed to horse blood contaminated with high or low viral concentrations of herpes simplex virus type 1 (HSV1) and attenuated polio virus type 1 at room temperature for 2 h. HSV1 was chosen as the surrogate for lipid viruses that include hepatitis B and HIV virus; polio virus represented the nonlipid viruses that cause infections in immunocompromised patients and are more resistant to sterilization. The trocars were subsequently cleaned and resterilized by low-temperature steam and formaldehyde at 80 degrees C for 3 h. Viral cultures were then repeated after sterilization. A cytopathic effect (CPE) was demonstrated at both concentrations for HSV1 in all trocars before but not after sterilization. For the polio virus, CPE was evident in 50% of the trocars (two of four) exposed to high viral concentration after sterilization.\nQuestion: Is it safe to reuse disposable laparoscopic trocars?",
        "gt": "Disposable trocars are difficult to resterilize and may harbor infectious viruses after their initial use. Therefore, the reuse of disposable trocars in laparoscopic surgery cannot be recommended.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Observed reductions in firearm suicides in Australia have been linked to the 1997 national firearms agreement (NFA) introduced following the 1996 Port Arthur massacre. The NFA placed strong access restrictions on firearms. To assess the impact of legislative restrictions on the incidence of firearm suicide in Queensland and explore alternative or contributory factors behind observed declines. The Queensland suicide register (QSR) provided detailed information on all male suicides in Queensland (1990-2004), with additional data for Australia (1968-2004) accessed from other official sources. Trends in suicide rates pre/post NFA, and in method selection, were assessed using negative binomial regressions. Changing method selection patterns were examined using a cohort analysis of 5 years of age classes for Australian males. The observed reduction in firearms suicides was initiated prior to the 1997 introduction of the NFA in Queensland and Australia, with a clear decline observed in Australian figures from 1988. No significant difference was found in the rate pre/post the introduction of the NFA in Queensland; however, a significant difference was found for Australian data, the quality of which is noticeably less satisfactory. A marked age-difference in method choice was observed through a cohort analysis demonstrating both time and age influences. Within sequential birth cohorts, rates of firearms suicides decreased in younger males but increased in hanging suicides; this trend was far less marked in older males.\nQuestion: Controlling firearms use in Australia: has the 1996 gun law reform produced the decrease in rates of suicide with this method?",
        "gt": "The implemented restrictions may not be responsible for the observed reductions in firearms suicide. Data suggest that a change in social and cultural attitudes could have contributed to the shift in method preference.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study evaluated the marginal quality of differently bonded direct resin composite restorations in enamel and dentin, before and after thermomechanical loading (TML). Special attention was focussed on the performance of selective enamel etching, etch-and-rinse, and self-etching adhesives. Eighty MO cavities with proximal margins beneath the cementoenamel junction were prepared in extracted human third molars. Direct resin composite restorations (Tetric EvoCeram, n=8) were placed with 4-step selective enamel etching (Syntac SE), 4-step etch-and-rinse (Syntac ER), 2-step etch-and-rinse (XP Bond, Scotchbond 1 XT/Single Bond Plus), 2-step self-etching (AdheSE, Clearfil SE Bond), 2-step self-etching with selective enamel etching (AdheSE SE, Clearfil SE Bond SE), and 2-step self-etching with etch-and-rinse (AdheSE TE, Clearfil SE Bond TE). Marginal gaps were analyzed using epoxy resin replicas under a scanning electron microscope at 200X magnification. Initially, high percentages of gap-free margins were identified for all adhesives. After TML, the results were as follows: (A) Enamel margins: When phosphoric acid was used on enamel, results were constantly higher (approximately 90%) compared with two-step self-etchin adhesives (approximately 70%; p<0.05). (B) Dentin margins: No statistical differences were found when etch-and-rinse and selective etch approaches were compared (59% to 64%; p>0.05). When self-etching adhesives were used as per manufacturers' directions, dentin margins exhibited the best marginal quality (74% to 82%; p<0.05). When self-etching adhesives were used under etch-and-rinse conditions, marginal quality in dentin was significantly reduced to 35% to 42% (p<0.05).\nQuestion: Selective enamel etching reconsidered: better than etch-and-rinse and self-etch?",
        "gt": "Enamel bonding was generally more effective with phosphoric-acid etching. Enamel bonding performance of 2-step self-etching adhesives was improved when phosphoric acid was applied on enamel selectively.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The Israeli National Health Insurance Law stipulates a National List of Health Services (NLHS) to which all residents are entitled from their HMOs. This list has been updated annually for almost a decade using a structured review and decision-making process. Although this process has been described in detail in previous papers, none of these have fully addressed legitimacy and fairness. We examine the legitimacy and fairness of the process of updating the NLHS in Israel. We assessed the priority-setting process for compliance with the four conditions of accountability for reasonableness outlined by Daniels and Sabin (relevance, publicity, appeals, and enforcement). These conditions emphasize transparency and stakeholder engagement in democratic deliberation. Our analysis suggests that the Israeli process for updating the NLHS does not fulfill the appeals and enforcement conditions, and only partially follows the publicity and relevance conditions, outlined in the accountability for reasonableness framework. The main obstacles for achieving these goals may relate to the large number of technologies assessed each year within a short time frame, the lack of personnel engaged in health technology assessment, and the desire for early adoption of new technologies.\nQuestion: The process of updating the National List of Health Services in Israel: is it legitimate?",
        "gt": "The process of updating the NLHS in Israel is unique and not without merit. Changes in the priority-setting process should be made to increase its acceptability among the different stakeholders.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Down syndrome is known to affect the natural history of complete atrioventricular septal defect. We analyzed whether Down syndrome affect the long-term results of complete atrioventricular septal defect when the defect is repaired during the first year of life. Repairs of complete atrioventricular septal defect were performed in 64 infants. Thirty-four infants were associated with Down syndrome, while the other 30 were non-Down patients. Complete follow-up rate was 95% with mean follow-up period of 99+/-47 months (maximum 169 months) in Down patients and 80+/-64 months (maximum 213 months) in non-Down patients. There was one operative death in each group (mortality rate of 2.9% in Down patients and 3.3% in non-Down patients), and three patients died at the late phase (one in Down patients and two in non-Down patients). Five patients underwent re-operation due to postoperative left atrioventricular valve regurgitation (one in Down patients and four in non-Down patients). Freedom from re-operation for left atrioventricular valve regurgitation and actuarial survival rate at 13 years were 96+/-4 and 94+/-4% in Down patients and 85+/-7 and 90+/-5% in non-Down patients (not significantly different).\nQuestion: Does Down syndrome affect the long-term results of complete atrioventricular septal defect when the defect is repaired during the first year of life?",
        "gt": "Down syndrome does not affect the long-term results of complete atrioventricular septal defect when the defect is repaired during the first year of life.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In recent years, hospital medicine programs have adopted \"procedure teams\" that supervise residents in performing invasive bedside procedures. The effect of procedure teams on patient satisfaction is unknown. We sought to measure patient satisfaction with procedures performed by a hospitalist-supervised, intern-based procedure service (HPS) with a focus on patient perception of bedside communication. This was a prospective survey. We surveyed all patients referred to the HPS for bedside thoracentesis, paracentesis, lumbar puncture, and arthrocentesis at a single academic medical center. Following each procedure, surveys were administered to English-speaking patients who could provide informed consent. Survey questions focused on patients' satisfaction with specific aspects of procedure performance as well as the quality and impact of communication with the patient and between members of the team. Of 95 eligible patients, 65 (68%) completed the survey. Nearly all patients were satisfied or very satisfied with the overall experience (100%), explanation of informed consent (98%), pain control (92%), and expertise (95%) of physicians. The majority of patients were satisfied with procedure duration (88%) and in those with therapeutic procedures most (89%) were satisfied with improvement in symptoms. Hearing physicians discuss the procedure at the bedside was reassuring to most patients (84%), who felt this to be a normal part of doing a procedure (94%).\nQuestion: Patient satisfaction with a hospitalist procedure service: is bedside procedure teaching reassuring to patients?",
        "gt": "Patients are highly satisfied with procedure performance by supervised trainees, and many patients were reassured by physician communication during the procedure. These results suggest that patient experience and teaching can be preserved with a hospitalist-supervised procedure service.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Diabetes requires substantial ongoing medical management and use of monitoring tests. However, physicians' performance of these tests is often suboptimal. This study explored primary care physicians' management of diabetes in the context of both planned diabetes visits and acute visits for conditions unrelated to diabetes. Semi-structured depth interviews were conducted with 12 primary care physicians in 9 family practice and internal medicine practices distributed throughout the state of South Carolina. All interviews were tape recorded and transcribed. Themes, divergences, and trends were identified and discussed by the investigators. Although all participants reported a preference toward planned diabetes management, because most patients fail to adhere to scheduled care, opportunistic disease management tended to be the default mode of diabetes care. Participants reported performing appropriate tests during scheduled visits but acknowledged that when confined to acute visits, diabetes care was difficult to perform. Reasons included time constraints and patient agenda. Participants reported that inadequate tracking of completion of diabetes standards of care influenced their adherence to guidelines.\nQuestion: Disease management for diabetes among family physicians and general internists: opportunism or planned care?",
        "gt": "The current system of delivering diabetes care opportunistically in the context of non-diabetes acute visits may need to be more closely examined in an effort to improve the delivery of services.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Recently, a strategy for treating stroke directly at the emergency site was developed. It was based on the use of an ambulance equipped with a scanner, a point-of-care laboratory, and telemedicine capabilities (Mobile Stroke Unit). Despite demonstrating a marked reduction in the delay to thrombolysis, this strategy is criticized because of potentially unacceptable costs. We related the incremental direct costs of prehospital stroke treatment based on data of the first trial on this concept to one year direct cost savings taken from published research results. Key parameters were configuration of emergency medical service personnel, operating distance, and population density. Model parameters were varied to cover 5 different relevant emergency medical service scenarios. Additionally, the effects of operating distance and population density on benefit-cost ratios were analyzed. Benefits of the concept of prehospital stroke treatment outweighed its costs with a benefit-cost ratio of 1.96 in the baseline experimental setting. The benefit-cost ratio markedly increased with the reduction of the staff and with higher population density. Maximum benefit-cost ratios between 2.16 and 6.85 were identified at optimum operating distances in a range between 43.01 and 64.88 km (26.88 and 40.55 miles). Our model implies that in different scenarios the Mobile Stroke Unit strategy is cost-efficient starting from an operating distance of 15.98 km (9.99 miles) or from a population density of 79 inhabitants per km2 (202 inhabitants per square mile).\nQuestion: Is prehospital treatment of acute stroke too expensive?",
        "gt": "This study indicates that based on a one-year benefit-cost analysis that prehospital treatment of acute stroke is highly cost-effective across a wide range of possible scenarios. It is the highest when the staff size of the Mobile Stroke Unit can be reduced, for example, by the use of telemedical support from hospital experts. Although efficiency is positively related to population density, benefit-cost ratios can be greater than 1 even in rural settings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to explore how activity of daily living (ADL) stages and the perception of unmet needs for home accessibility features associate with a history of falling. Participants were from a nationally representative sample from the Second Longitudinal Survey of Aging conducted in 1994. The sample included 9250 community-dwelling persons 70 yrs or older. The associations of ADL stage and perception of unmet needs for home accessibility features with a history of falling within the past year (none, once, or multiple times) were explored after accounting for sociodemographic characteristics and comorbidities using a multinomial logistic regression model. The adjusted relative risk of falling more than once peaked at 4.30 (95% confidence interval, 3.29-5.61) for persons with severe limitation (ADL-III) compared those with no limitation (ADL-0) then declined for those at complete limitation (ADL-IV). The adjusted relative risks of falling once and multiple times were 1.42 (95% confidence interval, 1.07-1.87) and 1.85 (95% confidence interval, 1.44-2.36), respectively, for those lacking home accessibility features.\nQuestion: Do elderly people at more severe activity of daily living limitation stages fall more?",
        "gt": "Risk of falling appeared greatest for those whose homes lacked accessibility features and peaked at intermediate ADL limitation stages, presumably at a point when people have significant disabilities but sufficient function to remain partially active.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Vaginal intraepithelial neoplasia (VAIN) is usually detected in patients with synchronous or antecedent cervical or vulval intraepithelial or invasive cancer. VAIN has the potential to progress to malignancy. To determine the incidence and severity and analyse the management of vaginal dysplasia in patients undergoing primary hysterectomy for cervical cancer. A retrospective study (1984-1998) identified 210 primary invasive cervical cancers. One-hundred and twenty-three patients had a primary hysterectomy. In follow-up six patients were found to have dyskaryosis in a second vaginal smear. Biopsies in the six patients with colposcopic lesions showed VAIN II (n=2), VAIN III (n=1),VAIN III / possible early invasion (n = 1) and invasive carcinoma (n=2). One patient with recurrent squamous cancer received salvage radiotherapy and one with recurrent adenocarcinoma received high dose progestogens and topical 5-fluorouracil.\nQuestion: Vaginal cytology following primary hysterectomy for cervical cancer: is it useful?",
        "gt": "All patients are disease-free at follow-up.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is increasing evidence that environmental factors such as air pollution from mine dumps, increase the risk of chronic respiratory symptoms and diseases. The aim of this study was to investigate the association between proximity to mine dumps and prevalence of chronic respiratory disease in people aged 55 years and older. Elderly persons in communities 1-2 km (exposed) and 5 km (unexposed), from five pre-selected mine dumps in Gauteng and North West Province, in South Africa were included in a cross-sectional study. Structured interviews were conducted with 2397 elderly people, using a previously validated ATS-DLD-78 questionnaire from the British Medical Research Council. Exposed elderly persons had a significantly higher prevalence of chronic respiratory symptoms and diseases than those who were unexposed., Results from the multiple logistic regression analysis indicated that living close to mine dumps was significantly associated with asthma (OR = 1.57; 95% CI: 1.20 - 2.05), chronic bronchitis (OR = 1.74; 95 CI: 1.25 - 2.39), chronic cough (OR = 2.02; 95% CI: 1.58 - 2.57), emphysema (OR = 1.75; 95% CI: 1.11 - 2.77), pneumonia (OR = 1.38; 95% CI: 1.07 - 1.77) and wheeze (OR = 2.01; 95% CI: 1.73 - 2.54). Residing in exposed communities, current smoking, ex-smoking, use of paraffin as main residential cooking/heating fuel and low level of education emerged as independent significant risk factors for chronic respiratory symptoms and diseases.\nQuestion: Chronic respiratory disease among the elderly in South Africa: any association with proximity to mine dumps?",
        "gt": "This study suggests that there is a high level of chronic respiratory symptoms and diseases among elderly people in communities located near to mine dumps in South Africa.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The study aim was to assess if an undersized mitral annuloplasty for functional mitral regurgitation (FMR) in dilated cardiomyopathy can determine a clinically relevant mitral stenosis during exercise. Both, rest and stress echocardiography were performed in 12 patients submitted to an undersized ring annuloplasty for FMR in dilated cardiomyopathy. The mean ring size was 27 +/- 1.3 mm. All patients were in NYHA functional classes I-II, were in stable sinus rhythm, and without significant residual mitral regurgitation (grade<or = 2/4). At peak exercise (mean 81 +/- 12 W), the main cardiac performance indices were significantly improved, including systolic blood pressure (121 +/- 5.6 versus 169 +/- 14 mmHg, p<0.001), stroke volume (63 +/- 15 versus 77 +/- 14 ml, p<0.001), left ventricular ejection fraction (43 +/- 9% versus 47 +/- 9%, p = 0.001), and systolic right ventricular function (pulsed tissue Doppler index peak systolic velocity: 8.6 +/- 1.7 versus 11.1 +/- 3.2 cm/s, p = 0.004). A mild increase in planimetric mitral valve area was observed at peak exercise (2.12 +/- 0.4 versus 2.17 +/- 0.3 cm2, p = 0.05). Although the transmitral mean gradient was increased from 3.2 +/- 1.2 to 6.3 +/- 2.3 mmHg (p<0.0001), the systolic pulmonary artery pressure did not change significantly (27 +/- 2.8 versus 30.1 +/- 6.4 mmHg, p = 0.3), thus revealing a preserved cardiac adaptation to exercise.\nQuestion: Undersized annuloplasty for functional mitral regurgitation: is it responsible for clinically relevant mitral stenosis during exercise?",
        "gt": "In these preliminary data, postoperative clinically relevant mitral stenosis was not observed in patients submitted to mitral repair for FMR. Stress echocardiography represents a valuable tool to assess an appropriate cardiac response to exercise and to detect a significant exercise-induced pulmonary hypertension after undersized annuloplasty ring surgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the cumulative effect of repeated transcutaneous electrical nerve stimulation (TENS) on chronic osteoarthritic (OA) knee pain over a four-week treatment period, comparing it to that of placebo stimulation and exercise training given alone or in combination with TENS. Sixty-two patients, aged 50-75, were stratified according to age, gender and body mass ratio before being randomly assigned to four groups. Patients received either (1) 60 minutes of TENS, (2) 60 minutes of placebo stimulation, (3) isometric exercise training, or (4) TENS and exercise (TENS&Ex) five days a week for four weeks. Visual analogue scale (VAS) was used to measure knee pain intensity before and after each treatment session over a four-week period, and at the four-week follow-up session. Repeated measures ANOVA showed a significant cumulative reduction in the VAS scores across the four treatment sessions (session 1, 10, 20 and the follow-up) in the TENS group (45.9% by session 20, p<0.001) and the placebo group (43.3% by session 20, p = 0.034). However, linear regression of the daily recordings of the VAS indicated that the slope in the TENS group (slope = -2.415, r = 0.943) was similar to the exercise group (slope = -2.625, r = 0.935), which were steeper than the other two groups. Note that the reduction of OA knee pain was maintained in the TENS group and the TENS&Ex group at the four-week follow-up session, but not in the other two groups.\nQuestion: Does four weeks of TENS and/or isometric exercise produce cumulative reduction of osteoarthritic knee pain?",
        "gt": "The four treatment protocols did not show significant between-group difference over the study period. It was interesting to note that isometric exercise training of the quadriceps alone also reduced knee pain towards the end of the treatment period.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Web-based course evaluation systems offer the potential advantage of timely evaluations. The authors examined whether elapsed time between teaching and student evaluation of teaching impacts preclinical courses' quality ratings. The overall relationship of elapsed time with evaluation rating was explored with regression and ANOVA. Time between teaching event and evaluation was categorized by weeks. Within-teaching-events means and variances in evaluations related to elapsed weeks were compared using repeated-measures ANOVA. With more elapsed weeks, quality mean ratings increased (P<.001) and variability decreased (P<.001); effect sizes were small (average effect size = 0.06). Trends were similar in regression analysis and for data aggregated by event.\nQuestion: Elapsed time between teaching and evaluation: does it matter?",
        "gt": "Summaries of event quality are negligibly impacted by evaluation timing. Future studies should examine the impact of other Web-based evaluation features on evaluation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the level of informed choice in women invited for breast cancer screening for the first time. To determine the content of decision-relevant knowledge, 16 experts were asked to judge whether each of 51 topics represented essential information to enable informed choices. To assess the level of informed choices, a questionnaire was then sent to all 460 invited women in the south-western part of the Netherlands who turned 50 in August 2008. Of all 229 respondents, 95% were deemed to have sufficient knowledge as they answered at least 8 out of 13 items correctly. In 90% there was consistency between intention (not) to participate and attitude. As a result, 88% made an informed choice. Sixty-eight percent of women responded correctly on the item of over-diagnosis. Even if all non-respondents were assumed to have no knowledge, 50% of the total group invited to participate still had sufficient knowledge.\nQuestion: Do women make an informed choice about participating in breast cancer screening?",
        "gt": "Women were deemed to have sufficient relevant knowledge of the benefits and harms if they answered at least half of the items correctly.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine if column agglutination technology (CAT) for titration of anti-D and anti-c concentrations produces comparable results to those obtained by continuous flow analyser (CFA). Anti-D and anti-c are the two commonest antibodies that contribute to serious haemolytic disease of the foetus and neonate (HDFN). Current practice in the UK is to monitor these antibodies by CFA quantification, which is considered more reproducible and less subjective than manual titration by tube IAT (indirect antiglobulin test). CAT is widely used in transfusion laboratory practice and provides a more objective endpoint than tube technique. Antenatal samples were (i) quantified using CFA and (ii) titrated using CAT with the reaction strength recorded by a card reader and expressed as a titre score (TS). The TS rose in accordance with levels measured by quantification and was able to distinguish antibody levels above and below the threshold of clinical significance.\nQuestion: Antenatal monitoring of anti-D and anti-c: could titre scores determined by column agglutination technology replace continuous flow analyser quantification?",
        "gt": "CAT titre scores provided a simple and reproducible method to monitor anti-D and anti-c levels. The method was sensitive to a wide range of antibody levels as determined by quantification. This technique may have the potential to replace CFA quantification by identifying those cases that require closer monitoring for potential HDFN.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Hepatitis E is a major health problem in developing countries including India. The incidence and mortality rate in pregnant women with fulminant hepatic failure (FHF) due to hepatitis E virus (HEV) has been reported to be significantly higher, specifically in Asian women. Pregnancy is usually associated with an altered status of sex steroid hormones and immunity. Steroid hormones directly influence the replication through their effects on viral regulatory elements. Moreover, pregnant women in Asia generally suffer from folate deficiency, which is known to cause reduced immunocompetence leading to greater risk of multiple viral infections and higher viral load. To correlate and analyze the viral load and genotypes of HEV in acute liver failure with that of acute viral hepatitis among pregnant and nonpregnant women. A total of 100 FHF and 150 acute viral hepatitis (AVH) patients (50, 75 pregnant and 50, 75 nonpregnant, respectively), were included in the study. These cases were evaluated on the basis of history, clinical examination, liver function profile, and serological test of hepatitis A, B, C, and E using commercially available ELISA kits. Quantification of HEV RNA-positive samples was carried out. Out of 100 FHF and 150 acute viral hepatitis (AVH) patients, 28 (56%) and 22 (29.3%) pregnant and 7 (14%) and 8 (16%) nonpregnant, respectively, were HEV RNA-positive. HEV viral load in FHF pregnant women was 5.87 x 10(4)+/- 1.5 x 10(5) microL/mL as compared to AVH pregnant women 343.29 +/- 216.44 microL/mL and FHF and AVH nonpregnant 199.2 +/- 225.5 microL/mL and 13.83 +/- 7.8 microL/mL, respectively. Sequencing data of all the positive samples of FHF and AVH pregnant and nonpregnant women showed genotype 1.\nQuestion: Does hepatitis E viral load and genotypes influence the final outcome of acute liver failure during pregnancy?",
        "gt": "HEV viral load was found to be significantly higher (P<0.05) in pregnant patients compared to the nonpregnant. Pregnancy appears to be a risk factor for viral replication. The viral copies of HEV in FHF pregnant women were comparatively higher when compared to AVH pregnant women, which may be related to the severity of the disease in these patients. We could detect only one genotype (genotype 1) in our study population. Thus in the absence of other genotypes in this population, the impact of genotype could not be adequately assessed in this study.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To provide evidence whether mechanical thrombectomy with stent-retrievers in the treatment of acute ischemic stroke causes intimal damage. This study analyzed thrombi retrieved by mechanical thrombectomy from cerebral arteries in 48 consecutive patients with acute ischemic stroke for the presence of endothelial cells using CD34 antibodies. Of 48 thrombi analyzed, CD34-positive cells were absent in 20, present as isolated cells in 21, and found in clusters in 7 thrombi. We did not find any subendothelial vessel wall structures.\nQuestion: Immunohistochemical analysis of thrombi retrieved during treatment of acute ischemic stroke: does stent-retriever cause intimal damage?",
        "gt": "Our findings suggest that mechanical thrombectomy with stent-retrievers does not cause relevant intimal damage in acute ischemic stroke treatment. Clinical Trial Registration- URL: http://www.germanctr.de. Unique identifier: DRKS00004695.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Nitric oxide (NO), a potent vasodilator, is presumed to be constitutively released in most mammalian blood vessels. In isolated rat thoracic aorta, however, hemoglobin (Hb), a nitric oxide scavenger, elicited contraction only when the vessels were precontracted with an alpha adrenergic agonist. Does vascular contraction induce endothelial NO release? Thoracic aortic rings from male Sprague-Dawley rats were prepared with or without the endothelium. Vessel rings were contracted with several distinct types of contractile agonists and NO release was probed using a Hb contraction assay in the presence and absence of nitro-l-arginine methyl ester (NAME), a NO synthase inhibitor. In vessel rings precontracted with norepinephrine, potassium chloride, arginine vasopressin, prostaglandin F(2alpha), or serotonin, Hb elicited significant additional contractions. In contrast, Hb failed to elicit significant contractions in vessel rings without the functional endothelium or vessels pretreated with NAME. The Hb mediated additional contraction was not inhibited by calmidazolium, a calmodulin antagonist, and protein kinase inhibitors staurosporine and 2,5-dihydromethylcinnamate. Intercellular gap junction inhibitor 2,3-butanedione monoxime at a low dose (<2 mM) significantly attenuated the NE/Hb mediated contractions but at a high dose (>15 mM) completely prevented both contractions. The contraction coupled NO release may be mediated through a mechanism distinct from the Ca(2+)-calmodulin-dependent endothelial NOS pathway.\nQuestion: Contraction coupled endothelial nitric oxide release: a new paradigm for local vascular control?",
        "gt": "In the isolated rat thoracic aorta, endothelial NO release may be coupled to contractile stimulus. This vascular property appears to render a unique local control mechanism independent of baroreflex and other central mechanisms.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We investigated whether hemodialysis (HD) patients prefer standard or renal-specific oral nutritional supplements (ONS). Standard ONS Fortisip (Nutricia Clinical Care, Wiltshire, Trowbridge, UK) and renal ONS Renilon (Nutricia Clinical Care) and Nepro (Abbott Laboratories, Ltd., Maidenhead, Berkshire, UK) were compared using single-blind taste tests and face-to-face, interviewer-administered questionnaires. This study took place in our HD unit in September 2007. There were 40 patients, including 24 males, 14 smokers, and 26 Caucasians, aged<30 years (n = 6), 31 to 50 years (n = 13), 51 to 70 years (n = 12), and>70 years (n = 9). Patients ranked ONS taste on a Likert scale (1 to 5), and compared flavor options, phosphate-binder requirements, and fluid contribution. Which factors influenced a patient's choice of ONS? Gender, smoking status, ethnicity, and age influenced patients' choices. The taste of Fortisip and Nepro was liked by 58% (n = 23), versus 28% liking Renilon (n = 11). Renilon was disliked by 35% (n = 14), Nepro was disliked by 30% (n = 12), and Fortisip was disliked by 25% (n = 10). The favorite taste was Fortisip, in 52% (n = 21). However, 21% (n = 4) who preferred the taste of renal ONS would not choose them long-term because of their limited flavor ranges. The lack of phosphate binders with Renilon was a deciding factor in 27% (n = 19/33). The low fluid contribution of renal ONS influenced the choice of 43% (n = 12/28). All factors considered, standard ONS remained most popular for patients aged>70 years. However, in all other subgroups, and particularly males and non-Caucasians, renal ONS became more popular. Many patients (23%; n = 9) would sacrifice taste for the benefits of renal ONS.\nQuestion: Do hemodialysis patients prefer renal-specific or standard oral nutritional supplements?",
        "gt": "Renal ONS are more popular in HD patients because of their low fluid contribution and phosphate-binder requirements, which can influence preference over taste. Patients need information to make informed choices.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Because the response to treatment is limited, patients with metastatic renal cell carcinoma (mRCC) typically receive multiple treatments. Guidelines recommend everolimus for patients previously treated with tyrosine kinase inhibitors (TKI) sunitinib or sorafenib. This study evaluated the efficacy of TKI re-treatment in patients with disease progression after a TKI-everolimus sequence. Data were reviewed for patients enrolled in RECORD-1 (Renal Cell Cancer Treatment With Oral RAD001 Given Daily) at French sites. Response, progression-free survival (PFS), and overall survival were evaluated in patients treated with a TKI-everolimus-TKI sequence. Thirty-six patients received a TKI after everolimus: sunitinib in 17 patients, sorafenib in 15, and dovitinib (TKI258) in 4. The response rate with TKI re-treatment was 8%, and the disease-control rate (response plus stable disease) was 75%. The median PFS with each component of the TKI-everolimus-TKI sequence was 10.7 months (95% CI, 1.8-28.5 months), 8.9 months (95% CI, 1.7-34.6 months), and 8.2 months (95% CI, 5.2-11.9 months), respectively. The median overall survival from the start of everolimus was 29.1 months (95% CI 21.1 to not reached months), which suggests a benefit in using TKI in this setting.\nQuestion: Are tyrosine kinase inhibitors still active in patients with metastatic renal cell carcinoma previously treated with a tyrosine kinase inhibitor and everolimus?",
        "gt": "Administration of a TKI-everolimus-TKI sequence may be associated with clinical benefit and should be prospectively investigated.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Current guidelines on the management of mild head trauma (traumatic brain injury/TBI) do not include the presence of a skull fracture in determining the risk of intracranial injury. However, in our setting cranial radiography is still performed frequently to rule out the presence of skull fracture. To estimate the prevalence of clinically-important traumatic brain injuries (ciTBI) in children younger than two years of age with mild TBI. Descriptive observational study. All children attended in emergency department with mild TBI (Glasgow \u226514 points) for a year were included. We defined ciTBI as intracranial injuries that caused death or required neurosurgery, intubation for more than 24 hours, inotropic drugs or mechanical ventilation. The study included 854 children, of which 457 (53.5%) were male. The median patient age was 11.0 months (P25-75: 7.5-17.0 months). In 741 cases (86.8%) the mechanism of TBI was a fall. In 438 cases (51.3%) skull radiography was performed. Eleven children (1.3%) had intracranial injury, but none met the criteria for ciTBI (estimated prevalence of ciTBI was 0%; CI 95%: 0%-0.4%).\nQuestion: Children with minor head injury in the emergency department: Is skull radiography necessary for children under 2 years?",
        "gt": "Children younger than two years of age with mild TBI have low prevalence of ciTBI. Consequently, it is possible to monitor children younger than two years with a TBI without performing skull radiography.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Reports from the National Wilms' Tumor Study (NWTS) Group on the subject of chest computed tomography (CT) versus chest radiograph for the detection of lung metastases from Wilms tumor are reviewed. Thirty-two patients with lung nodules detected by CT, with negative chest radiographs, were identified. Five patients were excluded from further analysis. Of the remaining 27 patients, 18 were treated as stage IV, receiving therapy with three drugs and lung irradiation; the other nine were treated with less intensive therapy and no lung irradiation. The investigators found no significant difference between the overall survival between these two groups of patients (94% and 88%, respectively). In an earlier study, four of 11 children (36%) with normal chest radiographs and positive chest CT results were treated by ignoring the CT findings. These data compared with a relapse rate of only 20% in a control population. The studies do not statistically address the question of the impact of CT of the chest on survival.\nQuestion: Current controversy: is computed tomography scan of the chest needed in patients with Wilms' tumor?",
        "gt": "All children should have the benefit of the most sensitive imaging available, including CT, to detect tumor spread.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The dietary diversity score (DDS) is a good indicator of diet quality as well as of diet-disease relationships; therefore, the present study was undertaken to reveal the effect of a lifestyle intervention on this index. A baseline and three evaluation studies were conducted in two intervention districts (Isfahan and Najaf-Abad) and a reference area (Arak), all located in central Iran. The Isfahan Healthy Hearth Programme (IHHP) targeted the entire population of nearly 2 million in urban and rural areas of the intervention communities. One of the main strategies of the lifestyle intervention phase in the IHHP was healthy nutrition. Usual dietary intake was assessed using a forty-nine-item FFQ. A diversity score for each food group was calculated and the DDS was considered the sum of the diversity scores of the food groups. There were significant increases in DDS in both intervention areas (P = 0.0001) after controlling for confounding factors. There was a significant interaction between area and evaluation stage with regard to DDS (P = 0.0001). The effect of the intervention on the diversity scores of all food groups was also significant (P = 0.0001 for all) after adjusting for socio-economic status.\nQuestion: Do lifestyle interventions affect dietary diversity score in the general population?",
        "gt": "The community-based lifestyle intervention in the IHHP was successful in improving DDS which might be related to an increase of diet quality of the population that in turn might decrease the risks of chronic diseases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Many modifications to the traditional residency model contribute to the ongoing paradigm shift in surgical education; yet, the frequency and manner by which such changes occur at various institutions is less clear. To address this issue, our study examined the variability in endoscopy and laparoscopy training, the potential impact of new requirements, and opinions of Program Directors in Surgery (PDs). A 22-item online survey was sent to 251 PDs in the United States. Appropriate parametric tests determined significance. In all, 105 (42%) PDs responded. No difference existed in response rates among university (56.2%), university-affiliated/community (30.5%), or community (13.3%) program types (p = 0.970). Surgeons alone (46.7%) conducted most endoscopy training with a trend toward multidisciplinary teams (43.8%). A combination of fellowship-trained minimally invasive surgeons and other surgeon types (66.7%) commonly provided laparoscopy training. For adequate endoscopy experience in the future, most PDs (74.3%) plan to require a formal flexible endoscopy rotation (p<0.001). For laparoscopy, PDs intend for more minimally invasive surgery (59%) as well as colon and rectal surgery (53.4%) rotations (both p<0.001). Respondents feel residents will perform diagnostic endoscopy (86.7%) and basic laparoscopy (100%) safely on graduation. Fewer PDs confirm graduates will safely practice therapeutic endoscopy (12.4%) and advanced laparoscopy (52.4%). PDs believe increased requirements for endoscopy and laparoscopy will improve procedural competency (79% and 92.4%, respectively) and strengthen the fields of surgical endoscopy and minimally invasive surgery (55.2% and 68.6%, respectively). Less believe new requirements necessitate redesign of cognitive and technical skills curricula (33.3% endoscopy, 28.6% laparoscopy; p = 0.018). A national surgical education curriculum should be a required component of resident training, according to 79% of PDs.\nQuestion: Do increased training requirements in gastrointestinal endoscopy and advanced laparoscopy necessitate a paradigm shift?",
        "gt": "PDs employ and may implement varied tools to meet the increased requirements in endoscopy and laparoscopy. With such variability in educational methodology, establishment of a national surgical education curriculum is very important to most PDs.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The study included 45 Belgian families with at least one type 1 diabetic child aged six to 18 years (25 girls and 20 boys). Parents completed demographic questionnaires about themselves and their children. Information on type 1 diabetes in their child and the family-medical history were also collected. The number of severe-hypoglycaemic events and hospitalizations for hyperglycaemia were documented for the last 12 months, as were HbA(1c) levels over the last 16 months. Finally, family cohesiveness (FACES-III) and parental alexithymia (TAS-20) were assessed. Hierarchical regression analyses showed that the perception of family cohesion by mothers (P<0.05) was a predictor of the number of severe hypoglycaemic events in the last 12 months. Parents' demographic variables (marital and professional status, P<0.001) and maternal alexithymia (P<0.05) were found to be predictors of the number of hospitalizations for hyperglycaemia in the last 12 months. As for HbA(1c), only two parental demographic variables were significant predictors (marital and professional status, P<0.01 and P<0.05, respectively).\nQuestion: Does family cohesiveness and parental alexithymia predict glycaemic control in children and adolescents with diabetes?",
        "gt": "The maternal perception of family cohesiveness and maternal alexithymia predict on glycaemic control in children and adolescents with diabetes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Growth reference charts are usually based on measurements of children free from a medical condition that affects growth. However, samples collected during the past decades often contain a large proportion of overweight or obese children. Because obesity increases linear growth, the question arises to what extent the percentiles curves for length/height are affected by the presence of children with overweight or obesity. Data from two cross-sectional samples of 2-year-old to 18-year-old children were analysed: 12,252 Belgian children, measured in 2002-2004, and 6159 Norwegian children, measured in 2003-2006. The LMS method was used to estimate height-for-age curves with and without children considered overweight or obese according to the International Obesity Task Force thresholds. The prevalence of overweight (including obesity) and obesity was 13.0% and 2.8% in the Belgian and 13.8% and 2.3% in the Norwegian sample. Children were taller when overweight (+0.49 and 0.43 SD, in the Belgian and Norwegian sample, respectively) or obese (+0.73 and 0.72 SD in the Belgian and Norwegian sample, respectively). Effect sizes were smaller in younger and older children, which points to an advanced age of maturation as a possible cause. Excluding overweight and obese children had only a minor impact on the growth curves with largest difference in mean height SD scores -0.09 in the Belgian and -0.12 in the Norwegian sample with a corresponding increase of up to 0.5% and 1.2% in number of children>+2 SD.\nQuestion: Should children with overweight or obesity be excluded from height references?",
        "gt": "Current Belgian and Norwegian growth references for length/height were found to be largely unaffected by the current proportion of overweight and obese children. There is, therefore, no need for revised height charts that exclude overweight or obese children.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Working while ill has been found to predict coronary heart disease. We tested if this association was due to triggering. We used a nested case-control study in an occupational cohort to examine sickness absences during a 2-year period immediately before the first coronary event for 133 cases and 928 matched controls without a history of coronary events. Working while ill was defined as no absence despite being unhealthy (suboptimal self-rated health or psychological distress). The odds of a coronary event were not higher for cases who worked while ill than for correspondingly unhealthy controls who took>0 to 14 days of absence per year (OR = 0.62; 95% CI = 0.28 to 1.38). These results were little affected by multiple adjustments.\nQuestion: Does working while ill trigger serious coronary events?",
        "gt": "We found no evidence that working while ill acts as a short-term trigger for coronary events.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Potential lymphatic drainage patterns from cutaneous melanomas of the head and neck are said to be variable and frequently unpredictable. The aim of this article is to correlate the anatomic distribution of pathologically involved lymph nodes with primary melanoma sites and to compare these findings with clinically predicted patterns of metastatic spread. A prospectively documented series of 169 patients with pathologically proven metastatic melanoma was reviewed by analyzing the clinical, operative, and pathologic records. Clinically, it was predicted that melanomas of the anterior scalp, forehead, and face could metastasize to the parotid and neck levels I-III; the coronal scalp, ear, and neck to the parotid and levels I-V; the posterior scalp to occipital nodes and levels II-V; and the lower neck to levels III-V. Minimum follow up was 2 years. There were 141 therapeutic (97 comprehensive, 44 selective) and 28 elective lymphadenectomies (4 comprehensive dissections, 21 selective neck dissections, and 3 cases in which parotidectomy alone was performed). Overall, there were 112 parotidectomies, 44 of which were therapeutic and 68 elective. Pathologically positive nodes involved clinically predicted nodal groups in 156 of 169 cases (92.3%). The incidence of postauricular node involvement was only 1.5% (3 cases). No patient was initially seen with contralateral metastatic disease; however, 5 patients (2.9%) failed in the contralateral neck after therapeutic dissection. In 68% of patients, metastatic disease involved the nearest nodal group, and in 59% only a single node was involved.\nQuestion: Do nodal metastases from cutaneous melanoma of the head and neck follow a clinically predictable pattern?",
        "gt": "Cutaneous malignant melanomas of the head and neck metastasized to clinically predicted nodal groups in 92% of patients in this series. Postauricular and contralateral metastatic node involvement was uncommon.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Neonatal mortality and morbidity are gender-biased in low-birth-weight (LBW) infants. The male disadvantage theory has been suggested to be responsible for these maturational differences. To examine the impact of gender on neonatal hyperbilirubinemia.DESIGN/ A retrospective observational study. Data on all LBW infants admitted to George Washington University neonatal intensive care unit and surviving for>48 hrs from January 1992 to March 2003 were analyzed. Males and females were compared for gestational age, birth weight, race, Apgar scores at 1 and 5 mins, peak bilirubin levels, sepsis, and intraventricular hemorrhage (IVH). Significant differences were entered in a regression model to detect the influence of gender on bilirubin (Bili). Analysis was repeated after stratification of infants into: group A,<1000 g; group B, 1000-1499 g; and group C, 1500-2499 g. A total of 840 infants were included in this study. When comparing males (n = 407) with females (n = 433), significant differences were detected in birth weight (1,539 +/- 541 vs. 1,428 +/- 549 g; p = .003), IVH (14.2% vs. 9%; p = .025), and Bili (10.1 +/- 3.0 vs. 9.2 +/- 2.8 mg%; p<.001). No differences were detected in gestational age, sepsis, or Apgar 1 and 5. Difference in Bili for the entire group remained significant in the regression model (regression coefficient [RC] = 0.79 +/- 0.22; p<.001). In subgroup analyses: group A Bili (8.4 +/- 2.3 vs. 8.0 +/- 2.0; p = .14) and group B Bili (9.0 +/- 2.1 vs. 9.2 +/- 2.2; p = .51) did not differ in bivariate or multivariate analyses. In group C, Bili was (11.3 +/- 3.1 vs. 10.1 +/- 3.3; p<.001) and remained the only significant difference in the regression model (RC = 1.19 +/- 0.37; p = .001).\nQuestion: Does gender affect neonatal hyperbilirubinemia in low-birth-weight infants?",
        "gt": "Bili in LBW infants is significantly higher in males when compared with females. After stratification to birth weight subgroups, significance is retained in the 1500- to 2499-g group after logistic regression analysis. Bili levels in infants<1500 g are influenced more significantly by factors other than gender, such as sepsis and IVH.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Numerous clinical studies have shown that biofilm formation by Staphylococcus epidermidis on the outer surface of a silicone breast implant is strongly associated with capsular contracture formation. Traditional administration of systemic antibiotics and antiseptic washing are not necessarily the most effective methods for the prevention of initial biofilm formation on implants in the clinical scenario. In this study an alternative or supplement was sought for preventing or delaying bacterial colonisation and adherence to the outer surface of a breast implant, by establishing an in vitro model for investigating this complex problem. The in vitro antimicrobial activity of several antimicrobial agents was investigated for inhibitory effects on biofilm formation by S. epidermidis. The study consisted of two experiments. The first experiment consisted of two groups (A and B) of seven discs each whilst the second experiment was divided into three groups (C, D and E) of 14 discs each. Each group of 14 consisted of seven smooth and seven textured discs. Discs (biopsies) of each implant were individually coated with one of six different antimicrobial agents. Controls that received no agent were included in the various experimental groups. In the first experiment disc diffusion sensitivity testing was performed and inhibition zone sizes were measured. In the second experiment the discs were cultured in broth. The degree of biofilm formation was evaluated by scanning electron microscopy (SEM). In the first in vitro experiment, all six agents showed a measurable antimicrobial effect against the biofilm-forming strain of S. epidermidis when compared to the effect against the American Type Culture Collection strain. In the second in vitro experiment, discs coated with Chloramex, Fucidin and Terramycin did not allow biofilm formation to take place for at least 7 days.\nQuestion: Antimicrobial coating agents: can biofilm formation on a breast implant be prevented?",
        "gt": "Staphylococcus epidermidis biofilm formation on the outer surface of a silicone breast implant was prevented in vitro for at least 7 days by coating with an appropriate antimicrobial agent. Further evaluation of the interaction between antimicrobial coating agents and S. epidermidis biofilm formation needs to be made before conclusions regarding the clinical scenario can be drawn.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess whether adoption of the patient-centered medical home (PCMH) reduces emergency department (ED) utilization among patients with and without chronic illness. Data from approximately 460,000 Independence Blue Cross patients enrolled in 280 primary care practices, all converting to PCMH status between 2008 and 2012. We estimate the effect of a practice becoming PCMH-certified on ED visits and costs using a difference-in-differences approach which exploits variation in the timing of PCMH certification, employing either practice or patient fixed effects. We analyzed patients with and without chronic illness across six chronic illness categories. Among chronically ill patients, transition to PCMH status was associated with 5-8 percent reductions in ED utilization. This finding was robust to a number of specifications, including analyzing avoidable and weekend ED visits alone. The largest reductions in ED visits are concentrated among chronic patients with diabetes and hypertension.\nQuestion: Do patient-centered medical homes reduce emergency department visits?",
        "gt": "Adoption of the PCMH model was associated with lower ED utilization for chronically ill patients, but not for those without chronic illness. The effectiveness of the PCMH model varies by chronic condition. Analysis of weekend and avoidable ED visits suggests that reductions in ED utilization stem from better management of chronic illness rather than expanding access to primary care clinics.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Numerous predictors of coronary artery bypass grafting (CABG) outcomes have been identified. We aimed to determine whether the duration of surgery independently predicts outcome in patients undergoing CABG. We retrospectively reviewed data from 337 patients (mean age 62 +/- 7 years) who underwent CABG consecutively at our institution between January 2005 and December 2006. Duration of surgery correlated positively with length of both surgical intensive care unit (SICU) stay (r = .147, P = .004) and ventilator support (r = .097, P = .038) in univariate analysis, but only with length of SICU stay (P = .01) in a multivariate logistic regression after confounding factors were controlled for in the model. The regression coefficient was .006; every additional 30 minutes of surgery time was associated with 4.32 more hours of SICU stay. Duration of surgery was not associated with survival (P>.05).\nQuestion: Does the duration of surgery affect outcomes in patients undergoing coronary artery bypass grafting?",
        "gt": "Although duration of surgery did not affect short-term survival after CABG, surgical duration independently predicted length of SICU stays. Efforts to reduce the length of operations may promote more efficient use of hospital resources.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study is to verify the existence of an association between maternal periodontal disease and pre-term delivery in an unselected population of post-partum Turkish women. This case-control study was conducted on 100 women who gave birth in either a special or a government maternity hospital. The case group consisted of 50 mothers who had delivered an infant before 37 weeks' gestation and weighed under 2500 g. The control group included 50 mothers who had given birth to an infant with a birth weight of more than 2500 g and a gestational age of \u226537 weeks. Data of mothers and infants were collected using medical registers and questionnaires. Clinical periodontal examinations were carried out in six sites on every tooth in the mother's mouth. A participant who presented at least four teeth with one or more sites with a PPD \u22654 mm and CAL \u22653 mm at the same site was considered to have periodontal disease. Statistical methods included parametric and non-parametric tests and multiple logistic regression analysis. There were no statistically significant differences between the cases and controls with regard to periodontal disease and pre-term delivery (OR = 1.48; 95% CI = 0.54-4.06).\nQuestion: Is there a relationship between maternal periodontitis and pre-term birth?",
        "gt": "The findings indicated that maternal periodontitis was not a possible risk factor for pre-term delivery. Further studies with additional clinical trials are needed to explore the possible relationship between periodontal disease and pre-term birth.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The objective of the study was to determine whether a model for predicting vaginal birth after cesarean (VBAC) can also predict the probabilty of morbidity associated with a trial of labor (TOL). Using a previously published prediction model, we categorized women with 1 prior cesarean by chance of VBAC. Prevalence of maternal and neonatal morbidity was stratfied by probability of VBAC success and delivery approach. Morbidity became less frequent as the predicted chance of VBAC increased among women who underwent TOL (P<.001) but not elective repeat cesarean section (ERCS) (P>.05). When the predicted chance of VBAC was less than 70%, women undergoing a TOL were more likely to have maternal morbidity (relative risk [RR], 2.2; 95% confidence interval [CI], 1.5-3.1) than those who underwent an ERCS; when the predicted chance of VBAC was at least 70%, total maternal morbidity was not different between the 2 groups (RR, 0.8; 95% CI, 0.5-1.2). The results were similar for neonatal morbidity.\nQuestion: Can a prediction model for vaginal birth after cesarean also predict the probability of morbidity related to a trial of labor?",
        "gt": "A prediction model for VBAC provides information regarding the chance of TOL-related morbidity and suggests that maternal morbidity is not greater for those women who undergo TOL than those who undergo ERCS if the chance of VBAC is at least 70%.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A wish to die is common in older persons and is associated with increased mortality. Several risk factors have been identified, but the association between religiousness and a wish to die in older adults has been underexplored, and the association between death attitudes and the presence of a wish to die has not been investigated yet. The aim of this study is to explore the relationship between religiousness and death attitudes on the one hand and wish to die on the other hand, adjusting for clinical factors such as the presence of depression or somatic disorder. The sample comprised 113 older inpatients (from a psychiatric and somatic ward) with a mean age of 74 years. Psychiatric diagnoses were assessed by the Structured Clinical Interview for DSM-IV Disorders, and logistic regression analyses estimated the unique contribution of religiousness and death attitudes to the wish to die, controlling for socio-demographic variables, depressive disorder, and somatic symptoms. Both religiousness and death attitudes were associated with a wish to die in univariate models. Adding these variables in a multivariate logistic hierarchical model, death attitudes remained significant predictors but religiousness did not; 55% of the pseudovariance of the wish to die was explained by these variables, with an effective size of 0.89. Major depressive episode, somatic symptoms, Fear of Death, and Escape Acceptance were the most important predictors of the wish to die.\nQuestion: Are religiousness and death attitudes associated with the wish to die in older people?",
        "gt": "This study suggests that how older adults perceive death partly determines whether they have a wish to die. There may be a clinical, patient-oriented benefit in discussing with older patients about how they perceive death, as this can play a role in the early detection (and prevention) of death or suicide ideation and associated behaviors in older adults.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although the apolipoprotein E genotype epsilon4 (apoE4) has been associated with high cholesterol levels, whether it is an independent predictor of coronary events is not certain. We measured apoE genotypes in 730 participants in the Baltimore Longitudinal Study of Aging (421 men and 309 women, mean [+/- SD] age of 52+/-17 years) who were free of preexisting coronary heart disease. A proportional hazards regression model was used to study the association between risk factors and the occurrence of coronary events, defined as angina pectoris, documented myocardial infarction by history or major Q waves on the electrocardiogram (Minnesota Code 1:1 or 1:2), or coronary death, adjusted for other risk factors, including total plasma cholesterol level. The apoE4 allele was observed in 200 subjects (27%), including 183 heterozygotes and 17 homozygotes. Coronary risk factor profiles were similar in those with and without apoE4. Coronary events developed in 104 (14%) of the 730 subjects, including 77 (18%) of the 421 men during a mean follow-up of 20 years and 27 (9%) of the 309 women during a mean follow-up of 13 years. Coronary events occurred significantly more frequently in subjects with apoE4 (n = 40, 20%) than in those without this allele (64, 12%, P<0.05). In a multivariate model, apoE4 was an independent predictor of coronary events in men (risk ratio [RR]= 2.9, 95% confidence interval [CI]: 1.8 to 4.5, P<0.0001) but not in women (RR = 0.9, 95% CI: 0.4 to 1.9, P = 0.62).\nQuestion: Is the apoE4 allele an independent predictor of coronary events?",
        "gt": "The apoE4 genotype is a strong independent risk factor for coronary events in men, but not women. The association does not appear to be mediated by differences in total cholesterol levels.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In recent times, medical schools have committed to developing good communication and history taking skills in students. However, there remains an unresolved question as to which constitutes the best educational method. Our study aims to investigate whether the use of videotape recording is superior to verbal feedback alone in the teaching of clinical skills and the role of student self-assessment on history taking and communication skills. A randomized controlled trial was designed. The study was conducted with 52 of the Dokuz Eylul University Faculty of Medicine second year students. All students' performances of communication and history taking skills were assessed twice. Between these assessments, the study group had received both verbal and visual feedback by watching their video recordings on patient interview; the control group received only verbal feedback from the teacher. Although the self-assessment of the students did not change significantly, assessors' ratings increased significantly for videotaped interviews at the second time.\nQuestion: Is the use of videotape recording superior to verbal feedback alone in the teaching of clinical skills?",
        "gt": "Feedback based on videotaped interviews is superior to the feedback given solely based on the observation of assessors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Our objective was to assess the impact of disruption by a new 2-week vacation break on outcomes of required third-year clerkships. Mean scores on National Board of Medical Examiners (NBME) clerkship specific clinical science subject (\"subject\") examinations and overall student evaluations were compared for clerkships with the break and those over the previous 3 years without the break. Students were surveyed about the impact of the break on learning and the time spent studying during the break. No significant differences were found in examination scores between clerkships with the break and those without. Overall student clerkship evaluations were significantly different only for the surgery clerkship. The break was regarded more favorably by students on the 8-week than the 6-week clerkships, but student perspectives varied significantly by specialty. The time reported studying varied significantly by specialty and campus. Student comments were predominantly supportive of the break and focused on the advantages of opportunity to relax, spend time with family, and to study. Concerns included forgetting content knowledge, losing skills, and having difficulty regaining momentum on return to the clerkship.\nQuestion: Does a Vacation Break Impact the Outcomes of Required Clinical Clerkships?",
        "gt": "Interruption of clerkships by a 2-week break was not associated with any significant change in subject examination scores or overall student evaluation of the clerkship, despite predominantly positive comments. Significant differences were reported by specialty in student perception of benefit and reported time studying during the break.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Measuring FE(NO) is a novel and non-invasive way to monitor airway inflammation (e.g. asthma). This clinical study was designed to investigate whether drinking ethanol might distort FE(NO) measurements. Twenty healthy subjects drank 0.40 g ethanol/kg body weight in 15 min. Measurement of FE(NO) started approximately 30 min before drinking and at various times afterwards for 4 h post-dosing. Ethanol concentrations were determined in venous blood by gas chromatography and in end-exhaled breath by infra-red spectrometry. The within subject standard deviation for determination of FE(NO) was 1.3 ppb, corresponding to a CV of 7.7%. The mean change in FE(NO) from pre-drinking levels during the 4h testing was statistically significant (P<0.001) according to repeated measures ANOVA. In absolute units the mean change was small, -2.01 and -1.94 ppb at 3 and 4h post-dosing, respectively (P<0.013, P<0.005).\nQuestion: Does consumption of ethanol distort measurements of exhaled nitric oxide?",
        "gt": "FE(NO) measurements were reproducible even in subjects with moderate concentrations of ethanol in blood and breath. The small decrease in FE(NO) observed at 3 and 4 h post-drinking was less than the intra-subject variations in FE(NO) measurements. The breath-alcohol concentrations in this study exceed all other endogenous volatiles, thus making it unlikely that other substances in human breath will bias the FE(NO) measurements.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate whether L-Arginine has an effect on endogenous epidermal growth factor secretion and intestinal adaptation in massive small bowel resection an experimental study was performed. Fourteen albino Wistar rats weighing 250-300 g were used for the study. After performing 50% small bowel resection and anastomosis the rats were randomly divided into two groups. The first group received 500 mg/kg/day of L-Arginine intraperitoneally for 14 days just after the surgical procedure. The control group received isotonic saline instead. Body weight measurement was preformed daily. At the end of the second postoperative week all rats underwent relaparotomy. Small bowel was resected for histopathological examination. Levels of epidermal growth factor were measured by enzyme-linked immunosorbent assay in serum, saliva, and urine at the end of second postoperative week in both groups. The weight gain was higher in the L-Arginine treated group (P<0.05). Serum, saliva and urinary epidermal growth factor levels were significantly higher at the end of the second week compared to the control group (P<0.05). The villus height was higher on histopathological examination in L-Arginine treated group compared to the control group (P<0.05).\nQuestion: Does L-arginine induce intestinal adaptation by epithelial growth factor?",
        "gt": "L-Arginine resulted in a better intestinal adaptation after massive bowel resection. The high levels of epidermal growth factor in body fluids of L-Arginine treated rats could be the explanation for this effect.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether preoperative helical CT angiography (CTA) with three-dimensional (3D) reconstructed images improves outcome in patients with ureteropelvic junction obstruction (UPJO) by identifying crossing vessels that may lead to surgical failure. Twenty-five patients with UPJO underwent imaging with CTA to identify crossing vessels. Patients with crossing vessels or severe hydronephrosis underwent laparoscopic dismembered pyeloplasty. In the absence of crossing vessels, and with>25% renal function on MAG-3 scan, the patient underwent an endopyelotomy. Procedures were assessed as successful by resolution of patient symptoms as well as relief of obstruction on renal scintography. Twenty-seven procedures (14 laparoscopic dismembered pyeloplasties [9 in the setting of a crossing vessel], 11 ureteroscopic endopyelotomies, and two antegrade endopyelotomy procedures) were performed. Follow-up ranged from 2.4 to 40 months (mean 21.6 months). Twenty-three of the primary procedures (92.0%) were successful. Primary laparoscopic pyeloplasty was successful in 100% of patients, while primary endopyelotomy had a success rate of 83.3%. Both secondary procedures were successful rendering the patients unobstructed and pain free. No complications occurred. The sensitivity and specificity of CTA in determining crossing vessels was 78% and 40%, respectively.\nQuestion: Ureteropelvic junction obstruction: does CT angiography allow better selection of therapeutic modalities and better patient outcome?",
        "gt": "Helical CT angiography with 3D reconstructed images provides valuable preoperative information in patients with UPJO scheduled for surgical intervention. This study may be used in selecting patients for proper operative intervention according to the anatomy of crossing vessels to attain high treatment success rates.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The relation between white matter loss (WML) and diabetes is still debated. The aim of this study was to investigate the correlation between typical WML- and diabetes-related magnetic resonance imaging (MRI) findings in a cohort of patients scheduled for carotid endarterectomy (CEA). Ninety-three consecutive patients (mean age 71\u00b19years; male 71) were included in a single-centre retrospective study. All the patients underwent MRI as baseline evaluation prior to CEA. A neuroradiologist blinded to the presence of risk factors calculated WML volume and number of lesions on FLAIR images using a semi-automated segmentation technique. Receiver operating characteristics analysis was performed to search for any association between WML volume and the number of WML lesions. The Mann-Whitney tests were used to determine significant WML differences between diabetic and non-diabetic patients. Logistic regression analysis was performed to evaluate the potential association of other variables. The prevalence of diabetes was 20.4% (n=19). WML volume and number of WML lesions were significantly associated with diabetes (P=0.001). A statistically significant difference in WML volume was found between diabetic and non-diabetic patients (P<0.0001). Only diabetes, among all the investigated variables (WML volume, CAD status, age, smoking status, gender, hypertension, hyperlipidemia, diabetes) was significantly associated with WML (P=0.0001).\nQuestion: Is there an association between leukoaraiosis volume and diabetes?",
        "gt": "Our results demonstrate a strong statistical correlation between diabetes and WML. Future scientific challenges could include the identification of potential therapeutic targets and the creation of dedicated screening protocols for WML in diabetic patients other than the simple measurement of leukoaraiosis total burden.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: China has a high burden of drug-resistant tuberculosis (TB) and diabetes mellitus (DM). The objectives of this study were to determine the following in patients with culture-confirmed TB: 1) demographic characteristics and disease patterns in relation to the presence or absence of type 2 diabetes and 2) presence or absence of drug resistance to isoniazid (INH), rifampicin (RMP) or both in relation to duration of diabetes and control of diabetes. This is a cross-sectional and retrospective study involving record reviews. There were 621 patients with culture-positive TB, of whom 187 (30%) had previously known or new type 2 diabetes. In those with diabetes, there was a significantly higher proportion of males, persons aged \u226535 years and patients registered with new TB (p<0.05). Prevalence of multidrug-resistant TB (MDR-TB) was 6.2% in new patients (N=422) and 62.3% in previously treated patients (N=199), with no significant differences between those with and without diabetes. In patients with diabetes, there was no association of drug resistance with diabetes duration or disease control [assessed by fasting blood glucose (FBG) at 1 week].\nQuestion: Is resistance to anti-tuberculosis drugs associated with type 2 diabetes mellitus?",
        "gt": "A high proportion of patients with TB in a tertiary health facility, Beijing, China, had diabetes, but there was no association between type 2 diabetes and drug-resistant TB. Further prospective studies are needed to confirm these findings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This matched-paired analysis explores disparities in health-related quality of life (QOL) and common toxicities between African American (AA) and white patients following proton therapy for prostate cancer at our institution. A total of 1536 men with clinically localized prostate cancer were treated from 2006 to 2009 with definitive proton therapy to a median dose of 78 Gy +/- androgen deprivation therapy. A cohort of 92 consecutively treated AA men was matched to a cohort of 92 white men on the basis of National Comprehensive Cancer Network risk category and age. The 2 groups were compared with regard to comorbidities, demographics, and treatment regimen. Differences in genitourinary and gastrointestinal (GI) toxicity according to the Common Terminology Criteria for Adverse Events scale and QOL data from the Expanded Prostate Index Composite 26-question questionnaire were reported. Median follow-up was 2.1 years. Baseline patient and treatment characteristics were similar between the 2 groups with the exception of prostate-specific antigen \u226510 (32% for AAs vs. 20% for whites; P=0.068) and use of androgen deprivation therapy (26% for AAs vs. 21% for whites; P=0.38). No difference in Expanded Prostate Index Composite 26-question sexual summary, urinary incontinence, urinary obstruction, or bowel summary scores was detected between the 2 groups, nor was there a difference in grade 2 or higher GI toxicity (P=0.45). AAs had a statistically nonsignificant higher absolute incidence of late grade 3 genitourinary toxicity (4.4% vs. 0%; P=0.12).\nQuestion: Does Race Influence Health-related Quality of Life and Toxicity Following Proton Therapy for Prostate Cancer?",
        "gt": "After 2 years, there were no disparities in health-related QOL, physician-reported Common Terminology Criteria for Adverse Events GI toxicity, or biochemical relapse. Longer follow-up is needed to confirm these findings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The value of epicardial adipose tissue (EAT) thickness as determined by echocardiography in cardiovascular risk assessment is not well understood. The aim of this study was to determine the associations between EAT thickness and Framingham risk score, carotid intima media thickness, carotid artery plaque, and computed tomographic coronary calcium score in a primary prevention population. Patients presenting for cardiovascular preventive care (n = 356) who underwent echocardiography as well as carotid artery ultrasound and/or coronary calcium scoring were included. EAT thickness was weakly correlated with Framingham risk score. The prevalence of carotid plaque was significantly greater in those with EAT thickness \u2265 5.0 mm who either had low Framingham risk scores or had body mass indexes \u2265 25 kg/m(2), compared with those with EAT thickness<5.0 mm. No significant association between EAT thickness and carotid intima-media thickness or coronary calcium score existed.\nQuestion: Epicardial fat: an additional measurement for subclinical atherosclerosis and cardiovascular risk stratification?",
        "gt": "EAT thickness \u2265 5.0 mm may identify an individual with a higher likelihood of having detectable carotid atherosclerosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The study was carried out to determine the learning curve patterns for basic laparoscopic technical skills. Thirty-seven surgical residents with limited laparoscopic experience performed 10 repetitions of 6 tasks on a virtual-reality trainer (MIST-VR) with standardized distribution of practice. Assessment was based on time, errors, and economy of motion as measured by MIST-VR. Proficiency levels were established by testing experienced laparoscopic surgeons. Four learning curve patterns were determined. Surgeons in group 1 (5.4%) demonstrated proficiency from the beginning; group 2 (70.3%) achieved predefined expert criteria between 2 and 9 repetitions; group 3 (16.2%) demonstrated improvement but was unable to achieve proficiency within 10 repetitions. Group 4 (8.1%) underperformed and showed no tendency of skills improvement, reflecting a group of subjects who probably are unable to learn laparoscopic technique.\nQuestion: Can everyone achieve proficiency with the laparoscopic technique?",
        "gt": "The results indicated that a group of subjects could not reach proficiency in the psychomotor skills relevant for laparoscopy. We believe that this is an important issue that should be addressed in future research.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Professional setting might be a key determinant of physicians' attitudes toward practice guidelines, influencing the effect of their implementation. Because no previous surveys have specifically considered this aspect, we evaluated the perceived role and usefulness of guidelines, as well as barriers to and facilitators of their implementation, for hospital, primary care, and nonpracticing clinicians. A 43-item self-administered questionnaire was sent to all National Health Service physicians in the province of Modena, Italy (593 primary care physicians, 1049 hospital physicians, and 149 nonpracticing clinicians), and 1199 (66.9%) responded. Opinions and attitudes were assessed using 5-point ordinal scales and an attitude measurement scale. Results were evaluated overall and by professional setting, sex, age, year of graduation, and academic background. Practice guidelines were generally perceived to be less useful than other sources of medical information (eg, personal experience, conferences, colleagues, articles, the Internet, and textbooks [pharmaceutical representatives were the exception]). Most physicians thought that guidelines are developed for cost-containment reasons and expressed concerns about their limited applicability to individual patients and local settings. Most respondents did not favor the involvement of health professionals other than physicians in guideline development and use and preferred nonmonetary incentives for their implementation. Answers to individual items and attitude scores varied significantly across professional settings. Primary care physicians showed, in general, the least favorable attitudes toward practice guidelines, toward nonphysicians participating in guideline development and use, and toward incentives for guideline users.\nQuestion: Practice guidelines: useful and \"participative\" method?",
        "gt": "Physicians perceived practice guidelines as externally imposed and cost-containment tools rather than as decision-supporting tools. Regularly monitoring attitudes toward practice guidelines can be helpful to evaluate potential barriers to their adoption.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To explore cultural context for smoking cessation within Chinese communities in Vancouver, and identify opportunities to support development of culturally appropriate resources for cessation. Applied participatory approach involving community members, patients, and key-informants in the design and implementation of the research. Whereas many participants were motivated to quit, their perceptions of desire to do so were not supported by effective interventions and many attempts to quit were unsuccessful.\nQuestion: Does culture or illness change a smoker's perspective on cessation?",
        "gt": "Tobacco control clinics and care providers need to adopt culturally and linguistically relevant interventions to facilitate behavioral modifications and cessation in ethnic minority communities.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Concerns have been raised regarding residual symptoms of caudal segment (L5-S1) degeneration that may affect clinical outcomes or require additional surgery after isolated L4-5 fusion, especially if there is pre-existing L5-S1 degeneration. This study aimed to evaluate the L5-S1 segment after minimally invasive lumbar interbody fusion at the L4-5 segment, as well as the influence of pre-existing L5-S1 degeneration on radiologic and clinical outcomes. This retrospective study evaluated patients with isthmic spondylolisthesis and degenerative spondylolisthesis who underwent mini-open anterior lumbar interbody fusion with percutaneous pedicle screw fixation (PSF) or minimally invasive transforaminal interbody fusion with PSF at the L4-5 segment. The minimum follow-up period was 7\u00a0years, and radiographic evaluations were conducted via magnetic resonance imaging, computed tomography, and plain radiography at the 5-year follow-up. Clinical outcomes were assessed using the Visual Analog Score, Oswestry Disability Index, and surgical satisfaction rate. Patients were divided into two groups, those with and without pre-existing L5-S1 degeneration, and their final outcomes and incidence of radiographic and clinical adjacent segment disease (ASD) were compared. Among 70 patients who underwent the procedures at our institution, 12 (17.1%) were lost to follow-up. Therefore, this study evaluated 58 patients, with a mean follow-up period of 9.4\u2009\u00b1\u20092.1\u00a0years. Among these patients, 22 patients had pre-existing L5-S1 degeneration, while 36 patients did not have pre-existing L5-S1 segmental degeneration. There were no significant differences in the clinical outcomes at the final follow-up when the two groups were compared. However, radiographic ASD at L5-S1 occurred in seven patients (12.1%), clinical ASD at L5-S1 occurred in three patients (5.2%), and one patient (1.7%) required surgery. In the group with pre-existing degeneration, L5-S1 degeneration was radiographically accelerated in four patients (18.2%) and clinical ASD developed in one patient (4.5%). In the group without pre-existing degeneration, L5-S1 degeneration was radiographically accelerated in three patients (8.3%) and clinical ASD developed in two patients (5.7%). There were no differences in the incidence of ASD when we compared the two groups.\nQuestion: Does pre-existing L5-S1 degeneration affect outcomes after isolated L4-5 fusion for spondylolisthesis?",
        "gt": "Pre-existing L5-S1 degeneration does not affect clinical and radiographical outcomes after isolated L4-5 fusion.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Serum FSH elevations and decreases in inhibin B have been consistently demonstrated in the early follicular phase of cycles in women of advanced reproductive age. However, secretory products of the dominant follicle (estradiol and inhibin A) in the serum of older ovulatory women are maintained at levels similar to those of their younger counterparts. The goal of this investigation was to determine if ovarian secretory capacity is dependent on relative FSH levels and if basal measures of ovarian reserve reflect ovarian secretory capacity. We administered equivalent low, but effective doses of recombinant FSH for 5 days to a group of older subjects (40-45 years, n=9) and younger controls (20-25 years, n=10) after pituitary suppression with a GnRH agonist. Outcome measures included follicular development as determined by serial transvaginal ultrasound examinations and serum levels of estradiol, inhibin A and inhibin B. Serum levels of estradiol and inhibin A were not statistically different between the two groups, while the number of large follicles formed was greater in the younger subjects. Basal parameters of ovarian reserve were not significantly correlated with ovarian secretory capacity, but did correlate with the number of follicles recruited in response to low-dose FSH.\nQuestion: Reproductive ageing and ovarian function: is the early follicular phase FSH rise necessary to maintain adequate secretory function in older ovulatory women?",
        "gt": "By providing equivalent serum levels of FSH in older and younger reproductive aged women, this study demonstrates that the secretory capacity of recruited follicles is maintained in older reproductive aged women.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Varicocelectomy after previous inguinal surgery poses a potential risk of testicular volume loss. To assess the extent to which varicocelectomy can be done without the complication of ipsilateral testis atrophy we present outcomes in adolescent patients with a history of inguinal surgery who underwent ipsilateral varicocelectomy. We retrospectively reviewed patient data from a single urologist practice. Testicular volume was recorded preferentially by ultrasound or, when unavailable, by ring orchidometry. Testicular asymmetry was calculated using the formula, [(right testis volume - left testis volume)/right testis volume] \u00d7 100. Symmetry was defined as less than 10% asymmetry. Catch-up growth was defined as resolution of asymmetry. We identified 22 adolescent patients who fit study criteria. The patients underwent a total of 25 varicocelectomies since 3 underwent bilateral repair after previous bilateral inguinal surgery. Initial inguinal surgery included inguinal herniorrhaphy, hydrocelectomy and orchiopexy. Varicocelectomy was done laparoscopically in 17 cases and via open technique in 8 with variations in preservation/sacrifice of the lymphatics and artery. Median \u00b1 SD followup was 24.2 \u00b1 18.2 months. After varicocelectomy mean testicular asymmetry decreased from 27.6% to 10.5%. There was no incidence of testicular atrophy postoperatively. The incidence of catch-up growth was 43% with no difference between the artery sparing and the nonartery sparing technique.\nQuestion: Is adolescent varicocelectomy safe after previous inguinal surgery?",
        "gt": "Varicocelectomy with a history of previous inguinal surgery is safe and provides a significant incidence of testicular catch-up growth. Artery sparing vs sacrificing technique did not make a difference in terms of catch-up growth.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Many emergency medicine staff report anecdotally that fellow hospital staff have a low opinion of emergency medicine. No research into this attitude has been published. The aim of this study is to determine whether there is stigma attached to emergency medicine and practitioners. A postal questionnaire of all medical staff at a district general hospital, to evaluate the presence or absence of eight perceptions associated with stigma. The response rate was 49.5%, with the response rate decreasing with decreasing grade. Of the stigmatizing themes tested in this study, six of the eight were demonstrated to be associated with negative attitudes, with the remaining two themes positive attitudes towards emergency medicine were suggested. The responses were similar, irrespective of grade and speciality (where given by respondees). Responses that were ambivalent or not completed varied between 25 and 48% in the returned questionnaires.\nQuestion: Is a career in emergency medicine associated with stigma?",
        "gt": "This paper demonstrates that stigmatizing opinions towards emergency medicine exist and that these negative opinions may be widely held by hospital staff.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The introduction of ambulatory blood pressure monitoring into clinical practice has defined a clinical condition called 'isolated office hypertension'. The aim of this study was to evaluate the long-term systolic and diastolic blood pressure changes in patients with isolated office hypertension and to identify the presence of markers capable of identifying which patients will develop sustained hypertension. All the 407 patients enrolled had a random office systolic or/and diastolic blood pressure of over 140/90mmHg and a mean daytime ambulatory blood pressure of 130/84mmHg or less. At enrollment, each patient underwent a 'baseline examination' made up of a physical evaluation, a 24h ambulatory blood pressure monitoring, and a mental arithmetic test performed at the end of the 24h ambulatory monitoring. Of the 173 patients finally studied, 102 (58.9%) developed sustained hypertension with an increase in both ambulatory systolic and diastolic blood pressure. At the time of the baseline examination, the patients were divided into two groups. Group A included patients with mean ambulatory systolic and diastolic blood pressures in the first hour of 130/84mmHg or less; group B included patients with mean ambulatory systolic and diastolic pressures in the first hour of greater than 130/84mmHg. During the mental arithmetic test, the systolic and heart rate values increased significantly only in group B patients. Of the 102 patients who had become hypertensive by the time of the follow-up examination, 84 (82%) belonged to group B.\nQuestion: Isolated office hypertension: are there any markers of future blood pressure status?",
        "gt": "These data suggest that isolated office hypertension may indeed be a transitional state towards the development of sustained hypertension. Moreover, the mean ambulatory blood pressure value during the first hour can be considered to be a marker of a higher risk of developing sustained hypertension.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Full thickness grafts on the nose do not always heal without problems. Partial or entire necrosis of the graft is likely to lead to less favourable cosmetic results and prolonged wound care. No consensus exists as to the use of systemic antibiotics to increase the success rate of survival of a full thickness skin graft on the nose after non-melanoma skin cancer surgery. The objective of the study was to evaluate the effect of systemic antibiotics on the survival of full thickness grafts on the nose. We performed a randomized, controlled trial in which we compared azithromycin with standard treatment in 30 patients, who underwent a full thickness graft reconstruction of a surgical defect on the nose after surgery for non-melanoma skin cancer. Percentage survival of the graft was the main outcome measure. A statistically significant difference in favour of the grafts treated with azithromycin was seen (P=0.002). Of all the variables analysed, only smoking had a significant negative effect on the survival of the graft.\nQuestion: Do systemic antibiotics increase the survival of a full thickness graft on the nose?",
        "gt": "Systemic antibiotics with an accurate bacterial spectrum should be advised in full thickness skin graft reconstruction after surgery for non-melanoma skin cancer of the nose. Smoking should be strongly discouraged.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Most youth smokers intend to quit, but the majority is neither aware nor interested in most conventional cessation approaches. As such, a critical first step in understanding youth cessation is to better understand the beliefs youth have about different cessation options. This cross-sectional study used self-reported data collected from 26,379 grade 9 to 12 students in Ontario, Canada. We examined both the attitudes of youth smokers toward common smoking cessation approaches and factors associated with intentions to join a school-based cessation program. The majority of youth smokers intend to quit smoking but tend to have negative attitudes toward most formal smoking cessation approaches; Nicotine Replacement Therapy (NRT) was an exception. Among occasional smokers, self-identification as a smoker and being physically active were positively associated with intending to join a school-based cessation program. Having tried to quit smoking at least once in the past year more than doubled the likelihood of being interested in a school-based program among both occasional and daily smokers.\nQuestion: Youth smokers' beliefs about different cessation approaches: are we providing cessation interventions they never intend to use?",
        "gt": "Findings have the potential for informing the development of more effective campaigns for engaging adolescent smokers into smoking cessation treatment. Results also reinforce the need for programmatic innovation within and beyond school settings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patient satisfaction is an increasing area of interest due to implications of pay for performance and public reporting of results. Although scores are adjusted for patient factors, little is known about the relationship between hospital structure, postoperative outcomes, and patient satisfaction with the hospital experience. Hospitals participating in the University HealthSystem Consortium database from 2011-2012 were included. Patients were restricted to those discharged by general surgeons to isolate surgical patients. Hospital data were paired with Hospital Consumer Assessment of Healthcare Providers and Systems (HCAHPS) results from the Hospital Compare website. Postoperative outcomes were dichotomized based on the median for all hospitals and stratified based on surgical volume. The primary outcome of interest was high on overall patient satisfaction, whereas other HCAHPS domains were assessed as secondary outcomes. Chi square and binary logistic regression analyses were performed to evaluate whether postoperative outcomes or surgical volume more significantly influenced high patient satisfaction. The study population consisted of 171 hospitals from the University HealthSystem Consortium database. High surgical volume was a more important predictor of overall patient satisfaction regardless of hospital complication (P<0.001), readmission (P<0.001), or mortality rates (P = 0.009). Volume was found to play less of a role in predicting high satisfaction on the other HCAHPS domains. Postoperative outcomes were more predictive of high satisfaction with providers, the hospital experience, and environment.\nQuestion: Patient satisfaction: does surgical volume matter?",
        "gt": "High surgical volume more strongly predicted overall patient satisfaction on the HCAHPS survey than postoperative outcomes, whereas volume was less predictive in other HCAHPS domains. Patients may require more specific questioning to identify high quality, safe hospitals.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: DSM-IV subtypes anorexia nervosa by the presence or absence of bulimic symptoms. Assessing whether bulimic symptoms are related to the probability of recovery can provide justification for subtyping of anorexia. Two hundred twenty-five treatment-seeking women with anorexia and/or bulimia nervosa were interviewed every 3 months for up to 4 years. Survival methods were used for analyses. Less than half of the entire cohort recovered; however, the great majority of the women became less symptomatic over time. Contrary to findings from previous studies, bulimic anorexics had a higher rate of recovery than restricting anorexics.\nQuestion: Subtyping eating disorders: is it justified?",
        "gt": "Differences in course provide some support for the subtyping of anorexia nervosa. Additional prospective studies are needed before subtyping can be warranted.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Oncoplastic breast reduction has been shown to be an effective approach to breast conservation surgery in women with macromastia. Clear surgical margins can be achieved while simultaneously improving symptomatic macromastia and enhancing aesthetic outcomes. Little has been written about postoperative complications after this procedure, beyond the risk of locoregional recurrence. This study aimed to compare the complication profile for oncoplastic breast reduction versus reduction for benign macromastia. A retrospective review of our experience with oncoplastic breast reduction was performed. This represented a consecutive series of 118 patients undergoing bilateral breast reduction during the 7-year study period from March 2005 to March 2012. There were 64 patients identified who underwent oncoplastic breast reduction. Patients were determined to be a good candidate for breast conservation therapy if it was felt that clear surgical margins could be obtained without mastectomy. Postoperative complications (within 6 weeks of surgery) were compared to a control group of 56 patients undergoing reduction for benign macromastia. The associations between complications and potential risk factors were analyzed using logistic regression. Patients undergoing oncoplastic breast reduction and reduction for benign macromastia had some key differences. In general, macromastia patients were younger (mean age, 42.3 vs 57.5 years; P<0.001) and had lower body mass index (mean, 26.1 vs 30.6 kg/m2; P<0.001) compared to those patients having oncoplastic reduction. Within the oncoplastic reduction group, 14 (21.9%) patients had a total of 16 complications; among the benign macromastia group, 9 (16.1%) patients had a total of 10 complications (P = 0.420). On univariate analysis, oncoplastic reduction was not predictive of having a perioperative complication (odds ratio, 1.462; 95% confidence interval, 0.579-3.696; P = 0.422). Body mass index was found to be predictive of having a complication after reduction for either indication (odds ratio, 1.108; 95% confidence interval, 1.018-1.206; P = 0.017). Within the oncoplastic reduction cohort at an average follow-up of 34.6 months (range, 0.3-90.3 months), 5 (7.9%) patients developed locoregional recurrence and 2 patients developed distant metastasis.\nQuestion: A Comparative Retrospective Analysis of Complications After Oncoplastic Breast Reduction and Breast Reduction for Benign Macromastia: Are These Procedures Equally Safe?",
        "gt": "Compared with reduction mammoplasty for benign macromastia, a widely accepted procedure, patients undergoing oncoplastic breast reduction were equally likely to have a postoperative complication. Elevated body mass index was shown to be a statistically significant predictor of having a complication after reduction for either indication. Overall complication rates were acceptably low for both procedures.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Mast cells (MCs) are multifunctional immune cells that produce a number of vasoactive or thromboactive mediators. Elevated numbers of human heart MCs are observed in the shoulder regions of coronary atherosclerotic plaques, suggesting that they play a role in plaque rupture. Cardiac MC degranulation after myocardial ischemia has been documented in animal models. Cardiac MCs are highly profibrinolytic cells and release tryptase, their specific protease, after ischemic events. Mast cell activation and release of tryptase may differentiate among patients with acute coronary syndromes (ACS), potentially determining the clinical course of ACS. Tryptase levels may indirectly reflect the fibrinolytic status of patients. Mast cell activation after ACS was estimated in 10 controls and 52 patients by measuring the serum levels of tryptase in the acute phase, at 2 weeks, and at 3 months after the ACS episode. Total tryptase levels were determined by using the UniCAP system and analyzed with respect to the patients' clinical types of ACS on admission (ACS with persistent ST-segment elevation on electrocardiogram or with ST-segment depression). Significant differences in serum tryptase levels between the groups were found, with higher serum tryptase concentrations in the ST-segment depression group in the acute phase, and at follow-up.\nQuestion: Tryptase levels in patients after acute coronary syndromes: the potential new marker of an unstable plaque?",
        "gt": "Serum tryptase concentration differences among patients with distinct types of ACS may indicate a more important role of human heart MCs in ACS with ST-segment depression pathogenesis. To our knowledge, this is the first report indicating that serum tryptase levels may differentiate patients with distinct types of ACS.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Central venous catheter (CVC)-related infections are a substantial problem in the intensive care unit (ICU). Our infection control team initiated the routine use of antiseptic-coated (chlorhexidine-silver sulfadiazine; Chx-SS) CVCs in our adult ICUs to reduce catheter-associated (CA) and catheter-related (CR) blood stream infection (BSI) as we implemented other educational and best practice standardization strategies. Prior randomized studies documented that the use of Chx-SS catheters reduces microbial colonization of the catheter compared with an uncoated standard (Std) CVC but does not reduce CR-BSI. We therefore implemented the routine use of uncoated Std CVCs in our surgical ICU (SICU) and examined the impact of this change. The use of uncoated Std CVCs does not increase CR-BSI rate in an SICU. Prospective evaluation of universal use of uncoated Std CVCs, implemented November 2007 in the SICU. The incidences of CA-BSI and CR-BSI were compared during November 2006-October 2007 (universal use of Chx-SS CVCs) and November 2007-October 2008 (universal use of Std CVCs) by t-test. The definitions of the U.S. Centers for Disease Control and Prevention were used for CA-BSI and CR-BSI. Patient data were collected via a dedicated Acute Physiology and Chronic Health Evaluation (APACHE) III coordinator for the SICU. Annual use of CVCs increased significantly in the last six years, from 3,543 (2001) to 5,799 (2006) total days. The APACHE III scores on day 1 increased from a mean of 54.4 in 2004 to 55.6 in 2008 (p\u2009=\u20090.0010; 95% confidence interval [CI] 1.29-5.13). The mean age of the patients was unchanged over this period, ranging from 58.2 to 59.6 years. The Chx-SS catheters were implemented in the SICU in 2002. Data regarding the specific incidence of CR-BSI were collected beginning at the end of 2005, with mandatory catheter tip cultures when CVCs were removed. Little difference was identified in the incidence of BSI between the interval with universal Chx-SS use and that with Std CVC use. (Total BSI 0.7 vs. 0.8 per 1,000 catheter days; CA-BSI 0.5 vs. 0.8 per 1,000 catheter days; CR-BSI 0.2 vs. 0 per 1,000 catheter days.) No difference was seen in the causative pathogens of CA-BSI or CR-BSI.\nQuestion: Prevention of catheter-related blood stream infection: back to basics?",
        "gt": "Eliminating the universal use of Chx-SS-coated CVCs in an SICU with a low background incidence of CR-BSIs did not result in an increase in the rate of CR-BSIs. This study documents the greater importance of adherence to standardization of the processes of care related to CVC placement than of coated CVC use in the reduction of CR-BSI.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To test women's ability to recall their past binging and purging behaviors. Ten-year follow-up study of women who had participated in a cross-sectional survey during college. In 1982, a sample of freshman and senior women at a large university in the Boston area were questioned about their weight, dieting history, bulimic symptoms, and eating patterns, attitudes, and concerns. In 1992, all subjects who responded to the 1982 survey were followed up to assess changes in bulimic symptoms and ability to recall past behaviors. Among the 476 women who responded to both surveys, the percentage in 1992 who reported having ever binged and/or purged was less than the percentage in 1982, indicating that the recall of past behaviors was less than perfect. Denial in 1992 of ever having engaged in the behaviors ranged from 22% among the women who were self-inducing vomiting in 1982 to 64% among the women who had reported current fasting or strict dieting in 1982. Recall of past behaviors in 1992 was better among the women who had been current bingers or purgers in 1982.\nQuestion: Disordered eating: can women accurately recall their binging and purging behaviors 10 years later?",
        "gt": "Our results demonstrate that ability to recall past binging and purging is only modest. Therefore to better understand the mental and physical health consequences of these behaviors this information should be collected prospectively.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Implantable left ventricular assist devices (LVADs) were designed for permanent implant, but we began their use for bridge-to-transplant (BTTx) to study their safety and effectiveness. We review our experience in order to compare the BTTx lessons learned with the outcomes and goals of permanent implants. From December 1991 until January 2002, 264 patients received 277 LVADs for BTTx. We analyzed temporal trends in pre-LVAD patient factors and device-specific time-related complications. Survival to transplant was 69%. Adverse event analysis demonstrated a high risk of infections (0.56, 1.28, and 1.88 per patient at 30 days and 3 and 6 months). HeartMate devices were more prone to infection than Novacor devices (p<0.0001). Cerebral infarctions occurred less commonly than infections (0.15, 0.25, 0.30 at 30 days and 3 and 6 months), were more common in Novacor than HeartMate (p = 0.0001), and were decreased by the new Novacor Vascutek conduit (p = 0.07), but these were still slightly higher than the HeartMate (p = 0.04). Device failures occurred in 21 instances (all but one were in HeartMate devices [p = 0.04 vs Novacor]), but have significantly decreased (p<0.0001) in HeartMate since 1998.\nQuestion: Do left ventricular assist device (LVAD) bridge-to-transplantation outcomes predict the results of permanent LVAD implantation?",
        "gt": "Infections and device durability limit the chronic use of the HeartMate device, but device failures are decreasing. Novacor has fewer problems with infection and durability, and the new Vascutek conduit will reduce, but not eliminate, strokes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: All epidemiological studies (cohort and case-control) which estimate risk of congenital malformations after exposure to metronidazole during early pregnancy were included in the meta-analysis. To obtain a summary odds ratio, the Mantel-Haenszel method was used. A test to verify absence of heterogeneity was also performed. One unpublished case-control and four published cohort studies fulfilled the inclusion criteria and were not statistically heterogeneous. A summary odds ratio was calculated for metronidazole exposure during the first trimester: OR = 1.08, 95% CI: 0.90-1.29, heterogeneity test chi2 = 4.72, P = 0.32.\nQuestion: Is metronidazole teratogenic?",
        "gt": "This meta-analysis did not find any relationship between metronidazole exposure during the first trimester of pregnancy and birth defects.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether access to cardiac procedures and drugs contributes to social and ethnic differences in coronary heart disease in a population setting. Prospective study with follow up over 15 years. Civil service employment grade was used as a measure of individual socioeconomic position. Need for cardiac care was determined by the presence of angina, myocardial infarction, and coronary risk factors. 20 civil service departments originally located in London. 10,308 civil servants (3414 women; 560 South Asian) aged 35-55 years at baseline in 1985-8. Use of exercise electrocardiography, coronary angiography, and coronary revascularisation procedures and secondary prevention drugs. Inverse social gradients existed in incident coronary morbidity and mortality. South Asian participants also had higher rates than white participants. After adjustment for clinical need, social position showed no association with the use of cardiac procedures or secondary prevention drugs. For example, men in the low versus high employment grade had an age adjusted odds ratio for angiography of 1.87 (95% confidence interval 1.32 to 2.64), which decreased to 1.27 (0.83 to 1.94) on adjustment for clinical need. South Asians tended to be more likely to have cardiac procedures and to be taking more secondary prevention drugs than white participants, even after adjustment for clinical need.\nQuestion: Does access to cardiac investigation and treatment contribute to social and ethnic differences in coronary heart disease?",
        "gt": "This population based study, which shows the widely observed social and ethnic patterning of coronary heart disease, found no evidence that low social position or South Asian ethnicity was associated with lower use of cardiac procedures or drugs, independently of clinical need. Differences in medical care are unlikely to contribute to social or ethnic differences in coronary heart disease in this cohort.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Despite the widely accepted view that Helicobacter pylori is the most important cause of peptic ulcer disease, recent studies have suggested that the microbe protects against nonsteroidal anti-inflammatory drug (NSAID)-associated gastroduodenal lesions and promotes ulcer healing. We investigated the effects of H. pylori eradication on the healing of NSAID-associated bleeding peptic ulcers. Chronic NSAID users presenting with peptic ulcer haemorrhage underwent endoscopy to secure haemostasis and to document H. pylori infection by rapid urease test and culture. They were prospectively randomized to receive either omeprazole (20 mg once daily) for 8 weeks or a 1-week course of triple therapy (bismuth subcitrate 120 mg, tetracycline 500 mg, metronidazole 400 mg, all given four times daily) plus omeprazole (20 mg once daily) for 8 weeks. Endoscopy was repeated after 8 weeks. Final H. pylori status was determined by a 13C-urea breath test that was performed at least 4 weeks after discontinuation of omeprazole. 195 H. pylori-infected NSAID users, complicated by bleeding ulcers, were randomized to receive omeprazole alone (102) or triple therapy plus omeprazole (93). 174 patients returned for second endoscopy at 8 weeks (91 in the omeprazole group, 83 in the triple therapy group). Urea breath test was negative in 14% in the omeprazole group vs. 92% in the triple therapy group (P<0.001). Complete ulcer healing was achieved in 88 (97%) patients in the omeprazole group and 77 (93%) in the triple therapy group (P=0. 31). On intention-to-treat analysis, ulcers were healed in 86% of the omeprazole group and 83% of the triple therapy group (P=0.50). There was no significant difference in the healing rates of gastric or duodenal ulcers between the two groups.\nQuestion: Does eradication of Helicobacter pylori impair healing of nonsteroidal anti-inflammatory drug associated bleeding peptic ulcers?",
        "gt": "Eradication of H. pylori did not impair the healing of NSAID-associated bleeding peptic ulcers.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adherence to statin therapy has been shown to be suboptimal. In statin-treated patients with residual elevated low density lipoprotein cholesterol (LDL-C) levels the physician must decide whether to switch to a more potent statin or try and achieve better adherence. We examined the association between adherence and LDL-C within low, moderate and high intensity statin groups in a \"real world\" setting. We assessed annual adherence by the mean MPR (Medication Possession Ratio = number of purchased/prescribed daily doses) in unselected patient group. Statins were stratified (ACC/AHA Guideline) into low, moderate and high intensity groups. The impact of adherence on LDL levels was assessed by LOESS (locally weighted scatter plot smoothing). Out of 1183 patients 173 (14.6%) were treated with low, 923 (78.0%) with moderate and 87 (7.4%) with high intensity statins. Statin intensity was inversely associated with adherence (MPR 77\u00b121, 73\u00b122 and 69\u00b121% for low, moderate and high intensity respectively, p=0.018). Non-adjusted LDL levels decreased with higher adherence: a 10% adherence increase resulted in LDL decrease of 3.5, 5.8 and 7.1mg/dL in low, moderate and high intensity groups. Analysis of the adherence effect on LDL levels adjusted for age, DM and ischemic heart disease showed that MPR above 80% was associated with an additional decrease in LDL levels only in the high intensity group.\nQuestion: Statin adherence and LDL cholesterol levels. Should we assess adherence prior to statin upgrade?",
        "gt": "Increased adherence to statins beyond an MPR of 80% improves LDL levels only among patients given high intensity therapy. Switching from lower to higher intensity therapy may be more effective than further efforts to increase adherence.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We employed the placebo-caffeine paradigm to test whether the presence or absence of a substance (caffeine) influences the placebo effect. In experiment 1 consisting of four conditions with n = 15 participants each (control, placebo, two double-blind groups, each with placebo only), we maximized the placebo effect through expectation. Effects were assessed with physiological (blood pressure, heart rate), psychomotor (response times), and well-being indicators (self-report). In experiment 2, caffeine was administered in one of the double-blind groups, and another condition was added where caffeine was given openly. Effect sizes were medium to large for some outcome parameters in experiment 1 and 2, showing partial replicability of the classical placebo effect. Although not formally significant, differences between the double blind placebo conditions of the two experiments (with and without caffeine present) were medium to small. There was a significant difference (p = 0.03) between experiment 1 and experiment 2 in the physiological variables, and a near significant interaction effect between groups and experiments in the physiological variables (p = 0.06).\nQuestion: Does the presence of a pharmacological substance alter the placebo effect?",
        "gt": "The question warrants further scrutiny. The presence of a pharmacological substance might change the magnitude of the placebo response.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There have been dramatic changes in neurology over the past decade; these advances require a constant adaptation of residents' theoretical and practical training. The French Association of Neurology Residents and the College of Neurology Teachers conducted a national survey to assess the French neurology residents' satisfaction about their training. A 16-item questionnaire was sent via e-mail to French neurology residents completing training in 2014. Data were collected and processed anonymously. Of eligible respondents, 126 returned the survey, representing approximately 40% of all the French neurology residents. Most residents (78%) rated their clinical training favorably. Seventy-two percent reported good to excellent quality teaching of neurology courses from their faculty. However, many residents (40%) felt insufficient their doctoral thesis supervision. All residents intended to enter fellowship training after their residency, and most of them (68%) planned to practice in a medical center.\nQuestion: Are the French neurology residents satisfied with their training?",
        "gt": "French neurology residents seemed satisfied with the structure and quality of their training program. However, efforts are required to improve management of the doctoral thesis and make private practice more attractive and accessible during the residency. In the future, similar surveys should be scheduled to regularly assess neurology residents' satisfaction and the impact of the forthcoming national and European reforms.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To study the relationship between the primary sensitization to wasp venoms and the geographical and seasonal circumstances of the anaphylaxis-induced sting. We performed a retrospective review of 115 patients (age 10-80) who suffered a systemic reaction to a wasp sting. Season and type of locality (urban or rural) at the moment of the sting were recorded. Serum specific IgE levels to venoms from Vespula and Polistes were measured, and a primary sensitization was determined to whichever genus of wasp for which the highest class of specific IgE was observed. The primary sensitization in relation to the type of locality and the season was assessed using the chi-square test. Most reactions occurred in urban areas (67.8 %), and in the summer season (63.4 %). Most patients were sensitized to Vespula venom (94.8 %). Primary sensitization was to Vespula in 56.5 %, to Polistes in 10.4 %, and undetermined in 33 %. The distribution of geographical areas did not show significant differences in relation to primary sensitization (p>0.05). Most patients with primary sensitization to Vespula suffered the anaphylaxis-induced sting after the spring season, with a statistically significant result (p<0.05).\nQuestion: Hypersensitivity to Vespula and Polistes: can we tell the primary sensitization from the clinical history?",
        "gt": "In our population, the probability of Vespula sting is higher than Polistes sting when the reaction occurs after spring. This finding can help us to identify the responsible vespid when the diagnostic tests do not provide an accurate result.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Traits and mental states are considered to be inter-related parts of theory of mind. Attribution research demonstrates the influential role played by traits in social cognition. However, there has been little investigation into how individuals with autism spectrum disorders (ASD) understand traits. The ability of individuals with ASD to infer traits from descriptions of behavior was investigated by asking participants to read trait-implying sentences and then to choose one of two words that best related to the sentence. In Experiment 1, individuals with ASD performed similarly to matched controls in being faster at choosing the trait in comparison to the semantic associate of one of the words in the sentence. The results from Experiments 1 and 2 provided converging evidence in suggesting that inferring traits from textual descriptions of behavior occurs with relatively little effort. The results of Experiment 3 suggested that making trait inferences took priority over inferring actions or making semantic connections between words.\nQuestion: Do individuals with autism spectrum disorders infer traits from behavior?",
        "gt": "Individuals with ASD infer traits from descriptions of behavior effortlessly and spontaneously. The possibility of trait inference being a spared socio-cognitive function in autism is discussed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients with single-suture craniosynostosis (SSC) are at an elevated risk for long-term learning disabilities. Such adverse outcomes indicate that the early development of neural processing in SSC may be abnormal. At present, however, the precise functional derangements of the developing brain remain largely unknown. Event-related potentials (ERPs) are a form of noninvasive neuroimaging that provide direct measurements of cortical activity and have shown value in predicting long-term cognitive functioning. The current study used ERPs to examine auditory processing in infants with SSC to help clarify the developmental onset of delays in this population. Fifteen infants with untreated SSC and 23 typically developing controls were evaluated. ERPs were recorded during the presentation of speech sounds. Analyses focused on the P150 and N450 components of auditory processing. Infants with SSC demonstrated attenuated P150 amplitudes relative to typically developing controls. No differences in the N450 component were identified between untreated SSC and controls.\nQuestion: Direct brain recordings reveal impaired neural function in infants with single-suture craniosynostosis: a future modality for guiding management?",
        "gt": "Infants with untreated SSC demonstrate abnormal speech sound processing. Atypicalities are detectable as early as 6 months of age and may represent precursors to long-term language delay. Electrophysiological assessments provide a precise examination of neural processing in SSC and hold potential as a future modality to examine the effects of surgical treatment on brain development.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: No evidence addresses the effectiveness of patient-centered cultural competence training in non-Western settings. To examine whether a patient-centered cultural competency curriculum improves medical students' skills in eliciting the patients' perspective and exploring illness-related social factors. Fifty-seven medical students in Taiwan were randomly assigned to either the control (n = 27) or one of two intervention groups: basic (n = 15) and extensive (n = 15). Both intervention groups received two 2-hour patient-centered cultural competency workshops. In addition, the extensive intervention group received a 2-hour practice session. The control group received no training. At the end of the clerkship, all students were evaluated with an objective structured clinical examination (OSCE). Students in the extensive intervention group scored significantly higher than the basic intervention and control groups in eliciting the patient's perspective (F = 18.38, p<0.001, eta(2) = 0.40). Scores of both intervention groups were significantly higher than the control group in the exploring social factors (F = 6.66, p = 0.003, eta(2) = 0.20).\nQuestion: Cross-cultural medical education: can patient-centered cultural competency training be effective in non-Western countries?",
        "gt": "Patient-centered cultural competency training can produce improvement in medical students' cross-cultural communication skills in non-Western settings, especially when adequate practice is provided.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Low levels of physical activity (PA) and poor fitness tend to predict a decline in mobility. The current study investigated whether PA modifies the predictive value of health-related fitness (HRF) tests on difficulty in walking 2 km (WD). PA was assessed by self-reported questionnaires in 1990 and 1996. Subjects age 55 to 69 years and free of self-reported WD participated in assessment of HRF in 1996. Occurrence of WD was assessed by questionnaire in 2002 (n=537). There were no statistically significant interactions between PA and HRF tests; thus, PA and HRF were both independent predictors of WD. Regardless of the PA level, the subjects in the poorest performing third in each HRF test had higher risk of WD than the subjects in the best performing third.\nQuestion: Does physical activity affect the predictive value of health-related fitness tests on walking difficulty?",
        "gt": "PA and HRF seemed to be independent predictors of WD, although the association of PA with WD was weaker than the association of HRF. Thus, PA did not modify the predictive value of HRF on WD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The cognitive behavioural (CB) model of health anxiety proposes parental illness leads to elevated health anxiety in offspring by promoting the acquisition of specific health beliefs (e.g. overestimation of the likelihood of illness). Our study tested this central tenet of the CB model. Participants were 444 emerging adults (18-25-years-old) who completed online measures and were categorized into those with healthy parents (n = 328) or seriously ill parents (n = 116). Small (d = .21), but significant, elevations in health anxiety, and small to medium (d = .40) elevations in beliefs about the likelihood of illness were found among those with ill vs. healthy parents. Mediation analyses indicated the relationship between parental illness and health anxiety was mediated by beliefs regarding the likelihood of future illness.\nQuestion: Linking Illness in Parents to Health Anxiety in Offspring: Do Beliefs about Health Play a Role?",
        "gt": "Our study incrementally advances knowledge by testing and supporting a central proposition of the CB model. The findings add further specificity to the CB model by highlighting the importance of a specific health belief as a central contributor to health anxiety among offspring with a history of serious parental illness.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Pyelectasis can be defined as mild to moderate dilatation of the urinary tract and is diagnosed by means of an ultrasound scan (0.5-2cm transverse diameter in the initial ultrasound performed after birth). There is some disagreement about whether cystography should be indicated as standard practice. The aim of this study was to establish if renal function tests are useful in determining which cases of mild to moderate dilatation of the urinary tract do not require an initial cystography. The study was conducted on 79 infants (57 males, 22 females) with pyelectasis. Seventy-three were diagnosed in utero and 6 after birth. All infants underwent at least one cystography and one desmopressin urine concentration test before one year of age. Compared to infants without vesicoureteral reflux (VUR) (n=68), infants with VUR (n=11; two with Grade I, three with Grade II, five with Grade III, two with Grade IV) showed a significantly lower (P=.006) maximum urine osmolality and a significantly higher microalbumin/creatinine ratio (P<.001) and NAG/creatinine ratio (P=.003). The negative predictive value of the first two tests was 93%. Sensitivity of the maximum urine osmolality to detect VUR was 72.7% (specificity 63.2%). Sensitivity of the microalbumin/creatinine ratio to detect VUR was 62.5% (specificity 75%). The positive probability ratio (PR) was 1.29 for the NAG/creatinine ratio, 2.03 for the maximum urine osmolality and 2.5 for the microalbumin/creatinine ratio. The negative PR was 0.95 for the NAG/creatinine ratio, 0.43 for the maximum urine osmolality and 0.5 for the microalbumin/creatinine ratio.\nQuestion: Should a cystography be performed on all breastfeeding infants with mild to moderate dilatation of the urinary tract?",
        "gt": "Pyelectasis is a benign condition. Only 2 patients required pharmacological intervention (prophylactic treatment for VUR Grade IV patients). Initially at least, cystography should not be indicated in cases of microalbuminuria and/or normal urine concentrations.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To study the influence of continuous administration of heparin on platelet function in intensive care patients. Prospective, serial investigation. Clinical investigation on a surgical and neurosurgical intensive care unit in a university hospital. The study included 45 patients: 15 postoperative with patients sepsis (Acute Physiology and Chronic Health Evaluation II score between 15 and 25), 15 trauma patients (Injury Severity Score 15 to 25), and 15 neurosurgical patients. Management of the patients was carried out according to the guidelines for modern intensive care therapy. Sepsis and trauma patients received standard (unfractionated) heparin continuously [aim: an activated partial thromboplastin time (aPTT) approximately 2.0 times normal value; sepsis-heparin and trauma-heparin patients], whereas neurosurgical patients received no heparin (neurosurgical patients). From arterial blood samples, platelet aggregation was measured by the turbidimetric method. Platelet aggregation was induced by adenosine diphosphate (ADP; 2.0 mumol/l), collagen (10 micrograms/ml), and epinephrine (25 mumol/l). Measurements were carried out on the day of diagnosis of sepsis or 12 h after hemodynamic stabilization (trauma and neurosurgery patients) (baseline) and during the next 5 days at 12.00 noon. Standard coagulation parameters [platelet count and fibrinogen and antithrombin III (AT III) plasma concentrations] were also monitored. Heparin 4-10 U/kg per h (mean dose: approximately 500 U/h) was necessary to reach an aPTT of about 2.0 times normal. Platelet count was highest in the neurosurgical patients, but it did not decrease after heparin administration to the trauma and sepsis patients. AT III and fibrinogen plasma levels were similar in the three groups of patients. In the sepsis group, platelet aggregation variables decreased significantly (e.g., epinephrine-induced maximum platelet aggregation:-45 relative % from baseline value). Platelet function recovered during the study and even exceeded baseline values (e.g., ADP-induced maximum platelet aggregation: +42.5 relative % from baseline value). Continuous heparinization did not blunt this increase of platelet aggregation variables. In the heparinized trauma patients, platelet aggregation variables remained almost stable and were no different to platelet aggregation data in the untreated neurosurgical patients.\nQuestion: Does continuous heparinization influence platelet function in the intensive care patient?",
        "gt": "Continuous administration of heparin with an average dose of approximately 500 U/h did not negatively influence platelet function in the trauma patients. Recovery from reduced platelet function in the sepsis group was not affected by continuous heparinization. Thus, continuous heparinization with this dose appears to be safe with regard to platelet function in the intensive care patient.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Drug therapy can improve patients' quality of life and health outcomes; however, underuse, overuse and inappropriate use of drugs can occur. Systematic examination of potential opportunities for improving prescribing and medication use is needed. To convene a diverse group of stakeholders to learn about and discuss advantages and limitations of data sources, tools and methods related to drug prescribing indicators; foster methods to assess safe, appropriate and cost-effective prescribing; increase awareness of international organizations who develop and apply performance indicators relevant to Canadian researchers, practitioners and decision-makers; and provide opportunities to apply information to the Canadian context. Approximately 50 stakeholders (health system decision-makers, senior and junior researchers, healthcare professionals, graduate students) met June 1-2, 2009 in Halifax, Canada. Four foundational presentations on evaluating quality of prescribing were followed by discussion in pre-assigned breakout groups of a prepared case (either antibiotic use or prescribing for seniors), followed by feedback presentations. Many European countries have procedures to develop indicators for prescribing and quality use of medicines. Indicators applied in diverse settings across the European Union use various mechanisms to improve quality, including financial incentives for prescribers.\nQuestion: Prescribing indicators: what can Canada learn from European countries?",
        "gt": "Further Canadian approaches to develop a system of Canadian prescribing indicators would enable federal/provincial/territorial and international comparisons, identify practice variations and highlight potential areas for improvement in prescribing, drug use and health outcomes across Canada. A more standardized system would facilitate cross-national research opportunities and enable Canada to examine how European countries use prescribing indicators, both within their country and across the European Union.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Hyperuricemia is commonly associated with obesity, glucose intolerance, hypertension, dyslipidemia, and atherosclerotic cardiovascular disease. The resemblance of the metabolic syndrome and hyperuricemia has led to the suggestion that hyperuricemia is a part of the metabolic syndrome. The purpose of this study is to examine the contribution of uric acid (UA) as an additional component of the metabolic syndrome in middle-aged men. In total, 393 male participants, aged 45-60 years, were recruited from a professional health evaluation program. Anthropometric measurements and blood pressure (BP) were taken after an overnight fast. Fasting blood samples were collected for the measurements of glucose, UA, and lipid profile. Logistic regression models were fitted to examine the relationship between UA and the diagnosis of metabolic syndrome. Factor analysis was performed to explore the relationship between UA and the components of the metabolic syndrome. The diagnosis of the metabolic syndrome was significantly associated with waist circumference (WC), glucose, triglycerides (TG), high-density lipoprotein cholesterol (HDL-C), systolic BP, and liver enzyme levels, but not associated with UA levels. The sensitivity of hyperuricemia (serum UA>or = 7.0 mg/dL) for the diagnosis of the metabolic syndrome was 58.0% and the specificity was 55.3%. In factor analysis, UA aggregated with body mass index, WC, glucose, log TG, and HDL-C as a metabolic factor. Systolic and diastolic BP were loaded on a second factor separately. The model loaded with UA explained a similar proportion of the total variance (56.9%), as did the model loaded without UA (62.5%).\nQuestion: Is hyperuricemia another facet of the metabolic syndrome?",
        "gt": "Our results suggest that the contribution of UA as an additional component of the syndrome seems to be insignificant. We propose that hyperuricemia might not be an important facet for the understanding of the underlying structure of the metabolic syndrome.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether intrauterine growth retardation associated with normal umbilical artery blood flow is a benign condition. A prospective comparative study of growth retarded fetuses with normal and abnormal umbilical artery blood flow. The fetal assessment clinic of a large maternity hospital in Ireland. 179 Women with singleton pregnancies in which the fetal abdominal circumference, measured by ultrasonography, was below the fifth centile for gestation. Perinatal deaths, fetal distress requiring caesarean section, preterm delivery, cerebral irritation. Of 124 fetuses with normal flow, all physically normal fetuses survived but one baby had cerebral irritation; there were six preterm deliveries and four caesarean sections for fetal distress. Among 55 women with abnormal flow there were two midtrimester abortions, three perinatal deaths, and one case of cerebral irritation in physically normal fetuses.\nQuestion: Is intrauterine growth retardation with normal umbilical artery blood flow a benign condition?",
        "gt": "Intrauterine growth retardation associated with normal umbilical blood flow is a different entity from that associated with abnormal flow, normal flow being largely benign and abnormal flow carrying a serious risk of adverse outcome.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The effect of post-transplant maintenance tyrosine kinase inhibitors (TKIs) on the outcomes of allogeneic hematopoietic stem cell transplantation in high-risk Philadelphia chromosome-positive (Ph(+)) leukemia remains unknown. A retrospective analysis that included allograft recipients with accelerated phase and blast phase chronic myeloid leukemia or Ph(+) acute lymphoblastic leukemia who had received post-transplant maintenance TKI therapy from 2004 to\u00a02014. A total of 26 patients, 9 with accelerated phase/blast phase CML and 17 with Ph(+) acute lymphoblastic leukemia, received maintenance post-transplant therapy with imatinib, dasatinib, nilotinib, or ponatinib. The TKI was selected according to the pretransplantation TKI response, anticipated toxicities, and ABL1 domain mutations, when present. Newer generation TKIs were initiated at a\u00a0\u2265 50% dose reduction from the standard pretransplantation dosing to limit the toxicities and avoid therapy interruptions. TKIs were started a median of 100 days (range, 28-238 days) after transplantation and were administered for a median of 16 months (range, 8 days to 105 months). Eight patients discontinued therapy because of adverse events. With a median follow-up of 3.6 years (range, 4 months to 8.7 years), the 5-year relapse-free survival rate was 61%. All 3 patients who developed a relapse underwent successful salvage treatment and remained disease-free. The 5-year overall survival rate was 78%.\nQuestion: Does Post-Transplant Maintenance Therapy With Tyrosine Kinase Inhibitors Improve Outcomes of Patients With High-Risk Philadelphia Chromosome-Positive Leukemia?",
        "gt": "Maintenance TKI therapy after transplantation is feasible and might reduce the incidence of relapses and improve outcomes after allogeneic hematopoietic stem cell transplantation for patients with high-risk Ph(+) leukemia.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Wine glass size can influence both perceptions of portion size and the amount poured, but its impact upon purchasing and consumption is unknown. This study aimed to examine the impact of wine glass size on wine sales for on-site consumption, keeping portion size constant. In one establishment (with separate bar and restaurant areas) in Cambridge, England, wine glass size (Standard; Larger; Smaller) was changed over eight fortnightly periods. The bar and restaurant differ in wine sales by the glass vs. by the bottle (93\u00a0% vs. 63\u00a0% by the glass respectively). Daily wine volume purchased was 9.4\u00a0% (95\u00a0% CI: 1.9, 17.5) higher when sold in larger compared to standard-sized glasses. This effect seemed principally driven by sales in the bar area (bar: 14.4\u00a0% [3.3, 26.7]; restaurant: 8.2\u00a0% [-2.5, 20.1]). Findings were inconclusive as to whether sales were different with smaller vs. standard-sized glasses.\nQuestion: Does wine glass size influence sales for on-site consumption?",
        "gt": "The size of glasses in which wine is sold, keeping the portion size constant, can affect consumption, with larger glasses increasing consumption. The hypothesised mechanisms for these differential effects need to be tested in a replication study. If replicated, policy implications could include considering glass size amongst alcohol licensing requirements.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although posterior wall of left atrium (LA) is known to be arrhythmogenic focus, little is known about the effect of posterior wall isolation (PWI) in patients who undergo radiofrequency catheter ablation (RFCA) for persistent atrial fibrillation (PeAF). We randomly assigned 120 consecutive PeAF patients to additional PWI [PWI (+), n=60] or control [PWI (-), n=60]groups. In all patients, linear ablation was performed after circumferential pulmonary vein isolation (PVI). Linear lesions included roof, anterior perimitral, and cavotricuspid isthmus lines with conduction block. In PWI (+) group, posterior inferior linear lesion was also conducted. Creatine kinase-MB (CK-MB) and troponin-T levels were measured 1day after RFCA. LA emptying fraction (LAEF) was assessed before and 12 months after RFCA. A total of 120 subjects were followed for 12 months after RFCA. There were no significant differences between two groups in baseline demographics and LA volume (LAV). The levels of CK-MB and troponin-T and procedure time were not significantly different between the groups. AF termination during RFCA was more frequently observed in PWI (+) than control (P=0.035). During follow-up period, recurrence occurred in 10 (16.7%) patients in PWI (+) and 22 (36.7%) in control (P=0.02). The change in LAEF was not significantly different between the groups. On multivariate analysis, smaller LAV and additional PWI were independently associated with procedure outcome.\nQuestion: Does isolation of the left atrial posterior wall improve clinical outcomes after radiofrequency catheter ablation for persistent atrial fibrillation?",
        "gt": "PWI in addition to PVI plus linear lesions was an efficient strategy without deterioration of LA pump function in patients who underwent RFCA for PeAF.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Ceramic-on-ceramic bearing couples are theoretically attractive in total hip arthroplasty (THA) because of low wear, but concerns regarding ceramic fracture and squeaking have arisen. Improved material properties of newer alumina matrix composite (AMC) materials, known as Delta ceramics, may reduce these risks. In addition, the use of thinner liners and larger femoral heads may be helpful clinically to lower the rate of dislocation. However, limited short-term clinical results are available and intermediate-term effects are unclear.QUESTIONS/ (1) What is the frequency of bearing-related complications (dissociation, fracture, and noise) with ceramic-on-ceramic AMC bearings in cementless THA? (2) What other complications arose in patients treated with these bearings? (3) What are the Harris hip scores (HHS) and survivorship free from reoperation and revision at a minimum of 5 years after cementless THA performed with AMC bearings? Over a 9-month period in 2009, one surgeon performed 125 THAs, of which 100 (80% of the total) were performed with cementless, AMC bearings. During the period in question, the exclusion criteria for this implant were primary THAs with severe acetabular or femoral bone defect and revision THAs. Of these, 94 hips (95%) in 91 patients were available for analysis at a minimum of 5 years (range, 5-6 years), because five patients (six hips) had died. Mean age at the time of arthroplasty was 55 \u00b1 14 years. Prostheses with an identical design and Biolox(\u00ae) Delta ceramics were used in all patients. Noise was classified into squeaking, clicking, grinding, and popping. Ceramic fracture, dislocation, and any other complications associated with the use of AMC ceramics were also investigated. Clinical evaluation included the modified HHS preoperatively and at each followup. Survivorship free from reoperation and revision was calculated using the Kaplan-Meier method. Of 91 patients, four developed bearing-related complications, including one with liner dissociation despite initial square seating and three with clicking. No patients had ceramic fractures. A single event of perioperative dislocation occurred in one patient and postoperative periprosthetic fracture occurred in two hips. Mean HHS improved from 56 to 93 points at the final followup (p<0.001). Survivorship at 5 years free from reoperation and revision was 96.8% and 97.9%, respectively.\nQuestion: Do alumina matrix composite bearings decrease hip noises and bearing fractures at a minimum of 5 years after THA?",
        "gt": "Improved material properties combined with the possible use of larger diameter heads make AMC ceramics a promising alternative bearing option with seemingly comparable clinical outcomes reported by others with conventional ceramic bearings. Despite these encouraging results, however, meticulous technical precautions such as square seating and proper impaction in particular should be taken during liner insertion, because we did observe one liner dissociation and several patients with hip noises.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We recently showed that diminished motor cortical excitability is associated with high levels of post-stroke fatigue. Motor cortex excitability impacts movement parameters such as reaction and movement times. We predicted that one or both would be influenced by the presence of post-stroke fatigue. 41 first-time stroke survivors (high fatigue n=21, Fatigue Severity Scale 7 (FSS-7) score>5; low fatigue n=20, FSS-7 score<3) participated in the study. Movement times, choice and simple reaction times were measured in all participants. A three way ANOVA with fatigue (high and low), task (movement time, simple reaction time and choice reaction time) and hand (affected and unaffected) as the three factors, revealed a significant difference between affected (but not unaffected) hand movement times in the high compared to low fatigue groups. Reaction times, however, were not different between the high-fatigue and low-fatigue groups in either the affected or unaffected hand.\nQuestion: Post-stroke fatigue: a problem of altered corticomotor control?",
        "gt": "Previously, we showed that motor cortex excitability is lower in patients with high post-stroke fatigue. Our current findings suggest that post-stroke fatigue (1) is a problem of movement speed (possibly a consequence of diminished motor cortex excitability) and not movement preparation, and (2) may have a focal origin confined to the lesioned hemisphere. We suggest that low motor cortex excitability in the lesioned hemisphere is a viable therapeutic target in post-stroke fatigue.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Before being communicated to the caregiver, critical laboratory values are verified by repeat testing to ensure their accuracy and to avoid reporting false or erroneous results. To determine whether 2 testing runs offered any advantage over a single testing run in ensuring accuracy or in avoiding the reporting of false or erroneous results. Within the hematology laboratory, 5 tests were selected: hemoglobin level, white blood cell count, platelet count, prothrombin time, and activated partial thromboplastin time. A minimum of 500 consecutive critical laboratory test values were collected retrospectively for each test category. The absolute value and the percentage of change between the 2 testing runs for each critical value were calculated and averaged for each test category and then compared with our laboratory's preset, acceptable tolerance limits for reruns. The mean results obtained for the absolute value and the percentage of change between the testing runs were 0.08 g/dL (1.4%) for hemoglobin levels, 50 cells/\u00b5L (10.2%) for white blood cell counts, 1500 cells/\u00b5L (9.9%) for platelet counts, 0.7 seconds (1.4%) for prothrombin time, and 5.1 seconds (4.4%) for activated partial thromboplastin time (all within our laboratory's acceptable tolerance limits for reruns). The percentage of specimens with an absolute value or a mean percentage of change outside our laboratory's acceptable tolerance limits for reruns ranged between 0% and 2.2% among the test categories. No false or erroneous results were identified between the 2 testing runs in any category.\nQuestion: Does routine repeat testing of critical values offer any advantage over single testing?",
        "gt": "Routine, repeat testing of critical hemoglobin level, platelet count, white blood cell count, prothrombin time, and activated partial thromboplastin time results did not offer any advantage over a single run.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to assess whether changes in Cystatin C (CyC) after 48 h post contrast media exposure was a reliable indicator of acute kidney injury and the validity of a risk scoring tool for contrast-induced acute kidney injury (CI-AKI). We enrolled 121 patients for whom diagnostic coronary angiography were planned. The risk score for CI-AKI was calculated and serum creatinine (sCr) and CyC were measured before and 48 h post coronary angiography. CyC and sCr based AKI was calculated as a 25% increase from baseline within 48 h from contrast media exposure. Mean serum CyC and creatinine concentrations were 0.88 \u00b1 0.27 mg/dL and 0.79 \u00b1 0.22 mg/dL, respectively before the procedure and 1.07 \u00b1 0.47 mg/dL and 0.89 \u00b1 0.36 mg/dL, respectively 48 h after contrast media exposure (P<0.001). CyC based AKI occurred in 45 patients (37.19 %) and sCr based AKI occurred in 20 patients (16.52%) after the procedure. Mean risk score was found to be 4.00 \u00b1 3.478 and 3.60 \u00b1 4.122 for CyC based AKI and sCr based AKI, respectively and was significantly increased in CyC based AKI group (P<0.001).\nQuestion: Is cystatin-C superior to creatinine in the early diagnosis of contrast-induced nephropathy?",
        "gt": "CyC measured 48 h after contrast media exposure may be a more sensitive indicator of CI-AKI relative to creatinine and Mehran risk scoring is in good correlation with CyC increase.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The growing number of human immunodeficiency virus type 1 (HIV-1) infections worldwide and the increasing use of immunosuppressive modalities for organ transplantation have contributed to an epidemic of Kaposi's sarcoma (KS), which has been etiologically linked to human herpesvirus 8 (HHV8) or KS-associated virus. Since the onset of the acquired immunodeficiency syndrome epidemic, inflammation has been recognized as an essential component of KS pathology. HHV8 bears a gene (K1) encoding a transmembrane protein with an immunoreceptor tyrosine-based activation motif. This motif is present in receptors that mediate inflammation. To dissect the cellular effects of K1 function and the eventual role of K1 in KS, we developed a cell model for studying K1 expression. K1 was cloned from BC-3 lymphoma cells. To monitor transcriptional activation, K1 was coexpressed with plasmids containing luciferase under control of various promoters. K1 expression was monitored by indirect immunofluorescence and by combined immunoprecipitation/immunoblot analysis. Inflammatory cytokines were measured by enzyme-linked immunosorbent assay. Cellular transfection of the K1 gene induced reporter expression under control of nuclear factor-kappa B (NF-kappaB), which controls the transcription of numerous proteins involved in inflammation. Treatment of cells with aspirin, an agent that targets this intracellular pathway and blocks cell inflammatory responses, blocked K1-induced NF-kappaB-dependent promoter activity. When a second KS cofactor, i.e., the HIV-1-transactivating gene tat, was coexpressed with K1, we observed an additive effect on NF-kappaB-dependent transcription. K1 transfection stimulated the secretion of cytokines interleukin (IL) 6, granulocyte-macrophage colony-stimulating factor, and IL-12. Cells treated with the conditioned media of K1 transfectants exhibited similar characteristics of K1 transfectants, indicating that a paracrine loop was being activated.\nQuestion: Human herpesvirus 8 K1-associated nuclear factor-kappa B-dependent promoter activity: role in Kaposi's sarcoma inflammation?",
        "gt": "Thus, K1 may activate cells in which it is expressed, as well as other cells in a paracrine manner. K1 cooperates in signaling with HIV-1 Tat, suggesting that both of the proteins from these viruses converge to reach an enhanced level of inflammation that may underlie progressive KS.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The benefit of concurrent chemoradiotherapy (CCRT) in elderly patients with inoperable esophageal squamous cell carcinoma (SCC) is controversial. This study aimed to assess the efficiency and safety of CCRT in elderly thoracic esophageal cancer patients. Between January 2002 and December 2011, 128 patients aged 65 years or older treated with CCRT or radiotherapy (RT) alone for inoperable thoracic esophageal SCC were analyzed retrospectively (RT alone, n\u200a=\u200a55; CCRT, n\u200a=\u200a73). No treatment-related deaths occurred and no patients experienced any acute grade 4 non-hematologic toxicities. Patients treated with CCRT developed more severe acute toxicities than patients who received RT alone. The 3-year overall survival (OS) rate was 36.1% for CCRT compared with 28.5% following RT alone (p\u200a=\u200a0.008). Multivariate analysis identified T stage and treatment modality as independent prognostic factors for survival. Further analysis revealed that survival was significantly better in the CCRT group than in the RT alone group for patients \u2264 72 years. Nevertheless, the CCRT group had a similar OS to the RT group for patients>72 years.\nQuestion: Is there a benefit in receiving concurrent chemoradiotherapy for elderly patients with inoperable thoracic esophageal squamous cell carcinoma?",
        "gt": "Our results suggest that elderly patients with inoperable thoracic esophageal SCC could benefit from CCRT, without major toxicities. However, for patients older than 72 years, CCRT is not superior to RT alone in terms of survival benefit.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare virologic success between adult patients on tenofovir (TDF) and zidovudine (AZT)-containing first-line antiretroviral (ART) regimens in 10 rural clinics in Lesotho, Southern Africa. Multicentre cross-sectional study, patients \u226516 years, on first-line ART \u22656 months, receiving AZT/lamivudine (3TC) or TDF/3TC combined with efavirenz (EFV) or nevirapine (NVP). Patient characteristics and clinical/therapeutic history were collected on the day of blood draw for viral load (VL). Analysis was stratified for non-nucleoside reverse transcriptase inhibitor (EFV or NVP). A logistic regression model weighted for patients' baseline characteristics was used to assess the likelihood of virologic success (<80 copies/ml) in patients with TDF- as compared to AZT-backbones. In total 1539 patients were included in the analysis. Most were clinically and immunologically stable (clinical failure: 2.7% (AZT) and 2.8% (TDF); immunological failure: 4.6% (AZT) and 4.8% (TDF)). In EFV-based regimens (n = 1162), TDF was significantly associated with higher rates of virologic suppression than AZT (93.8% vs. 88.1%; weighted odds ratio: 2.15 (95% CI: 1.29-3.58; P = 0.003)). In NVP-based regimens, a similar trend was observed, but not significant (89.4% vs. 86.7%; 1.99 (0.83-4.75, P = 0.121)).\nQuestion: Is zidovudine first-line therapy virologically comparable to tenofovir in resource-limited settings?",
        "gt": "These findings support the WHO recommendation to use TDF/3TC/EFV as first-line regimen. They do, however, not support the recommendation that patients who are clinically stable on AZT should continue on this first-line regimen.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: malnutrition is regarded as a major risk factor for complications and delayed recovery in hospitalised elderly patients. to examine the prevalence of malnutrition in hospitalised elderly patients and evaluate simple clinical screening criteria. To investigate whether malnutrition was related to lack of care from the health care or social welfare system, quality of life and hospital length of stay (LOS). non-acute geriatric hospital. 294 elderly patients admitted for rehabilitation after acute hospital care; 244 patients were available for assessment. questionnaire interview about nutrition, social network and quality of life. Anthropometric and biochemical measurements, assessment of physical and cognitive function, recording of LOS, discharge destination and diagnosis. 126 patients (51.6%) were at risk of malnutrition using the criteria of body mass index<22 kg/m2 and/or weight loss>or=5%/6 months. Poor quality of life in women (P<0.04) and loss of the health of a spouse (P<0.02) correlated with weight loss. No differences were found in patients at risk regarding LOS, discharge destination, or aid from the social welfare system.\nQuestion: Older hospitalised patients at risk of malnutrition: correlation with quality of life, aid from the social welfare system and length of stay?",
        "gt": "this study confirms a high prevalence of malnutrition risk in hospitalised elderly patients. The health care and social welfare system appeared to be unaware of the problem. Poor quality of life in females and loss of the health of a spouse were related to malnutrition risk. The screening variables that were used appeared not to predict hospital length of stay or discharge destination.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Since the introduction of randomized controlled trials (RCT) in clinical research, there has been discussion of whether enrolled patients have worse or better outcomes than comparable non-participants. To investigate whether very preterm infants randomized to a placebo group in an RCT have equivalent neurodevelopmental outcomes to infants who were eligible but not randomized (eligible NR). In the course of an RCT investigating the neuroprotective effect of early high-dose erythropoietin on the neurodevelopment of very preterm infants, the outcome data of 72 infants randomized to placebo were retrospectively compared with those of 108 eligible NR infants. Our primary outcome measures were the mental (MDI) and psychomotor (PDI) developmental indices of the Bayley Scales of Infant Development II at 24 months of corrected age. The outcomes of the two groups were considered equivalent if the confidence intervals (CIs) of their mean differences fitted within our \u00b15-point margin of equivalence. Except for a higher socioeconomic status of the trial participants, both groups were balanced for most perinatal variables. The mean difference (90% CI) between the eligible NR and the placebo group was -2.1 (-6.1 and 1.9) points for the MDI and -0.8 (-4.2 and 2.5) points for the PDI. After adjusting for the socioeconomic status, maternal age and child age at follow-up, the mean difference for the MDI was -0.5 (-4.3 and 3.4) points.\nQuestion: Randomized controlled trials in very preterm infants: does inclusion in the study result in any long-term benefit?",
        "gt": "Our results indicate that the participation of very preterm infants in an RCT is associated with equivalent long-term outcomes compared to non-participating infants.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A clinical and experimental assessment using human samples of lumbar ligamentum flavum (LF). To identify platelet-derived growth factor-BB (PDGF-BB) expression in hypertrophied LF of patients with lumbar spinal canal stenosis (LSS) and relate it to fibrosis. Recent studies showed that fibrosis in LF hypertrophy was due to accumulation of inflammation-related scar tissue. PDGF-BB participates in scar formation and collagen development in wound healing and fibrosis diseases. However, it is unclear whether PDGF-BB expression is associated with fibrosis of the hypertrophied LF in LSS. In all, 10 patients of LSS was enrolled in this study, while 10 patients of lumbar disc herniation (LDH) as a control group. LF thickness was measured by axial T1-weighted magnetic resonance imaging. Fibrosis was graded and type of collagen was identified. The location and the expression of PDGF-BB were analyzed using immunohistochemical stains, real-time polymerase chain reaction, and Western Blotting. Correlation among LF thickness, fibrosis, and PDGF-BB expression was analyzed. LF thickness was 5.3 \u00b1 1.0 mm (range from 3.9 to 7.5 mm) in the LSS group and 2.8 \u00b1 0.7 mm (range from 1.69 to 3.8 mm) in the LDH group. Obvious fibrosis was observed in all samples of the LSS group, and correlated to LF thickness of the dural, middle, and dorsal layers (P<0.05), respectively. PDGF-BB was detected in the hypertrophied LF, particularly in the dorsal layer. PDGF-BB expression was higher in the LSS group than that in the LDH group (P<0.05), and in the dorsal layer than the dural layer in the LSS group (P<0.05). PDGF-BB mRNA correlated significantly to thickness of LF (r = 0.41) and the severity of fibrosis (r = 0.69) (P<0.05).\nQuestion: Is platelet-derived growth factor-BB expression proportional to fibrosis in the hypertrophied lumber ligamentum flavum?",
        "gt": "A higher PDGF-BB expression existed in the hypertrophied LF of patients with LSS and could be a risk factor of the fibrosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To explore the putative effect of cardiac rehabilitation programs on the 'health-related quality of life' and 'return to work' in pre-retirement patients one year after coronary artery bypass grafting. Of the 2,085 patients aged 45-64 who survived one year after CABG and were Israeli residents, 145 (6.9%) had participated in rehabilitation programs. Of these, 124 (83%) who answered QOL questionnaires were individually matched with 248 controls by gender, age within 5 years, and the time the questionnaire was answered. All patients had full clinical follow-up including a pre-operative interview. The Short Form-36 QOL questionnaire as well as a specific questionnaire were mailed to surviving patients one year after surgery. Study outcomes included the scores on eight scales and two summary components of the SF-36, as well as 'return to work' and 'satisfaction with medical services' from the specific questionnaire. Analysis was done for matched samples. Cardiac rehabilitation participants had significantly higher SF-36 scores in general health, physical functioning, and social functioning. They had borderline significant higher scores in the physical summary component of the SF-36. The specific questionnaire revealed significantly better overall functioning, higher satisfaction with medical care, and higher rate of return to work. While participants in cardiac rehabilitation and their controls were similar in their socio-demographic and clinical profiles, participating patients tended to be more physically active and more fully employed than their controls.\nQuestion: Is participation in cardiac rehabilitation programs associated with better quality of life and return to work after coronary artery bypass operations?",
        "gt": "Rehabilitation participants had a self-perception of better HRQOL, most significantly in social functioning. Our findings of more frequent return to work and higher satisfaction with medical care should induce a policy to encourage participation in cardiac rehabilitation programs after CABG.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this study was to evaluate the diagnostic value of computer-aided diagnosis (CADx) in differentiating angiomyolipoma without visible fat from renal cell carcinoma (RCC) on MDCT. The study included 406 patients who had 47 angiomyolipomas without visible fat and 359 RCCs smaller than 4 cm, all of which were diagnosed on the basis of findings from nephrectomy or percutaneous biopsy performed at our institution between 2000 and 2011. MDCT (slice thickness, 2.5 mm for corticomedullary phase image or 5 mm for the other phase images) and clinical findings were blindly reviewed by two radiologists in a single session. At the time the study was performed, radiologist 1 had 8 years of experience, and radiologist 2 had 18 years of experience. On the basis of the MDCT and clinical findings, CADx classified renal tumors as angiomyolipoma and RCC, and each radiologist independently recorded the probability score (0-5) for angiomyolipoma. The accuracy of CADx versus radiologists in diagnosing angiomyolipoma was compared using ROC analysis. Interobserver agreement between the two radiologists was evaluated. CADx yielded an area under the curve (Az) value of 0.949, which was greater than the Az values yielded by radiologists 1 and 2 (0.872 and 0.782, respectively; p<0.05). In addition, the Az value for radiologist 1 was greater than that for radiologist 2 (p = 0.01). CADx with a threshold of -1.0085 showed greater sensitivity than radiologist 1 and greater sensitivity, specificity, and accuracy than radiologist 2 (p<0.05). The interobserver agreement for the differentiation was fair (\u03ba = 0.289).\nQuestion: Does Computer-Aided Diagnosis Permit Differentiation of Angiomyolipoma Without Visible Fat From Renal Cell Carcinoma on MDCT?",
        "gt": "CAD can improve diagnostic performance in differentiating angiomyolipoma from RCC. The diagnostic performance of radiologists is variable according to the clinical experience and physical and emotional states of the radiologists.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The incidental finding of hemangiomas has increased, but the problem of the correct surgical indications of this tumor has yet to be solved. The aim of this work is to establish whether the psychological request of surgery from patients known to have a benign tumor of the liver must be avoided or not. Age, sex, symptoms, estroprogestinic oral therapy, methods of diagnosis, surgical procedures, morbidity, mortality, postoperative hospital stay and follow-up of the patients affected by hepatic hemangioma, observed from 1992 to 2002 in our institution, have been considered. Seventeen patients, with a mean age of 44 years (range 26-72), were hospitalized for hepatic hemangioma, 8 (47%) of them were operated on and 9 (53%) were managed by observation. The operated patients presented various symptoms. One patient was operated on for traumatic rupture of the hemangioma. Non-operated patients were asymptomatic or with slight dyspeptic symptoms not related with the tumor. The first diagnostic radiological examination was ultrasonography (US) in all cases. All lesions were larger than 4cm. The types of surgical procedures were 5 enucleations, and 3 hepatic resections. All operated patients resolved their clinical symptomatology, except two patients that had requested surgery for psychological implications. These patients presented their symptoms again after 2and 3 years of follow-up respectively.\nQuestion: Does the psychological request of the patient justify the surgery for hepatic hemangioma?",
        "gt": "Our results suggest that liver hemangiomas should be operated for symptoms well related to the tumor or for bleeding. Psychological requests from the patients should be avoided every time.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A direct comparison of outcomes between moderate mixed aortic valve disease (MAVD) and isolated aortic stenosis (AS) or aortic regurgitation (AR) has not been performed, making evidence-based recommendations difficult in patients with MAVD. This study sought to determine adverse event (AE) occurrence (the primary endpoint), defined as New York Heart Association functional class III/IV symptoms, aortic valve replacement, or cardiac death, and to compare AE rates between MAVD and isolated AS or AR. Asymptomatic patients were identified with moderate MAVD and an ejection fraction\u00a0\u226550% and were followed at Mayo Clinic from 1994 to 2013. Moderate MAVD was defined as a combination of moderate AS and moderate AR. Age- and sex-matched control groups were selected with isolated moderate AR (n\u00a0= 117), moderate AS (n\u00a0= 117), or\u00a0severe AS (n\u00a0= 117). At 9.1 \u00b1 4.2 years of follow-up, patients with moderate MAVD (n\u00a0= 251) had a mean age of 63 \u00b1 11 years, 73% were male, and 38% had bicuspid valve. AE occurred in 193 (77%) patients in this group, including symptom development (69%), aortic valve replacement (67%), and cardiac death (4%). Predictors of AE were older age (hazard ratio [HR]: 1.71 per decade; 95% confidence interval [CI]: 1.38 to 1.97 per decade; p\u00a0= 0.001), and relative wall thickness>0.42 (HR:\u00a02.01; 95% CI: 1.86 to 2.33; p\u00a0= 0.002). AE rates were similar in the MAVD and severe AS group (71% vs. 68% at 5\u00a0years; p\u00a0= 0.49), but were significantly higher compared with the moderate AS and AR groups.\nQuestion: Outcomes in Moderate Mixed\u00a0Aortic\u00a0Valve\u00a0Disease: Is it Time for a Paradigm Shift?",
        "gt": "MAVD patients had outcomes comparable to those with severe AS, and preserved ejection fraction and should be monitored closely for symptoms.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients with end-stage renal failure undergoing haemodialysis (HD) are exposed to oxidative stress. Increased levels of malondialdehyde (MDA) were demonstrated in plasma of uraemic patients, indicating accelerated lipid peroxidation (LPO) as a consequence of multiple pathogenetic factors. The aim of our investigation was to examine the role of renal anaemia in oxidative stress in HD patients. MDA and 4-hydroxynonenal (HNE) were measured in three groups of patients undergoing HD: group I comprised eight patients with a blood haemoglobin (Hb)<10 g/dl (mean Hb = 8.1+/-1.3 g/dl), and group II were eight patients with a Hb>10 g/dl (mean Hb=12.4+/-1.9g/dl); none of these 16 patients had been treated with human recombinant erythropoietin (rHuEpo). Group III comprised 27 patients with a mean Hb of 10.5+/-1.6 g/dl after long-term rHuEpo treatment. Mean plasma concentrations of both MDA and HNE were significantly higher (P<0.0001) in all 43 HD patients than in 20 healthy controls (MDA 2.85+/-0.25 vs 0.37+/-0.03 microM, HNE 0.32+/-0.03 vs 0.10+/-0.01 microM). Comparing the three groups, it was shown that HD patients with a Hb<10 g/dl had significantly higher plasma levels of LPO products (MDA 3.81+/-0.86 microM, HNE 0.45+/-0.07 microM) than HD patients with a Hb>10g/dl (MDA 2.77+/-0.58 UM, HNE 0.25+/-0.05 microM), and than HD patients treated with rHuEpo (MDA 2.50+/-0.12 microM, HNE 0.29+/-0.03 microM). Furthermore, an inverse correlation between plasma concentration of LPO products and haemoglobin levels was seen (r=0.62, P<0.0001).\nQuestion: Does long-term treatment of renal anaemia with recombinant erythropoietin influence oxidative stress in haemodialysed patients?",
        "gt": "Radical generation in HD patients might be caused in part by renal anemia itself. Treatment with rHuEpo may decrease radical generation effectively in HD patients due to the increase in the number of red blood cells and blood haemoglobin concentration.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Two methods to assess liver echogenicity were compared. Liver/kidney echogenicity ratio was measured in 41 persons with the ultrasound software and visually graded by two radiologists and a radiographer. These echogenicity ratios and grades were related to risk factors for fatty liver and to liver enzyme levels. These determinants explained 55% of the radiologists' mean grades, 14% of the radiographer's and 31% of the measured echogenicity ratios.\nQuestion: Liver echogenicity: measurement or visual grading?",
        "gt": "Radiologists' visual gradings correlated best with the indirect determinants of early liver pathology. Computerized measurements may be inferior to visual grading due to the lack of holistic tissue diagnostics.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Personality and cognition are often considered as disparate constructs, both in normal individuals and in those with a psychosis. The goal of the present study was to analyze the relationship between dimensions of personality and cognitive performance in individuals with psychosis. Sixty-one consecutively admitted patients with an acute psychotic episode were recruited for this study. Personality was assessed through a semistructured interview with a close relative using the Personality Assessment Schedule. A wide neuropsychological battery was applied, including attentional, executive, memory tasks and global cognition. Assessments took place when symptomatology was in remission. Higher scores on a passive-dependent dimension were significantly associated with poorer memory performance. Similarly, higher levels for a schizoid dimension were significantly associated with poorer executive performance. The results remained significant after partialling out the effect of gender, psychopathological dimensions and drug status.\nQuestion: Are personality traits associated with cognitive disturbance in psychosis?",
        "gt": "It is hypothesized that personality traits and cognitive performance are interrelated domains in psychosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Between December 2011 and November 2013, we enrolled 118 consecutive cases with severe sepsis admitted to ICU in this retrospective study. Levels of C-reactive protein (CRP), NLR, and white blood cell count (WBC) were recorded on admission and patients' renal function was monitored for seven consecutive days. The rate of AKI occurrence 7 days after enrollment was 57.6%. NLR levels were higher in the AKI group (Group 1) than in the non-AKI group (Group 2) on the day of ICU admission (p<0.001). AKI development was independently associated with NLR, Acute Physiology and Chronic Health Evaluation II (APACHE II) and duration of invasive mechanical ventilation (MV) in multivariate logistic regression analysis. The area under the receiver-operating characteristic (ROC) curve of NLR for predicting AKI was 0.986, which was superior to WBC and CRP (p<0.05). The cut-off value of 10.15 for NLR had the highest validity for predicting AKI in patients with severe sepsis. The sensitivity, specificity, negative-predictive value (NPV), and positive-predictive value (PPV), for this cut-off value was 90.2%, 92.9%, 90.4%, and 92.7%, respectively.\nQuestion: Can neutrophil-lymphocyte ratio be independent risk factor for predicting acute kidney injury in patients with severe sepsis?",
        "gt": "NLR is superior to CRP, and WBC for predicting the development of AKI in patients with severe sepsis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Data on the frequency of resolution of anaphylaxis to foods are not available, but such resolution is generally assumed to be rare. To determine whether the frequency of negative challenge tests in children with a history of anaphylaxis to foods is frequent enough to warrant challenge testing to re-evaluate the diagnosis of anaphylaxis, and to document the safety of this procedure. All children (n=441) who underwent a double-blind, placebo-controlled food challenge (DBPCFC) between January 2003 and March 2007 were screened for symptoms of anaphylaxis to food by history. Anaphylaxis was defined as symptoms and signs of cardiovascular instability, occurring within 2 h after ingestion of the suspected food. Twenty-one children were enrolled (median age 6.1 years, range 0.8-14.4). The median time interval between the most recent anaphylactic reaction and the DBPCFC was 4.25 years, range 0.3-12.8. Twenty-one DBPCFCs were performed in 21 children. Eighteen of 21 children were sensitized to the food in question. Six DBPCFCs were negative (29%): three for cows milk, one for egg, one for peanut, and one for wheat. In the positive DBPCFCs, no severe reactions occurred, and epinephrine administration was not required.\nQuestion: Should children with a history of anaphylaxis to foods undergo challenge testing?",
        "gt": "This is the first study using DBPCFCs in a consecutive series of children with a history of anaphylaxis to foods, and no indications in dietary history that the food allergy had been resolved. Our study shows that in such children having specific IgE levels below established cut-off levels reported in other studies predicting positive challenge outcomes, re-evaluation of clinical reactivity to food by DBPCFC should be considered, even when there are no indications in history that anaphylaxis has resolved. DBPCFCs can be performed safely in these children, although there is a potential risk for severe reactions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Myocarditis is an inflammation of the heart muscle and represents a challenge for diagnosis and treatment. On account of the lack of sensitivity and specificity of routine cardiac tests, there is a need for accurate diagnostic imaging. The aim of this study is to review the role of gated 99Tc-methoxyisobutylisonitrile myocardial perfusion scintigraphy (G-MPS) in the diagnosis and follow-up of the patients with myocarditis in comparison with gallium scintigraphy. Thirteen patients with a clinical diagnosis of myocarditis were included in the study. All underwent rest G-MPS and the images were then evaluated by quantitative perfusion single-photon emission computed tomography and quantitative gated single photon emission computed tomography software program. Visual evaluation of perfusion was performed as well as analysis of motion with thickening function [expressed as summed rest score, summed motion score, and summed thickening score (STS)] with calculation of ejection fraction (EF) and lung-to-heart (L/H) ratio. Eight patients underwent 67Ga scintigraphy. Clinical, echocardiography, and cardiac enzymes (creatinine kinase-MB, myoglobulin, troponin T, brain natriuretic peptide) data were gathered from the patients' charts. Clinical outcome was grouped according to prognosis. Spearman's correlation (SC) test was used for comparison analysis. Myocardial perfusion defects were observed in eight patients. Perfusion defects in the left ventricle involve a mean of 7.25% (range: 1-11%), whereas wall motion abnormality on G-MPS was more prominent, which showed to be a better marker for myocardial inflammation and necrosis. The 67Ga scintigraphy findings were normal in all, but two. The G-MPS EF (33+/-21%) was slightly lower than the echocardiography EF (40+/-15%), but with close correlation (SC coefficient: 0.635). Comparison of scintigraphic findings with clinical parameters showed that summed motion score with G-MPS EF and STS with L/H ratios were highly correlated (0.932 and 0.622, respectively). The maximum brain natriuretic peptide and L/H ratio with STS were highly correlated with the patients' outcomes (SC coefficient: -0.621, 0.821, and 0.579, respectively), as well.\nQuestion: Gated myocardial perfusion scintigraphy in children with myocarditis: can it be considered as an indicator of clinical outcome?",
        "gt": "Tc-methoxyisobutylisonitrile G-MPS is therefore helpful in providing additional diagnostic and prognostic information in patients with myocarditis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Venous thromboembolism is a common source of morbidity and mortality but a variety of preventative measures are available. To audit the current practice of thromboprophylaxis and compare against published protocols. Three-hundred and seventy-six (376) surgical patients were surveyed prospectively. A Performa was completed recording the presence of up to 11 risk factors. A risk score was calculated and the use of specific thromboprophylatic measures identified. Heparin thromboprophylaxis was widely used, eight patients (who were on aspirin therapy) failed to receive any prophylaxis (risk factors 4-6). In addition there were 60 patients at low risk (risk score<2) received LMWH from which they were unlikely to benefit.\nQuestion: Risk-based evaluation of thromboprophylaxis among surgical inpatients: are low risk patients treated unnecessarily?",
        "gt": "Thromboembolic prophylaxis is widely but unselectively applied. Adoption of a risk: benefit ratio approach should ensure those who would benefit from thromboprophylaxis are adequately treated while those in whom thromboprophylaxis is not indicated are spared unnecessary therapy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Hispanic-Americans are the fastest growing minority group in the United States. Many studies have compared prostate cancer treatment outcomes between black and white men, but few such studies have been done with Hispanic men. We compared clinical and pathological features as well as the treatment failure rate of radical prostatectomy in contemporaneously treated groups of Hispanic and white men with prostate cancer. Between 1995 and 2002, 136 Hispanic men and 315 white men underwent radical prostatectomy. Treatment failure was defined as having a prostate specific antigen (PSA) of 0.2 or greater more than 8 weeks after surgery or receiving any adjuvant therapy. Known predictors of failure and race were evaluated for their ability to predict treatment failure. Median followup was 32 months for Hispanic and 36 months for white patients. Hispanic men were older, had a higher percentage of abnormal rectal examinations, Gleason 7 tumors and preoperative PSA levels greater than 10. Preoperative PSA, specimen Gleason score, pathological stage and surgical margin were all strongly associated with treatment failure (p<0.001). Despite differences in clinical characteristics, overall failure rates did not differ between Hispanic and white men (18.7% vs 17.8%). The odds ratio for treatment failure for Hispanic relative to white men after adjusting for the previously mentioned risk factors was 0.87 (95% CI [0.44, 1.68], p = 0.670).\nQuestion: Is Hispanic race an important predictor of treatment failure following radical prostatectomy for prostate cancer?",
        "gt": "This study shows that Hispanic race does not influence the treatment failure rate of radical prostatectomy in contemporaneously treated patients with prostate cancer at 1 institution. To our knowledge this study represents the largest of its kind, but longer followup and other confirmatory studies are needed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Both the material and geometry of a total knee arthroplasty (TKA) component influence the induced periprosthetic bone strain field. Strain, a measure of the local relative deformation in a structure, corresponds to the mechanical stimulus that governs bone remodeling and is therefore a useful in vitro biomechanical measure for assessing the response of bone to new implant designs and materials. A polyetheretherketone (PEEK) femoral implant has the potential to promote bone strains closer to that of natural bone as a result of its low elastic modulus compared with cobalt-chromium (CoCr).QUESTIONS/ In the present study, we used a Digital Image Correlation (DIC) technique to answer the following question: Does a PEEK TKA femoral component induce a more physiologically normal bone strain distribution than a CoCr component? To achieve this, a DIC test protocol was developed for periprosthetic bone strain assessment using an analog model; the protocol aimed to minimize errors in strain assessment through the selection of appropriate analysis parameters. Three synthetic bone femurs were used in this experiment. One was implanted with a CoCr femoral component and one with a PEEK femoral component. The third (unimplanted) femur was intact and used as the physiological reference (control) model. All models were subjected to standing loads on\u00a0the corresponding polyethylene (ultrahigh-molecular-weight polyethylene) tibial component,\u00a0and speckle image data were acquired for surface strain analysis using DIC in six repeat tests. The strain in 16 regions of interest on the lateral surface of each of the implanted bone models was plotted for comparison with the corresponding strains in the intact case. A Wilcoxon signed-rank test was used to test for difference at the 5% significance level. Surface analog bone strain after CoCr implantation indicated strain shielding (R2= 0.6178 with slope, \u03b2 = 0.4314) and was lower than the intact case (p = 0.014). The strain after implantation with the PEEK implant deviated less from the intact case (R2= 0.7972 with slope \u03b2 = 0.939) with no difference (p = 0.231).\nQuestion: Does a PEEK Femoral TKA Implant Preserve Intact Femoral Surface Strains Compared With CoCr?",
        "gt": "The strain shielding observed with the contemporary CoCr implant, consistent with clinical bone mineral density change data reported by others, may be reduced by using a PEEK implant.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study was performed to determine whether the implementation of clinical pathways for patients who undergo major vascular procedures in a community hospital would shorten the length of stay and reduce charges when compared with Medicare standards. Length of stay, hospital costs, and morbidity, mortality, and readmission rates for the four most common vascular diagnosis-related group (DRG) categories at our institution were compared with Medicare standards. The four categories were DRG 005 (extracranial vascular procedures), DRG 110 (aortic and renal procedures), DRG 478 (leg bypass with comorbidity), and DRG 479 (leg bypass without comorbidity). Between May 1, 1994, and June 30, 1996, 112 patients underwent carotid endarterectomy, 42 patients underwent aortic or renal procedures, and 130 patients underwent lower extremity bypass procedures (68% with comorbidity). Only Medicare patients were included because exact cost/reimbursement data were available. No admissions were excluded. The average length of stay was 1.2 days for DRG 005, 6.9 days for DRG 110, and 3.2 and 2.1 days for DRGs 478 and 479, respectively. The average cost savings when compared with the Medicare reimbursement was $4338 for DRG 005, $7161 for DRG 110, $4108 for DRG 478, and $2313 for DRG 479. Readmission was necessary for 9% of peripheral bypass patients. Ten percent of patients in DRG 005 and 86% of patients in DRG 110 needed intensive care, whereas only 2% of patients who underwent complicated bypass procedures did. Ninety percent of carotid endarterectomy patients and 23% of leg bypass patients were discharged on the first postoperative day. There were two postoperative strokes (2%) after carotid surgery. Thirty-three percent of aortic/renal patients had complications that led to care outside the clinical pathway. Twenty-five percent of leg bypass patients required home care to treat open foot wounds. Total inpatient cost savings were $1,256,000 when compared with Medicare reimbursement.\nQuestion: Do clinical pathways for major vascular surgery improve outcomes and reduce cost?",
        "gt": "Clinical pathways significantly improve the length of stay and decrease inpatient charges for major vascular surgical procedures while maintaining high standards of care. Factors that favorably affected the length of stay and hospital charges were outpatient arteriography, same-day admission, early ambulation, physical therapy, home care, use of the intensive care unit on a selective basis, and early discharge. Factors that adversely affected these outcomes were emergency admission, inpatient arteriography, thrombolytic therapy, complications, and the need for dialysis or anticoagulation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Anemia in chronic heart failure (CHF) is common, varying in prevalence between 14.4% and 55%, and is more frequent in patients with more severe heart failure. Patients with CHF who have anemia have a poorer quality of life, higher hospital admission rates, and reduced exercise tolerance. We explored the relation between hematinic levels and hemoglobin (Hb) levels and exercise tolerance in a group of patients with CHF. We analyzed data from 173 patients with left ventricular systolic dysfunction (LVSD), 123 patients with symptoms of heart failure, but preserved left ventricular (LV) systolic function (\"diastolic dysfunction\"), and 58 control subjects of similar age. Each underwent echocardiography, a 6-minute walk test, and blood tests for renal function and Hb and hematinic levels (vitamin B12, iron, and folate). We classified patients as having no anemia (Hb level>12.5 g/dL), mild anemia (Hb level from 11.5-12.5 g/dL), or moderate anemia (Hb level<11.5 g/dL). Of patients with LVSD, 16% had moderate anemia and 19% had mild anemia. Of patients with preserved LV function, 16% had moderate anemia and 17% had mild anemia. Four control subjects had a Hb level<12.5 g/dL. Of all patients, 6% were vitamin B12 deficient, 13% were iron deficient, and 8% were folate deficient. There was no difference between patients with LVSD and the diastolic dysfunction group. In patients with LVSDS, the average Hb level was lower in New York Heart Association class III than classes II and I. The distance walked in 6 minutes correlated with Hb level in both groups of patients with CHF (r = 0.29; P<.0001). Patients with anemia achieved a lower pVO2 (15.0 [2.3] vs 19.5 [4.4], P<.05). Peak oxygen consumption correlated with Hb level (r = 0.21, P<.05) in the patients, but not in the control subjects. In patients with anemia, the mean creatinine level was higher than in patients with a Hb level>12.5 g/dL, but there was no clear relationship with simple regression. Hematocrit level and mean corpuscular volume were not different in the patients with diastolic dysfunction, patients with LV dysfunction, or the control subjects. Hematocrit levels were not influenced by diuretic dose. Patients with anemia were not more likely to be hematinic deficient than patients without anemia.\nQuestion: Are hematinic deficiencies the cause of anemia in chronic heart failure?",
        "gt": "Patients with symptoms and signs of CHF have a high prevalence of anemia (34%) whether they have LV dysfunction or diastolic dysfunction, but few patients have hematinic deficiency. Hemoglobin levels correlate with subjective and objective measures of severity and renal function.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Treatment delay, or the time lapse between diagnosis and surgery, may have a detrimental effect on cancer outcomes. This study assesses the effect of treatment delay on cancer-related outcomes in a large, continuous series of surgically\u00a0treated colon cancer patients. All surgical colon cancer cases at our center from 2004 through 2011 were reviewed. Patients who underwent preoperative chemotherapy, emergency admissions, palliative cases, and incidental and postoperative diagnoses were excluded. Treatment delay was correlated with outcomes in univariate and multivariate regression and proportional hazards models. In 769 included patients, for every treatment-delay quartile increase, odds of death decreased by an odds ratio (OR) of 0.78 (p\u00a0=\u00a00.001), and metastatic recurrence by OR 0.78 (p\u00a0=\u00a00.013). Shorter survival duration had a hazard ratio (HR) of 0.81 (p\u00a0=\u00a00.001) and shorter disease-free survival HR 0.72 (p\u00a0<\u00a00.001). Multivariate regression adjusting for baseline staging greatly reduces these ratios, and makes them non-significant. Similar patterns were shown in high-risk subsets, including stage III disease, ethnic minorities, patients with positive margins, and extramural vascular invasion.\nQuestion: Treatment delay in surgically-treated colon cancer: does it affect outcomes?",
        "gt": "The inverse relation between treatment delay and survival and recurrence reflected adequate prioritization of advanced and high-risk cases and concurrently showed that, matched for stage and risk categories, treatment delay was not associated with worse cancer outcomes for patients with colon cancer. A reasonable delay between diagnosis and subsequent surgery is not detrimental to patient outcomes and permits more flexibility in scheduling and justifies allowing time to complete proper preoperative evaluation and staging, improving the quality and safety of resection and treatment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Hepatitis C virus (HCV) infection is often clinically silent in haemodialysed (HD) patients and their immune response may modulate liver damage in HCV infection. IL-10 and TGF-beta1 could play a role in this setting as, IL-10 down-regulates hepatic fibrosis, while TGF-beta1 is a pro-fibrotic cytokine.AIM: To evaluate the role of IL-10 and TGF-beta1 in HD/HCV+ patients. 71 HD/HCV+ patients (58 with normal [HD/HCV-N] and 13 with high serum transaminases [HD/HCV-H]), 40 non-uremic patients with chronic hepatitis C (HCV+), 56 HD anti-HCV- patients and 20 healthy volunteers (H). IL-10 and TGF-beta1 serum levels were assessed using ELISA tests. Liver histology was assessed by Ishak's score. IL-10 serum levels were significantly higher in HD patients, both HCV+ (3.7+/-0.4 pg/ml; p<0.01) and HCV- (3.8+/-0.8 pg/ml; p<0.05) than in non-uremic HCV patients (2.3+/-0.4 pg/ml). Among the HD/HCV+ patients, IL-10 serum levels were similar in HD/HCV-N and in HD/HCV-H patients. Among the HD/HCV+ patients, IL-10 serum levels were similar in those with moderate histological damage compared to those with mild damage. TGF-beta1 serum levels were significantly lower in HD patients, both HCV+ (4.6+/-0.9 ng/ml) and HCV- (6.0+/-0.9 ng/ml) than in non-uremic HCV+ patients (8.1+/-1.1 ng/ml; p<0.001 and p<0.01, respectively), but similar to the values found in H (5.3+/-0.9 ng/ml; p=n.s.). No correlation was seen between IL-10 and TGF-beta1 serum levels in any of the groups considered.\nQuestion: HCV infection in haemodialysed patients: a role for serum IL-10 and TGF-beta1 in liver damage?",
        "gt": "Patients on haemodialysis treatment to have high levels of IL-10, which remain high even when patients are anti-HCV+, whereas the opposite is true of TGF-beta1. The cytokine pattern observed in HD patients is compatible with the hypothesis explaining the relatively benign evolution of HCV-related liver disease in HD patients, and has a pathophysiological role.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Thrombocytosis can follow surgery and has occasionally been observed after major orthopaedic surgery. The aim of the present study was to ascertain the platelet count (PLTC) change in patients admitted to a rehabilitation unit after major joint surgery and whether deep venous thrombosis (DVT) and poor outcomes occurred in those who had thrombocytosis. PLTC, red blood cells (RBC), haemoglobin (Hb), fibrinogen, and D-dimers were assessed in patients on admission and at discharge after major joint surgery. Functional outcomes were ascertained using the Barthel Scale (BS), the Functional Independence Measure (FIM) and gait evaluation. Thrombocytosis was considered to have occurred when PLTC was greater than or equal to 500 \u00d7 100(9)/L. All subjects with thrombocytosis had ultrasonography to assess DVT occurrence. The patients were divided into \"young\" and \"old\" groups according to an age cut-off of 75 years to investigate potential age-related differences. Two hundred and seventy-five patients were identified and 142 (36 M and 106 F, mean age 77.2\u2009\u00b1\u200910.7) were enrolled. Seventy-six (53.5%) underwent total hip arthroplasty (THA), 40 (51.1%) underwent hip internal fixation and 26 (18.3%) subjects underwent total knee arthroplasty (TKA). The young and old groups included 60 and 82 patients, respectively. Fifty-nine (42.4%) patients had PLTC above 400 \u00d7 100(9)/L. Of these, 28 (20.1%) had thrombocytosis with PLTC above 500 \u00d7 100(9)/L, and 15 of them (10.7%) had very high values above 600 \u00d7 100(9)/L. Increased levels of fibrinogen and D-dimers were also detected. No subject with thrombocytosis had DVT. Outcome was not affected by PLTC. At discharge, significant improvement in all functional assessments was observed in young compared to old people; gait: 2.9\u2009\u00b1\u20090.2 vs. 2.2\u2009\u00b1\u20090.8; BS: 97\u2009\u00b1\u20096.9 vs. 70.5\u2009\u00b1\u200925.6; and FIM: 116.4\u2009\u00b1\u200910.9 vs. 83.6\u2009\u00b1\u200931.2 (p\u2009<\u20090.004), respectively. BS and FIM mean scores were positively correlated with Hb level.\nQuestion: Thrombocytosis after hip and knee surgery in the rehabilitation setting: is it an occasional phenomenon?",
        "gt": "Elevated PLTC and thrombocytosis were not uncommon in patients after major joint surgery, but no subject developed DVT. Platelet count change did not affect the outcome. Higher age and lower haemoglobin level correlated with poorer functional recovery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We hypothesised that pharmacokinetic factors might go some way to explaining the risk of major gastrointestinal haemorrhage with non-steroidal anti-inflammatory drugs (NSAIDs), with bleeders exhibiting a reduced clearance of NSAIDs compared with non-bleeders and set out to investigate this. Fifty patients presenting to hospital with acute gastrointestinal bleeding while taking piroxicam, indomethacin, diclofenac or naproxen and age, sex, musculoskeletal disease and drug matched community dwelling controls, up to two for each index case, who had not bled were recruited. Clinical details including duration of therapy were recorded. Bleeders discontinued the implicated NSAID at presentation, controls at least five half-lives before the study. Bleeders were contacted by letter 1 month after discharge and invited to take part and were studied after a median delay of 5 months. Subjects received an oral dose of their respective NSAID and venous blood was sampled, over a period determined by the half-life of the NSAID. Plasma concentrations were determined by high performance liquid chromatography. The median length of treatment for the index patients was 1 year (range 2 weeks--28 years) and for the control patients 2 years (1 month--25 years), P<0.0005. There were no significant differences in peak plasma concentration, time to peak plasma concentration or area under the plasma concentration-time curve between bleeders or controls for any of the NSAIDs studied, apart from piroxicam Cmax being lower in bleeders at 2.07 mg l(-1) than in controls at 3.21 mg l(-1), mean difference (95% CI) -1.14 (-1.83 - -0.48), P<0.005.\nQuestion: Are altered pharmacokinetics of non-steroidal anti-inflammatory drugs (NSAIDs) a risk factor for gastrointestinal bleeding?",
        "gt": "The data failed to support the hypothesis that reduced clearance of NSAIDs, which results in higher plasma concentrations, is a risk factor for acute gastrointestinal haemorrhage.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Vaginal radical trachelectomy (VRT) is the most widely evaluated form of conservative management of young patients with early-stage (IB1) cervical cancer. Patients with nodal involvement or a tumor size greater than 2 cm are not eligible for such treatment. The aim of this study is to report the impact of a \"staging\" conization before VRT. This is a retrospective study of 34 patients potentially selected for VRT for a clinical and radiologic cervical tumor less than 2 cm. Among them, 28 underwent finally a VRT (20 of them having a previous conization before this procedure) and 6 patients with macroscopic cervical cancer, confirmed by punch biopsies, \"eligible\" for VRT (<2 cm) had undergone \"staging\" conization (without further VRT) to confirm the tumor size and lymphovascular space involvement (LVSI) status. Six patients having \"staging\" conization before VRT had finally been deemed contraindications to VRT due to the presence of a histologically confirmed tumor greater than 2 cm and/or associated with multiple foci of LVSI. Among 28 patients who underwent VRT, 1 received adjuvant chemoradiation (this patient recurred and died of disease). Two patients treated with RVT (without postoperative treatment) recurred. Ten pregnancies (9 spontaneous and 1 induced) were observed in 9 patients. Among 4 patients with macroscopic \"visible\" tumor who do not underwent a \"staging\" conization before VRT, 2 recurred. Among 11 patients who underwent VRT and having LVSI, 3 recurred.\nQuestion: Analysis of a continuous series of 34 young patients with early-stage cervical cancer selected for a vaginal radical trachelectomy: should \"staging\" conization be systematically performed before this procedure?",
        "gt": "These results suggest that if a conization is not performed initially, it should then be included among the staging procedures to select patients for VRT.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the attitudes, knowledge and practices of general dental practitioners (GDPs), specialists and consultants in paediatric dentistry in London, towards child protection. Additionally, to determine if children attending paediatric dental casualty at the Eastman Dental Hospital (EDH) and those who need treatment of caries under general anaesthesia (GA) are on the child protection register (CPR). The survey was conducted by postal questionnaires with 14 closed questions. A total of 228 dentists were invited to participate in the study. Children who attended EDH and required treatment under GA or at paediatric dental casualty were checked against the CPR. The respond rate was 46% (105/228). Overall 15% (16/105) of dentists had seen at least one patient with suspected child abuse in the last six months, but only 7% (7/105) referred or reported cases to child protection services. Reasons for dentists not referring included: fear of impact on practice (10%; 11/105); fear of violence to child (66%; 69/105); fear of litigation (28%; 29/105); fear of family violence against them (26%; 27/105); fear of consequences to the child (56%; 59/105); lack of knowledge regarding the procedures for referral (68%; 71/105); and lack of certainty about the diagnosis (86%; 90/105). Of the 220 children attending for dental GA and casualty from October 2004 to March 2005, one child was found to be on the CPR.\nQuestion: A survey of attitudes, knowledge and practice of dentists in London towards child protection. Are children receiving dental treatment at the Eastman Dental Hospital likely to be on the child protection register?",
        "gt": "More information and training is required to raise awareness of the potential importance of the role of dentists in child protection. Improved communication between dental and medical departments is important for safeguarding children.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although it has been known that folate will participate in colorectal carcinogenesis, the relationship between blood folate level and colorectal cancer is less consistent. The blood folate level does not reflect the systemic folate status. By contrast, serum homocysteine has become a sensitive marker for the folate deficiency. We attempted to explain the correlation between folate and colorectal cancer according to the serum homocysteine level. We reviewed the clinical records, including alcohol history of 184 patients taking the colonoscopy and measurement of the serum homocysteine level at Health Promotion Center from 2001 to 2002. One hundred fifty-one of 184 were included, excluding 33 patients with previous history of colonic polyp, cerebrovascular, cardiovascular attack and thromboembolism. They were divided into the normal control (n=111) and the adenomatous polyp group (n=40). We had selected the colorectal cancer group (n=50) from the collection list of the tissue and blood bank less than 3 months storage interval. There was no significant difference in the mean serum homocysteine level among three groups. However, in the subjects with high alcohol consumption, there was a significant difference in the mean serum homocysteine between the normal control (n=7) and the adenomatous polyp group (n=9) (10.2 vs 15.1 mumol/L, p<0.05).\nQuestion: Is serum homocysteine level elevated in colorectal tumor?",
        "gt": "There was no correlation of serum homocysteine and colorectal tumor. However, in the subjects with high alcohol consumption, high serum homocysteine might be related to the development of adenomatous polyp.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We report our experience with ureterocalyceal anastomosis in children regarding indications and outcome. A retrospective review was performed of all cases that underwent open ureterocalyceal anastomosis at our center between 2000 and 2006. Records were reviewed for patient age, history, affected side, indication of surgery and operative details. Clinical and radiological outcome was assessed. Success was defined as both symptomatic relief and radiographic resolution of obstruction at last follow up. There were 10 cases (six males, four females) with a mean age of 6.5 years (range 3-13 years). Follow up ranged from 6 to 46 months (mean 18). The indications for surgery were failed pyeloplasty in six patients and iatrogenic injury of the ureteropelvic junction or the upper ureter in four. No significant perioperative complications were encountered in the study group. Overall success rate was 80%. Relief of obstruction was evident in eight patients as documented by intravenous urography or nuclear renography, while secondary nephrectomy was necessitated in two patients with severely impaired ipsilateral renal function and normal contralateral kidney. In patients with preserved renal units, the differential function on the involved side was stable on comparing the preoperative and postoperative renographic clearance (26 vs 24 ml/min).\nQuestion: Ureterocalyceal anastomosis in children: is it still indicated?",
        "gt": "Ureterocalyceal anastomosis in children is still indicated in some difficult situations. Excellent functional results can be achieved in properly selected cases. Nephrectomy may be indicated in cases with impaired renal function and inability to perform salvage procedure.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although the use of laparoscopy for the management of postoperative complications has been previously well documented for different pathologies, there is scarce information regarding its use after laparoscopic colorectal surgery. Data were prospectively collected from all patients undergoing laparoscopic colorectal surgery between June 2000 to October 2007. Patients were divided into two groups according to the approach used for the reoperation: laparoscopy (Group I) or laparotomy (Group II). Data were statistically analyzed by using Student's t-test and chi-squared test. In all, 510 patients were analyzed. Twenty-seven patients (5.2 percent), 14 men and 13 women (men/women Group I: 10/7 vs. Group II: 4/6; P = not significant (NS)), required a second surgery because of postoperative complications (Group I: 17 (63 percent); Group II: 10 (37 percent)). Mean age was 60 +/- 17 years (Group I: 61.7 +/- 17.7 vs. Group II: 57.1 +/- 16 years; P = NS). Fifteen patients (55.5 percent) had anastomotic leaks (Group I 13/17 (76.5 percent) vs. Group II 2/13 (15 percent); P = 0.004). The were no differences between the groups regarding the length of stay or postoperative complications (Group I: 11.9 +/- 9.6 vs. Group II: 18.1 +/- 19.7 days: P = NS; Group I: 1 vs. Group II: 3; P = NS).\nQuestion: Is a laparoscopic approach useful for treating complications after primary laparoscopic colorectal surgery?",
        "gt": "Laparoscopic approach is a useful tool for treating complications after laparoscopic colorectal surgery, especially anastomotic leaks. Randomized, controlled trials are necessary to validate these findings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate sexual satisfaction on women who have experienced sexual intercourse with the same partner on non-circumcised and circumcised states. A total of 19 women between 19 and 53 y/o, median age 30, in which their sexual partner was programmed for circumcision were included in this study. The survey was a validated version on the Changes on Sexual Functioning Questionnaire (CSFQ). General sexual satisfaction, pain during vaginal penetration, desire, vaginal orgasm, vaginal lubrication, sexual frequency changes in oral and/or anal sexual activities and esthetical perception on circumcised penis were surveyed before the procedure and 2 months after. Changes on Vaginal lubrication during intercourse were significant (p = 0.004), it diminished from 78% to 63%. There were no statistically significant differences on general sexual satisfaction, pain during vaginal penetration, desire, vaginal orgasm.\nQuestion: Does circumcision has an effect on female's perception of sexual satisfaction?",
        "gt": "Circumcision has either negative or positive effect on female's partner perception of sexual satisfaction.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the relationship between physical impairment and brain-computer interface (BCI) performance. We present a meta-analysis of 29 patients with amyotrophic lateral sclerosis and six patients with other severe neurological diseases in different stages of physical impairment who were trained with a BCI. In most cases voluntary regulation of slow cortical potentials has been used as input signal for BCI-control. More recently sensorimotor rhythms and the P300 event-related brain potential were recorded. A strong correlation has been found between physical impairment and BCI performance, indicating that performance worsens as impairment increases. Seven patients were in the complete locked-in state (CLIS) with no communication possible. After removal of these patients from the analysis, the relationship between physical impairment and BCI performance disappeared. The lack of a relation between physical impairment and BCI performance was confirmed when adding BCI data of patients from other BCI research groups.\nQuestion: Brain-computer interfaces and communication in paralysis: extinction of goal directed thinking in completely paralysed patients?",
        "gt": "Basic communication (yes/no) was not restored in any of the CLIS patients with a BCI. Whether locked-in patients can transfer learned brain control to the CLIS remains an open empirical question.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To demonstrate that the round window insertion (RWI) for cochlear implantation with multichannel electrodes is a reliable, safe, and effective technique. Retrospective case review. Academic tertiary referral center. One hundred thirty consecutive cochlear implants (72 female and 58 male subjects) performed from August 2009 to August 2011. Devices included 83 Cochlear, 40 Med El, and 7 Advanced Bionics (AB) cochlear implants. Subsequent to a full audiometric assessment, patients underwent a mastoidectomy with facial recess approach whereby the primary surgical objective was to perform a RWI. When the surgeon was unable to access the round window safely, a cochleostomy was performed anterior and inferior to the round window. Postoperative performance was measured with Hearing in Noise Test, the Consonant-Nucleus-Consonant test, and/or the Arizona Biomedical Sentences test. Surgical feasibility of reliably performing a RWI, reason for cochleostomy, postoperative complications, and audiometric performance. In 111 (85.4%) of 130 procedures, a RWI was performed; in 19 (14.6%), a cochleostomy was readily performed by the same approach. Reasons for creating a cochleostomy included facial nerve and jugular bulb location. There were no major postoperative complications in either group and 13 total minor complications. There was no statistically significant difference in postoperative complications or in audiometric performance between the 2 groups.\nQuestion: The round window: is it the \"cochleostomy\" of choice?",
        "gt": "The RWI may offer several advantages over a cochleostomy, and it seems to be a reliable, safe, and effective technique for cochlear implantation with today's cochlear implant electrodes. Further studies would be necessary to verify these findings for broad application to the cochlear implant patient population.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the clinical features, regularly associated microorganisms and their susceptibility to antibiotics, and the clinical outcomes of foot ulcers in patients with diabetes at the Yaound\u00e9 Central Hospital, Cameroon. A retrospective analysis of routinely collected hospital data, and data validation by survey of clinical notes was conducted from November 1999 to October 2002 for adult diabetic patients with foot ulcers. Clinical data were recorded for each patient, followed by a record of microbiological investigations where available. Of 503 patients with diabetes admitted during the study period, 54 (10.7%) had foot ulcers. Male subject represented 66.7% of this population. The mean age of the study population was 59.66 +/- 1.52 years. The foot ulcer led to the diagnosis of diabetes in six patients in whom the condition was previously unidentified. Of the 54 patients with foot ulcers, nine (16.7%) were selected for surgery and the remaining 45 were managed conservatively. Microbiological investigations were available for 21 patients. Proteus mirabilis was the most frequent microorganism yielded, and was regularly associated with Staphylococcus aureus. All the microorganisms isolated showed high sensitivity to second-generation quinolone antibiotics and were regularly sensitive to aminoglycoside antibiotics. Nine (16.7%) patients died and seven (13%) were discharged at their own request.\nQuestion: Diabetic foot ulcers in Cameroon: can microflora prevalence inform probabilistic antibiotic treatment?",
        "gt": "The mortality rate among our diabetic patients with foot ulcers is high and the combination of second-generation quinolone and aminoglycoside antibiotics can be proposed as a probabilistic antibiotic approach to treating foot infection.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study tests the assumption that psychiatric diagnosis facilitates clinical evaluations of need in emergency care before and after controlling for danger. The data are from structured crisis assessments completed by emergency clinicians in four ethnically diverse locales (N = 653). Clinician-assigned diagnosis was categorized as adjustment, disruptive, mood, psychotic, and other, and a Danger scale score reflected danger to self or others. Mood and psychotic disorders significantly increased hospital rates in multivariate analyses which controlled for demographic characteristics, site, and danger when relevant. The model with the best fit included both diagnosis and danger.\nQuestion: Is diagnosis relevant in the hospitalization of potentially dangerous children and adolescents?",
        "gt": "Decisions should be linked to verifiable ratings of need and attention to danger, and its measurement should complement the current focus on diagnosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We report the case of a 58-year-old female with clinical, radiological, and histopathological evidence of Rasmussen's encephalitis, representing the oldest confirmed case to date. The patient presented with complex partial seizures characterized by numbness of the left face and staring spells. These progressed to a state of epilepsia partialis continua with jerking of the left face, as well as severe cognitive impairment and loss of all communication. The patient responded well to Intravenous Immunoglobulin (IVIG) therapy despite early complications and with ongoing treatment is living independently with minimal cognitive impairment.\nQuestion: Rasmussen's encephalitis in a 58-year-old female: still a variant?",
        "gt": "This represents the oldest confirmed case of Rasmussen's encephalitis and suggests that this diagnosis should be considered in patients of any age with an appropriate clinical picture. We recommend IVIG as a first line therapy for adult cases of Rasmussen's encephalitis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Indications for operative intervention in the treatment of diverticulitis have become unclear. We hypothesized that surgical treatment for diverticulitis has decreased resulting in proportionately more complicated diverticulitis cases (free perforation and/or abscess). We conducted a retrospective analysis of patients with diverticular disease in the Nationwide Inpatient Sample from 1991 through 2005. We used diagnostic codes to identify all patient discharges with diverticular disease and then determined the proportion of discharges with diverticulitis, perforated disease, diverticular abscess, and surgical treatment. During the study period, 685,390 diverticulitis discharges were recorded. The ratio of diverticulitis discharges increased from 5.1 cases per 1,000 inpatients in 1991 to 7.6 cases per 1,000 inpatients in 2005 (P<0.0001). The proportion of patients who underwent colectomy for uncomplicated diverticulitis declined from 17.9% in 1991 to 13.7% in 2005 (P<0.0.0001). During the same period, the proportion of free diverticular perforations as a fraction of all diverticulitis cases remained unchanged (1.5%). The proportion of diverticular abscess discharges as a fraction of all diverticulitis cases increased from 5.9% in 1991 to 9.6% in 2005 (P<0.0001). Last, we noted a decrease in diverticular perforations and/or abscess treated with colectomy, 71.0% in 1991 to 55.5% in 2005 (P<0.0001).\nQuestion: Is the decline in the surgical treatment for diverticulitis associated with an increase in complicated diverticulitis?",
        "gt": "Despite a significant decline in surgical treatment for diverticulitis, there has been no change in the proportion of patients discharged for free diverticular perforation. There was an increase in diverticular abscess discharges, but this finding was not associated with an increase in same stay surgical treatment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Endoscopic vein harvesting is one of the most popular minimally invasive vein-harvesting techniques for coronary artery bypass graft surgery. It is associated with improved cosmetic outcome and fewer wound-related problems compared with the conventional open technique. However, its efficacy with regard to conduit damage and long-term patency has recently been questioned. Learning curve-associated trauma to the vein has a major impact on vein quality and the incidence of graft failure post-surgery. In an attempt to address this problem, we have devised and tested a learning tool termed Manchester Endoscopic Learning Tool (MELT). In this study, we compare vein quality following MELT training with standard recommended training. Fourteen practitioners across seven UK centres were enrolled into the study. Practitioners were categorized into two groups receiving MELT or standard training. Data were collected prospectively from the first eight vein retrievals per operator following training. A total of n = 112 vein-harvesting procedures were included in the study. Veins harvested by MELT practitioners had fewer small avulsions (P<0.001), required fewer repairs (P<0.001) and experienced a lower incidence of bruising (P<0.001) than veins obtained by practitioners receiving standard training. The incidence of very short side branches requiring repair was also significantly reduced (P<0.001) in the MELT group compared with standard training.\nQuestion: Does the introduction of a comprehensive structured training programme for endoscopic vein harvesting improve conduit quality?",
        "gt": "Our formalized training programme consistently minimizes vein trauma resulting in better-quality conduits when compared with the current standard training. Exposure of surgical practitioners to the structured curriculum during their endoscopic vein harvesting training will enhance their learning and lead to better-quality conduits. This is likely to impart clinical benefit post-surgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is accumulating evidence that greater availability of green space in a neighbourhood is associated with health benefits for the local population. One mechanism proposed for this association is that green space provides a venue for, and therefore encourages, physical activity. It has also been suggested that socio-economic health inequalities may be narrower in greener areas because of the equalised opportunity for physical activity green spaces provide. However, research exploring associations between the availability of green space and physical activity has produced mixed results. Limits to the assessment of the type and amount of physical activity which occurs specifically in green space may account for these mixed findings. This observational study was therefore concerned with the extent to which green space is a venue for physical activity and whether this could account for narrower socio-economic health inequalities in greener neighbourhoods. Secondary analysis of cross sectional data on 3679 adults (16+) living in urban areas across Scotland matched with a neighbourhood level measure of green space availability. Associations between green space availability and both total physical activity, and activity specifically within green space, were explored using logistic regression models. Interactions between socio-economic position and physical activity were assessed. All models adjusted for age, sex and household income. The availability of green space in a neighbourhood was not associated with total physical activity or that specifically in green space. There was no evidence that income-related inequalities in physical activity within green space were narrower in greener areas of Scotland.\nQuestion: Is level of neighbourhood green space associated with physical activity in green space?",
        "gt": "Physical activity may not be the main mechanism explaining the association between green space and health in Scotland. The direct effect of perceiving a natural environment on physiological and psychological health may offer an alternative explanation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Eotaxin-1 (CCL11) is a protein expressed in various tissues influencing immunoregulatory processes by acting as selective eosinophil chemo-attractant. In prostate cancer (PCa), the expression and functional role of CCL11 have not been intensively investigated so far. Therefore, the aim of the present study was to investigate the diagnostic or prognostic potential of Eotaxin-1 in PCa patients. We analyzed serum from 140 patients who have undergone prostate biopsy due to elevated prostate-specific antigen (PSA) levels as well as serum of 20 individuals with PSA levels<\u20091ng/ml (healthy control group). Moreover, 40 urine samples were analyzed. A custom-made Q-Plex array ELISA (Quansys Biosciences) for the detection of Eotaxin-1 was performed and Q-View Software used for quantification. In addition, clinical courses of patients documented in our Prostate Biobank database were analyzed. ROC and survival analyses were used to determine the diagnostic and prognostic power of Eotaxin-1 levels. Serum Eotaxin-1 levels were significantly decreased in PCa (P\u2009=\u20090.006) as well as in benign prostate hyperplasia (P\u2009=\u20090.0006) compared to the control group. ROC analysis revealed that Eotaxin-1 is a significant marker to distinguish PCa from disease-free prostate. Moreover, we found that Eotaxin-1 expression is significantly decreased in Gleason score (GS) 6 (P\u2009=\u20090.0135) and GS 8 (P\u2009=\u20090.0057) patients compared to samples of healthy men, respectively. However, PCa aggressiveness was not predictable by Eotaxin-1 levels. In line with serum analyses, urine Eotaxin-1 was significantly decreased in patients with PCa compared to cancer-free individuals (P\u2009=\u20090.0185) but was not different between cancers of different GS. Patient\u015b follow-up analyses showed no significant correlation between serum Eotaxin-1 levels and time to biochemical recurrence. Survival analyses also revealed no significant changes in progression-free survival among low (\u2264\u2009112.2\u2009pg/ml) and high (>\u2009112.2\u2009pg/ml) Eotaxin-1 serum levels.\nQuestion: Is Eotaxin-1 a serum and urinary biomarker for prostate cancer detection and recurrence?",
        "gt": "Although this study has not established a prognostic role of Eotaxin-1 in PCa patients, this chemokine may serve as a diagnostic marker to distinguish between disease-free prostate and cancer.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although epinephrine is one of the most commonly used vasoconstrictor in association with local anesthesia in dentistry, systemic effects of topical admission of epinephrine for sinus augmentation have not been investigated yet. The purpose of this study was to reveal the safety of epinephrine as a topical vasoconstrictor in sinus augmentation procedures. Forty-three healthy patients who require sinus floor augmentation for dental implant placement were included in this study. Patients were divided into 2 groups according to the application of either epinephrine-soaked cottonoid or saline-soaked cottonoid for sinus floor augmentation, and heart rate, systolic, and diastolic pressures were evaluated and compared before, during, and after the procedure. Although there were changes in heart rate, systolic, and diastolic blood pressures, no statistical significance was observed for neither heart rate nor systolic and diastolic blood pressures (P>0.05).\nQuestion: Does the topical use of epinephrine for sinus floor augmentation affect systemic hemodynamics?",
        "gt": "This study showed that the topical use of 1/100,000 epinephrine ensures efficacy by helping the clinician to elevate the sinus membrane and keeps the changes in systemic hemodynamics within safe limitations.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Improved survival after prophylactic implantation of a defibrillator in patients with reduced left ventricular ejection fraction (EF) after myocardial infarction (MI) has been demonstrated in patients who experienced remote MIs in the 1990s. The absolute survival benefit conferred by this recommended strategy must be related to the current risk of arrhythmic death, which is evolving. This study evaluates the mortality rate in survivors of MI with impaired left ventricular function and its relation to pre-hospital discharge baseline characteristics. The clinical records of patients who had sustained an acute MI between 1999 and 2000 and had been discharged from the hospital with an EF of<or = 40% were included. Baseline characteristics, drug prescriptions, and invasive procedures were recorded. Bivariate and multivariate analyses were performed using a primary end point of total mortality. One hundred sixty-five patients were included. During a median follow-up period of 30 months (interquartile range, 22 to 36 months) 18 patients died. The 1-year and 2-year mortality rates were 6.7% and 8.6%, respectively. Variables reflecting coronary artery disease and its management (ie, prior MI, acute reperfusion, and complete revascularization) had a greater impact on mortality than variables reflecting mechanical dysfunction (ie, EF and Killip class).\nQuestion: Reduced ejection fraction after myocardial infarction: is it sufficient to justify implantation of a defibrillator?",
        "gt": "The mortality rate among survivors of MIs with reduced EF was substantially lower than that reported in the 1990s. The strong decrease in the arrhythmic risk implies a proportional increase in the number of patients needed to treat with a prophylactic defibrillator to prevent one adverse event. The risk of an event may even be sufficiently low to limit the detectable benefit of defibrillators in patients with the prognostic features identified in our study. This argues for additional risk stratification prior to the prophylactic implantation of a defibrillator.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Women with fertility problems experience a higher prevalence of negative emotions than women without fertility problems. The goal of this study was to compare the effects of psychological intervention with psychotropic medication on the mental health improvement of depressed infertile women. In a randomized controlled clinical trial, 89 depressed infertile women that they were recruited and divided into three groups in three groups: cognitive behavior therapy (CBT), antidepressant therapy, and a control group. Twenty-nine participants in the CBT method received 10 sessions on relaxation training, restructuring, and eliminating negative automatic thoughts and dysfunctional attitudes to infertility. Thirty participants in the pharmacotherapic group took 20mg fluoxetine daily for 90 days. Thirty control subjects did not receive any intervention. All participants completed the Beck Depression Inventory (BDI) and the General Health Questionnaire (GHQ) at the beginning and end of the study. Paired t-test, ANOVA, chi(2), and McNemar tests were used to analyze the data. Fluoxetine significantly reduced the mean of three subscale scores of the GHQ anxiety (7.3+/-4.1 vs. 5.1+/-3.2), social function (7+/-2.8 vs. 4.3+/-2), and depression (7.8+/-5.2 vs. 4.4+/-2.2) but could not significantly change the mean score of psychosomatic signs. The CBT method effectively reduced the mean of all four GHQ subscales: anxiety (8+/-4 vs. 3.2+/-2), social function (7.2+/-2.6 vs. 4.7+/-2.5), depression (7.7+/-4.2 vs. 3.6+/-2.7), and psychosomatic signs (7.5+/-3.2 vs. 5.5+/-3.2). Also, both methods significantly reduced the total GHQ scores. Successful treatment of depression in three groups was fluoxetine group 50%, CBT 79.3%, and control 10%. The mean Beck scores among the groups at the beginning and end of study were, respectively: fluoxetine 23.2+/-8.6 versus 14.3+/-8.5 (p<0.001), CBT 20+/-7.9 versus 7.7+/-4.8 (p<0.001), and control 19.8+/-8.5 versus 19.7+/-8.4 (p=0.9). Although both fluoxetine and CBT significantly decreased the mean BDI scores more than the control group, the decrease in the CBT group was significantly greater than the fluoxetine group.\nQuestion: Is psychotherapy a reliable alternative to pharmacotherapy to promote the mental health of infertile women?",
        "gt": "Psychotherapy, such as group CBT, was superior to or at least as effective as pharmacotherapy to promote the well being of depressed infertile women.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the perioperative and long-term results of total pancreatectomy (TP), and to assess whether it provides morbidity, mortality, and quality of life (QoL) comparable to those of the pylorus-preserving (pp)-Whipple procedure in patients with benign and malignant pancreatic disease. TP was abandoned for decades because of high peri- and postoperative morbidity and mortality. Because selected pancreatic diseases are best treated by TP, and pancreatic surgery and postoperative management of exocrine and endocrine insufficiency have significantly improved, the hesitance to perform a TP is disappearing. In a prospective study conducted from October 2001 to November 2006, all patients undergoing a TP (n = 147; 100 primary elective TP [group A], 24 elective TP after previous pancreatic resection [group B], and 23 completion pancreatectomies for complications) were included, and perioperative and late follow-up data, including the QoL (EORTC QLQ-C30 questionnaire), were evaluated. A matched-pairs analysis with patients receiving a pp-Whipple operation was performed. Indications for an elective TP (group A + B) were pancreatic and periampullary adenocarcinoma (n = 71), other neoplastic pancreatic tumors (intraductal papillary mucinous neoplasms, neuroendocrine tumors, cystic tumors; n = 34), metastatic lesions (n = 8), and chronic pancreatitis (n = 11). There were 73 men and 51 women with a mean age of 60.9 +/- 11.3 years. Median intraoperative blood loss was 1000 mL and median operation time was 380 minutes. Postoperative surgical morbidity was 24%, medical morbidity was 15%, and mortality was 4.8%. The relaparotomy rate was 12%. Median postoperative hospital stay was 11 days. After a median follow-up of 23 months, global health status of TP patients was comparable to that of pp-Whipple patients, although a few single QoL items were reduced. All patients required insulin and exocrine pancreatic enzyme replacements. The mean HbA1c value was 7.3% +/- 0.9%.\nQuestion: Is there still a role for total pancreatectomy?",
        "gt": "In this cohort study, mortality and morbidity rates after elective TP are not significantly different from the pp-Whipple. Because of improvements in postoperative management, QoL is acceptable, and is almost comparable to that of pp-Whipple patients. Therefore, TP should no longer be generally avoided, because it is a viable option in selected patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of the present study is to evaluate the effects of the increased number of caesarean deliveries (CDs) in cases of multiple repeat caesarean deliveries (MRCDs) on maternal and neonatal morbidity. MRCDs admitted to our hospital between January 2013 and September 2014 were analysed retrospectively. A total number of 1133 women were included in the study and were divided into 4 groups. Group 1: second CDs (n\u2009=\u2009329); Group 2: third CDs (n\u2009=\u2009225); Group 3: fourth CDs (n\u2009=\u2009447); Group 4: fifth CDs (n\u2009=\u2009132). The clinical, demographic, intraoperative and postoperative data of the patients were registered upon the review of patient files. The differences among the groups were found to be statistically significant in terms of mean maternal age, gravida, APGAR (Activity, Pulse, Grimace, Appearance, Respiration) scores, hospital stay and operation time. In addition, the difference was also statistically significant for severe adhesion, bladder injury and premature birth. No statistically significant difference was observed among the groups with respect to placenta previa, placenta accreta, caesarean hysterectomy, uterine scar rupture.\nQuestion: Multiple repeat caesarean deliveries: do they increase maternal and neonatal morbidity?",
        "gt": "According to our findings, MRCDs seem to increasing the maternal and neonatal morbidity even though they are not life-threatening.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate sympathetic system activity in bladder pain syndrome/interstitial cystitis (BPS/IC) patients and to investigate if chronic adrenergic stimulation in intact rats induces BPS/IC-like bladder modifications. Clinical study--In BPS/IC patients and aged and body mass index matched volunteers TILT test was undertaken and catecholamines were measured in plasma and 24\u2009hr urine samples. Experimental study--Phenylephrine was injected subcutaneously (14 days) to female Wistar rats. Pain behavior, spinal Fos expression, urinary spotting, number of fecal pellets expelled, frequency of reflex bladder contractions, and urothelial height were analyzed. Urothelium permeability was investigated by trypan blue staining. Immunoreactivity against caspase 3 and bax were studied in the urothelium and against alpha-1-adrenoreceptor and TRPV1 in suburothelial nerves. Mast cell number was determined in the sub-urothelium. In rats with lipopolysaccharide-induced cystitis, urinary catecholamines, and Vesicular Monoamine Transporter 2 (VMAT2) expression in bladder nerves were analyzed. The TILT test showed an increase of sympathetic activity. Noradrenaline levels in blood at resting conditions and in 24-hr urine samples were higher in BPS/IC patients. Phenylephrine administration increased visceral pain, spinal Fos expression, bladder reflex activity, urinary spotting and the number of expelled fecal pellets. The mucosa showed urothelial thinning and increased immunoreactivity for caspase 3 and bax. Trypan blue staining was only observed in phenylephrine treated animals. Suburothelial nerves co-expressed alpha1 and TRPV1. Mastocytosis was present in the suburothelium. Cystitis increased sympathetic nerve density and urinary noradrenaline levels.\nQuestion: Can the adrenergic system be implicated in the pathophysiology of bladder pain syndrome/interstitial cystitis?",
        "gt": "Excessive adrenergic stimulation of the bladder may contribute to the pathophysiological mechanisms of BPS/IC.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A better prognosis in obese patients has been described in acute coronary syndromes (ACS). However, this evidence is mostly based on retrospective studies and has provided conflicting results. No study reported cause-specific mortality according to body mass index (BMI) in ACS. We aimed to prospectively assess the impact of BMI on mortality and its specific causes in ACS patients. We included non-selected ACS patients admitted in a tertiary care coronary unit, collecting baseline characteristics, management and clinical course. Patients were stratified into five clinically meaningful BMI subgroups of<20, 20-24.9, 25-29.9, 30-35,>35 kg/m(2). The primary outcome was 1 year mortality, its causes and its association with BMI. This association was assessed by the Cox regression method. We included 2040 patients in our study with a mean age of 62.1 years. Low weight patients (BMI<20) were older, with less cardiovascular risk factors, higher prevalence of chronic obstructive pulmonary disease and worse renal function. Mean follow up was 334 days. The unadjusted analysis showed lower all-cause mortality in all subgroups as compared to low weight patients. After adjusting for potential confounders, this association remained significant for patients with a BMI 20-24.9. Cardiac mortality was similar across BMI subgroups. In contrast, the adjusted analysis showed a significantly lower non-cardiac mortality in patients with a BMI 20-24.9, 25-29.9 and 30-35 as compared to low weight patients.\nQuestion: Body mass index and acute coronary syndromes: paradox or confusion?",
        "gt": "Baseline characteristics in ACS patients significantly differ according to their BMI status. The prognostic impact of BMI seems mostly related to extra-cardiac causes in low weight patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Aminoglycosides have been reported to produce a curare-like neuromuscular blockade in animals at serum concentrations higher than those obtained with traditional dosing (1-2 mg/kg every 8 h) in humans. Aminoglycoside-induced neuromuscular blockade is rarely, if ever, seen in humans with traditional dosing. The recent adoption of once-daily dosing of aminoglycosides has raised concerns about increased potential for this adverse effect because higher serum concentrations are produced. The objective of this study was to determine if once-daily dosing of aminoglycosides inhibits respiratory muscle function. Nine mechanically ventilated ICU patients on once-daily dosing of gentamicin 6 mg/kg/day were assessed for respiratory muscle strength by measuring maximum inspiratory pressure (MIP). MIP is a measurement of the maximal negative pressure generated by repeated inhalations against an occluded airway over 20 s. This was measured within 1 hour before (MIPpre) and within 1 hour after each aminoglycoside dose (MIPpost). Mean values for MIPpre and MIPpost were -26.7 cm H2O and -26.5 cm H2O, respectively. The mean difference between MIPpre and MIPpost was -0.2 cm H2O, which was not statistically significant (P>0.05).\nQuestion: Does once-daily dosing of aminoglycosides affect neuromuscular function?",
        "gt": "The effect of gentamicin (6 mg/kg/day) on respiratory muscle function was not statistically, nor clinically significant, and weaning from mechanical ventilation does not seem to be inhibited by once-daily dosing of aminoglycosides as detectable by measurement of MIP.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In 1989 the United States Public Health Service Expert Panel on the Content of Prenatal Care reported that health education should become a more integral part of prenatal care. Key questions about providing this education have not been examined. Our study compared the type of information provided to women who sought prenatal care in a public clinic and to those who were seen in a private practice and the degree to which the patients were satisfied with the information they received. One hundred fifty-nine pregnant women (80 seen in a public clinic, 79 seen in a private practice) completed two questionnaires about 38 topics commonly cited as important during pregnancy. At the first prenatal visit, the women reported their level of interest in each of the topics. At 36 to 40 weeks' gestation the women completed a second questionnaire to assess whether information was provided for each topic and whether they had learned as much as desired. Overall, the women in the public sector received more information than did the women who were cared for privately. This was statistically significant at the p<0.05 level for 25 of the 38 topics. Satisfaction with information learned was highly correlated with information received during prenatal care, but, surprisingly, it was not shown to be associated with the patient's interest level at the first visit. Fewer than 50% of private patients reported having received information about such important topics as acquired immunodeficiency syndrome, sexually transmitted diseases, preterm birth prevention, family planning, and family violence.\nQuestion: Are there differences in information given to private and public prenatal patients?",
        "gt": "The one-on-one approach to health education in pregnancy usually used in the private setting may not facilitate addressing many topics believed to be important components of contemporary prenatal care. Providers of private prenatal care should initiate discussion of prenatal health education topics rather than relying on patient interest in requesting information. Just as public prenatal care programs have devoted significant resources to more comprehensive prenatal education, the providers in the private sector must assure that pregnant women receive the same comprehensive information. In so doing, these providers can help promote an optimal outcome for their patients, their patients' unborn children, and the family unit.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The objective of this study is to determine parents' awareness of their children's headaches and to evaluate some of the factors that affect this awareness. The subjects of the study are 2601 children who were diagnosed with headache. Data on the children and the parents was collected using a detailed data form. The diagnosis of headache in children was made on the basis of the criteria of the International Headache Society (IHS). If the parents of a child diagnosed with headache reported that their child had headache, the parent was evaluated to be aware of his/her child's headache. In the statistical analyses, chi-square and binary logistic regression were used. Almost 74% of parents were aware of their children's headache. It was found that migraine type headache, female gender, being the first child of the family, travel sickness of children, the presence of headache history in one of the family members; the number of family members and mother's age are factors that affect the awareness level of parents. It was also revealed that parents who do not work outside are more aware of their children's headache and that educational and financial status do not have any effect on the degree of awareness.\nQuestion: Are parents aware of their schoolchildren's headaches?",
        "gt": "In a city like Mersin, which is economically well developed when compared with the rest of the country, one quarter of the parents are not aware of their children's headache.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: For direct laryngoscopy, we compared midline and left-molar approaches with respect to ease of intubation, using a Macintosh blade. We investigated the relationship between failure of the left-molar approach and preoperative risk factors for difficult intubation. With local ethics committee approval, 200 consecutive adult, nonpregnant patients were included in the study. The demographic data, body mass index, Mallampati modified score, interincisor gap, and mentohyoid and thyromental distances were measured preoperatively. First, the Macintosh blade was inserted using the midline approach, and then optimal external laryngeal manipulation (OELM) was applied. Second, the blade was inserted using the left-molar approach. The glottic views were assessed according to the Cormack-Lehane classification before and after OELM in both approaches. In cases where tracheal intubation failed with the left-molar approach, the midline approach was applied again and endotracheal intubation took place. The grade I glottic view obtained using the midline approach without OELM did not change in 94.3% of the patients with the left-molar approach without OELM; in addition, the grade II glottic view improved to grade I in 52.8% of the patients with the same technique (P<0.001). Although the number of patients with a grade I or II glottic view in the left-molar approach was 197, only 37 patients could be intubated using the left-molar approach. In addition, 59.5% of them were intubated at the second attempt with the left-molar approach, while the incidence of a second attempt was 1.2% with the midline approach (P<0.001). There was no correlation between the preoperative risk factors for difficult intubation and failure of the left-molar approach.\nQuestion: Left-molar approach for direct laryngoscopy: is it easy?",
        "gt": "Difficulty in the insertion of the endotracheal tube limits the efficacy of the left-molar approach. It is not possible to predict the failure of intubation with the left-molar approach by considering the preoperative risk factors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Two hundred and fifty patients (response rate 78%) from five tertiary level hospitals in Zagreb, Croatia, anonymously filled in the questionnaire on informed consent and communication practices by Nemcekova et al in the period from April to December 2011. Eighty five percent of patients received complete, understandable information, presented in a considerate manner. Patients in surgical departments received a higher level of information than those in internal medicine departments. Patients were informed about health risks of the proposed treatments (in 74% of cases) and procedures (76%), health consequences of refusing a medical intervention (69%), and other methods of treatment (46%). However, patients pointed out a number of problems in physician-patient communication.\nQuestion: Are physician-patient communication practices slowly changing in Croatia?",
        "gt": "Communication practices during informed consent-obtaining process in hospitals in Zagreb are based on a model of shared decision-making, but paternalistic physician-patient relationship is still present. Our results indicate that Croatia is undergoing a transition in the physician-patient relationship and communication.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the effect of synchronous endometrial endometrioid cancer (SEEC) on the prognosis of patients with Stage 1 endometrioid ovarian cancer (EOC). Clinicopathological data of cases with Stage 1 EOC from January 2000 to November 2013 were retrieved from the computerized database of Etlik Zubeyde Hanim Women's Health and Research Hospital. Of the 31 patients included in the study, 15 patients had primary synchronous endometrial and ovarian cancer (SEOC) (Group 1) and 16 patients had EOC alone (Group 2). Ovarian cancer substage and grade were compared between the two groups, and no significant differences were found. Most of the patients with SEEC had Grade 1 tumours (n=13, 86.7%). In Group 1, nine (60.0%) patients had endometrial tumours with superficial myometrial invasion, and six (40.0%) patients had deep myometrial invasion. Median follow-up was 94 months. Ten-year disease-free survival rates were 92.9% for Group 1 and 84.6% for Group 2 (p=0.565).\nQuestion: Does synchronous endometrioid endometrial cancer have any prognostic effect on Stage I endometrioid ovarian cancer?",
        "gt": "Patients with Stage 1 EOC have excellent long-term survival. The presence of SEEC does not influence the prognosis of patients with Stage 1 EOC, even in the presence of deep myometrial invasion.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Psychological interventions show greater efficacy when evaluated with distressed patients. We report on the feasibility of implementing screening for recruiting distressed cancer patients to a randomized controlled trial of problem-solving therapy (PST), characteristics associated with enrolment, and time investment and challenges of implementing screening. Three medical settings implemented screening of patients, directly after cancer treatment (T1) and 2 months later (T2), using Hopkins Symptom Checklist-25 and one question about need for services. Distressed patients indicating need for services were interviewed. Eligible patients were offered the possibility to participate in the trial. Consenting patients were randomized to PST or waitlist. At T1, 366 of 970 screened patients (37%) scored above the cutoff and at T2, 208 of 689 screened patients (30%). At either or both T1 and T2, 423 patients reported distress, of whom 215 indicated need for services. Only 36 (4% of 970) patients consented to trial participation. Twenty-seven patients needed to be screened to recruit a single patient, with 17 h required for each patient recruited. Barriers to screening were time constraints and negative attitudes of oncology staff towards screening.\nQuestion: Is implementing screening for distress an efficient means to  recruit patients to a psychological intervention trial?",
        "gt": "Implementing screening proved inefficient for recruiting distressed cancer patients post-treatment to a randomized controlled trial on PST, with need for services being much less than anticipated. Consecutively screening patients did not result in a sample representative of the larger pool of distressed patients, which may lower generalizability. An adequately powered intervention trial using screening requires a feasibility study establishing recruitment rates and dedicated, funded staff assistance.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Transurethral laser prostatectomy has evolved as a viable alternative for the management of benign prostate enlargement. Since the renaissance of laser prostatectomy with the advent of the holmium:yttrium-aluminum-garnet laser in the 1990s, various lasers and subsequent procedures have been introduced. These techniques can be categorized as vaporizing, resecting, and enucleating approaches. Photoselective vaporization of the prostate (PVP) is dominated by high-power lithium triborate (LBO) crystal lasers (GreenLight XPS). The mainstay of this technique is for the treatment of small to medium prostate volumes whereas enucleating techniques, such as holmium laser enucleation of the prostate and thulium enucleation of the prostate, focus on large-volume glands. In order to perspectively \"delimit\" LBO into the field of large-volume prostates, we developed LBO en bloc enucleation to render it as a competing transurethral enucleating approach. We present a detailed stepwise progressive technique developed in Madrid, Spain, for the complete removal of the transitional zone by vapoenucleation. The steps include exposition of the prostatic capsule by PVP toward the peripheral zone, thereby identifying the anatomical limits of enucleation. Subsequently, the transitional zone is excised in a single bloc and morcellated after its placement into the bladder.\nQuestion: Common trend: move to enucleation-Is there a case for GreenLight enucleation?",
        "gt": "This new GreenLight en bloc enucleation technique allows to treat larger prostates than those previously treated with the PVP technique.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The goal of this study was to examine the reasons for early readmissions within 30 days of discharge to a major academic neurosurgical service. A database of readmissions within 30 days of discharge between April 2009 and September 2010 was retrospectively reviewed. Clinical and administrative variables associated with readmission were examined, including age, sex, race, days between discharge and readmission, and insurance type. The readmissions were then assigned independently by 2 neurosurgeons into 1 of 3 categories: scheduled, adverse event, and unrelated. The adverse event readmissions were further subcategorized into patients readmitted although best practices were followed, those readmitted due to progression of their underlying disease, and those readmitted for preventable causes. These variables were compared descriptively. A total of 348 patients with 407 readmissions were identified, comprising 11.5% of the total 3552 admissions. The median age of readmitted patients was 55 years (range 16-96 years) and patients older than 65 years totaled 31%. There were 216 readmissions (53% of 407) for management of an adverse event that was classified as either preventable (149 patients; 37%) or unpreventable (67 patients; 16%). There were 113 patients (28%) who met readmission criteria but who were having an electively scheduled neurosurgical procedure. Progression of disease (48 patients; 12%) and treatment unrelated to primary admission (30 patients; 7%) were additional causes for readmission. There was no significant difference in the proportion of early readmissions by payer status when comparing privately insured patients and those with public or no insurance (p = 0.09).\nQuestion: Are readmission rates on a neurosurgical service indicators of quality of care?",
        "gt": "The majority of early readmissions within 30 days of discharge to the neurosurgical service were not preventable. Many of these readmissions were for adverse events that occurred even though best practices were followed, or for progression of the natural history of the neurosurgical disease requiring expected but unpredictably timed subsequent treatment. Judicious care often requires readmission to prevent further morbidity or death in neurosurgical patients, and penalties for readmission will not change these patient care obligations.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It is usually believed that loss of residual renal function is associated with anorexia and the development of malnutrition. We conducted a retrospective study in our center to evaluate the effect of declining residual renal function on patients' nutritional status. All incident uremic patients (n = 46) who began peritoneal dialysis from January 1, 2003 June 1, 2003 in our center were closely followed for 1 year with focus on maintaining strict volume control with time on dialysis. Patient's residual renal function (RRF) was assessed by the average renal urea and creatinine clearances. Those patients who had more than 50% decrease in GFR were selected for the present analysis. Serum albumin (ALB), dietary protein intake (DPI) and subjective global assessment (SGA) were closely followed. There were 16 patients (9 males and 7 females) included in the present analysis, among whom 31.3% were diabetics. Patients' GFR declined significantly (RRF were 4.32 +/- 2.69, 2.99 +/- 2.21 and 1.24 +/- 0.99 ml/min for Months 1, 6 and 12, respectively, p<0.05), along with a significant decline in urine volume (985.62 +/- 543.29, 698.13 +/- 463.59 and 425.63 +/- 320.52 ml/d for Months 1, 6 and 12, respectively, p<0.01). Although weekly peritoneal Kt/V did not increase significantly, peritoneal ultrafiltration increased significantly during this period (428.75 +/- 408.96, 534.38 +/- 296.39, 844.38 +/- 440.35 ml for Months 1, 6 and 12, respectively, p<0.05). Serum ALB increased significantly (32.34 +/- 5.07, 34.74 +/- 4.89 and 36.21 +/- 3.98 g/l for Months 1, 6 and 12, respectively, p<0.01). DPI also increased significantly. The prevalence of malnutrition (by SGA) decreased from 62.5% at the start of dialysis to 18.8% at the end of this study (p<0.05).\nQuestion: Does loss of residual renal function lead to malnutrition in peritoneal dialysis patients?",
        "gt": "Our study suggests that rapid decline of residual renal function in PD patients does not necessarily lead to decreased dietary protein intake and deteriorated nutritional status. Focus on incremental peritoneal fluid removal along with the decline in residual renal function and, thus, maintaining volume control may be one of the critical reasons for the success.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate whether using long-axis or short-axis view during ultrasound-guided internal jugular and subclavian central venous catheterization results in fewer skin breaks, decreased time to cannulation, and fewer posterior wall penetrations. Prospective, randomized crossover study. Urban emergency department with approximate annual census of 60,000. Emergency medicine resident physicians at the Denver Health Residency in Emergency Medicine, a postgraduate year 1-4 training program. Resident physicians blinded to the study hypothesis used ultrasound guidance to cannulate the internal jugular and subclavian of a human torso mannequin using the long-axis and short-axis views at each site. An ultrasound fellow recorded skin breaks, redirections, and time to cannulation. An experienced ultrasound fellow or attending used a convex 8-4 MHz transducer during cannulation to monitor the needle path and determine posterior wall penetration. Generalized linear mixed models with a random subject effect were used to compare time to cannulation, number of skin breaks and redirections, and posterior wall penetration of the long axis and short axis at each cannulation site. Twenty-eight resident physicians participated: eight postgraduate year 1, eight postgraduate year 2, five postgraduate year 3, and seven postgraduate year 4. The median (interquartile range) number of total internal jugular central venous catheters placed was 27 (interquartile range, 9-42) and subclavian was six catheters (interquartile range, 2-20). The median number of previous ultrasound-guided internal jugular catheters was 25 (interquartile range, 9-40), and ultrasound-guided subclavian catheters were three (interquartile range, 0-5). The long-axis view was associated with a significant decrease in the number of redirections at the internal jugular and subclavian sites, relative risk 0.4 (95% CI, 0.2-0.9) and relative risk 0.5 (95% CI, 0.3-0.7), respectively. There was no significant difference in the number of skin breaks between the long axis and short axis at the subclavian and internal jugular sites. The long-axis view for subclavian was associated with decreased time to cannulation; there was no significant difference in time between the short-axis and long-axis views at the internal jugular site. The prevalence of posterior wall penetration was internal jugular short axis 25%, internal jugular long axis 21%, subclavian short axis 64%, and subclavian long axis 39%. The odds of posterior wall penetration were significantly less in the subclavian long axis (odds ratio, 0.3; 95% CI, 0.1-0.9).\nQuestion: Is long-axis view superior to short-axis view in ultrasound-guided central venous catheterization?",
        "gt": "The long-axis view for the internal jugular was more efficient than the short-axis view with fewer redirections. The long-axis view for subclavian central venous catheterization was also more efficient with decreased time to cannulation and fewer redirections. The long-axis approach to subclavian central venous catheterization is also associated with fewer posterior wall penetrations. Using the long-axis view for subclavian central venous catheterization and avoiding posterior wall penetrations may result in fewer central venous catheter-related complications.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We earlier discovered partial recovery in a patient with autoimmune Addison's disease. The aim of this study was to assess the occurrence of adrenocortical recovery in patients with autoimmune adrenalitis. Cross-sectional study. Twenty-seven adult patients with autoimmune Addison's disease on stable glucocorticoid and mineralocorticoid replacement therapy (RT) attending the Department of Endocrinology of a university teaching hospital were included in this study. Adrenocortical function was assessed by performing an adrenocorticotrophic hormone (ACTH) (250 \u03bcg Synacthen) stimulation test (SST) after interruption of current glucocorticoid and mineralocorticoid RT. A normal adrenal response was defined as a serum cortisol concentration \u2265500 nm 30 or 60 min after stimulation. Partial recovery was defined as a cortisol concentration \u2265100 and \u2264500 nm after stimulation. In 17 patients (63%), serum cortisol concentrations remained undetectable 30 and 60 min after the administration of ACTH. None of the remaining 10 participants had a normal response. Only one patient reached a cortisol concentration of 100 nm after 60 min, but this could not be confirmed during a second SST.\nQuestion: Does recovery of adrenal function occur in patients with autoimmune Addison's disease?",
        "gt": "In this cross-sectional study among 27 patients with autoimmune adrenalitis, no new cases of adrenocortical recovery were found.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Depletion of central nervous system catecholamines, including dopamine, can decrease MAC (the minimum alveolar concentration of an inhaled anesthetic required to suppress movement in response to a noxious stimulus in 50% of test subjects); release of central nervous system catecholamines, including dopamine, can increase MAC; and increased free dopamine concentrations in the striatum can decrease MAC. Such findings suggest that dopamine receptors might mediate part of the capacity of inhaled anesthetics to provide immobility in the face of noxious stimulation. We measured the effect of blockade of D2 dopamine-mediated transmission with 0.3 mg/kg or 3.0 mg/kg droperidol on the MAC of cyclopropane, desflurane, halothane, isoflurane, or sevoflurane in rats, and the effect of 3.0 mg/kg droperidol on the dose or concentration of etomidate (an anesthetic known to act principally by enhancing the response of gamma-aminobutyric acid(A) receptors to gamma-aminobutyric acid) required to suppress movement in response to noxious stimulation. Blockade of D2 dopamine-mediated transmission with droperidol does not decrease the MAC of cyclopropane, desflurane, halothane, isoflurane, or sevoflurane or its equivalent for etomidate in rats.\nQuestion: Do dopamine receptors mediate part of MAC?",
        "gt": "These data, plus data from studies by others about D1 dopamine receptors, indicate that dopamine receptors do not mediate the immobility produced by inhaled anesthetics.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Congenic strains of mice are assumed to differ only at a single gene or region of the genome. These mice have great importance in evaluating the function of genes. However, their utility depends on the maintenance of this true congenic nature. Although, accumulating evidence suggests that congenic strains suffer genetic divergence that could compromise interpretation of experimental results, this problem is usually ignored. During coinfection studies with Salmonella typhimurium and Theiler's murine encephalomyelitis virus (TMEV) in major histocompatibility complex (MHC)-congenic mice, we conducted the proper F2 controls and discovered significant differences between these F2 animals and MHC-genotype-matched P0 and F1 animals in weight gain and pathogen load. To systematically evaluate the apparent non-MHC differences in these mice, we infected all three generations (P0, F1 and F2) for 5 MHC genotypes (b/b, b/q and q/q as well as d/d, d/q, and q/q) with Salmonella and TMEV. Infected P0 MHC q/q congenic homozygotes lost significantly more weight (p = 0.02) and had significantly higher Salmonella (p<0.01) and TMEV (p = 0.02) titers than the infected F2 q/q homozygotes. Neither weight nor pathogen load differences were present in sham-infected controls.\nQuestion: Infection-dependent phenotypes in MHC-congenic mice are not due to MHC: can we trust congenic animals?",
        "gt": "These data suggest that these strains differ for genes other than those in the MHC congenic region. The most likely explanation is that deleterious recessive mutations affecting response to infection have accumulated in the more than 40 years that this B10.Q-H-2q MHC-congenic strain has been separated from its B10-H-2b parental strain. During typical experiments with congenic strains, the phenotypes of these accumulated mutations will be falsely ascribed to the congenic gene(s). This problem likely affects any strains separated for appreciable time and while usually ignored, can be avoided with the use of F2 segregants.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the effect of treatment by a cardiologist on mortality of elderly patients with acute myocardial infarction (AMI, heart attack), accounting for both measured confounding using risk-adjustment techniques and residual unmeasured confounding with instrumental variables (IV) methods.DATA SOURCES/ Medical chart data and longitudinal administrative hospital records and death records were obtained for 161,558 patients aged>or =65 admitted to a nonfederal acute care hospital with AMI from April 1994 to July 1995. Our principal measure of significant cardiologist treatment was whether a patient was admitted by a cardiologist. We use supplemental data to explore whether our analysis would differ substantially using alternative definitions of significant cardiologist treatment. This retrospective cohort study compared results using least squares (LS) multivariate regression with results from IV methods that accounted for additional unmeasured patient characteristics. Primary outcomes were 30-day and one-year mortality, and secondary outcomes included treatment with medications and revascularization procedures.DATA COLLECTION/ Medical charts for the initial hospital stay of each AMI patient underwent a comprehensive abstraction, including dates of hospitalization, admitting physician, demographic characteristics, comorbid conditions, severity of clinical presentation, electrocardiographic and other diagnostic test results, contraindications to therapy, and treatments before and after AMI. Patients admitted by cardiologists had fewer comorbid conditions and less severe AMIs. These patients had a 10 percent (95 percent CI: 9.5-10.8 percent) lower absolute mortality rate at one year. After multivariate adjustment with LS regression, the adjusted mortality difference was 2 percent (95 percent CI: 1.4-2.6 percent). Using IV methods to provide additional adjustment for unmeasured differences in risk, we found an even smaller, statistically insignificant association between physician specialty and one-year mortality, relative risk (RR) 0.96 (0.88-1.04). Patients admitted by a cardiologist were also significantly more likely to have a cardiologist consultation within the first day of admission and during the initial hospital stay, and also had a significantly larger share of their physician bills for inpatient treatment from cardiologists. IV analysis of treatments showed that patients treated by cardiologists were more likely to undergo revascularization procedures and to receive thrombolytic therapy, aspirin, and calcium channel-blockers, but less likely to receive beta-blockers.\nQuestion: Does physician specialty affect the survival of elderly patients with myocardial infarction?",
        "gt": "In a large population of elderly patients with AMI, we found significant treatment differences but no significant incremental mortality benefit associated with treatment by cardiologists.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We recently reported that children with acute leukemias who show increasing mixed chimerism (MC) after allogeneic stem-cell transplantation have a significantly enhanced risk of relapse. Here we present the results of a prospective multicenter study to investigate (1) whether relapse of acute lymphoblastic leukemia (ALL) can be determined in advance by serial analysis of chimerism, and (2) if outcome can be influenced by withdrawal of immunosuppression and/or by low-dose donor lymphocyte infusion when increasing MC is detected. Serial and quantitative analysis of chimerism was performed using a fluorescent-based short-tandem-repeat-polymerase chain reaction in 163 children with ALL. One hundred one patients revealed complete chimerism (CC) or low-level MC (CC/low-level MC); increasing MC was found in 46 patients; and decreasing MC, in 16 patients. Relapse was significantly more frequent in patients with increasing MC (26 of 46) than in patients with CC/low-level MC (eight of 101) or in patients with decreasing MC (0 of 16; P<.0001). The probability of 3-year event-free survival (EFS) was 54% for all patients, 66% for patients with CC/low-level MC (n = 101), 66% for patients with decreasing MC (n = 16), and 23% for patients with increasing MC (n = 46; P<.0001). Of the 46 patients with increasing MC, 31 received immunotherapy. This group had a significantly higher 3-year EFS estimate (37%) than the 15 patients who did not receive immunotherapy (0%; P<.001).\nQuestion: Increasing mixed chimerism is an important prognostic factor for unfavorable outcome in children with acute lymphoblastic leukemia after allogeneic stem-cell transplantation: possible role for pre-emptive immunotherapy?",
        "gt": "Serial analysis of chimerism reliably identifies patients at highest risk to relapse. The 3-year EFS of patients with increasing MC without immunotherapy was 0%, by which overt relapse could be prevented in a considerable group of patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Laparoscopic donor nephrectomy has become the standard of care in many renal transplant centers. Many centers are reluctant to perform right laparoscopic donor nephrectomies, primarily due to concerns about transplanting a kidney with a short renal vein. A retrospective review of 26 right and 24 left consecutive donor nephrectomies and their recipients was performed. Patient demographics, preoperative, perioperative, and postoperative data were recorded and compared. Patient demographics were similar between groups. Multiple vessels were encountered more frequently on the right side (10 vs. 3, p = 0.04) and the donated kidney had lesser preoperative function in the right group as determined by nuclear medicine imaging (46.5% vs. 49.4%, p<0.001). Donor operating times were less in the right group (198 vs. 226 min, p = 0.016). There was no difference in implantation difficulty as demonstrated by similar operative and warm ischemia times. Complication rates were similar between both groups of donors and recipients.\nQuestion: Is right laparoscopic donor nephrectomy right?",
        "gt": "Right laparoscopic donor nephrectomy requires less operating time than, and is associated with similar outcomes for donors and recipients as, left laparoscopic donor nephrectomy. Right laparoscopic donor nephrectomy may be preferable in general and should be considered when multiple renal vessels are present on the left side and/or when preoperative function of the left kidney is greater than the right.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study was conducted to determine whether vaccination with the quadrivalent human papillomavirus (HPV) vaccine after loop electrosurgical excision procedure (LEEP) for high-grade cervical intraepithelial neoplasia (CIN2-3) is effective in preventing recurrence of CIN2-3. Between August 2007 and July 2010, 737 patients aged 20-45 years who were diagnosed with CIN2-3 were treated by LEEP and followed. Three hundred and sixty patients were vaccinated with the quadrivalent HPV vaccine after LEEP (vaccination group), and 377 patients were followed without vaccination (non-vaccination group). The vaccination group received the first dose at 1 week after LEEP and the remaining two doses two and six months later. Post-LEEP follow-up was performed at 3, 6, 9, 12, 18, and 24 months during the first 2 years and yearly thereafter. Irrespective of causal HPV type, 36 (4.9%) patients developed recurrence. In the vaccination group (360 patients), 9 patients (2.5%) developed recurrence, whereas 27 patients (7.2%) in the non-vaccination group (377 patients) developed recurrence. In patients infected with HPV of 16 and/or 18 type, 5 patients (2.5%) in the vaccination group (197 patients) and 18 patients (8.5%) in the non-vaccination group (211 patients) developed recurrent disease related to vaccine HPV types (HPV 16 or 18 types) after LEEP (P<0.01). Multivariate analysis showed that no vaccination after LEEP was an independent risk factor for recurrent CIN2-3 (HR=2.840; 95% confidence interval, 1.335-6.042; P<0.01).\nQuestion: Is vaccination with quadrivalent HPV vaccine after loop electrosurgical excision procedure effective in preventing recurrence in patients with high-grade cervical intraepithelial neoplasia (CIN2-3)?",
        "gt": "Vaccination with the quadrivalent HPV vaccine after treatment may be considered in preventing recurrence of CIN2-3.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To study the appropriateness of lipid-lowering drugs treatment through four methods of calculating coronary risk (CR). Crossover study. Primary care centre. All patients receiving lipid-lowering drugs. CR was determined for individuals with application criteria by four methods: the simplified Framingham, Dundee-Risk-Disk, modified Sheffield label and Cardiovascular Risk in Primary Care (CVRap). 330 patients followed the treatment, 137 men and 193 women with an average age of 58.8 (SD 10.2). 54.2% received statims, 28.5% clofibrates, 13.6% resins and 3.6% other drugs. 186 patients were included, 75 (22.7%) being excluded because of secondary prevention and the rest because they were not the right age or had no cholesterol data prior to treatment. 38.3% were at high CR according to Framingham, 25.6% according to CVRap, 18.7% according to Dundee-Risk-Disk and 16% according to modified Sheffield. Concordance between these methods was adequate.\nQuestion: Do the patients we treat with hypolipemic drugs have a coronary risk?",
        "gt": "Between 16% and 38.3% of the individuals treated are at high CR. If we also include patients with severe Hypercholesterolaemia and diabetics with Hypercholesterolaemia, this percentage rises to 59.7-73.3%, according to the CR assessment method used.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients with incurable cancer are faced with difficult decisions regarding whether to take chemotherapy in an attempt to preserve the quality and/or prolong the quantity of their lives. The average prolongation in survival with chemotherapy compared with best supportive care has not been well described. We performed a literature search using PUBMED combined with expert inquiry to identify trials comparing cytotoxic chemotherapy with best supportive care. Twenty-five randomized, controlled clinical trials comparing cytotoxic chemotherapy with best supportive care were identified. Sixteen trials (64%) were in patients with non-small-cell lung cancer (NSCLC). Data were extracted and analyzed. Sufficient data for statistical modeling were available for NSCLC trials. The mean sample size of the NSCLC trials was 175 patients. Response rates in the treatment arms for NSCLC ranged from 7% to 42%. A relationship between response rate and survival was observed for NSCLC. The estimated relationship for NSCLC suggested that each 3.3% increase in response rate correlated, on average, with a 1-week increase in median survival, and each 2% increase in response rate correlated, on average, with a 1% increase in 1-year survival. The mean increase in 1-year survival for trials of agents with at least a 20% response rate in NSCLC was 16%. Formulas are provided to help estimate how a given response rate may effect median and 1-year survival relative to best supportive care alone for NSCLC.\nQuestion: Are chemotherapy response rates related to treatment-induced survival prolongations in patients with advanced cancer?",
        "gt": "We found a relationship between response rate and both median and 1-year survival in NSCLC. This information may help oncologists estimate how an NSCLC chemotherapy regimen with a given response rate can, on average, impact survival relative to supportive care alone.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Increasing concentrations of N-(4-hydroxyphenyl) retinamide (4-HPR)-treatment pushed autophagy down to apoptosis in a dose-dependent manner, and 4-HPR-induced ROS contribute to this process. Since we found that ASK1-regulated JNK1 and p38 are responsible for 4-HPR-induced autophagy and apoptosis, respectively, we further utilized co-immunoprecipitation followed by liquid chromatography-tandem mass spectrometry analysis to identify proteins that specifically bind to ASK1 under different oxidative states. Of note, DJ-1, a crucial antioxidant protein, was identified. Interestingly, DJ-1 functions as a redox sensor that senses ROS levels and determines the cellular response to 4-HPR: Under mild oxidative stress, moderate oxidation of DJ-1 is recruited to inhibit the activity of ASK1 and maintain cell viability by activating autophagy; under a lethal level of oxidative stress, excessive oxidized DJ-1 dissociates from ASK1 and activates it, thereby initiating p38 activation and enabling the cells to commit to apoptosis. Moreover, the depletion of DJ-1 increases the sensitivity of tumor cells to 4-HPR both in vitro and in vivo. Our results reveal that the different oxidation states of DJ-1 function as a cellular redox sensor of ROS caused by 4-HPR and determine the cell fate of autophagy or apoptosis. Moreover, the results suggest that DJ-1 might be a potent therapeutic target for cancer treatment.\nQuestion: The oxidation states of DJ-1 dictate the cell fate in response to oxidative stress triggered by 4-hpr: autophagy or apoptosis?",
        "gt": "ROS-mediated changes in the oxidation state of DJ-1 are involved in 4-HPR's effect on pushing autophagy down to apoptosis. Consequently, this change mediates ASK1 activation by regulating DJ-1-ASK1 complex formation and determines the cell fate of autophagy or apoptosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Currently, hospital benchmarking organizations are often limited to short-term surgical quality comparisons among hospitals. The goal of this study was to determine whether long-term rates of incisional hernia repair after common abdominal operations could be used to compare hospital long-term surgical quality. This was a cohort study with up to 4 years of follow-up. Patients who underwent 1 of 5 common inpatient abdominal operations were identified in 2005-2008 American College of Surgeons NSQIP data linked to Medicare inpatient records. The main outcomes included occurrence of an incisional hernia repair. A multivariable, shared frailty Cox proportional hazards regression was used to compare each hospital's incisional hernia rate with the overall mean rate for all hospitals and control for American College of Surgeons NSQIP preoperative clinical variables. A total of 37,134 patients underwent 1 of 5 common inpatient abdominal operations, including colectomy, small bowel resection, ventral hernia repair, pancreatic resection, or cholecystectomy, at 1 of 216 hospitals participating in American College of Surgeons NSQIP during the 4-year period. There were 1,474 (4.0%) patients who underwent an incisional hernia repair, at a median follow-up time of 16 months (interquartile range 8 to 25 months) after initial abdominal surgery. After risk adjustment, there was no significant difference in the ratio of any one hospital's adjusted hazard rate for incisional hernia repair vs the average hospital adjusted hazard rate.\nQuestion: Is there hospital variation in long-term incisional hernia repair after abdominal surgery?",
        "gt": "Risk-adjusted hospital rates of incisional hernia repair do not vary significantly from the average. This suggests that incisional hernia repair might not be sensitive enough as a long-term quality metric for benchmarking hospital performance.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Transoesophageal echocardiography (TEE) is recommended prior to circumferential pulmonary vein ablation (CPVA) in patients with atrial fibrillation (AF) to identify left atrial (LA) or left atrial appendage (LAA) wall thrombi. It is not clear whether all patients undergoing CPVA should receive pre-procedural TEE. We wanted to assess the incidence of LA thrombus in these patients and to identify factors associated with its presence. Consecutive patients referred for CPVA from 2004 to 2009 underwent TEE within 48 h prior to the procedure. Of 408 patients included in the study, 6 patients (1.47%) had LA thrombi, persistent AF, and LA dilation. Compared with patients without thrombus, these six patients had larger LA diameter (P = 0.0001) and more frequently were women (P = 0.002), had persistent AF (P = 0.04), and had underlying structural cardiac disease (P = 0.014). The likelihood of presenting LA thrombus increased with the number of these four risk factors present (P<0.001). None of the patients with paroxysmal AF and without LA dilation had LA thrombus. A cut-off value of 48.5 mm LA diameter yielded 83% sensitivity, 92% specificity, and a 10.1 likelihood ratio to predict LA thrombus appearance.\nQuestion: Usefulness of transoesophageal echocardiography before circumferential pulmonary vein ablation in patients with atrial fibrillation: is it really mandatory?",
        "gt": "The incidence of LA thrombus prior to CPVA is low. Persistent AF, female sex, structural cardiopathy, and LA dilation were associated with the presence of LA thrombus. Our data suggest that the use of TEE prior to CPVA to detect LA thrombi might not be needed in patients with paroxysmal AF and no LA dilation or structural cardiopathy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To report treatment compliance, toxicity and clinical outcome of chemoradiotherapy (CRT) for anal carcinoma in HIV-negative vs. HIV-positive patients treated with highly active antiretroviral therapy. Between 1997 and 2008, 25 HIV-positive and 45 HIV-negative patients received CRT (50.4 Gy at 1.8 Gy/fraction plus 5.4-10.8 Gy boost; 5-fluorouracil, 1000 mg/m(2), Days 1-4 and 29-32, mitomycin C, 10 mg/m(2), Days 1 and 29). Median follow-up was 51 (range, 3-235) months. HIV-positive patients were significantly younger (mean age, 47 vs. 57 years, p<0.001) and predominantly male (92% vs. 29%, p<0.001). CRT could be completed in all patients with a reduction of chemotherapy and/or RT-interruption in 28% and 8%, respectively, in HIV-positive patients, and in 9% and 11%, respectively, in HIV-negative patients. Acute Grade 3/4-toxicity occurred in 44% vs. 49% (p=0.79). Initial complete response (84% vs. 93%, p=0.41), 5-year rates of local control (65% vs. 78%, p=0.44), cancer-specific (78% vs. 90%, p=0.17) and overall survival (71% vs. 77%, p=0.76) were not significantly different.\nQuestion: Concurrent chemoradiotherapy with 5-fluorouracil and mitomycin C for anal carcinoma: are there differences between HIV-positive and HIV-negative patients in the era of highly active antiretroviral therapy?",
        "gt": "HIV-positive patients with anal cancer can be treated with standard CRT, with the same tolerability and toxicity as HIV-negative patients. Long-term local control and survival rates are not significantly different between these groups.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the outcome of men presenting with lower urinary tract symptoms (LUTS) associated with large postvoid residual urine volumes (PVR). The study included men presenting with LUTS and a PVR of>250 mL who, because of significant comorbidity, a low symptom score or patient request, were managed conservatively and prospectively, and were followed with symptom assessment, serum creatinine levels, flow rates and renal ultrasonography. Patients were actively managed if there was a history of previous outflow tract surgery, prostate cancer, urethral strictures, neuropathy, elevated creatinine or hydronephrosis. In all, 93 men (mean age 70 years, range 40-84) with a median (range) PVR of 363 mL (250-700) were included in the study and followed for 5 (3-10) years. At presentation, the median maximum flow rate was 10.2 (3-30) mL/s and the voided volume 316 (89-714) mL. The measured PVR remained stable in 47 (51%), reduced in 27 (29%) and increased in 19 (20%) patients; 31 patients (33%) went on to transurethral resection of the prostate after a median of 30 (10-120) months, because of serum creatinine elevation (two), acute retention (seven), increasing PVR (eight) and worsening symptoms (14). Of 31 patients 25 were available for evaluation after surgery; their median PVR was 159 (0-1000) mL, flow rate 18.4 (4-37) mL/s and voided volume 321 (90-653) mL. Symptoms were improved in all but five men. There was no difference in initial flow rate, voided volume or PVR between those who developed complications or went on to surgery and those who did not. Urinary tract infections (UTIs) occurred in five patients and two developed bladder stones.\nQuestion: Is the conservative management of chronic retention in men ever justified?",
        "gt": "Complications such as renal failure, acute retention and UTIs are uncommon in men with large, chronic PVRs. Conservative management for this group of patients is reasonable but outpatient review is prudent. There were no factors that could be used to predict those patients who eventually required surgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: An in vivo sheep model was used to investigate the effect of spinal instrumentation on the healing process of posterolateral spinal fusion. To examine the role of spinal instrumentation during the healing process of posterolateral fusion. In long bone fractures, internal fixation improves the union rate but does not accelerate the healing process. Spinal instrumentation also improves the fusion rate in spinal arthrodesis. However, it remains unclear whether the use of spinal instrumentation expedites the healing process of spinal fusion. Sixteen sheep underwent posterolateral spinal arthrodeses at L2-L3 and L4-L5 using equal amounts of autologous bone. One of those segments was selected randomly to be augmented with transpedicular screw fixation (Texas Scottish Rite Hospital spinal system). The animals were killed at 8 weeks or 16 weeks after surgery. Fusion status was evaluated by biomechanical testing, manual palpation, plain radiography, computed tomography, and histology. Instrumented fusion segments demonstrated significantly higher stiffness than did uninstrumented fusions at 8 weeks after surgery. Radiographic assessment and manual palpation showed that the use of spinal instrumentation improved the fusion rate at 8 weeks (47% versus 38% in radiographs, 86% versus 57% in manual palpation). Histologically, the instrumented fusions consisted of more woven bone than the uninstrumented fusions at 8 weeks after surgery. The 16-week-old fusion mass was diagnosed biomechanically, radiographically, and histologically as solid, regardless of pedicle screw augmentation.\nQuestion: Does spinal instrumentation influence the healing process of posterolateral spinal fusion?",
        "gt": "The current study's results demonstrated that spinal instrumentation creates a stable mechanical environment to enhance the early bone healing of spinal fusion.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Measurement of Peak Nasal Inspiratory Flow (PNIF) seems to be a cheap and easily performed method to assess nasal patency. As demonstrated in a previous work, PNIF is influenced by SEX, AGE and HEIGHT. However there is a large degree of between-patient variability in PNIF levels. The purpose of this analysis is to determine whether the measurement of the pulmonary ventilatory capacity, by mean of Peak Expiratory Flow (PEF), enables more precise determination of PNIF. Repeated measurements of PNIF and PEF were performed in 112 volunteers. 100 of these fulfilled the study criteria (55 females and 45 males) and all of them were non-smokers, non-asthmatic, without nose and paranasal sinuses problems, with ages ranging from 15 to 71 years. Statistical analysis was undertaken to determine whether a relationship existed between PNIF and age, sex and height, but which also considered PEF. The data from both experiments were analysed together. In both groups there is a clear tendency for PNIF to increase with PEF. As clearly demonstrated in this work the value of PEF is informative in predicting PNIF and that the larger the value of PEF, the larger the value of PNIF.\nQuestion: Does peak nasal inspiratory flow relate to peak expiratory flow?",
        "gt": "PNIF is a useful method to study nasal patency in both primary and secondary care to aid diagnosis of nasal disease, but low values of PNIF have to be confirmed by a study of the PEF as PNIF low values may be an expression of low ventilatory activity rather than an expression of nasal obstruction.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cyclin E is a protein that plays a key role in the G1 -->S transition of the normal cell cycle. The product of retinoblastoma gene (pRb) is the master regulator of entry into the cell cycle and p21 protein is a cyclin-dependent kinase inhibitor that disturbs the progression through the cell cycle. The expression of these proteins, among many others, is being deregulated in tumorogenesis. The aim of this study was to investigate whether cyclin E, pRb, and p21 can be used as prognostic indicators in gastric cancer. Fifty-six patients with gastric adenocarcinoma, who underwent curative resection, constituted the group of our study. The immunohistochemical expression of cyclin E, pRb, and p21 proteins was examined and correlated with clinical-pathological parameters and survival. Positive cyclin E immunostaining was observed in 23 tumors (41.1%). It was associated with intestinal Lauren classification (P=0.003), nodal infiltration (P=0.0025), size of the tumor>5 cm (P=0.032), and lymphatic (P=0.042) and vascular invasion (P= 0.0029). Nevertheless, the survival of patients with positive cyclin E tumors was not significantly shorter than that of negative patients. Positive pRb immunostaining was found in 24 (42.9%) cases and it was associated with the absence of Helicobacter pylori (P=0.044), whereas positive p21 immunostaining was found in 21 tumors (37.5%) and it was associated with less depth of gastric wall infiltration (P=0.001), the absence of lymphatic (P=0.019) and vascular infiltration (P=0.024), and the absence of liver metastasis (P=0.044). Cyclin E expression was associated with pRb expression (P=0.023), but was correlated inversely with p21 expression (P=0.009). The survival of patients with pRb-positive tumors and the survival of patients with p21-positive tumors were significantly longer than that of negative patients (P= 0.0044 and P<0.001, respectively).\nQuestion: Does the expression of cyclin E, pRb, and p21 correlate with prognosis in gastric adenocarcinoma?",
        "gt": "The expression of cyclin E could not predict the survival in this series of patients with gastric cancer, whereas the expression of pRb and p21 was associated with a favorable prognosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: First-time pass rates on the American Board of Surgery Certifying Examination (ABSCE) have now become one of the standards of excellence to evaluate residency programs. Our residency program started monthly simulated and critiqued (verbal, written, and video) oral examinations (MSCE) in 2003. The current study explores the outcomes of this intervention. We evaluated ABSCE performance of 48 residents who graduated from a large academic/community program between the years 2001 and 2006 though a prospective study with historical controls. Residents were divided into 2 groups: The intervention group comprised the 2003 to 2006 classes, which underwent MSCE; the historical control group spanned the 2001 and 2002 classes, which did not undergo MSCE. Results in the ABSCE were compared between groups using the Fisher exact test. In addition, the intervention group was queried in relation to the most important aspects of the MSCE as a learning experience through a structured questionnaire. A statistically significant improvement (p = 0.038) in ABSCE first-time pass rates was noted in the intervention group. Examinees unanimously asserted they had been helped by the MSCE. Improvements in clinical reasoning and promotion of self-study were the most often cited benefits of the MSCE.\nQuestion: Improving outcomes on the ABS Certifying Examination: can monthly mock orals do it?",
        "gt": "Monthly simulated and critiqued oral examinations improved the first-time pass rate of the American Board of Surgery Certifying Examination. Additional perceived benefits of this intervention included improvements in clinical reasoning and promotion of self-study.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although disaster simulation trainings were widely used to test hospital disaster plans and train medical staff, the teaching performance of the instructors in disaster medicine training has never been evaluated. The aim of this study was to determine whether the performance indicators for measuring educational skill in disaster medicine training could indicate issues that needed improvement. The educational skills of 15 groups attending disaster medicine instructor courses were evaluated using 13 measurable performance indicators. The results of each indicator were scored at 0, 1 or 2 according to the teaching performance. The total summed scores ranged from 17 to 26 with a mean of 22.67. Three indicators: 'Design', 'Goal' and 'Target group' received the maximum scores. Indicators concerning running exercises had significantly lower scores as compared to others.\nQuestion: Can performance indicators be used for pedagogic purposes in disaster medicine training?",
        "gt": "Performance indicators could point out the weakness area of instructors' educational skills. Performance indicators can be used effectively for pedagogic purposes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Ureteral stents are used to reduce urologic complications after renal transplantation. However, they predispose to infection. The optimal time to keep them in the urinary tract has not yet been defined. The aim of this study was to evaluate the effect of early removal at the end of 2 weeks on urinary tract infections and early urologic complications (within 3 months), such as ureteroneocyctostomy leakage as well as ureteral anastomosis stricture or obstruction. We retrospectively analyzed the medical records of 48 patients who underwent renal transplantation using a ureteral stent. The patients were divided into two groups according to the time of stent removal: at the end of 2 weeks (group A; n = 10) versus at a later time (group B; n = 38). The urologic complication rate was 0% in group A and the urinary tract infection rate, 2%. The urologic complication rate was 0% in group B and the urinary tract infection rate, 35%.\nQuestion: Is removal of the stent at the end of 2 weeks helpful to reduce infectious or urologic complications after renal transplantation?",
        "gt": "Early removal of the stent at the end of 2 weeks after renal transplantation is decreased the rate of urinary tract infections.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to examine the relationship between the maternal level of antiphospholipid antibodies (aPA) measured by anticardiolipin antibodies (aCL) and fetal growth retardation (SGA). A nested case control design was carried out in a prospective cohort study of 1552 para I and para II women. The study group consisted of all 138 women who gave birth to a SGA-child (defined as birthweight<10th percentile). A control group of 276 women was randomly selected from mothers of non-SGA children. Levels of aPA were measured in banked sera drawn from the women in the 33rd week of pregnancy and compared between cases and controls. There were 3 (2.5%) sera with aPA above 97.5 percentile among the cases and 3 (1.2%) among the controls. This difference was not statistically significant.\nQuestion: Can maternal antiphospholipid antibodies predict the birth of a small-for-gestational age child?",
        "gt": "Antiphospholipid antibody measurements obtained at 33 weeks of gestation cannot be used to assess the risk of birth of a small for gestational age infant among parous women.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether three-dimensional conformal partial breast irradiation (3D-PBI) spares lung tissue compared with whole breast irradiation (WBI) and to include the biologically equivalent dose (BED) to account for differences in fractionation. Radiotherapy treatment plans were devised for WBI and 3D-PBI for 25 consecutive patients randomized on the NSABP B-39/RTOG 0413 protocol at Mayo Clinic in Jacksonville, Florida. WBI plans were for 50 Gy in 25 fractions, and 3D-PBI plans were for 38.5 Gy in 10 fractions. Volume of ipsilateral lung receiving 2.5, 5, 10, and 20 Gy was recorded for each plan. The linear quadratic equation was used to calculate the corresponding dose delivered in 10 fractions and volume of ipsilateral lung receiving these doses was recorded for PBI plans. Ipsilateral mean lung dose was recorded for each plan and converted to BED. There was a significant decrease in volume of lung receiving 20 Gy with PBI (median, 4.4% vs. 7.5%; p<0.001), which remained after correction for fractionation (median, 5.6% vs. 7.5%; p = 0.02). Mean lung dose was lower for PBI (median, 3.46 Gy vs. 4.57 Gy; p = 0.005), although this difference lost significance after conversion to BED (median, 3.86 Gy(3) vs 4.85 Gy(3), p = 0.07). PBI plans exposed more lung to 2.5 and 5 Gy.\nQuestion: Does three-dimensional external beam partial breast irradiation spare lung tissue compared with standard whole breast irradiation?",
        "gt": "3D-PBI exposes greater volumes of lung tissue to low doses of radiation and spares the amount of lung receiving higher doses when compared with WBI.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cytoblocks (CBs), or cell blocks, provide additional morphological detail and a platform for immunocytochemistry (ICC) in cytopathology. The Cellient(\u2122) system produces CBs in 45\u00a0minutes using methanol fixation, compared with traditional CBs, which require overnight formalin fixation. This study compares Cellient and traditional CB methods in terms of cellularity, morphology and immunoreactivity, evaluates the potential to add formalin fixation to the Cellient method for ICC studies and determines the optimal sectioning depth for maximal cellularity in Cellient CBs. One hundred and sixty CBs were prepared from 40 cytology samples (32 malignant, eight benign) using four processing methods: (A) traditional; (B) Cellient (methanol fixation); (C) Cellient using additional formalin fixation for 30\u00a0minutes; (D) Cellient using additional formalin fixation for 60\u00a0minutes. Haematoxylin and eosin-stained sections were assessed for cellularity and morphology. ICC was assessed on 14 cases with a panel of antibodies. Three additional Cellient samples were serially sectioned to determine the optimal sectioning depth. Scoring was performed by two independent, blinded reviewers. For malignant cases, morphology was superior with Cellient relative to traditional CBs (P\u00a0<\u00a00.001). Cellularity was comparable across all methods. ICC was excellent in all groups and the addition of formalin at any stage during the Cellient process did not influence the staining quality. Serial sectioning through Cellient CBs showed optimum cellularity at 30-40\u00a0\u03bcm with at least 27 sections obtainable.\nQuestion: Automated Cellient(\u2122) cytoblocks: better, stronger, faster?",
        "gt": "Cellient CBs provide superior morphology to traditional CBs and, if required, formalin fixation may be added to the Cellient process for ICC. Optimal Cellient CB cellularity is achieved at 30-40\u00a0\u03bcm, which will impact on the handling of cases in daily practice.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Different surgical techniques for pilonidal disease have been described in the literature. In this study, our aim was to evaluate the influence of routine cavity drainage in the Karydakis flap technique. As much as 50 male patients with pilonidal sinus who underwent the Karydakis flap operation were evaluated prospectively.The patients were assigned randomly into two groups (Group 1 with suction drain; Group 2 fibrin glue). Fluid collection was encountered in 8 out of 50 patients (6.25%): 6 in Group 2 (24%) of which 4 experienced superficial, healed with simple dressing, the other 2 with substantial dehiscence healed with wound dressing; 2 in Group 1 (8%) were treated with wound punctures.There has been no recurrence in any of the patients during the follow-up period.The Karydakis flap operations can be performed with a near zero recurrence rate with the use of drains.\nQuestion: Are postoperative drains necessary with the Karydakis flap for treatment of pilonidal sinus?",
        "gt": "We recommend the use of fibrin sealant with Karydakis flap procedure, but further studies are needed to confirm this conclusion.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Preoperative core needle biopsies may increase the risk of surgical site infection (SSI) in breast cancer surgery. The purpose of this randomized trial was to determine whether a prophylactic antibiotic would prevent SSI under these conditions. Imaging-guided multiple core needle biopsies were performed one to two weeks prior to surgery to obtain confirmation of the presence of breast cancer. Then the patients were randomized to receive either a single intravenous dose of 1.0 g of dicloxacillin (n = 144) or placebo infusion of saline (n = 148) 30 min prior to operation. After breast surgery, incisional morbidity was monitored for 30 days. The number of SSIs was compared with that in 672 patients treated before the implementation of core needle biopsies. The patient characteristics and risk factors for SSI were similar in the antibiotic prophylaxis and placebo groups. The incidence of SSI was 7.2% (21/292) in the prospective trial compared with 6.8% (46/672) in the retrospective cohort (p = 0.890). The incidence of postoperative SSIs was 5.6% (8/144) in the dicloxacillin group and 8.8% (13/148) in the placebo group (p = 0.371). For the first two weeks, there was a non-significant trend to fewer SSIs in the antibiotic group (n = 1) than the placebo group (n = 4). Body mass index, smoking, or previous illness did not affect the likelihood of SSI.\nQuestion: Does preoperative core needle biopsy increase surgical site infections in breast cancer surgery?",
        "gt": "Core needle biopsy did not increase the incidence of SSI. Antibiotic prophylaxis did not prevent SSI, probably because so few infections occurred.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: An institutional ethical review board approved the case-control study carried out at the Gazi University, Faculty of Dentistry, Turkey. A total of 80 patients with traumatic dental injuries and 80 patients with other dental problems participated in the study. Patients' parents filled in two scales: Conners' Rating Scales-Revised Attention Deficiency Hyperactive Disorder-Index, Oppositional Behavior, Hyperactivity, Anxious-Shy, Social Problems, Inattentive and Hyperactive-Impulsive subscales; and Emotion Regulation Checklist, with two subscales of Emotional Lability and Emotion Regulation. Multiple logistic regression analyses were performed separately for male and female patients. Oppositional behaviour, hyperactivity and social problems were found to be risk factors for male patients. Being anxious/shy was the protective factor for both males and females. Classification accuracy for males and females were calculated to be 79.2% and 85.2% respectively.\nQuestion: Are behaviour risk factors for traumatic dental injuries in childhood different between males and females?",
        "gt": "Several risk factors for childhood traumatic dental injuries were found to differ for male and female patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Statins have a well-established role in prevention of vascular events but are associated with muscle-related adverse events. The dose relationship with these adverse events is unclear. We present an original analysis of Canadian and US case reports of statin-associated rhabdomyolysis with a focus on dose response. A typical clinical case is also summarized. All cases of statin-associated rhabdomyolysis reported to Health Canada's Canadian Vigilance Program and to the US Food and Drug Administration's Adverse Event Reporting System from 2004-2008 were analyzed by severity and dose equivalence. Canadian national statin utilization data from 2002-2007 were used to estimate the dose-related incidence of rhabdomyolysis corrected for levels of utilization. The clinical case illustrates well the potential severity of statin-induced rhabdomyolysis. Combined Canadian/US data revealed an average of 812 cases of statin-induced rhabdomyolysis reported annually with a mean patient age of 64.4 years (35.5% female). The worst outcomes reported were renal dysfunction in 17.0%, acute renal failure in 19.8%, dialysis in 5.2%, and death in 7.6%. Using 10 mg atorvastatin per day as the reference dose, the odds ratios of rhabdomyolysis were 3.8 (95% CI 2.3-6.6) for 40 mg/day atorvastatin dose equivalent and 11.3 (95% CI 6.4-20.4) for 80 mg/day atorvastatin dose equivalent.\nQuestion: Statin-associated rhabdomyolysis: is there a dose-response relationship?",
        "gt": "The results of our adverse drug analysis suggest a dose-response relationship. Given the widespread use of statins, the ability to predict which patients will experience serious muscle-related harm is a research priority.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Issues around end-of-life health care have attracted increasing attention in the last decade. One question that has arisen is whether very elderly individuals receive overly aggressive treatment at the end of life. The purpose of this study was to address this issue by examining whether health care use at the end life varies by age. The study included all adults 65 years old or older who died in Manitoba, Canada in 2000 (N = 7678). Measures were derived from administrative data files and included location of death, hospitalizations, intensive care unit (ICU) admission, long-term care (LTC) use, physician visits, and prescription drug use in the last 30 days versus 180 days before death, respectively. Individuals 85 years old or older had increased odds of being in a LTC institution and also dying there than did individuals 65-74 years old. They had, correspondingly, lower odds of being hospitalized and being admitted to an ICU. Although some statistically significant age differences emerged for physician visits, the effects were small. Prescription drug use did not vary by age.\nQuestion: Health care use at the end of life among older adults: does it vary by age?",
        "gt": "These findings indicate that very elderly individuals tended to receive care within LTC settings, with care that might be considered aggressive declining with increasing age. However, health care use among all age groups was substantial. A critical issue that needs to be examined in future research is how to ensure quality end-of-life care in a variety of clinical contexts and care settings for individuals of all ages.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There are many risk classification schemes that determine both treatment and outcome for patients with papillary thyroid cancer. Most of these formulas often utilize tumor size as the key predictor of outcome. Furthermore, there is no clear consensus regarding the treatment of small papillary cancers. Therefore, we reviewed our experience in order to determine which factors best predict outcome for papillary thyroid cancer. In addition, we sought to establish a tumor size threshold beyond which papillary cancers require treatment. From May 1994 to October 2004, 174 patients underwent surgery for papillary thyroid cancer (PTC) at our institution. These patients were divided into five groups based on tumor size. The data from these groups were analyzed utilizing ANOVA, Chi-square and linear regression analysis. The mean age of the patients was 42 +/- 1 years and 126 (72%) were female. Mean tumor size was 17.2 +/- 1.1 mm. The overall outcome was quite good with a survival rate of 97% and a recurrence rate of 12%. On univariate analysis, there was no difference amongst the groups in regards to age or gender. However, there was a significantly higher incidence of lymph node metastasis amongst those with the largest tumors. Consequently, those patients with the largest tumors were treated more aggressively, with 75% undergoing total thyroidectomies and 85% receiving radioactive iodine therapy. However, on univariate and multivariate analysis, tumor size was not shown to correlate with higher recurrence. Rather, the only factor associated with a greater recurrence rate was the presence of lymph node metastases.\nQuestion: Is tumor size the best predictor of outcome for papillary thyroid cancer?",
        "gt": "At our institution, the recurrence rates for PTC were similar for all sizes of tumors. Furthermore, presence of metastatic disease at the time of diagnosis, rather than tumor size, seems to be a better predictor of recurrence and outcome.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We conducted a community-based study to determine the relationship among night-time frequency, sleep disturbance and general health-related quality of life (GHQL). A total of 2271 participants, men and women, aged 41-70 and randomly selected in three Japanese towns completed a postal questionnaire survey. This questionnaire included: the International Prostate Symptom Score, the overall incontinence score of the International Consultation of Incontinence Questionnaire Short Form for lower urinary tract symptoms, the Pittsburg Sleep Quality Index for sleep problems, the Medical Outcome Study Short Form-8 for GHQL, and medical history of disease, cigarette smoking, and alcohol consumption. A multiple regression model was used for statistical analysis, and P<0.05 was considered significant. Although night-time frequency by itself was closely associated with most aspects of GHQL, this association disappeared in four domains (general health perception, vitality, mental health and emotional role) and in the two summary scores of the Medical Outcome Study Short Form-8 after inclusion of the influence of sleep problems represented by the total score on the Pittsburg Sleep Quality Index. However, three domains (physical function, physical role, and social function) remained significantly associated with night-time frequency. Sleep problems were by far the worst risk factor for the deterioration of GHQL.\nQuestion: Night-time frequency, sleep disturbance and general health-related quality of life: is there a relation?",
        "gt": "Night-time frequency appeared to be associated with GHQL mainly by affecting sleep conditions, a symptom that independently influenced some aspects of GHQL.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Studies of the protective effect of breastfeeding on asthma have not brought unequivocal results, and thus this issue remains controversial. Antibiotic use, known to increase asthma risk, may be involved in this relationship. The objective of this study was to assess the influence of breastfeeding duration on obesity and asthma risk in childhood and to test a mediating role of antibiotic use in infancy. A cross-sectional anthropometric and questionnaire study was conducted on 1,277 schoolchildren 8 years of age. Data on weight status, asthma, breastfeeding duration, antibiotic administration in infancy, socioeconomic status, and lifestyle were analyzed. Multivariate standard and logistic regression and mediation analyses, controlling for confounders, were applied. Total duration of breastfeeding was negatively related to the child's body mass index (p=0.038), fat percentage (p=0.030), and obesity risk (p=0.032). Dropping the variable of antibiotic use from the model made the breastfeeding duration a significant predictor of low asthma risk (p=0.027). Antibiotic treatment mediated the relationship between breastfeeding duration and asthma risk (Sobel's z=-2.61, p=0.009).\nQuestion: Is the Relationship Between Breastfeeding and Childhood Risk of Asthma and Obesity Mediated by Infant Antibiotic Treatment?",
        "gt": "Our findings support protective effects of longer duration of breastfeeding against obesity and asthma. We propose a new mechanism for a relationship between breastfeeding and asthma: shorter breastfeeding compromises infant health and thereby leads to antibiotic treatment, which in turn increases the risk of asthma.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The presence of posttraumatic stress disorder (PTSD) in trauma survivors has been linked with family dysfunction and symptoms in their children, including lower self-esteem, higher disorder rates and symptoms resembling those of the traumatized parent. This study aims to examine the phenomenon of intergenerational transfer of PTSD in an Australian context. 50 children (aged 16-30) of 50 male Vietnam veterans, subgrouped according to their fathers' PTSD status, were compared with an age-matched group of 33 civilian peers. Participants completed questionnaires with measures of self-esteem, PTSD symptomatology and family functioning. Contrary to expectations, no significant differences were found between the self-esteem and PTSD symptomatology scores for any offspring groups. Unhealthy family functioning is the area in which the effect of the veteran's PTSD appears to manifest itself, particularly the inability of the family both to experience appropriate emotional responses and to solve problems effectively within and outside the family unit.\nQuestion: The adjustment of children of Australian Vietnam veterans: is there evidence for the transgenerational transmission of the effects of war-related trauma?",
        "gt": "Methodological refinements and further focus on the role of wives/mothers in buffering the impact of veterans' PTSD symptomatology on their children are indicated. Further effort to support families of Veterans with PTSD is also indicated.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the effect of a humidity detector device on the quality of life of patients with urinary incontinence IU. Quasi-experimental study: a series of ten cases followed for a month. The devices were placed and the questionnaires filled in before and after using it for at least ten hours a day during a month. Health related quality of life was assessed through the questionnaires for IU convalidated and adapted to our specific environment: Urogenital Inventory Distress (UDI) and Incontinence Impact Questionary (IIQ). An improvement of 58 points by a four option Likert scale was considered a positive impact in the quality of life (IIQ). The scores obtained in UDI and IIQ are described before and after use the device and paried T test and Wilcoxon sign test were carried out to compare the scores obtained in each instance. The capacity to detect a difference of 58 points on the UDI scale was calculated (minimum relevant difference). A binomial test was undertaken to ascertain a probability of achieving an increase in the above mentioned index which would exceed the clinical relevance threshold. Average increase in IIQ improvement: x = 5.48 (Std Error = 20.43) 95% CI = -34.56 to 45.56. Average increase in UDI improvement: x = -11.87 (Std Error = 20.70) 95% IC = -52.45 to 28.70. The power of the analysis to detect as relevant a difference of a 588 point increase in IIQ 71.1% and probability of obtaining a relevant improvement in the questionnaire IIQ 10% (IC 95%) 0% to 39.4%.\nQuestion: Do the incontinent patients improve their equality of life using a humidity detector device?",
        "gt": "A negative impact in the Quality of Life due to frequent changes of incontinence pads.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Inguinal hernia repair, hydrocelectomy, and orchidopexy are commonly performed surgical procedures in children. Postoperative pain control is usually provided with a single-shot caudal block. Blockade of the ilioinguinal nerve may lead to additional analgesia. The aim of this double-blind, randomized controlled trial was to evaluate the efficacy of an adjuvant blockade of the ilioinguinal nerve using ultrasound (US) guidance at the end of the procedure with local anesthetic vs normal saline and to explore the potential for prolongation of analgesia with decreased need for postoperative pain medication. Fifty children ages 1-6 years scheduled for unilateral inguinal hernia repair, hydrocelectomy, orchidopexy, or orchiectomy were prospectively randomized into one of two groups: Group S that received an US-guided ilioinguinal nerve block with 0.1 ml x kg(-1) of preservative-free normal saline and Group B that received an US-guided nerve block with 0.1 ml x kg(-1) of 0.25% bupivacaine with 1 : 200,000 epinephrine at the conclusion of the surgery. After induction of anesthesia but prior to surgical incision, all patients received caudal anesthesia with 0.7 ml x kg(-1) of 0.125% bupivacaine with 1 : 200,000 epinephrine. Patients were observed by a blinded observer for (i) pain scores using the Children and Infants Postoperative Pain Scale, (ii) need for rescue medication in the PACU, (iii) need for oral pain medications given by the parents at home. Forty-eight patients, consisting of 46 males and two females, with a mean age of 3.98 (SD +/- 1.88) were enrolled in the study. Two patients were excluded from the study because of study protocol violation and/or alteration in surgical procedure. The average pain scores reported for the entire duration spent in the recovery room for the caudal and caudal/ilioinguinal block groups were 1.92 (SD +/- 1.59) and 1.18 (SD +/- 1.31), respectively. The average pain score difference was 0.72 (SD +/- 0.58) and was statistically significant (P<0.05). In addition, when examined by procedure type, it was found that the difference in the average pain scores between the caudal and caudal/ilioinguinal block groups was statistically significant for the inguinal hernia repair patients (P<0.05) but not for the other groin surgery patients (P = 0.13). For all groin surgery patients, six of the 23 patients in the caudal group and eight of the 25 patients in the caudal/ilioinguinal block group required pain rescue medications throughout their entire hospital stay or at home (P = 0.76). Overall, the caudal group received an average of 0.54 (SD +/- 1.14) pain rescue medication doses, while the caudal/ilioinguinal block group received an average of 0.77 (SD +/- 1.70) pain rescue medication doses; this was, however, not statistically significant (P = 0.58).\nQuestion: Unilateral groin surgery in children: will the addition of an ultrasound-guided ilioinguinal nerve block enhance the duration of analgesia of a single-shot caudal block?",
        "gt": "The addition of an US-guided ilioinguinal nerve block to a single-shot caudal block decreases the severity of pain experienced by pediatric groin surgery patients. The decrease in pain scores were particularly pronounced in inguinal hernia repair patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Despite the development of new surgical techniques, the fascial sling procedure remains an important surgical technique for the treatment of female urinary stress incontinence. An advantage of combining it with an additional Burch colposuspension has been suggested. The objective of our study was to evaluate retrospectively selected patients who had undergone a fascial sling procedure with and without Burch colposuspension. Of a total of 390 females who underwent an incontinence operation at our department between 1990 and 1999, 56 patients had had a fascial sling plasty. A total of 50 patients (89 %) were followed for a median of 59.5 months. The median age was 60 years. 56 % of the patients displayed recurrent stress incontinence. The previous operations had been performed via a vaginal approach in 42.9 % and an abdominal approach in 57.1 %. The sling procedure used was that of Narik and Palmrich. Of the 50 patients, 14 had an additional Burch colposuspension. The continence rates (no pads) were for patients with a fascial sling procedure alone 63.9 % and for the combination of both operations 64.4 %. An improvement (1-3 pads) was seen in 27.8 % and 21.4 %, respectively. No changes were seen in 5.6 % and 7.1 % and impairment was seen in 2.7 % and 7.1 %, respectively. After a five-year follow-up, the total patient satisfaction rate was 78 %.\nQuestion: Does a Combined Fascial Sling - Burch Colposuspension Display Advantages over a Fascial Sling alone for Treatment of Urinary Stress Incontinence in Females?",
        "gt": "The fascial sling is effective operative technique for treating female urinary stress incontinence, especially in severe and type III incontinence and in patients who had undergone previous operations for incontinence. The operation is safe and is the only technique that offers controlled overcorrection in desperate cases. An advantage of adding a Burch colposuspension to the fascial sling procedure was not detected in our patient group.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Studies have reported associations between mortality and air pollution, but questions subsist on the identification of susceptible subgroups in the population. We studied individual characteristics that modify the relationship between particulate air pollution and mortality among elderly. We examined 527 nonaccidental deaths (197 cardiorespiratory deaths) among the 1469 subjects from the Personnes Agees QUID cohort in Bordeaux between 1988 and 1997. Air pollution was measured as black smoke by urban monitoring background stations. We used a case crossover approach and calculated odds ratio by conditional logistic regression models. We observed associations between the third lag day and cardiorespiratory mortality for an increase of 10 microg/m3 of black smoke (odds ratio = 1.30, 95% confidence interval: 1.01-1.68).\nQuestion: Do subject characteristics modify the effects of particulate air pollution on daily mortality among the elderly?",
        "gt": "Our results provide insight into factors possibly conferring susceptibility to the acute effect of urban air pollution.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Annual trends in the rate of utilisation of PHI in three different clinical categories were compared with published trends in PHI membership to assess the degree to which PHI membership predicts PHI use in Western Australia. The WA Data Linkage System was used to extract all hospital morbidity records in Western Australia from 1981 to 2001. The adjusted annual incidence rate ratio of hospitalisation as a privately insured patient versus a public (Medicare) patient was estimated using Poisson regression in each clinical category across three age groups in each year. The rate ratios were graphed as segmented trend lines and compared with published data for trends in PHI membership. The most significant changes in the use of PHI versus the public system occurred between 1981 and 1984 overall clinical categories. These changes were consistent with those documented for PHI membership. From 1992 onwards, significant changes in the trend were observed in the surgical clinical category, compared with the medical and obstetric clinical categories. Further, the trend observed in the surgical clinical category at this time was inconsistent with that documented for PHI membership. Between 2000 and 2001, only the surgical clinical category showed a similar change in trend as that documented for PHI membership.\nQuestion: Do marginal changes in PHI membership accurately predict marginal changes in PHI use in Western Australia?",
        "gt": "Between 1981 and 1991 the timing and direction of changes in PHI membership were found to be congruent with that of PHI use in all three clinical categories. However, between 2000 and 2001 trends in PHI membership were only congruent with trends in PHI use in the surgical clinical category. We conclude that investigating marginal changes in PHI membership represents an incomplete method for assessing the effectiveness of policies aimed at reducing the pressure on the public system.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Percutaneous transluminal treatment of a thrombotic vein graft yields poor results. We have previously reported our experience with transluminal percutaneous coronary ultrasound thrombolysis (CUT) in the setting of acute myocardial infarction (AMI). This report describes the first experience with ultrasound thrombolysis in thrombus-rich lesions in saphenous vein grafts (SVGs), most of which were occluded. The patients (n=20) were mostly male (85%), aged 64+/-4 years old. The presenting symptom was AMI in 2 patients (10%) and unstable angina in the rest. Fifteen patients (75%) had totally occluded SVGs. The median age of clots was 6 days (range, 0 to 100 days). The ultrasound thrombolysis device has a 1.6-mm-long tip and fits into a 7F guiding catheter over a 0.014-in guidewire in a \"rapid-exchange\" system. CUT (41 kHz, 18 W,</=6 minutes) led to device success in 14 (70%) of the patients and residual stenosis of 65+/-28%. Procedural success was obtained in 13 (65%) of the patients, with a final residual stenosis of 5+/-8%. There was a low rate of device-related adverse events: 1 patient (5%) had a non-Q-wave myocardial infarction, and distal embolization was noted in 1 patient (5%). Adjunct PTCA or stenting was used in all patients. There were no serious adverse events during hospitalization.\nQuestion: Percutaneous transluminal therapy of occluded saphenous vein grafts: can the challenge be met with ultrasound thrombolysis?",
        "gt": "Ultrasound thrombolysis in thrombus-rich lesions in SVGs offers a very promising therapeutic option.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine the necessity and adequacy of basic science training for urologic oncology training programs. Evaluated whether urology physician scientists are adequately trained in the basic sciences. The current urologic oncology training system does not adequately train physician scientists. We propose a major reform to define, train, and maintain the urology physician scientists.\nQuestion: The hybrid of basic science and clinical training for the urologic oncologist: Necessity or waste?",
        "gt": "Urology physician scientists have played a major role in advancement of urologic oncology. Major reform is necessary, if we wish to continue to successfully train urologic oncology physician scientists.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We assessed whether testicular growth arrest is related to varicocele size in adolescents. We also determined whether adolescents with a varicocele and testes of equal size treated nonoperatively are at significant risk for growth arrest and, if so, whether this risk is related to varicocele size. We retrospectively reviewed the records of boys with a varicocele. Testis volume was measured with calipers and computed into cc as (length x width x breadth) x 0.521. Testicular growth arrest was defined as left testis at least 15% smaller than the right testis. Varicocele size was graded 1-barely palpable, 2-palpable but not visible, 3a-visible and, 1 to 1.5 times the size of the ipsilateral testis, 3b-1.5 to 2 times the size of the ipsilateral testis and 3c-greater than 2 times the size of the ipsilateral testis. Boys with a grade 1 varicocele and those treated with previous inguinal or testicular surgery were excluded from study. Repair was recommended for testicular growth arrest or discomfort. Data were analyzed with chi-square and Fisher's exact test. The records of 124 boys 7 to 18 years old (mean age 13) with a varicocele were reviewed. Seven patients were excluded from analysis, yielding a total of 117 boys. Testicular growth arrest was observed at initial visit in 10 of 33 (30.3%) grade 2, 18 of 37 (48.6%) grade 3a, 14 of 31 (45.2%) grade 3b and 6 of 16 (37.5%) grade 3c cases (p not significant), or a total of 38 of 84 (45.2%) grade 3 cases (p<0.01) plus grade 2. Followup ranged from 1 to 5 years. Of the cases of equal sized testes at presentation growth arrest was observed in 3 of 16 (18.8%) grade 2, 2 of 11 (18.2%) grade 3a, 4 of 14 (28.6%) grade 3b and 3 of 9 (33.3%) grade 3c (p not significant), or a total of 9 of 34 (26.5%) grade 3 cases (p not significant) plus grade 2. Overall, testicular growth arrest was found in 13 of 33 (39%) grade 2 and 47 of 84 (56%) grade 3 varicoceles (p<0.01).\nQuestion: Testicular growth arrest and adolescent varicocele: does varicocele size make a difference?",
        "gt": "Boys with a varicocele are at significant risk for testicular growth arrest, irrespective of varicocele size, and those with a grade 3 varicocele have a higher risk of testicular growth arrest than those with a grade 2 varicocele. Of boys with testes of equal size at diagnosis growth arrest is observed during adolescence in approximately 25% irrespective of varicocele size.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Roux-en-Y gastric bypass (RYGBP) either laparoscopic or open has been increasingly employed in the treatment of patients with morbid obesity. Laparoscopic approach is believed to be superior over open approach in terms of shorter hospital stay and easier recovery. We aimed to assess feasibility and safety of open RYGBP with short stay in comparison with laparoscopic RYGBP. One hundred and ninety consecutive patients were assigned to open (n=103) or laparoscopic (n=87) RYGBP. The first 20 patients of the laparoscopic arm were excluded due to procedure learning curve. Patients were treated by a multidisciplinary team focused on successfully RYGBP with short stay (1 day). Short stay was reached by 90% of patients operated with open approach and 81% by laparoscopy (P=0.070). Discharge in the second day was reached by 97% of patients in both groups. Procedure length [(median (IQR)] was faster for open RYGBP [103 (70-180 min) vs. 169 (105-248 min); P<0.0001]. Thirty-day readmission rate was similar between groups (3% vs. 7%; P=0.266). There was no death in either group.\nQuestion: Hospital discharge in the day following open Roux-en-Y gastric bypass: is it feasible and safe?",
        "gt": "Short stay (1 day) following open gastric bypass was a feasible and safe procedure. This approach might have economic impact and might increase patient acceptance for open RYGBP.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate trends in the provision of mental health services and financing in Brazil. Data from DATASUS (the Brazilian Unified Health Computerized System) with free access in the web were collected regarding the number of beds, the development of new community centers, the number of mental health professionals, and costs involved from 1995 to 2005. In ten years, the number of psychiatric beds decreased 41% (5.4 to 3.2 per 10,000 inhabitants) while community services have increased nine-fold (0.004 to 0.037 per 10,000 inhabitants). Psychologists and social workers have accounted for three and two-fold, respectively, as much hirings as psychiatrists. Psychiatric admissions accounted for 95.5% of the budget in 1995 and 49% in 2005, and the expenses with community services and medication have increased 15% each. As a whole, the expenses in mental health decreased by 26.7% (2.66 to 1.95 US$ per capita).\nQuestion: Is psychiatric reform a strategy for reducing the mental health budget?",
        "gt": "There has been a clear switch from hospital to community psychiatric care in Brazil, where the system can now provide a diversity of treatments and free access to psychotropics. However, the coverage of community services is precarious, and the reform was not accompanied by an increased public investment in mental health. The psychiatric reform is not a strategy for reducing costs; it necessarily implies increasing investments if countries decide to have a better care of those more disadvantaged.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Chronic calcineurin inhibitor (CNI) nephrotoxicity is associated with histologic kidney lesions, but the contribution of maintenance-dose CNI use to the decline over time in glomerular filtration rate (GFR) post liver transplantation (OLT) remains unclear. We studied annual changes in estimated GFR>1 year posttransplant among 105 CNI-treated adult OLT patients with a GFR of 60-100 mL/min at 1 year during a mean follow-up of 7 years (20 years in 20 patients). The annual GFR decline>1 year posttransplant was 0.2 mL/min per year (SD 3.8). This decline rate was unaffected by the decade of OLT, follow-up period, or GFR at 1 year, and showed no correlation with CNI blood levels. Of the 13 (12%) patients with a GFR deterioration>3 mL/min per year, 77% presented with hypertension, diabetes, and/or dyslipidemia. The decline in GFR>1 year post-OLT did not exceed the decline of 0.5-0.8 mL/min per year reported in the general population. Declines faster than 3 mL/min per year, which occurred no more frequently among patients than in the general population, seemed attributable to coexistent vascular risk factors.\nQuestion: Long-term renal function deteriorates at a similar rate among liver transplant patients with preserved renal function at 1 year and in the general population: is chronic calcineurin inhibitor nephrotoxicity overrated?",
        "gt": "Among OLT patients with preserved renal function at 1 year posttransplant, our findings challenge the clinical impact of chronic progressive CNI nephrotoxicity and highlight the importance of a tight control of blood pressures, glucose and lipid levels, and other modifiable risk factors in order to preserve long-term renal function.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Acromegaly is characterized not only by disabling symptoms, but also by relevant co-morbidities. Insulin resistance, leading to glucose intolerance is one of the most important contributory factors to the cardiovascular mortality in acromegaly. We analysed the records of 220 na\u00efve patients with acromegaly diagnosed at our Department in the years 1995-2007. Diagnosis of active acromegaly was established on the basis of widely recognized criteria. In each patient glucose and insulin concentrations were assessed when fasting and during the 75 g OGTT. Normoglycaemia existed in 46% of acromegalic patients. Among glucose tolerance abnormalities we found impaired fasting glucose in 19%, impaired glucose tolerance in 15% and overt diabetes mellitus in 20%. There was no statistically significant differences in gender, duration of the disease, basal plasma GH, IGF-1 or fasting insulin concentrations between normoglycaemic patients and those with impairments in glucose tolerance. The groups showed statistically significant differences with respect to age at diagnosis (p<0.01). There was no significant correlation between GH, IGF-1 concentrations and fasting plasma glucose. There was no correlation between the duration of the disease and fasting plasma glucose. We found a statistically significant correlation between plasma GH, IGF-1 concentrations and HOMA, QUICKI and insulinAUC.\nQuestion: Abnormalities in glucose homeostasis in acromegaly. Does the prevalence of glucose intolerance depend on the level of activity of the disease and the duration of the symptoms?",
        "gt": "The prevalence of diabetes mellitus among acromegalics is much higher than in the general population. The occurrence of glucose tolerance impairments does not depend on the duration of the disease. In patients with acromegaly insulin resistance and hyperinsulinemia are positively correlated with the level of activity of the disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Childhood-onset schizophrenia (COS) is a severe form of the adult-onset disorder with a high rate of premorbid developmental abnormalities. Early symptoms of pervasive developmental disorder (PDD) have been reported in five independent studies of COS. In this study, we compared evidence for premorbid PDD as a nonspecific manifestation of impaired neurodevelopment seen in schizophrenia, or as an independent risk factor for COS. Diagnosis of past or current autism or PDD was made according to the DSM-IV criteria. COS patients with and without PDD were compared with respect to neuropsychological, clinical, and neurobiological measures. Several candidate genes for autism were examined in the entire COS sample and the subgroup with PDD using the Transmission Disequilibrium Test (TDT) and Quantitative TDT (QTDT). Nineteen (25%) of COS probands had a lifetime diagnosis of PDD: one met criteria for autism, two for Asperger's disorder, and 16 for PDD not otherwise specified. Premorbid social impairment was most common feature for COS-PDD subjects. The PDD group did not differ from the rest of the COS sample with respect to age of onset, IQ, response to medications, and rate of familial schizotypy. Unexpectedly, two siblings of COS-PDD probands met criteria for nuclear autism. There was no difference between PDD and non-PDD groups with respect to initial brain magnetic resonance imaging (MRI) measures. However, rate of gray matter loss was greater for PDD (n = 12) than for the non-PDD (n = 27) subgroup (-19.5 +/- 11.3 mL/year vs. -9.6 +/- 15.3 mL/year; p =.05). None of eight candidate genes for autism were associated with COS or COS-PDD.\nQuestion: Pervasive developmental disorder and childhood-onset schizophrenia: comorbid disorder or a phenotypic variant of a very early onset illness?",
        "gt": "Premorbid PDD in COS is more likely to be a nonspecific marker of severe early abnormal neurodevelopment. However, the occurrence of two siblings of COS-PDD probands (17%) with nuclear autism remains to be understood.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Obese and morbidly obese patients undergoing lumbar spinal fusion surgery are a challenge to the operating surgeon. Minimally invasive transforaminal lumbar interbody fusion (MIS-TLIF) and open-TLIF have been performed for many years with good results; however, functional outcomes after lumbar spine surgery in this subgroup of patients remain poorly understood. Furthermore, whether index MIS-TLIF or open-TLIF for the treatment of degenerative disc disease or spondylolisthesis in morbidly obese results in superior postoperative functional outcomes remains unknown. A total of 148 (MIS-TLIF: n\u00a0= 40, open-TLIF: n\u00a0= 108) obese and morbidly obese patients undergoing index lumbar arthrodesis for low back pain and/or radiculopathy between January 2003 and December 2010 were selected from a multi-institutional prospective data registry. We collected and analyzed data on patient demographics, postoperative complications, back pain, leg pain, and functional disability over 2 years. Patients completed the Oswestry Disability Index (ODI), Medical Outcomes Study Short-Form 36 (SF-36), and back and leg pain numerical rating scores before surgery and then at 12 and 24 months after surgery. Clinical outcomes and complication rates were compared between both patient cohorts. Compared with preoperative status, Visual Analog Scale (VAS) back and leg pain, ODI, and SF-36 physical component score/mental component score were improved in both groups. Both MIS-TLIF and open-TLIF patients showed similar 2-year improvement in VAS for back pain (MIS-TLIF: 2.42 \u00b1 3.81 vs. open-TLIF: 2.33 \u00b1 3.67, P\u00a0= 0.89), VAS for leg pain (MIS-TLIF: 3.77 \u00b1 4.53 vs. open-TLIF: 2.67 \u00b1 4.10, P\u00a0= 0.18), ODI (MIS-TLIF: 11.61 \u00b1 25.52 vs. open-TLIF: 14.88 \u00b1 22.07, P\u00a0= 0.47), and SF-36 physical component score (MIS-TLIF: 8.61 \u00b1 17.72 vs. open-TLIF: 7.61 \u00b1 15.55, P\u00a0= 0.93), and SF-36 mental component score (MIS-TLIF: 4.35 \u00b1 22.71 vs. open-TLIF: 5.96 \u00b1 21.09, P\u00a0= 0.69). Postoperative complications rates between both cohorts were also not significantly divergent between (12.50% vs. 11.11%, P\u00a0= 0.51).\nQuestion: A prospective, multi-institutional comparative effectiveness study of lumbar spine surgery in morbidly obese patients: does minimally invasive transforaminal lumbar interbody fusion result in superior outcomes?",
        "gt": "MIS-TLIF is a safe and viable option for lumbar fusion in morbidly obese patients and, compared with open-TLIF, resulted in similar improvement in pain and functional disability. Postoperative complications rates between both cohorts were also not significantly divergent.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Until recently, liver transplantation (Ltx) was the only available treatment for hereditary transthyretin (TTR) amyloidosis; today, however, several pharmacotherapies are tested. Herein, we present survival data from the largest available database on transplanted hereditary TTR patients to serve as a base for comparison. Liver transplantation was evaluated in a 20-year retrospective analysis of the Familial Amyloidosis Polyneuropathy World Transplant Registry. From April 1990 until December 2010, data were accumulated from 77 liver transplant centers. The Registry contains 1940 patients, and 1379 are alive. Eighty-eight Ltx were performed in combination with a heart and/or kidney transplantation. Overall, 20-year survival after Ltx was 55.3%. Multivariate analysis revealed modified body mass index, early onset of disease (<50 years of age), disease duration before Ltx, and TTR Val30Met versus non-TTR Val30Met mutations as independent significant survival factors. Early-onset patients had an expected mortality rate of 38% that of the late-onset group (P<0.001). Furthermore, Val30Met patients had an expected mortality rate of 61% that of non-TTR Val30Met patients (P<0.001). With each year of duration of disease before Ltx, expected mortality increased by 11% (P<0.001). With each 100-unit increase in modified body mass index at Ltx, the expected mortality decreased to 89% of the expected mortality (P<0.001). Cardiovascular death was markedly more common than that observed in patients undergoing Ltx for end-stage liver disease.\nQuestion: Liver Transplantation for Hereditary Transthyretin Amyloidosis: After 20 Years Still the Best Therapeutic Alternative?",
        "gt": "Long-term survival after Ltx, especially for early-onset TTR Val30Met patients, is excellent. The risk of delaying Ltx by testing alternative treatments, especially in early-onset TTR Val30Met patients, requires consideration.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This is a population-based study for which 1,414 diabetics were recruited. The fundi were photographed using 45-degree 4-field stereoscopic digital photography. The diagnosis of DR was based on Klein's classification of the Early Treatment Diabetic Retinopathy Study scales. The prevalence of DR was 33.3% (95% confidence interval, CI: 26.6-39.9) in known onset of diabetes (\u2264 40 years) compared to 15.6% (95% CI: 13.6-17.6) in those with late onset (>40 years; p<0.0001). In the group with age of known onset of diabetes \u2264 40 years, the risk factors, associated with any DR, were poor glycemic control (odds ratio, OR: 1.36 for every g% increase in glycosylated hemoglobin), insulin use (OR: 4.21), increasing known duration of diabetes (OR: 1.10 for increase of every year in known duration of diabetes) and presence of macroalbuminuria (OR: 13.39). In the late onset of diabetes group, besides the above-mentioned risk factors, the presence of microalbuminuria (OR: 2.08), male gender (OR: 1.67), presence of anemia (OR: 1.89) and increased systolic blood pressure (OR: 1.01) were the risk factors for DR.\nQuestion: Is prevalence of retinopathy related to the age of onset of diabetes?",
        "gt": "The prevalence of DR was almost twice more in those subjects who developed diabetes before the age of 40 years than those who developed it later.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Functional MRI (fMRI) of default mode network (DMN) brain activity during resting state is gaining attention as a potential non-invasive biomarker to diagnose incipient Alzheimer's disease. The aim of this study was to identify effects of normal aging on the DMN using different methods of fMRI processing and evaluation. fMRI was acquired in 17 young and 21 old healthy subjects and the data were analyzed with (a) volumes of interest (VOI)-based signal time course and (b) independent component analyses (ICA). In the first approach, the strength of DMN region inter-connectivity (as expressed with correlation coefficients) was of primary interest, the second method provided a measure of the magnitude of DMN co-activation. The older subjects exhibited significantly lower DMN activity in the posterior cingulate (PCC, t-test P<.001) as well as a tendency to lower activity in all other DMN regions in comparison to the younger subjects. We found no significant effect of age on DMN inter-connectivity.\nQuestion: Effects of aging on default mode network activity in resting state fMRI: does the method of analysis matter?",
        "gt": "Effects of normal aging such as loss of PCC co-activity could be detected by ICA, but not by signal time course correlation analyses of DMN inter-connectivity. This either indicates lower sensitivity of inter-connectivity measures to detect subtle DMN changes or indicate that ICA and time course analyses determine different properties of DMN co-activation. Our results, therefore, provide fundamental knowledge for a potential future use of functional MRI as biomarker for neurodegenerative dementias where diminished DMN activity needs to be reliably differentiated from that observed in health aging.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Because of the penetrating ability of the radiation used in nuclear medicine, metallic lead is widely used as radiation shielding. However, this shielding may present an insidious health hazard because of the dust that is readily removed from the surfaces of lead objects. The lead dust may become airborne, contaminate floors and other nearby surfaces, and be inadvertently inhaled or ingested by patients. We determined if the quantity of lead dust encountered within nuclear medicine departments exceeded Environmental Protection Agency (EPA) standards. For lead dust quantification, professional lead test kits were used to sample fifteen 1-ft(2) sections of different surfaces within the department. Four samples were collected once per week from each site. The samples were then submitted to a National Lead Laboratory-accredited program for a total lead measurement. Lead contamination (mug/ft(2)) for each of the 60 samples was compared with the EPA standards for lead dust. Lead contamination was present at 6 of the 15 sites, and of 60 samples, 18 exceeded the EPA standard of 50 mug/ft(2).\nQuestion: Is lead dust within nuclear medicine departments a hazard to pediatric patients?",
        "gt": "Lead contamination is present within nuclear medicine departments, and corrective measures should be considered when dealing with pediatric patients. A larger series needs to be conducted to confirm these findings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The evidence supporting the survival benefit of multiple arterial grafts in the general coronary bypass surgery (CABG) population is compelling. Alternatively, results of studies comparing 2 versus 1 internal thoracic artery (ITA) grafts in diabetics have reported conflicting survival data. The use of radial versus ITA as the second arterial conduit has not been studied. We obtained complete death follow-up in 1516 consecutive diabetic [64+/-10 years (mean+/-SD). Insulin/no insulin: There were 540 (36%)/976 (64%)] primary isolated CABG patients all with>or=1 ITA grafts. The series included 626 ITA/radial (41%) and 890 ITA/vein (59%) patients. Using separate radial-use propensity models, we matched one-to-one 475 (76%) ITA/radial to 475 (53%) unique ITA/vein patients; each including 166 insulin and 309 no insulin patients. Unadjusted survival was markedly better for (1) ITA/radial (94.3%, 86.7% and 70.4% at 1, 5 and 10 years, respectively) versus ITA/vein (91.8%, 74.5% and 53.8%; p<0.0001) and (2) for no insulin (94.2%, 82.8% and 65.5%) versus insulin (90.4%, 73.1% and 49.2%; p<0.0001). In matched patients, 11-year Kaplan-Meier analysis showed essentially identical ITA/radial and ITA/vein survival for all diabetics combined (p=0.53; log rank) and for the no insulin (p=0.76) cohort. Lastly, a trend for better ITA/radial survival in insulin dependent diabetics after the second postoperative year did not reach significance (p=0.13).\nQuestion: Does radial use as a second arterial conduit for coronary artery bypass grafting improve long-term outcomes in diabetics?",
        "gt": "Using radial as a second arterial conduit as opposed to vein grafting did not confer a survival benefit in diabetics. This unexpected result is perhaps related to relatively diminished radial graft patency and/or the augmented radial vasoreactivity characteristic of diabetics. These findings indicate that the radial survival advantage demonstrated in the general CABG population lies primarily in non-diabetics in whom this advantage may be underestimated.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We examined the changes of mean platelet volume (MPV) and platelet distribution width (PDW) in subjects with appendicitis and whether MPV and PDW could be used to predict the development of complication due to appendicitis. The healthy control group, the cases of appendicitis with perforation, and the cases of appendicitis without perforation were compared with regard to MPV and PDW. We determined whether MPV and PDW were independent variables predictive of the development of complication in subjects with appendicitis. This retrospective case-control study included a total of 362 patients (249 of which were male (68.8\u2009%) and 113 were female (31.2\u2009%); median age, 30 [range, 18-84 years]). One hundred and ninety-two subjects (53\u2009%) presented with appendicitis and 170 (47\u2009%) comprised the healthy control group. Sixty-six (18.2\u2009%) of the subjects with appendicitis developed complication. MPVs were lower in subjects of appendicitis without complication compared to the subjects of appendicitis with complication and the control group (MPV, 9.78\u2009\u00b1\u20090.99 vs. 10.20\u2009\u00b1\u20091.21 and 10.14\u2009\u00b1\u20091.03, respectively [p\u2009=\u20090.005]). The PDW levels were not different between the three groups. Independent variables predictive of the presence of complication included increased MPV and time from onset of symptoms to hospital presentation (odds ratio[confidence interval], p-value: 1.507[1.064-2.133], 0.021 and 18.887[5.139-69.410], 0.0001, respectively).\nQuestion: Can platelet indices be used as predictors of complication in subjects with appendicitis?",
        "gt": "Our findings suggested these, MPV values in cases of appendicitis without complication were lower than the cases with complication and healthy control and MPV is a predictor of the development of complication in subjects with appendicitis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Prenatal smoking is robustly associated with increased risk of conduct problems in offspring. Observational studies that provide detailed phenotypic description are critical for generating testable hypotheses about underlying processes through which the effects of prenatal smoking may operate. To this end, we use a developmental framework to examine the association of exposure with (1) oppositional defiant disorder and attention-deficit/hyperactivity disorder in young boys and (2) the pattern of delinquent behavior at adolescence. Using diagnostic measures and repeated measures of delinquency, we compare exposed and nonexposed boys from the youngest cohort of the Pittsburgh Youth Study (N = 448). Exposed boys were significantly more likely to (1) develop oppositional defiant disorder and comorbid oppositional defiant disorder-attention-deficit/hyperactivity disorder but not attention-deficit/hyperactivity disorder alone and (2) to have an earlier onset of significant delinquent behavior.\nQuestion: Is prenatal smoking associated with a developmental pattern of conduct problems in young boys?",
        "gt": "The early emergence and developmental coherence of exposure-related conduct problems is striking and is consistent with a behavioral teratological model. Phenotypically, exposure-related conduct problems appear to be characterized by socially resistant and impulsively aggressive behavior. Whether prenatal smoking plays an etiological role in or is a risk marker for the development of conduct problems, exposed offspring are at increased risk of an early-starter pathway to conduct problems.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Most of the studies on cardiovascular disease (CVD) risk factors in menopause have focused on serum lipid(lipoprotein) abnormalities and were conducted in populations which were not well controlled for several important influential factors. Two homogenous groups of 30 apparently healthy Caucasian premenopausal women and 3-5 years postmenopausal women who were nonobese, nonsmoking and not using estrogen were compared in a well-controlled cross-sectional design. Fasting serum ferritin and plasma total homocysteine (tHcy) were evaluated concomitantly to classical serum lipid(lipoprotein) risk factors. Relationships between risk factors and the influence of other contributing variables such as diet and body weight were also examined. Serum total cholesterol (p<0.01), low-density lipoproteins (LDL; p<0.05) and triglycerides (p<0.05) of postmenopausal women were greater than that of their menstruating counterparts, even though they ate a CVD-preventive diet, had similar body weight and body fat distribution. Their serum ferritin was almost 3-fold greater (p<0.0001) but was still within normal limits, except for the 38.5% of postmenopausal women who exhibited values above the 80 mug/l limit that has been associated with sharp increases in the rate of heart disease in either gender. Serum ferritin was low in one third of the postmenopausal group (as low as in the premenopausal control group, whose dietary iron intake was slightly below the nutritional recommendation). The mean plasma tHcy of the postmenopausal group was almost twice as elevated (p<0.0001). Both ferritin and tHcy were found to be linked to serum cholesterol. The correlation between tHcy and triglycerides was also significant.\nQuestion: Is serum ferritin an additional cardiovascular risk factor for all postmenopausal women?",
        "gt": "Early menopause is not associated with blood iron overload and CVD risk factor in an important proportion of women.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The Active Healthy Kids the Netherlands (AHKN) Report Card consolidates and translates research and assesses how the Netherlands is being responsible in providing physical activity (PA) opportunities for children and youth (<18 years). The primary aim of this article is to summarize the results of the 2016 AHKN Report Card. Nine indicators were graded using the Active Healthy Kids Global Alliance report card development process, which includes a synthesis of the best available research, surveillance, policy and practice findings, and expert consensus. Grades assigned were: Overall Physical Activity Levels, D; Organized Sport Participation, B; Active Play, B; Active Transportation, A; Sedentary Behaviors, C; Family and Peers, B; School, C; Community and the Built Environment, A; Government Strategies and Investments, INC.\nQuestion: Is our Youth Cycling to Health?",
        "gt": "Sedentary behavior and overall PA levels are not meeting current guidelines. However, the Dutch youth behaviors in sports, active transportation, and active play are satisfactory. Several modifiable factors of influence might be enhanced to improve these indicators or at least prevent regression. Although Dutch children accumulate a lot of daily PA through cycling, it is not enough to meet the current national PA guidelines of 60 minutes of moderate-to-vigorous PA per day.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: As our healthcare system moves toward bundling payments, orthopaedic trauma surgeons will be increasingly benchmarked on perioperative complications. We therefore sought to determine financial risks under bundled payments by identifying adverse event rates for (1) orthopaedic trauma patients compared with general orthopaedic patients and (2) based on anatomic region and (3) to identify patient factors associated with complications. Prospective. Multicenter.PATIENTS/ A total of 146,773 orthopaedic patients (22,361 trauma) from 2005 to 2011 NSQIP data were identified. Minor and major adverse events, demographics, surgical variables, and patient comorbidities were collected. Multivariate regressions determined significant risk factors for the development of complications. The complication rate in the trauma group was 11.4% (2554/22,361) versus 4.1% (5137/124,412) in the general orthopaedic group (P = 0.001). When controlling for all variables, trauma was a risk factor for developing complications [odds ratio (OR): 1.69, 95% confidence interval (CI): 1.57-1.81]. After controlling for several patient factors, hip and pelvis patients were 4 times more likely to develop any perioperative complication than upper extremity patients (OR: 3.79, 95% CI: 3.01-4.79, P = 0.01). Lower extremity patients are 3 times more likely to develop any complication versus upper extremity patients (OR: 2.82, 95% CI: 2.30-3.46, P = 0.01).\nQuestion: Adverse Events in Orthopaedics: Is Trauma More Risky?",
        "gt": "Our study is the first to show that orthopaedic trauma patients are 2 times more likely than general orthopaedic patients to sustain complications, despite controlling for identical risk factors. There is also an alarming difference in complication rates among anatomic regions. Orthopaedic trauma surgeons will face increased financial risk with bundled payments.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Whether the isolated VSD (i-VSD) is associated with aneuploidy to the same degree as a more severe heart anomaly is unclear. Our objective was to determine the likelihood of aneuploidy in pregnancies at a tertiary referral center when an i-VSD is detected before 24 weeks. A retrospective chart review of all detailed anatomy ultrasounds before 24 weeks performed at the University of Kansas Medical Center from 08/23/2006 to 06/07/2012 was conducted. A complete evaluation of the fetal heart was accomplished using gray scale and spectral/color Doppler examinations. The outcomes of each pregnancy were reviewed for any diagnoses of aneuploidy. Odds ratios were calculated. A total of 4078 pregnancies with complete obstetric and neonatal data were reviewed. The prevalence of an i-VSD was 2.7% (112/4078). The odds ratio of aneuploidy when an i-VSD was present was (OR: 36.0, 95% CI: 5.0, 258.1). This odds ratio remained large when either an abnormal or unknown serum screen was present.\nQuestion: Is an isolated ventricular septal defect detected before 24 weeks on ultrasound associated with fetal aneuploidy?",
        "gt": "The presence of an i-VSD present before 24 weeks does increase the risk of fetal aneuploidy. Whether a normal serum screen or first trimester screen for aneuploidy negates the association of an i-VSD with aneuploidy still remains undetermined.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Prior studies have shown that age \u226570 years is associated with more aggressive non-endometrioid histology and worse survival in endometrial cancer. The purpose of this study is to assess if age is an independent poor prognostic factor in endometrioid histologies. Under an IRB-approved protocol, we identified patients with surgical stage I to II endometrioid endometrial adenocarcinoma from 1995 to 2008 at two institutions. Patients were divided into two groups based on age at diagnosis: Group A (age 50-69 years) and Group B (age\u226570 years). All patients underwent hysterectomy, bilateral salpingoophorectomy, +/-pelvic/aortic lymphadenectomy and adjuvant therapy. Prognostic factors were evaluated by univariate and multivariate analyses. We identified 338 patients with stage IA to IIB endometrioid endometrial adenocarcinoma. The median age in Group A was 59 years (range 50-69) and Group B was 75 years (range 70-92). Patients in Group B were more likely to have hypertension (51% vs. 68%, p=0.006) and coronary artery disease (9% vs. 18%, p=0.03). There were no differences in progression-free or disease-specific survival, however, Group B had a worse overall survival (OS) (50.1 vs. 62.6 months, p=0.03). On univariate analysis, age (p=0.04), grade (p=0.006), and coronary artery disease (p=0.01) were associated with worse OS. After adjusting for grade and coronary artery disease, age was no longer a significant variable for OS (p=0.17).\nQuestion: Is older age a poor prognostic factor in stage I and II endometrioid endometrial adenocarcinoma?",
        "gt": "After adjusting for other poor prognostic factors, age \u226570 years alone may not be a significant variable affecting overall survival in patients with early stage endometrioid endometrial adenocarcinoma.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Despite significant risk for venous thromboembolism, severely injured trauma patients often are not candidates for prophylaxis or treatment with anticoagulation. Long-term inferior vena cava (IVC) filters are associated with increased risk of postphlebitic syndrome. Retrievable IVC filters potentially offer a better solution, but only if the filter is removed; our hypothesis is that the most of them are not. This retrospective study queried a level I trauma registry for IVC filter insertion from September 1997 through June 2004. One IVC filter was placed before the availability of retrievable filters in 2001. Since 2001, 27 filters have been placed, indicating a change in practice patterns. Filters were placed for prophylaxis (n = 11) or for therapy in patients with pulmonary embolism or deep vein thrombosis (n = 17). Of 23 temporary filters, only 8 (35%) were removed.\nQuestion: Are temporary inferior vena cava filters really temporary?",
        "gt": "Surgeons must critically evaluate indications for IVC filter insertion, develop standard criteria for placement, and implement protocols to ensure timely removal of temporary IVC filters.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It would be interesting to the emergency doctor to have at his disposal a helpful diagnostic tool like brain natriuretic peptide (BNP). Such assay is simple, available and reliable. To report our experience on the role of BNP in the etiological diagnosis of acute dyspnea (AD) in emergency room (ER) and to assess the cost-effectiveness ratio of such diagnosis strategy. A prospective study conducted in the ER of Rabta university teaching hospital of Tunis, from March 1st to June 20th 2010, involving 30 consecutive patients presenting to the emergency for AD. All patients underwent echocardiography in their acute phase and benefited from the dosage of BNP during the first 4 hours. The echocardiography parameters were collected by a single operator who was unaware of the results of the BNP dosage. The mean age of patients was 72.8years with a sex ratio of 1.5. AD was of orthopnea type in 9 cases and stage III NYHA dyspnea in the other patients. Clinical and radiological signs of left heart failure were noted in 30% of cases. Ultrasound data have objectified systolic dysfunction in 4 cases, diastolic in 3 cases and systolic plus diastolic in 10 cases. The BNP levels were below 100 pg/ml in 10 cases with pulmonary origin of the AD. A BNP level between 100 and 400 pg/ml was noted in 3 cases. In our study, the clinical probability of AHF prior to performing the test was estimated at 53% and estimated at 100% after the BNP assay. The BNP assay has reduced the length of stay in the emergency department 4 to 5 days and saved nearly 50% of the cost of care per patient.\nQuestion: Is BNP assay useful for the diagnosis of acute dyspnea in emergencies departments?",
        "gt": "The BNP assay, has allowed us to confirm the AHF all cases. Given the prognostic value and economic benefit of this test we recommend its use in ER of our country.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Histology has been identified as an important prognostic factor in Hodgkin's disease (HD) in adults. Information regarding the impact of histology on outcome in childhood HD is scarce. This study determines the effect of histology on the overall survival (OS) or progression-free survival (PFS) in a national series of children treated in a standardized manner. The results of treatment of 331 assessable patients, treated between January 1, 1982 and June 30, 1992, in the United Kingdom Children's Cancer Study Group (UKCCSG) Hodgkin's study I were reviewed to evaluate OS, PFS, and deaths according to stage and histology. Treatment was either involved-field radiation alone (stage IA) or chlorambucil, vinblastine, procarbazine, and prednisolone (ChlVPP) chemotherapy with or without mediastinal radiation. All were clinically staged at diagnosis. Nodular sclerosing (NS) HD was the most common histologic subtype (155 of 331 patients [47%]) and was uniformly distributed through all stages. Lymphocyte-depletion (LD) HD was extremely uncommon (<1%). Mixed-cellularity (MC) HD had the highest relapse rate, but this was only significant (P<.05) in stage I patients who received local irradiation alone. There was no other statistically significant difference in OS and PFS between the various histologic subtypes. Multivariate analysis for PFS and OS confirmed that stage was the most important prognostic factor and that histology did not have an effect after stratification by stage.\nQuestion: Does histology influence outcome in childhood Hodgkin's disease?",
        "gt": "This study demonstrates that with effective multiagent chemotherapy, histologic subtype does not influence outcome. The high relapse rates in stage I MC subtype indicates that MC HD is biologically aggressive and systemic treatment with or without local irradiation may be indicated. The high relapse rate in stage IV patients appeared to be independent of histology.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Macrophage death in advanced lesion has been confirmed to play an important role in plaque instability. However, the mechanism underlying lesion macrophage death still remains largely unknown. Immunohistochemistry showed that caspase-1 activated in advanced lesion and co-located with macrophages and TUNEL positive reaction. In in-vitro experiments showed that ox-LDL induced caspase-1 activation and this activation was required for ox-LDL induced macrophages lysis, IL-1\u03b2 and IL-18 production as well as DNA fragmentation. Mechanism experiments showed that CD36 and NLRP3/caspase-1/pathway involved in ox-LDL induced macrophage pyroptosis.\nQuestion: Oxidized low density lipoprotein induced caspase-1 mediated pyroptotic cell death in macrophages: implication in lesion instability?",
        "gt": "Our study here identified a novel cell death, pyroptosis in ox-LDL induced human macrophage, which may be implicated in lesion macrophages death and play an important role in lesion instability.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The objective of this study was to quantify the effects of radiation-induced cancer risks in patients with Bosniak category IIF lesions undergoing CT versus MRI surveillance. We developed a Markov-Monte Carlo model to determine life expectancy losses attributable to radiation-induced cancers in hypothetical patients undergoing CT versus MRI surveillance of Bosniak IIF lesions. Our model tracked hypothetical patients as they underwent imaging surveillance for up to 5 years, accounting for potential lesion progression and treatment. Estimates of radiation-induced cancer mortality were generated using a published organ-specific radiation-risk model based on Biological Effects of Ionizing Radiation VII methods. The model also incorporated surgical mortality and renal cancer-specific mortality. Our primary outcome was life expectancy loss attributable to radiation-induced cancers. A sensitivity analysis was performed to assess the stability of the results with variability in key parameters. The mean number of examinations per patient was 6.3. In the base case, assuming 13 mSv per multiphase CT examination, 64-year-old men experienced an average life expectancy decrease of 5.5 days attributable to radiation-induced cancers from CT; 64-year-old women experienced a corresponding life expectancy loss of 6.9 days. The results were most sensitive to patient age: Life expectancy loss attributable to radiation-induced cancers increased to 21.6 days in 20-year-old women and 20.0 days in 20-year-old men. Varied assumptions of each modality's (CT vs MRI) depiction of lesion complexity also impacted life expectancy losses.\nQuestion: Microsimulation model of CT versus MRI surveillance of Bosniak IIF renal cystic lesions: should effects of radiation exposure affect selection of imaging strategy?",
        "gt": "Microsimulation modeling shows that radiation-induced cancer risks from CT surveillance for Bosniak IIF lesions minimally affect life expectancy. However, as progressively younger patients are considered, increasing radiation risks merit stronger consideration of MRI surveillance.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The vast majority of pancreatic cancers occurs sporadically. The discovery of frequent variations in germline gene copy number can significantly influence the expression levels of genes that predispose to pancreatic adenocarcinoma. We prospectively investigated whether patients with sporadic pancreatic adenocarcinoma share specific gene copy number variations (CNVs) in their germline DNA. DNA samples were analyzed from peripheral leukocytes from 72 patients with a diagnosis of sporadic pancreatic adenocarcinoma and from 60 controls using Affymetrix 500K array set. Multiplex ligation-dependent probe amplification (MLPA) assay was performed using a set of self-designed MLPA probes specific for seven target sequences. We identified a CNV-containing DNA region associated with pancreatic cancer risk. This region shows a deletion of 1 allele in 36 of the 72 analyzed patients but in none of the controls. This region is of particular interest since it contains the YTHDC2 gene encoding for a putative DNA/RNA helicase, such protein being frequently involved in cancer susceptibility. Interestingly, 82.6% of Sicilian patients showed germline loss of one allele.\nQuestion: Germline copy number variation in the YTHDC2 gene: does it have a role in finding a novel potential molecular target involved in pancreatic adenocarcinoma susceptibility?",
        "gt": "Our results suggest that the YTHDC2 gene could be a potential candidate for pancreatic cancer susceptibility and a useful marker for early detection as well as for the development of possible new therapeutic strategies.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The relationship between the use of alcohol and aggression is complex and represents major public health issues. Delving into the nature of this association is vital, since various underlying factors may contribute to the expression of aggression. This study examined trait aggression by assessing correlates and, subsequently, the unique contribution of alcohol craving, and dysfunctional impulsivity, by means of correlational and mediational analyses. Forty inpatient detoxified alcohol-dependent patients were recruited. These participants completed the Desire for Alcohol Questionnaire (DAQ), Dickman Impulsivity Inventory (DII), and the Aggression Questionnaire (AQ). The findings indicated that aggression, dysfunctional impulsivity, and alcohol craving were all positively intercorrelated. The association between dysfunctional impulsivity and aggression was robust. The mediational analyses yielded that craving partially mediated this relationship, although not very substantial.\nQuestion: Does alcohol craving mediate the impulsivity-aggression relationship in recently detoxified alcohol-dependent patients?",
        "gt": "It was shown that impulsivity, as a personality characteristic, is strongly associated with aggressive behaviors, whereby the impact of craving on the relationship between impulsivity and trait aggression in alcohol-dependent inpatients was weak.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Homocystinuria due to cystathionine beta-synthase deficiency and familial hypercholesterolemia are inherited disorders of metabolism that are associated with premature development of cardiovascular disease. This study addresses the possibility that different patterns of carotid wall damage and cerebral blood flow hemodynamics are present in these two metabolic diseases. Twelve patients with homocystinuria due to cystathionine beta-synthase deficiency (mean age, 24 years), 10 patients with homozygous familial hypercholesterolemia (mean age, 26 years), and 11 healthy control subjects (mean age, 26 years) underwent a vascular examination by noninvasive methods. B-mode ultrasound imaging was used to obtain measurements of intima-media thickness of common carotid, bifurcation, and internal carotid arteries as an index of atherosclerosis. Cerebral blood flow velocity was estimated from vascular examination of the middle cerebral artery by transcranial Doppler. Systolic, diastolic, and mean velocities were measured. Pulsatility index, a possible indicator of vascular resistance in the cerebral circulation, was also calculated. Mean maximum intima-media thickness was 1.4 mm in patients with familial hypercholesterolemia, 0.6 mm in patients with homocystinuria, and 0.6 mm in control subjects. The difference between hypercholesterolemic and homocystinuric patients or control subjects was statistically significant (P<.001). Diastolic blood flow velocities were significantly reduced in the middle cerebral arteries of hypercholesterolemic patients compared with homocystinuric patients or control subjects (P<.05), whereas systolic or mean velocities did not differ. The pulsatility index, a possible indicator of vascular resistance in the cerebral circulation, was significantly higher in hypercholesterolemic patients compared with homocystinuric patients or healthy control subjects (P<.01). A direct relation was demonstrated between pulsatility index of the middle cerebral artery and mean maximum intima-media thickness of carotid arteries on the same side (P<.001).\nQuestion: Premature carotid atherosclerosis: does it occur in both familial hypercholesterolemia and homocystinuria?",
        "gt": "Familial hypercholesterolemia is responsible for diffuse and focal thickening of carotid arteries and possibly also for hyperlipidemic endothelial dysfunction extending to small resistance arteries and leading to a disturbed cerebral blood flow. Patients with homocystinuria due to homozygosis for cystathionine beta-synthase deficiency seldom have plaques in their carotid arteries. They are similar to healthy control subjects with regard to both intima-media thickness and blood flow velocity in the middle cerebral artery. Therefore, it is unlikely that typical atherosclerotic lesions precede thrombotic events in homocystinuria. However, it is possible that arterial dilatations caused by medial damage lead to thrombosis in homocystinuric patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess whether pleural fluid analysis (PFA) can confidently diagnose tuberculous pleural effusion (TPE). PFA of 548 TPEs was performed between January 1991 and December 2011. The control group consisted of patients with malignant PE (MPE), complicated parapneumonic/empyema (infectious) PE (IPE), miscellaneous PE (MisPE) and transudative PE (TrPE). The PFA of 548 histologically or culture-positive consecutive cases of TPE was compared with that of 158 consecutive cases of MPE, 113 cases of IPE, 37 cases of MisPE and 115 cases of TrPE. Statistically significant differences were noted in pleural fluid glucose, pH, cholesterol, triglycerides, adenosine deaminase (ADA), and total percentages of lymphocytes, neutrophils and macrophages when TPEs were compared to all other groups. Of the TPEs, 99.1% were exudates. Pleural fluid protein \u2265 5.0 g/dl, lymphocytes>80% and ADA>45 U/l were diagnostic of TPE, with a specificity of 100%, a sensitivity of 34.9% and an area under the curve of 0.975.\nQuestion: Can tuberculous pleural effusions be diagnosed by pleural fluid analysis alone?",
        "gt": "PFA alone was diagnostic in one third of the TPE cases, with a high probability in nearly 60%.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Urinalysis is the third major test in clinical laboratory. Manual technique imprecision urges the need for a rapid reliable automated test. We evaluated the H800-FUSIOO automatic urine sediment analyzer and compared it to the manual urinalysis technique to determine if it may be a competitive substitute in laboratories of central hospitals. 1000 urine samples were examined by the two methods in parallel. Agreement, precision, carryover, drift, sensitivity, specificity, and practicability criteria were tested. Agreement ranged from excellent to good for all urine semi-quantitative components (K>0.4, p = 0.000), except for granular casts (K = 0.317, p = 0.000). Specific gravity results correlated well between the two methods (r = 0.884, p = 0.000). RBCS and WBCs showed moderate correlation (r = 0.42, p = 0.000) and (r = 0.44, p = 0.000), respectively. The auto-analyzer's within-run precision was>75% for all semi-quantitative components except for proteins (50% precision). This finding in addition to the granular casts poor agreement indicate the necessity of operator interference at the critical cutoff values. As regards quantitative contents, RBCs showed a mean of 69.8 +/- 3.95, C.V. = 5.7, WBCs showed a mean of 38.9 +/- 1.9, C.V. = 4.9). Specific gravity, pH, microalbumin, and creatinine also showed good precision results with C.Vs of 0.000, 2.6, 9.1, and 0.00 respectively. In the between run precision, positive control showed good precision (C.V. = 2.9), while negative control's C.V. was strikingly high (C.V. = 127). Carryover and drift studies were satisfactory. Manual examination of inter-observer results showed major discrepancies (<60% similar readings), while intra-observer's results correlated well with each other (r = 0.99, p = 0.000).\nQuestion: Urinalysis: The Automated Versus Manual Techniques; Is It Time To Change?",
        "gt": "Automation of urinalysis decreases observer-associated variation and offers prompt competitive results when standardized for screening away from the borderline cutoffs.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study was aimed at exploring to what extent populations enrolled in randomized controlled trials (RCTs) of inhalation combination treatment for mild/moderate asthma in adults are fully representative of 'real-life' populations. The following is a retrospective analysis of the clinical records of outpatient subjects with an ascertained diagnosis of asthma. A retrospective analysis was performed. Stable conditions, such as smoking habit and chronic diseases other than asthma, were identified as exclusion criteria for RCTs. The selected criteria were then applied to asthmatic outpatients, yielding a population that was potentially eligible for RCTs. Out of 1,909 subjects, 824 (43.2%) met at least one of the exclusion criteria for RCTs. Cigarette smoking (occurring in 34.3% of the entire population), lung diseases other than asthma (5.0%), anxiety and depression (3.3%), arrhythmias (2.3%), and coronary artery disease (1.2%) would have been the most frequent causes for exclusion from RCTs. The proportion of patients excluded from RCTs appears to increase with age, reaching 57.1% in patients aged>85 years.\nQuestion: Are asthmatics enrolled in randomized trials representative of real-life outpatients?",
        "gt": "In a real-life setting,>40% of subjects with mild/moderate asthma are currently treated by protocols based on the results of RCTs for which they would not have been eligible. This proportion increases in elderly patients with comorbidities. These findings limit the generalizability of RCTs and advocate that complementary pragmatic studies be conducted. \u00a9 2015 S. Karger AG, Basel.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study assessed the relationship between stress reactivity (trait 1) and psychosis (trait 2) across genetically related persons (cross-twin, cross-trait design) to examine whether stress reactivity is an uncontaminated and unconfounded familial marker of psychosis risk. Reactivity to stress and subclinical psychotic experiences were assessed in 289 female, general population twin-pairs. Cross-trait, within-twin associations investigating the association between stress reactivity and subclinical psychotic experiences in each person, were calculated. In addition, cross-trait, cross-twin associations were calculated to assess whether stress reactivity in one twin was moderated by subclinical psychotic experiences in the co-twin. Cross-trait, within-twin analyses showed significant associations between stress reactivity and subclinical psychotic experiences in each person. In addition, the cross-trait cross-twin analyses showed that stress reactivity in twin 1 was significantly moderated by subclinical experiences in the co-twin.\nQuestion: Does reactivity to stress cosegregate with subclinical psychosis?",
        "gt": "The results suggest that the psychosis phenotype cosegregates with increased emotional reactivity to stress in daily life.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate on a population basis the suggestion that certain factors naturally alter the odds of having a boy or a girl, and that some women are predisposed towards having children of one particular gender. Routine data analysis. Routinely collected data on singleton infants born in Scotland from 1975 to 1988, linked so that births (live and still) to the same mother could be identified. The analyses relate to 549,048 first to fifth order births occurring to 330,088 women whose records were complete from the first delivery onwards. Gender of infant. Of 549,048 births, 51.4% were male. Apart from random variation, the sex ratio of 1.06 remained constant at all birth orders (P = 0.18). The probability of a male infant appeared unrelated to the genders of the preceding siblings (P>0.20 in second to fifth deliveries), and there was no evidence of variation with maternal age (P = 0.31), maternal height (P = 0.69), paternal social class (P = 0.12), maternal social class (P = 0.57), year of delivery (P = 0.84) or season of birth (P = 0.41). Whilst mothers whose children were all the same gender were more likely to continue childbearing than those with children of different genders, there was no evidence that those with daughters were more likely to continue than those with sons.\nQuestion: Sex ratios: are there natural variations within the human population?",
        "gt": "The suggestion that some women have a natural predisposition towards having children of a particular gender is not supported by these data. On a population basis there is no evidence to suggest that gender determination is anything other than a chance process.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Anterior shoulder instability with bone loss can be treated successfully with the modified Bristow procedure. Opinions vary regarding the role of the soft-tissue sling created by the conjoined tendon after transfer. Therefore, the aim of this study was to determine the effect of the modified Bristow procedure and conjoined tendon transfer on glenohumeral translation and kinematics after creating anterior instability. Eight cadaveric shoulders were tested with a custom shoulder testing system. Range-of-motion, translation, and kinematic testing was performed in 60\u00b0 of glenohumeral abduction in the scapular and coronal planes under the following conditions: intact joint, Bankart lesion with 20% glenoid bone loss, modified Bristow procedure, and soft tissue-only conjoined tendon transfer. A Bankart lesion with 20% bone loss resulted in significantly increased external rotation and translation compared with the intact condition (P\u00a0<\u00a0.05), as well as an anterior shift of the humeral head apex at all points of external rotation. Both the modified Bristow procedure and soft-tissue Bristow procedure maintained the increase in external rotation but resulted in significantly decreased translation (P\u00a0<\u00a0.05). There was no difference in translation between the 2 reconstructions.\nQuestion: Biomechanical analysis of the modified Bristow procedure for anterior shoulder instability: is the bone block necessary?",
        "gt": "The increase in external rotation suggests that the modified Bristow procedure does not initially restrict joint motion. Translational stability can be restored in a 20% bone loss model without a bone block, suggesting the importance of the soft-tissue sling.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine 5-year survival from haematological malignancies in children, adolescents and young adults in Australia and determine if there has been any improvement in survival for the older age groups compared with children (the age-related \"survival gap\"). Population-based study of all Australian children (aged 0-14 years), adolescents (15-19 years) and young adults (20-29 years) diagnosed with acute lymphoblastic leukaemia (ALL), acute myeloid leukaemia (AML), Hodgkin lymphoma (HL) and non-Hodgkin lymphoma (NHL) between 1982 and 2004, with follow-up to 2006. 5-year survival from ALL, AML, HL and NHL analysed for four periods of diagnosis (1982-1989, 1990-1994, 1995-1999 and 2000-2004). During 1982-2004, 13 015 people aged<or = 29 years were diagnosed with primary leukaemia or lymphoma in Australia. For those with ALL, 5-year survival for adolescents improved from 40% (1982-1989) to 74% (2000-2004); the improvement for young adults was smaller (31% to 47%), and both these groups still had lower survival than children, whose 5-year survival improved from 74% to 88%. There was a larger narrowing of the gap for AML: for cases diagnosed in 2000-2004, 5-year survival was similar for young adults (63%), adolescents (74%) and children (69%). For lymphoma cases diagnosed in 2000-2004, 5-year survival in all age groups was greater than 95% for HL and greater than 81% for NHL, although children fared better than adolescents and young adults.\nQuestion: Survival from haematological malignancy in childhood, adolescence and young adulthood in Australia: is the age-related gap narrowing?",
        "gt": "These Australian population-based data confirm an improvement in survival from haematological malignancies across all three age groups, but an age-related survival gap remains for adolescents and young adults compared with children, especially for young adults with ALL. Greater participation of adolescents and young adults in clinical trials and more detailed data collection are needed to provide evidence about optimal treatment regimens in these age groups.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Nipple-sparing mastectomy (NSM) preserves the native skin envelope, including the nipple-areolar skin, and has significant benefits including improved aesthetic outcome and psychosocial well-being. Patients with prior breast scars undergoing NSM are thought to be at increased risk for postoperative complications, such as skin and/or nipple necrosis. This study describes our experience performing NSM in patients who have had prior breast surgery and aims to identify potential risk factors in this subset of patients. A retrospective review of all patients undergoing nipple sparing mastectomy at The University of Utah from 2005 to 2011 was performed. Fifty-two patients had prior breast scars, for a total of 65 breasts. Scars were categorized into 4 groups depending on scar location: inframammary fold, outer quadrant, periareolar, and circumareolar. Information regarding patient demographics, social and medical history, treatment intent, and postoperative complications were collected and analyzed. Eight of the 65 breasts (12%) developed a postoperative infection requiring antibiotic treatment. Tobacco use was associated with an increased risk of infection in patients with prior breast scars (odds ratio [OR], 7.95; 95% confidence interval [CI], 1.37-46.00; P = 0.0206). There was a 13.8% rate of combined nipple and skin flap necrosis and receipt of chemotherapy (OR, 5.00; CI, 1.11-22.46; P = 0.0357) and prior BCT (OR, 12.5; CI, 2.2-71.0; P = 0.004) were found to be associated with skin flap or NAC necrosis.\nQuestion: Nipple Sparing Mastectomy in Patients With Prior Breast Scars: Is It Safe?",
        "gt": "Nipple-sparing mastectomy is a safe and viable option for patients with a prior breast scar. Our results are comparable to the published data in patients without a prior scar. Caution should be exercised with patients who have a history of tobacco use or those requiring chemotherapy because these patients are at increased risk for infection and NAC/skin flap necrosis, respectively, when undergoing NSM in the setting of a prior breast scar.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare the strength of the association between depression and mortality between elderly and younger individuals with diabetes mellitus. A survival analysis conducted in a longitudinal cohort study of persons with diabetes mellitus to test the association between depression and mortality in older (\u2265 65) and younger (18-65) adults. Managed care. Persons aged 18 and older with diabetes mellitus who participated in the Wave 2 survey of the Translating Research Into Action for Diabetes (TRIAD) Study (N = 3,341). The primary outcome was mortality risk, which was measured as days until death using linked data from the National Death Index. Depression was measured using the Patient Health Questionnaire. After controlling for age, sex, race and ethnicity, income, and other comorbidities, mortality risk in persons with diabetes mellitus was 49% higher in those with depression than in those without, although results varied according to age. After controlling for the same variables, mortality risk in persons aged 65 and older with depression was 78% greater than in those without. For those younger than 65, the effect of depression on mortality was smaller and not statistically significant.\nQuestion: Depression and all-cause mortality in persons with diabetes mellitus: are older adults at higher risk?",
        "gt": "This analysis suggests that the effect of depression on mortality in persons with diabetes mellitus is most significant for older adults. Because there is evidence in the literature that treatment of depression in elderly adults can lead to lower mortality, these results may suggest that older adults with diabetes mellitus should be considered a high-priority population for depression screening and treatment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cardiac troponin I (CTnI) has been shown to be a marker of myocardial injury. The aim of this prospective, randomized study was to compare intermittent antegrade warm cardioplegia with tepid blood cardioplegia in patients undergoing first elective coronary artery bypass graft, using CTnI release as the criterion for evaluating the adequacy of myocardial protection. Seventy patients were randomly assigned to one of two cardioplegia groups. CTnI concentrations were measured in serial venous blood samples drawn immediately before cardiopulmonary bypass and after aortic unclamping at 6, 9, 12, and 24 hours. Analysis of covariance with repeated measures was performed to test the effect of the type of cardioplegia and time on CTnI concentration. The total amount of CTnI released (8.23 +/- 20.5 microg in the warm group and 3.19 +/- 2.4 microg in the tepid group) was not statistically different (p = 0.23). The CTnI concentration did not differ for any sample in either of the two groups when adjusted on ejection fraction and the number of preoperative myocardial infarctions (p = 0.06). No patient in the tepid group versus 4 patients in the warm group showed CTnI evidence of perioperative myocardial infarction (p = 0.12).\nQuestion: Warm and tepid cardioplegia: do they provide equal myocardial protection?",
        "gt": "Our study showed no preference for warm or tepid cardioplegia in terms of myocardial protection, either for clinical or biological data.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Natriuretic peptides (NP) are well-established markers of heart failure (HF). During the past 5 years, analytical and clinical recommendations for measurement of these biomarkers have been published in guidelines. The aim of this follow-up survey was to investigate how well these guidelines for measurement of NP have been implemented in laboratory practice in Europe. Member societies of the European Federation of Clinical Chemistry and Laboratory Medicine were invited in 2009 to participate in a web-based audit questionnaire. The questionnaire requested information on type of tests performed, decision limits for HF, turn-around time and frequency of testing. There was a moderate increase (12%) of laboratories measuring NP compared to the initial survey in 2006. The most frequently used HF decision limits for B-type NP (BNP) and N-terminal BNP (NT-proBNP) were, respectively, 100 ng/L and 125 ng/L, derived from the package inserts in 55%. Fifty laboratories used a second decision limit. Age or gender dependent decision limits were applied in 10% (8.5% in 2006). The vast majority of laboratories (80%) did not have any criteria regarding frequency of testing, compared to 33% in 2006.\nQuestion: Do laboratories follow heart failure recommendations and guidelines and did we improve?",
        "gt": "The implementation of NP measurement for HF management was a slow process between 2006 and 2009 at a time when guidelines had just been established. The decision limits were derived from package insert information and literature. There was great uncertainty concerning frequency of testing which may reflect the debate about the biological variability which was not published for most of the assays in 2009.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether access to a computer generated electrocardiogram (ECG) report can reduce errors of interpretation by senior house officers (SHOs) in an accident and emergency department. Ten SHOs were asked to interpret 50 ECGs each: 25 with computer generated reports, 25 without. Their answers, and the computer generated reports, were compared with a \"gold standard\" produced by two experienced clinicians. The primary outcome measure was the proportion of major errors of interpretation. The computer reading system made two major errors (4%, 95% confidence interval (CI) 1.1% to 13.5%) compared with the gold standard. Access to the computer report did not significantly reduce major errors among SHOs (46 (18.4%) with report v 56 (22.4%) without, odds ratio 0.64, 95% CI 0.36% to 1.14%, p=0.13) or improve the proportion completely correct (104 (41.6%) with report v 91 (36.4%) without, odds ratio 1.43, 95% CI 0.88 to 2.33, p=0.15).\nQuestion: Do computer generated ECG reports improve interpretation by accident and emergency senior house officers?",
        "gt": "SHOs have a high error rate when interpreting ECGs, which is not significantly reduced by access to a computer generated report. Junior doctors should continue to seek expert senior help when they have to interpret a difficult ECG.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Respondent-driven sampling (RDS) is an increasingly used peer chain-recruitment method to sample \"hard-to-reach\" populations for whom there are no reliable sampling frames. Implementation success of RDS varies; one potential negative factor being the number of seeds used. We conducted a sensitivity analysis on estimates produced using data from an RDS study of gay, bisexual and other men who have sex with men (GBMSM) aged \u226516\u00a0years living in Vancouver, Canada. Participants completed a questionnaire on demographics, sexual behavior and substance use. For analysis, we used increasing seed exclusion criteria, starting with all participants and subsequently removing unproductive seeds, chains of \u22641 recruitment waves, and chains of \u22642 recruitment waves. We calculated estimates for three different outcomes (HIV serostatus, condomless anal intercourse with HIV discordant/unknown status partner, and injecting drugs) using three different RDS weighting procedures: RDS-I, RDS-II, and RDS-SS. We also assessed seed dependence with bottleneck analyses and convergence plots. Statistical differences between RDS estimators were assessed through simulation analysis. Overall, 719 participants were recruited, which included 119 seeds and a maximum of 16 recruitment waves (mean chain length\u2009=\u20091.7). The sample of>0 recruitment waves removed unproductive seeds (n\u2009=\u200950/119, 42.0%), resulting in 69 chains (mean length\u2009=\u20093.0). The sample of>1 recruitment waves removed 125 seeds or recruits (17.4% of overall sample), resulting in 37 chains (mean length\u2009=\u20094.8). The final sample of>2 recruitment waves removed a further 182 seeds or recruits (25.3% of overall sample), resulting in 25 chains (mean length\u2009=\u20096.1). Convergence plots and bottleneck analyses of condomless anal intercourse with HIV discordant/unknown status partner and injecting drugs outcomes were satisfactory. For these two outcomes, regardless of seed exclusion criteria used, the crude proportions fell within 95% confidence intervals of all RDS-weighted estimates. Significant differences between the three RDS estimators were not observed.\nQuestion: Does size really matter?",
        "gt": "Within a sample of GBMSM in Vancouver, Canada, this RDS study suggests that when equilibrium and homophily are met, although potentially costly and time consuming, analysis is not negatively affected by large numbers of unproductive or lowly productive seeds.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Many studies have suggested that general practitioners fail to detect a substantial minority of their patients who are psychologically distressed, and there is concern about the possible sequelae of this. Individual patients may suffer unresolved problems, and there are potential costs to the health service in consequent recurrent consultations, inappropriate referrals or treatment. Educational interventions based on small groups led by facilitators have been shown to alter the consultation behaviours of general practitioners that are known to be related to accurate detection of psychological distress.AIM: This controlled study aimed to show that, by utilizing a brief self-directed educational intervention focusing on detection of psychological distress, general practitioners can improve their performance significantly. For this purpose, a new educational intervention was designed: the second aim of the study was thus to assess the effectiveness of this specific intervention. An educational intervention was designed which focused on skills relevant to detecting psychological distress, using the principles of reflection on general practitioner performance and consultation skill work. It was designed to be used by individual general practitioners without outside support, using a combination of written background material, feedback on performance and analysis of video material. The effectiveness of the intervention was tested by comparing a trial and control cohort of general practitioners, using detection rates as an outcome measure. The detection rate of the general practitioners who underwent the intervention improved significantly compared with their performance before intervention and with that of the control group.\nQuestion: Detecting psychological distress: can general practitioners improve their own performance?",
        "gt": "General practitioners can improve their ability to detect psychological distress in their patients utilizing this self-directed educational approach.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of the present paper was to investigate whether screening for abdominal aortic aneurysm (AAA) causes health-related quality of life to change in men or their partners. A cross-sectional case-control comparison was undertaken of men aged 65-83 years living in Perth, Western Australia, using questionnaires incorporating three validated instruments (Medical Outcomes Study Short Form-36, EuroQol EQ-5D and Hospital Anxiety and Depression Scale) as well as several independent questions about quality of life. The 2009 men who attended for ultrasound scans of the abdominal aorta completed a short prescreening questionnaire about their perception of their general health. Four hundred and ninety-eight men (157 with an AAA and 341 with a normal aorta) were sent two questionnaires for completion 12 months after screening, one for themselves and one for their partner, each being about the quality of life of the respondent. Men with an AAA were more limited in performing physical activities than those with a normal aorta (t-test of means P = 0.04). After screening, men with an AAA were significantly less likely to have current pain or discomfort than those with a normal aorta (multivariate odds ratio: 0.5; 95% confidence interval (CI): 0.3-0.9) and reported fewer visits to their doctor. The mean level of self-perceived general health increased for all men from before to after screening (from 63.4 to 65.4).\nQuestion: Is screening for abdominal aortic aneurysm bad for your health and well-being?",
        "gt": "Apart from physical functioning, screening was not associated with decreases in health and well-being. A high proportion of men rated their health over the year after screening as being either the same or improved, regardless of whether or not they were found to have an AAA.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The concerns for hyperoxia-related brain tissue injury are well known to the medical community. The cerebro-vasodilatory properties of sevoflurane may create relative cerebral tissue \"hyperoxia\" during inhalational induction as compared to a propofol-based intravenous induction of anesthesia. The objective for this case series discussion was to identify any differences in cerebral tissue oxygenation secondary to induction of anesthesia with sevoflurane versus propofol. METHODS/ After institutional review board approval, the computer data of tissue cerebral oximetry of pediatric patients (1-18 years age group) undergoing non-cardiac surgeries was comparatively analyzed for changes over time between the groups of children who received sevoflurane induction versus propofol induction of anesthesia. \"Hyperoxia\" (\"hyperoxygenation\") was defined as significant percent changes from the baseline values as recorded in tissue cerebral oximetry. In this case series, seven patients underwent inhalational (INH) induction with high concentrations (8%) sevoflurane with nitrous oxide in 33% oxygen and four patients underwent intravenous (i.v.) induction with 2 mg/kg propofol and nitrous oxide in 33% oxygen. As compared to propofol, significant cerebral tissue \"hyperoxia\" occurred with sevoflurane induction (p = 0.003). This did not resolve over time.\nQuestion: Inhalational induction with \"vasoparalytic\" sevoflurane: are we \"hyperoxygenating\" while anesthetizing developing brains?",
        "gt": "As compared to intravenous induction with propofol, inhalational induction with \"vasoparalytic\" sevoflurane \"hyperoxygenates\" developing brains. This observation requires validation in larger trials to conclude appropriate effect on our practice of pediatric anesthesia and pediatric patient safety under anesthesia.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare efficacy and safety of 5% lidocaine medicated plaster with pregabalin in patients with post-herpetic neuralgia (PHN), and to assess the benefits of combining both drugs in patients not responding to either single agent. This was a two-stage adaptive, randomised, open-label, multicentre, non-inferiority study (NCT 00414349). The subset of patients with PHN is reported here. Patients with an absolute value of>4 on the NRS-3 were randomly assigned to 4-week treatment with 5% lidocaine medicated plaster or twice-daily pregabalin capsules titrated to effect. Subsequently, patients sufficiently treated with monotherapy (patients with NRS-3<or=4 at 4 weeks or a reduction on the NRS-3 from baseline of>or=2 points) continued with monotherapy; patients insufficiently treated with monotherapy received both drugs in combination for 8 weeks. Pain according to SF-MPQ and NPSI, onset of effect, reduction in worst pain on the NRS; allodynia severity; quality of life (QoL) based on EQ-5D, SF-36; PGIC; rescue medication intake; adverse events (AEs) monitoring. At 4 weeks, SF-MPQ total scores improved by -7.6 +/- 6.66 (mean +/- SD) under 5% lidocaine medicated plaster and by -5.3 +/- 7.93 under pregabalin. NPSI total scores declined by -1.6 +/- 1.73 under 5% lidocaine medicated plaster and -1.4 +/- 1.87 under pregabalin. Lidocaine plaster was also effective in reducing worst pain and showed a fast onset of effect. During combination treatment, SF-MPQ and NPSI scores, allodynia, EQ-5D and PGIC improved. Incidences of AEs were in line with previous reports for the two treatments and combination therapy was generally well-tolerated.\nQuestion: Post-herpetic neuralgia: 5% lidocaine medicated plaster, pregabalin, or a combination of both?",
        "gt": "Although this open-label study is lacking a placebo control group, the results suggest that 5% lidocaine medicated plaster is at least as effective as pregabalin for pain relief in PHN, with a favourable safety profile and a resulting positive benefit-risk ratio. In patients unresponsive to either monotherapy, combination therapy provides additional efficacy and is well-tolerated.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine the effect of autism spectrum (AS) tendencies and psychosocial job characteristics on health-related quality of life (HRQOL) among factory workers. A questionnaire survey was administered to 376 Japanese factory employees from the same company (response rate: 83.6%) in 2010. Psychosocial job characteristics, including job demand, job control, and social support, were evaluated using the Job Content Questionnaire (JCQ). AS tendencies was assessed using the Autism-Spectrum Quotient (AQ), and HRQOL was assessed using the Medical Outcomes Study Short-Form General Health Survey (SF-8). Associations were investigated using multiple logistic regression analysis adjusted for confounders. In the multivariate analysis, AQ was positively (odds ratio [OR]: 3.94; 95% confidence interval [CI]: 1.70-9.73) and social support in the workplace was inversely (OR: 0.25; 95% CI: 0.10-0.57) associated with poor mental HRQOL. No significant interaction was observed between AQ and JCQ subitems. Only social support was inversely associated with poor physical HRQOL (OR and 95% CI for medium social support: 0.45 and 0.21-0.94), and a significant interaction between AQ and job control was observed (p=0.02), suggesting that high job control was associated with poor physical HRQOL among workers with high AQ, whereas low job control tended to be associated with poor physical HRQOL among others.\nQuestion: Is high job control a risk factor for poor quality of life in workers with high autism spectrum tendencies?",
        "gt": "Our results suggest that AS tendencies have a negative effect on workers' HRQOL and social support is a primary factor in maintaining HRQOL. Moreover, a structured work environment can maintain physical HRQOL in workers with high AS tendencies since higher job control will be stressful.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Edema surrounding the medial collateral ligament (MCL) is seen on MR imaging in patients with MCL injuries and in patients with radiographic osteoarthritis in the non-traumatic knee. Because we noted MCL edema in patients without prior trauma or osteoarthritis, we studied the association between intra-articular pathology and MCL edema in patients without knee trauma. We evaluated the MR examinations of 247 consecutive patients (121 male, 126 female with a mean age of 44 years) without recent trauma for the presence of edema surrounding the MCL, meniscal and ACL tears, medial meniscal extrusion, medial compartment chondromalacia, and osteoarthritis. The percentages of patients illustrating MCL edema with and without each type of pathology were compared using Fisher's exact test to determine if there was a statistically significant association. We found MCL edema in 60% of 247 patients. MCL edema was present in 67% of patients with medial meniscal tears, 35% with lateral meniscal tears, 100% with meniscal extrusion of 3 mm or more, 78% with femoral chondromalacia, 82% with tibial chondromalacia, and 50% with osteoarthritis. The percentage of patients with edema increased with the severity of the chondromalacia. These associations were all statistically significant (p<0.02). The mean age of those with MCL edema was 49.7 years compared with 34.9 years without MCL edema ( p<0.001). Patient gender and ACL tear did not correlate with MCL edema. Nine (4%) of the 247 patients had MCL edema without intra-articular pathology. None of these 9 patients had MCL tenderness or joint laxity on physical examination.\nQuestion: Is intra-articular pathology associated with MCL edema on MR imaging of the non-traumatic knee?",
        "gt": "We confirmed that MCL edema is associated with osteoarthritis, but is also associated with meniscal tears, meniscal extrusion, and chondromalacia. In addition, MCL edema can be seen in patients without intra-articular pathology, recent trauma or MCL abnormality on physical examination.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We performed a prospective, population-based case-control study of 20,248 newborn born in the city of Mainz. A total of 1,451 infants (cases) with and 8,088 without congenital malformations (controls) were analysed. The relative risks of associations between obesity and malformations were calculated as odds ratios (OR) with 95% confidence intervals (CI). The prevalence of malformations in children of obese mothers is 11.1% and thus approximately 4% higher than those of the total study population. There is a significant odds ratio for major malformations (OR 1.3; KI 1.0-1.7). Statistically significant associations were calculated for malformations of the internal urogenital system (OR 1.7; 1.1-2.8), the eyes (OR 5.0; 1.3-20.0) and for orofacial clefts (OR 1.7; 1.1-2.8). Among the specific malformations the highest associations occurred for encephalocele (OR 7.3; 1.1-50.6), common truncus arteriosus (OR 6.3; 1.6-24.8) and Potter sequence (OR 6.3; 1.6-24.8). Adjustment for confounding factors (e.g. maternal diabetes mellitus and age) did not change the odds ratios.\nQuestion: Does maternal obesity increase the risk of fetal abnormalities?",
        "gt": "Our data demonstrate that newborn of obese mothers are at an increased risk for malformations. An adequate prenatal examination of these pregnancies should include ultrasound screening by specially trained ultrasonographers in tertiary units (DEGUM II/DEGUM III) and serum alpha-fetoprotein measurements. Public health campaigns for prevention are advised.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study reports 21 patients with Stage I-III low-grade non-Hodgkin's lymphoma who were treated with comprehensive lymphatic irradiation (CLI) at the University of Florida between 1966 and 1992. Sites clinically involved with disease were treated with 30 Gy, whereas clinically uninvolved sites were treated with 25 Gy. Median follow-up for the group was 14 years (24.5 years for Stage III patients). Overall absolute survival rates at 5, 10, and 15 years were 84%, 68%, and 34%. Cause-specific survival rates at 5, 10, and 15 years were 84%, 68%, and 56%. Freedom-from-relapse rates at 5, 10, and 15 years were 75%, 58%, and 58%, with no relapses noted after 10 years. Bulky disease (>6 cm) was a significant indicator of poor prognosis for cause-specific survival (p = .01).\nQuestion: Is comprehensive lymphatic irradiation for low-grade non-Hodgkin's lymphoma curative therapy?",
        "gt": "These data support findings from other institutions suggesting a role for CLI as potentially curative therapy with acceptable toxicity and a short treatment time for patients with Stages I and II and limited Stage III disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The sensitivity of endocervical curettage (ECC) can be suboptimal because of limited epithelial tissue. The false-negative rate for ECC in patients with cervical intraepithelial neoplasia involving the endocervical canal has been reported to be 45%. ECC samples are transported to pathology in formalin- or saline-filled containers; this fluid is discarded after the specimen has been submitted. We evaluated the utility of performing liquid-based cytological preparations from ECC transport container fluid as a way to increase the sensitivity of ECC specimens. Consecutive ECC specimens received at one of the two participating institutions were selected prospectively. A surgical pathology mesh bag was placed over a ThinPrep(\u00ae) CytoLyt(\u00ae) solution container, and the specimen was filtered through the bag, collecting the transport fluid in the container. The CytoLyt(\u00ae) was processed to obtain a container fluid ThinPrep(\u00ae) (CF-TP) liquid-based Papanicolaou (Pap) slide. The CF-TP slides were reviewed and the findings were compared with those from the ECC and follow-up specimens. The cohort included 53 patients. Discrepancies between CF-TP and ECC were seen in 14 of the 53 patients (26%); a more significant lesion was identified in CF-TP relative to ECC in 13 of these cases. CF-TP diagnosis was confirmed in eight of 11 cases with histological follow-up. A positive CF-TP result was confirmed by histology in six of nine cases with negative ECC.\nQuestion: Increasing the sensitivity of endocervical curettings by performing ThinPrep\u00ae Pap on transport container fluid: is diagnostic material going down the drain?",
        "gt": "Combining the pathological evaluation of ECC specimens with liquid-based cytology performed on the transport container fluid can increase the diagnostic sensitivity of the ECC procedure for the detection of cervical lesions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Upper GI (UGI) studies are routinely ordered to screen for malrotation before routine placement of gastrostomy (G) tubes. However, the usefulness of this study is unknown. A retrospective review of children with surgically placed G-tubes over a 2 year period (2011-2013) was performed. Patients with concomitant fundoplications were excluded. Three hundred ninety-three patients underwent G-tube placement. Of these, 299 patients (76%) had preoperative UGI, and 11 patients (3.7%) were identified with malrotation on UGI. Five (1.7%) patients underwent a Ladd's procedure. The remaining 6 either had malrotation associated with gastroschisis (n=5) or were lost to follow-up (n=1). Children<1 year did not have different rates of malrotation compared to older children (4.3% vs. 3.2%, p=0.617). Likewise, children with neurologic impairment (NI) had similar rates of malrotation compared to neurologically normal (NN) children (2.6% vs. 3.8%, p=0.692). The only significant difference in malrotation rate was between those with congenital gastrointestinal anomalies (24%) and those without (1.5%) (p<0.001).\nQuestion: Routine gastrostomy tube placement in children: Does preoperative screening upper gastrointestinal contrast study alter the operative plan?",
        "gt": "Preoperative screening UGI before routine G-tube placement led to an unexpected diagnosis of malrotation in only 1.7%. Given the added radiation risk associated with an UGI, our data suggest that an UGI is unnecessary prior to routine G-tube placement. A larger prospective study is warranted to validate these results.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Previous studies showed conflicting and inconsistent results regarding the effect of anatomic location of the melanoma on sentinel lymph node (SLN) positivity and/or survival. This study was conducted to evaluate and compare the effect of the anatomic locations of primary melanoma on long-term clinical outcomes. All consecutive cutaneous melanoma patients (n=2,079) who underwent selective SLN dissection (SLND) from 1993 to 2009 in a single academic tertiary-care medical center were included. SLN positive rate, disease-free survival (DFS), and overall survival (OS) were determined. Kaplan-Meier survival, univariate, and multivariate analyses were performed to determine predictive factors for SLN status, DFS, and OS. Head and neck melanoma (HNM) had the lowest SLN-positive rate at 10.8% (16.8% for extremity and 19.3% for trunk; P=0.002) but had the worst 5-year DFS (P<0.0001) and 5-year OS (P<0.0001) compared with other sites. Tumor thickness (P<0.001), ulceration (P<0.001), HNM location (P=0.001), mitotic rate (P<0.001), and decreasing age (P<0.001) were independent predictive factors for SLN-positivity. HNM with T3 or T4 thickness had significantly lower SLN positive rate compared with other locations (P\u22640.05). Also, on multivariate analysis, HNM location versus other anatomic sites was independently predictive of decreased DFS and OS (P<0.001). By Kaplan-Meier analysis, HNM was associated significantly with the worst DFS and OS.\nQuestion: Is head and neck melanoma different from trunk and extremity melanomas with respect to sentinel lymph node status and clinical outcome?",
        "gt": "Primary melanoma anatomic location is an independent predictor of SLN status and survival. Although HNM has a decreased SLN-positivity rate, it shows a significantly increased risk of recurrence and death as compared with other sites.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To test the hypothesis that iodinated contrast media may induce an elevation in serum potassium level. Protocol A: After intravenous infusion of contrast media into six rabbits, alterations of potassium ion concentrations were measured. Protocol B: Fresh rabbit blood was mixed in vitro with contrast media, and the fluctuations in potassium were monitored over a 30-minute period. Protocol C: Similar to protocol B, except that blood from humans with no reaction to contrast media was used. For protocol A, blood potassium levels increased above baseline levels. The elevations were statistically significant (P<.05). For protocol B, diatrizoate and ioxaglate caused a gradual increase in blood potassium levels, but iopamidol did not. In protocol C, all three contrast media caused statistically significant elevation in potassium levels. The release of potassium was statistically significant at 5 minutes (P<.05 for diatrizoate and ioxaglate, and P<.01 for iopamidol). The mean release rates (+/- standard deviation) by means of linear regression analysis were 0.0190 mmol/min +/- 0.0112 with diatrizoate, 0.0159 mmol/min +/- 0.0057 with iopamidol, and 0.0088 mmol/min +/- 0.0033 with ioxaglate.\nQuestion: Do iodinated contrast media increase serum potassium levels?",
        "gt": "Iodinated contrast media increase blood potassium levels causing release of potassium into intravascular spaces. This potassium release may play some role in contrast medium-induced adverse reactions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Fifty-nine patients with late-stage AMD (74.3 \u00b1 7.3 years) and 49 age-, sex-, and education-matched control subjects were compared for the presence of AD according to the guidelines of the National Institute of Neurological and Communicative Disorders and Stroke and the Alzheimer's Disease and Related Disorders Association (NINCDS-ADRDA). Detailed neuropsychological tests were performed for all subjects. Neuropsychiatric tests scores were lower in the AMD group than the control group. The frequency of AD was higher in patients with AMD (40.7% in AMD and 20.4% in control group, P = 0.03), and particularly higher in late dry (nonvascular) AMD (d-AMD) patients (71.4% in d-AMD and 31.1% in late wet (vascular) AMD, P = 0.007). d-AMD patients performed worse than controls on all tests. There was also an association between age, sex, and low education and neuropsychiatric tests scores (P<0.01). However, there was no association between visual acuity and neuropsychiatric tests scores.\nQuestion: Is Alzheimer disease related to age-related macular degeneration?",
        "gt": "The increased frequency of AD in patients with AMD is significant. This study demonstrated the importance of cognitive assessment in patients with AMD, particularly in the d-AMD type.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Immunoglobulin A (IgA) anti-endomysium antibodies, the most reliable immunological marker for both the screening and follow-up of coeliac disease, need monkey oesophagus as antigenic substrate; this limits their use because of high costs and the exploitation of endangered species. (1) To compare the diagnostic accuracy of anti-endomysium antibodies detected by indirect immunofluorescence on monkey oesophagus and on human umbilical cord; (2) to evaluate their reliability during follow-up in detecting non-compliant patients. One hundred and four untreated adults with biopsy-proven coeliac disease and 94 controls were investigated. Endomysium antibodies were found in 99 patients (95%) on both substrates, with a specificity, respectively, of 100% and 99% on monkey oesophagus and umbilical cord. One year after gluten withdrawal, out of 47 patients who were investigated, only six presented with complete mucosal recovery: none of these subjects was positive on either substrates, while, among patients with persistent histological alterations, endomysium positivity persisted in only 10 on monkey oesophagus, but in 32 on umbilical cord. Histology (recovery or persistent involvement) was in agreement with endomysium (negative or positive) in 34% on monkey oesophagus, but in 81% on umbilical cord (P<0.0001).\nQuestion: Is human umbilical cord the most suitable substrate for the detection of endomysium antibodies in the screening and follow-up of coeliac disease?",
        "gt": "Human umbilical cord, with its comparable diagnostic efficiency, could replace monkey tissues, with the advantages of saving both money and monkeys. Moreover, it seems the most suitable substrate in the follow-up, as it enables detection of non-compliant patients with persisting mucosal alterations.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To explore whether there exist differences in cognitive development between singletons and twins born after in vitro fertilization (IVF) or intracytoplasmic sperm injection (ICSI). A total of 566 children were recruited for the study, including 388 children (singletons, n=175; twins, n=213) born after IVF and 178 children (singletons, n=87; twins, n=91) born after ICSI. The cognitive development was assessed using the Chinese-Wechsler Intelligence Scale for Children (C-WISC). For all pre-term offspring, all the intelligence quotient (IQ) items between singletons and twins showed no significant differences no matter if they were born after IVF or ICSI. There was a significant difference in the cognitive development of IVF-conceived full-term singletons and twins. The twins born after IVF obtained significantly lower scores than the singletons in verbal IQ (containing information, picture&vocabulary, arithmetic, picture completion, comprehension, and language), performance IQ (containing maze, visual analysis, object assembly, and performance), and full scale IQ (P<0.05). The cognitive development of full-term singletons and twins born after ICSI did not show any significant differences. There was no significant difference between the parents of the singletons and twins in their characteristics where data were collected, including the age of the mothers, the current employment status, the educational backgrounds, and areas of residence. There were also no consistent differences in the duration of pregnancy, sex composition of the children, age, and height between singletons and twins at the time of our study although there existed significant differences between the two groups in the sex composition of the full-term children born after ICSI (P<0.05).\nQuestion: Is there a difference in cognitive development between preschool singletons and twins born after intracytoplasmic sperm injection or in vitro fertilization?",
        "gt": "Compared to the full-term singletons born after IVF, the full-term twins have lower cognitive development. The cognitive development of full-term singletons and twins born after ICSI did not show any significant differences. For all pre-term offspring, singletons and twins born after IVF or ICSI, the results of the cognitive development showed no significant differences.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Partial laryngectomy is used in the treatment of laryngeal cancer. Structural alterations of the upper airway arising from partial laryngectomy can cause obstructive sleep apnea (OSA). To compare the prevalence and severity of OSA in patients submitted to horizontal and vertical partial laryngectomy and assess the role of spirometry for these patients. Cross-sectional clinical study with individuals offered partial laryngectomy. The included patients were assessed through interview, upper airway endoscopy, polysomnography, and spirometry. Fourteen patients were evaluated and 92.3% were found to have OSA. The apnea-hypopnea index was significantly higher among patients submitted to vertical laryngectomy (mean = 36.9) when compared to subjects offered horizontal laryngectomy (mean = 11.2). The mean minimum oxyhemoglobin saturation was 85.9 in the horizontal laryngectomy group and 84.3 in the vertical laryngectomy group. Spirometry identified extrathoracic upper airway obstruction in all patients with OSA.\nQuestion: Obstructive sleep apnea: is there a difference between vertical and horizontal laryngectomy?",
        "gt": "The studied population had a high incidence of obstructive sleep apnea. OSA was more severe in patients offered vertical laryngectomy than in the individuals submitted to horizontal laryngectomy. Spirometry seems to be useful in the detection of cases of suspected OSA, as it suggests the presence of extrathoracic upper airway obstruction.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Several studies have investigated plasma androgen levels in women with recurrent miscarriage (RM) with conflicting results on whether an association between hyperandrogenaemia and RM exists. However, none of these studies included sensitive androgen measurements using a large data set. We therefore investigated the free androgen index (FAI) in a large number of women with RM in order to ascertain whether hyperandrogenaemia is a predictor of subsequent pregnancy outcome. We studied 571 women who attended the Recurrent Miscarriage Clinic in Sheffield and presented with>or =3 consecutive miscarriages. Serum levels of total testosterone and sex hormone-binding globulin were measured in the early follicular phase and FAI was then deduced. The prevalence of hyperandrogenaemia in RM was 11% and in a subsequent pregnancy, the miscarriage rate was significantly higher in the raised FAI group (miscarriage rates of 68% and 40% for FAI>5 and FAI<or = 5 respectively, P = 0.002).\nQuestion: Does free androgen index predict subsequent pregnancy outcome in women with recurrent miscarriage?",
        "gt": "An elevated FAI appears to be a prognostic factor for a subsequent miscarriage in women with RM and is a more significant predictor of subsequent miscarriage than an advanced maternal age (>or =40 years) or a high number (>or =6) of previous miscarriages in this study.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A retrospective comparative study was performed in patients with rectal cancer who achieved an incomplete clinical response after neoadjuvant chemoradiotherapy. Patients with significant tumour downsizing (>30% of the initial tumour size) were compared with controls (<30% reduction of the initial tumour size). During flexible proctoscopy carried out postchemoradiation, biopsies were performed using 3-mm biopsy forceps. The biopsy results were compared with the histopathological findings of the resected specimen. UICC (Union for International Cancer Control) ypTNM classification, tumour differentiation and regression grade were evaluated. The main outcome measures were sensitivity and specificity, negative and positive predictive values, and accuracy of a simple forceps biopsy for predicting pathological response after neoadjuvant chemoradiotherapy. Of the 172 patients, 112 were considered to have had an incomplete clinical response and were included in the study. Thirty-nine patients achieved significant tumour downsizing and underwent postchemoradiation biopsies. Overall, 53 biopsies were carried out. Of the 39 patients who achieved significant tumour downsizing, the biopsy result was positive in 25 and negative in 14. Only three of the patients with a negative biopsy result were found to have had a complete pathological response (giving a negative predictive value of 21%). Considering all biopsies performed, only three of 28 negative biopsies were true negatives, giving a negative predictive value of 11%.\nQuestion: Role of biopsies in patients with residual rectal cancer following neoadjuvant chemoradiation after downsizing: can they rule out persisting cancer?",
        "gt": "In patients with distal rectal cancer undergoing neoadjuvant chemoradiation, post-treatment biopsies are of limited clinical value in ruling out persisting cancer. A negative biopsy result after a near-complete clinical response should not be considered sufficient for avoiding a radical resection.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We sought to determine if a small muscle mass index (MMI) is actually detrimental for insulin sensitivity when studying a large group of postmenopausal women displaying various body composition statuses and when age and visceral fat mass (VFM) are taken into account. A cross-sectional study was conducted in 99 healthy postmenopausal women with a BMI of 28\u00b14 kg/m(2). Fat mass and total fat-free mass (FFM) were obtained from DXA and VFM and MMI were estimated respectively by the equation of Bertin and by: Total FFM (kg)/height (m)(2). Fasting plasma insulin and glucose were obtained to calculate QUICKI and HOMA as an insulin sensitivity index. Total MMI and VFM were both significantly inversely correlated with QUICKI and positively with HOMA even when adjusted for VFM. A stepwise linear regression confirmed Total MMI and VFM as independent predictors of HOMA and plasma insulin level.\nQuestion: Is a small muscle mass index really detrimental for insulin sensitivity in postmenopausal women of various body composition status?",
        "gt": "A small muscle mass might not be detrimental for the maintenance of insulin sensitivity and could even be beneficial in sedentary postmenopausal women. The impact of muscle mass loss on insulin sensitivity in older adults needs to be further investigated.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: According to observations by occupational health physicians, nearly 50 % of the seamen on German vessels will get diseases of the upper respiratory tract. An impact of the air-conditioning systems on these diseases has been suggested. To examine the hygienic quality of indoor air on seagoing vessels, a pilot study was initiated by the See-Berufsgenossenschaft. Air samples were taken on-site at different sampling sites and analysed for the occurrence of microorganisms. Bacteria showed the highest cell numbers and the highest distribution in indoor air on vessels, whereby the maximum level was determined in the air of crew cabins. The identification of bacteria showed that beside common airborne species, pathogens existed.\nQuestion: Does air conditioning impact on hygienic quality of indoor air on seagoing vessels?",
        "gt": "Air-conditioning seems to influence the quality of indoor air on seagoing vessels. Interim results of the study indicate that regular maintenance of air-conditioning systems is essential.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Loneliness and low mood are associated with significant negative health outcomes including poor sleep, but the strength of the evidence underlying these associations varies. There is strong evidence that poor sleep quality and low mood are linked, but only emerging evidence that loneliness and poor sleep are associated. To independently replicate the finding that loneliness and poor subjective sleep quality are associated and to extend past research by investigating lifestyle regularity as a possible mediator of relationships, since lifestyle regularity has been linked to loneliness and poor sleep. Using a cross-sectional design, 97 adults completed standardized measures of loneliness, lifestyle regularity, subjective sleep quality and mood. Loneliness was a significant predictor of sleep quality. Lifestyle regularity was not a predictor of, nor associated with, mood, sleep quality or loneliness.\nQuestion: An investigation of the relationship between subjective sleep quality, loneliness and mood in an Australian sample: can daily routine explain the links?",
        "gt": "This study provides an important independent replication of the association between poor sleep and loneliness. However, the mechanism underlying this link remains unclear. A theoretically plausible mechanism for this link, lifestyle regularity, does not explain the relationship between loneliness and poor sleep. The nexus between loneliness and poor sleep is unlikely to be broken by altering the social rhythm of patients who present with poor sleep and loneliness.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Colorectal cancer (CRC) screening programmes based on faecal immunochemical testing for haemoglobin (FIT) typically use a screening interval of 2\u2005years. We aimed to estimate how alternative FIT strategies that use a lower than usual positivity threshold followed by a longer screening interval compare with conventional strategies. We analysed longitudinal data of 4523 Dutch individuals (50-74\u2005years at baseline) participating in round I of a one-sample FIT screening programme, of which 3427 individuals also participated in round II after 1-3\u2005years. The cohort was followed until 2\u2005years after round II. In both rounds, a cut-off level of \u226550\u2005ng haemoglobin (Hb)/mL buffer (corresponding to 10\u2005\u00b5g Hb/g faeces) was used, representing the standard scenario. We determined the cumulative positivity rate (PR) and the numbers of subjects diagnosed with advanced adenomas (N_AdvAd) and early stage CRC (N_earlyCRC) in the cohort over two rounds of screening (standard scenario) and compared it with hypothetical single-round screening with use of a lower cut-off and omission of the second round (alternative scenario). In the standard scenario, the cumulative (ie, round I and II combined) PR, N_AdvAd and N_earlyCRC were 13%, 180% and 26%, respectively. In alternative scenarios using a cut-off level of respectively \u226511 and \u226522\u2005ng/HbmL buffer (corresponding to 2 and 4\u2005\u00b5g Hb/g faeces), the PRs were 18% and 13%, the N_AdvAd were 180 and 162 and the N_earlyCRC ranged between 22-27 and 22-26.\nQuestion: Immunochemical faecal occult blood testing to screen for colorectal cancer: can the screening interval be extended?",
        "gt": "The diagnostic yield of FIT screening using a lowered positivity threshold in combination with an extended screening interval (up to 5\u2005years) may be similar to conventional FIT strategies. This justifies and motivates further research steps in this direction.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To optimize a dual-energy computed tomographic protocol with sinogram-affirmed iterative reconstruction algorithms for improving small nodules detection. The raw data of a dual-energy computed tomographic arterial acquisition of a cirrhotic patient were reconstructed with a standard filtered back projection (B20f) and 3 iterative (I26, I30, I31) kernels with different strength (S3-S5). The 80-kilovolt (peak) (kVp) and the linear blended (DE_0.5) images (80-140 kVp) were analyzed. For each series, 8-subcentimeter low-contrast lesions were simulated within the liver. Four radiologists performed a detectability test and rated the image quality (5-point scales) in all images. The sensitivity increased from 31% (B20f) to 87.5% with sinogram-affirmed iterative reconstruction S5 kernels without a difference between 80-kVp and DE_0.5 series (W test, P = 0.062). The highest image quality rating was 3.8 (B20 DE_0.5), without difference from DE_0.5 I30-S5 and I26-S3.\nQuestion: Can sinogram-affirmed iterative reconstruction improve the detection of small hypervascular liver nodules with dual-energy CT?",
        "gt": "Iterative reconstructions increase the sensitivity for detecting abdominal lesions, even in the 80-kVp series. The kernel I30-S5 was considered the best.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The primary aim is to explore whether prescription drug expenditures by enrollees changed in Alabama's CHIP program, ALL Kids, after copayment increases in fiscal year 2004. The subsidiary aim is to explore whether non-pharmaceutical expenditures also changed. Data on ALL Kids enrollees between 1999-2007, obtained from claims files and the state's administrative database. We used data on children who were enrolled between one and three years both before and after the changes to the copayment schedule, and estimate regression models with individual-level fixed effects to control for time-invariant heterogeneity at the child level. This allows an accurate estimate of how program expenditures change for the same individual following copayment changes. Primary outcomes of interest are expenditures for prescription drugs by class and brand-name and generic versions. We estimate models for the likelihood of any use of prescription drugs and expenditure level conditional on use. Following the copayment increase, the probability of any expenditure decline by 5.8%, brand name drugs by 6.9%, generic drugs by 7.4%. Conditional on any use, program expenditures decline by 7.9% for all drugs, by 9.6% for brand name drugs, and 6.2% for generic drugs. The largest declines are for antihistamine drugs; the least declines are for Central Nervous System agents. Declines are smaller and statistically weaker for children with chronic health conditions. Concurrent declines are also seen for non-pharmaceutical medical expenditures.\nQuestion: Can increases in CHIP copayments reduce program expenditures on prescription drugs?",
        "gt": "Copayment increases appear to reduce program expenditures on prescription drugs per enrollee and may be a useful tool for controlling program costs.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Pneumonia is the leading cause of infectious death amongst children globally, with the highest burden in Africa. Early identification of children at risk of treatment failure in the community and prompt referral could lower mortality. A number of clinical markers have been independently associated with oral antibiotic failure in childhood pneumonia. This study aimed to develop a prognostic model for fast-breathing pneumonia treatment failure in sub-Saharan Africa. We prospectively followed a cohort of children (2-59 months), diagnosed by community health workers with fast-breathing pneumonia using World Health Organisation (WHO) integrated community case management guidelines. Cases were followed at days 5 and 14 by study data collectors, who assessed a range of pre-determined clinical features for treatment outcome. We built the prognostic model using eight pre-defined parameters, using multivariable logistic regression, validated through bootstrapping. We assessed 1,542 cases of which 769 were included (32% ineligible; 19% defaulted). The treatment failure rate was 15% at day 5 and relapse was 4% at day 14. Concurrent malaria diagnosis (OR: 1.62; 95% CI: 1.06, 2.47) and moderate malnutrition (OR: 1.88; 95% CI: 1.09, 3.26) were associated with treatment failure. The model demonstrated poor calibration and discrimination (c-statistic: 0.56).\nQuestion: Can We Predict Oral Antibiotic Treatment Failure in Children with Fast-Breathing Pneumonia Managed at the Community Level?",
        "gt": "This study suggests that it may be difficult to create a pragmatic community-level prognostic child pneumonia tool based solely on clinical markers and pulse oximetry in an HIV and malaria endemic setting. Further work is needed to identify more accurate and reliable referral algorithms that remain feasible for use by community health workers.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To analyze physician work production over a 5-year period to discover trends in productivity. Surgical workforce calculations over the past 25 years have projected major oversupply as well as looming shortages. Recent studies indicate that demand for surgical services will increase over the next two decades as the population ages and develops age related chronic diseases. This study examines actual physician productivity to determine whether there is capacity for increased work output in response to projected increases in demand. Physician productivity data as measured by relative value units were obtained from the Medical Group Management Association Physician Compensation Reports for a 5-year period. Surgeons were compared with nonsurgeons and across subspecialties. Surgeon and nonsurgeon productivity in terms of relative value units remained relatively stable over the study period; surgical:nonsurgical productivity per provider was 1.30-1.46:1.\nQuestion: Surgical work output: is there room for increase?",
        "gt": "Surgeons produce a significant amount of the total work in multi-specialty medical groups. These results may indicate that the surgical and general surgical workforce has reached a plateau with respect to clinical productivity. Predicted increases in demand for procedure-based work to care for the aging population are likely to be difficult to meet with the available workforce.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There has been considerable expansion in the use of flexible cystoscopy (FC) and people who can perform the procedure. Hence, there is a criticism that this procedure is being overused with no management benefit. We audited the use of FC in a district hospital for a period of 1 year. The results of FC for non-standard indications (other than haematuria and check cystoscopy) were analysed for their diagnostic yield. Of the 1,390 FCs performed, 295 were done for non-standard indications. 46.14% of these cystoscopies had positive findings. Cancer detection rate was 6.10%. Cystoscopy altered the management in 14.08% of patients and was supportive to diagnosis and management in 32.06%.\nQuestion: Do we need to perform cystoscopy on all adults attending urology centres as outpatients?",
        "gt": "This procedure is certainly not overused and the ever-increasing requirement of this simple procedure has serious resource implications for the National Health Service.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Retrospective analysis was conducted for 45 patients in a BDSR group and for 149 patients in a PD group. The T-stage (P<0.001), lymph node invasion (P = 0.010) and tumor differentiation (P = 0.005) were significant prognostic factors in the BDSR group. The 3- and 5-year overall survival rates for the BDSR group and PD group were 51.7% and 36.6%, respectively and 46.0% and 38.1%, respectively (P = 0.099). The BDSR group and PD group did not show any significant difference in survival when this was adjusted for the TNM stage. The 3- and 5-year survival rates were: stage Ia [BDSR (100.0% and 100.0%) vs PD (76.9% and 68.4%) (P = 0.226)]; stage Ib [BDSR (55.8% and 32.6%) vs PD (59.3% and 59.3%) (P = 0.942)]; stage IIb [BDSR (19.2% and 19.2%) vs PD (31.9% and 14.2%) (P = 0.669)].\nQuestion: Carcinoma of the middle bile duct: is bile duct segmental resection appropriate?",
        "gt": "BDSR can be justified as an alternative radical operation for patients with middle bile duct in selected patients with no adjacent organ invasion and resection margin is negative.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study provides understanding about the issues that affect nurse retention in a sector where employee attrition is a key challenge, further exacerbated by an ageing workforce. A quantitative study based on a self-completion survey questionnaire completed in 2010. Nurses employed in two UK National Health Service Foundation Trusts were surveyed and assessed using seven work-related constructs and various demographics including age generation. Through correlation, multiple regression and stepwise regression analysis, the potential combined effect of various explanatory variables on continuation intention was assessed, across the entire nursing cohort and in three age-generation groups. Three variables act in combination to explain continuation intention: work-family conflict, work attachment and importance of work to the individual. This combination of significant explanatory variables was consistent across the three generations of nursing employee. Work attachment was identified as the strongest marginal predictor of continuation intention.\nQuestion: Do nurses wish to continue working for the UK National Health Service?",
        "gt": "Work orientation has a greater impact on continuation intention compared with employer-directed interventions such as leader-member exchange, teamwork and autonomy. UK nurses are homogeneous across the three age-generations regarding explanation of continuation intention, with the significant explanatory measures being recognizably narrower in their focus and more greatly concentrated on the individual. This suggests that differentiated approaches to retention should perhaps not be pursued in this sectoral context.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The GlideScope video-guided laryngoscope is an alternative standard of care for rescue laryngoscopies when direct laryngoscopy is unsuccessful. During postoperative checks by an anesthesiologist, it was noticed that patients who reported sore throat often required GlideScope laryngoscopy. Consequently, it is difficult to determine whether postoperative sore throats are caused by irritation inflicted by multiple laryngoscopic attempts or the actual utilization of the GlideScope itself. The goal of this study was to determine whether the use of the GlideScope leads to a greater or lesser incidence of sore throat when compared with traditional laryngoscope blades used for intubation. Eligible patients scheduled for elective inpatient surgeries requiring endotracheal tube intubation were enrolled into this single-blinded prospective cohort study. \u03c7(2) Test, Fisher exact test, and t tests were used to compare differences across the primary end point and other demographic categories. Operating rooms and postanesthesia recovery unit, Albany Medical Center, Albany, NY. There were a total of 151 patients with American Society of Anesthesiologists grades 1 to 3 included in the study. Eighty-one patients were randomized to a control group that received traditional laryngoscopy via Macintosh/Miller blades and 70 patients received video-guided intubation via the GlideScope. The incidence of postoperative sore throat was recorded via a yes/no questionnaire within 24 hours after extubation. Secondary parameters such as provider type, sex, and perceived difficulty were also recorded. There was no significant difference in the proportion of patients reporting sore throat by type of blade used (Mac/Miller 36.3% vs GlideScope 32.4%, P = .619). For secondary outcomes, women were significantly more likely to report sore throat as compared with men (men 24.3% vs women 43.2%, P = .015), and the provider type was significantly associated with the occurrence of postoperative sore throat (attendings 26.8% vs certified registered nurse anesthetists 52.3% vs third-year clinical anesthesia residents 30%, P = .012).\nQuestion: Does the incidence of sore throat postoperatively increase with the use of a traditional intubation blade or the GlideScope?",
        "gt": "Use of the GlideScope videolaryngoscopy was not significantly associated with increased occurrence of postoperative sore throat when compared with traditional intubation techniques. Our results may enable more trainees to acquire intubation skills with the GlideScope during an initial intubation attempt in patients with American Society of Anesthesiologist grades 1 to 3, with optimization of patient satisfaction in respect to postoperative sore throats. In addition, a provider's choice of intubation technique based on either Macintosh/Miller blades or the GlideScope does not significantly impact a patient's risk of postoperative sore throat.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To identify the factors that contribute to the under-resourcing of Aboriginal health and to explore the impact that funding arrangements have on the implementation of Aboriginal health policy. Qualitative study based on 35 in-depth interviews with a purposive sample of frontline health professionals involved in health policy and service provision in the Northern Territory. Participants described three factors that contributed to the under-resourcing of Aboriginal health: inefficient funding arrangements, mainstream programs being inappropriate for Aboriginal Australians, and competing interests determining the allocation of resources. Insufficient capacity within the healthcare system undermines the multilevel implementation process whereby organisations need to have the capacity to recognise new policy ideas, assess their relevance to their existing work and strategic plan and to be able to incorporate the relevant new ideas into day-to-day practice.\nQuestion: Efficient funding: a path to improving Aboriginal healthcare in Australia?",
        "gt": "Insufficient resources for Aboriginal health were found to be a barrier to implementing Aboriginal health policy. Inadequate resources result from the cumbersome allocation of funding rather than simply the amount of funding provided to Aboriginal healthcare. Monitoring government performance and ensuring the efficient allocation of funds would allow us to develop the delivery system for Aboriginal healthcare and therefore provide greater opportunities to capitalise on current interventions and future efforts.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Overdose is a significant cause of death among heroin users. Frequently, other heroin users are present when an overdose occurs, which means the victim's life could be saved. There is a lack of studies that, based on heroin users own stories, examine their views, assessments, and responses to witnessed overdoses. The study is based on qualitative interviews with thirty-five heroin users who witnessed someone else's overdose. The heroin users generally had a positive attitude towards assisting peers who had overdosed. A number of factors and circumstances, however, contribute to witnesses often experiencing resistance to or ambivalence about responding. The witness's own high, the difficulty in assessing the seriousness of the situation, an unwillingness to disturb someone else's high, uncertainty about the motive behind the overdose and whether the victim does or does not want assistance as well as fear of police involvement, were common factors that acted as barriers to adequate responses in overdose situations.\nQuestion: Wasted, overdosed, or beyond saving--to act or not to act?",
        "gt": "The fact that being high makes it difficult to respond to overdoses, using traditional methods, argues for simpler and more effective response techniques. This can include intranasal naloxone programs for heroin users. The findings regarding the uncertainty about the intention of the overdose victim and the sensitivity to the experience of a good high argue for more up-front communication and discussion amongst using peers so that they can make their intentions clear to each other. Issues like this can be addressed in overdose education interventions. Overdose prevention measures also need to address the fact that fear of the police acts as a barrier to call emergency services.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We propose a simple and inexpensive in vitro crystallization assay of measuring turbidity by spectrophotometry in synthetic urine. We validated our method by investigating the effect of potassium (K) citrate on the crystallization of calcium oxalate monohydrate (CaOx), calcium phosphate, and magnesium ammonium phosphate using synthetic urine. The crystallization of CaOx was studied using turbidimetric measurements of solution produced by mixing calcium chloride and sodium oxalate at 37 \u00b0C, pH 5.7. The turbidity of the crystal suspension was measured immediately with double-beam spectrophotometer as the absorbance of light at 660 nm wavelength. The rates of crystal formation and aggregation were obtained by measuring optical density (OD) over 30 min. The obtained results were compared to CaOx crystal concentration with and without citrate assessed by optical microscopy. The sensitivity of spectrophotometry in measuring turbidity was confirmed by the linear correlation between the crystal concentration and OD readings at 660 nm seen on the standard curve. Under similar experimental conditions, the results were comparable to the ones obtained by optical microscopy. The OD readings over 30 min revealed an instant decrease in the number of crystals, with maximum aggregation noted at 18 min. Addition of K-citrate at 1.25 mg/ml led to initial less crystal formation (OD = 0.236 nm vs. OD = 0.527 nm), with a maximum aggregation reached at 18 min. Overall, citrate addition decreased nucleation with a small change in the aggregation (OD = 0.316 vs. OD = 0.359).\nQuestion: Urinary turbidity as a marker of crystallization: is spectrophotometric assessment useful?",
        "gt": "Spectrophotometric measurement of urinary turbidity is feasible and sensitive in assessing the potential clinical usefulness of different medications in inhibiting crystallization in urine.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: With ever increasing demands on emergency services it is necessary to consider how to enhance the recruitment and retention of emergency nurses in public hospitals. Personality is known to influence occupational choice, yet there is a lack of research exploring how personality may influence the workforce decisions of emergency nurses. A standardised personality test instrument, the NEO\u2122-PI-3, was used in a survey design inclusive of demographic questions to measure personality characteristics. Data were collected from 72 emergency nurses working at an Australian Emergency Department between July and October 2012. The personality scores of emergency nurses were compared against general population norms in each of five personality domains and their 30 associated facets. Participants scored higher than population norms in the domains of Extraversion (p<.001), Openness to experience (p<.001) and Agreeableness (p = .001), and in twelve facets, including excitement-seeking (p<.001) and competence (p = .003).\nQuestion: The personality of emergency nurses: is it unique?",
        "gt": "The personality profile of this sample of emergency nurses is different to the population norm. Assessment of personality and knowledge of its influence on specialty selection may assist in improving retention and recruitment in emergency nursing.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Whether and when to transfuse in anemia of prematurity is highly controversial. Some authors suggest transfusions simply if the hemoglobin (Hb) level is below a defined normal range. Others propose the use of clinical or laboratory parameters in anemic patients to decide whether to transfuse or not. A decreasing amount of circulating Hb should cause a compensatory increase in cardiac output (CO) and an increase in arterial serum lactate. In 56 anemic preterm infants (not in respiratory or hemodynamic failure) we analyzed CO after the first week of life using a Doppler sonographic method. At the same time serum lactate levels, Hb levels and oxygen saturation were registered. Nineteen of these patients were given transfusion when they demonstrated clinical signs of anemia by tachycardia>180/min, tachypnea, retractions, apneas and centralization (group 2). The remaining 37 patients were not transfused (group 1). Serum lactate, CO, heart rate (HR), oxygen delivery, respiratory rate, capillary refill and Hb were analyzed in both groups and in group 2 before and 12-24 h after transfusion. Data between groups 1 and 2 and in group 2 before and after transfusion were compared. In the 56 patients studied no linear correlation between Hb and CO or between Hb and serum lactate was found. Nor could any correlation be demonstrated between the other variables studied. Examining the subgroups separately, a negative linear correlation was demonstrated between serum lactate and oxygen delivery in group 2. No other significant correlations were detected. However, when the pre- and post-transfusion data were compared in group 2 (increase of Hb from 9.45 (SD 3.44) to 12.5 (SD 3.8) g/100 ml), the CO decreased from 281.3 (SD 162.6) to 224 (SD 95.7) ml/kg per min (p<0.01) and serum lactate decreased significantly from 3.23 mmol/l (SD 2.07) before to 1.71 (SD 0.83) after transfusion. Oxygen delivery was 35.8 (+/- 0.19) ml/kg per min group 1, 27.8 (+/- 0.05) pre- and 43.4 (+/- 0.07) post-transfusion in group 2 (p<0.01).\nQuestion: Do cardiac output and serum lactate levels indicate blood transfusion requirements in anemia of prematurity?",
        "gt": "CO measurements and serum lactate levels add little information to the decision-making process for blood transfusions, as neither CO nor serum lactate levels correlate with HB levels in an otherwise asymptomatic population of preterm infants. In infants where the indication for blood transfusion is made based on traditionally accepted clinical criteria, serum lactate is an additional laboratory indicator of impaired oxygenation, as it correlates significantly with oxygen delivery. A significant lower oxygen delivery in patients in whom blood transfusion is indicated and an increase in oxygen induced by transfusion demonstrate the value of these criteria in identifying preterm infants who benefit from transfusion.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the prevalence of coeliac disease in an Australian rural community. Retrospective analysis of stored serum samples from 3,011 random subjects from the Busselton Health Study. IgA antiendomysial antibodies (AEA) were detected by indirect immunofluorescence, and subjects testing positive were contacted and offered small-bowel biopsy. Prevalence of AEA positivity and biopsy-proven coeliac disease in the community with reference to the proportion of symptomatic to asymptomatic patients. 10 of 3,011 subjects were AEA positive. One subject had died, one subject could not be traced and one refused small-bowel biopsy. All subjects with detectable AEA who consented to biopsy had pathological changes consistent with coeliac disease. The prevalence of newly diagnosed biopsyproven coeliac disease is 7 in 3,011 (1 in 430). Two further subjects had a diagnosis of coeliac disease before this study. When all AEA-positive patients and those previously diagnosed are included, the prevalence is 12/3,011 (1 in 251). There was a significant clustering of cases in the 30-50-years age range, with 10/12 (83%; 95% CI, 52%-98%) aged between 30 and 50 years, compared with 1,092/3,011 (36%; 95% CI, 35%-38%) of the total population (P<0.03). Of the eight AEA-positive subjects who could be contacted, four had symptoms consistent with coeliac disease and four were asymptomatic. Three subjects were iron-deficient, four subjects had first-degree relatives with coeliac disease and one subject had type 1 diabetes mellitus.\nQuestion: High prevalence of coeliac disease in a population-based study from Western Australia: a case for screening?",
        "gt": "The prevalence of coeliac disease is high in a rural Australian community. Most patients are undiagnosed, and asymptomatic.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study evaluates the agreement in prolapse staging between clinical examination, dynamic magnetic resonance (MR), imaging and perineal ultrasonography. Anatomical landmarks in the anterior, central, and posterior compartment were assessed in relation to three reference lines on dynamic MR imaging and one reference line on dynamic ultrasonography. These measurements were compared to the according POP-Q measurements. Agreement between the three methods was analyzed with Spearman's rank correlation coefficient (r(s)) and Bland and Altman plots. Correlations were good to moderate in the anterior compartment (r(s) range = 0.49; 0.70) and moderate to poor (r(s) range = -0.03; 0.49) in the central and posterior compartment. This finding was independent of the staging method and reference lines used.\nQuestion: POP-Q, dynamic MR imaging, and perineal ultrasonography: do they agree in the quantification of female pelvic organ prolapse?",
        "gt": "Pelvic organ prolapse staging with the use of POP-Q, dynamic MR imaging, and perineal ultrasonography only correlates in the anterior compartment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Pleiotropic effects of recombinant human erythropoietin (EPO) have recently been discovered in many non-renal animal models. The renoprotective effects of EPO and carbamylated-erythropoietin (CEPO), a novel EPO which has a small stimulatory effect on hemoglobin, have never been explored in unilateral ureteral obstruction (UUO), a chronic tubulointerstitial (TI) disease model which is independent of systemic factors. In order to examine the effects of EPO and CEPO treatments on renal TI injury, 36 male Sprague-Dawley rats, weighing 250-320 g, underwent: UUO without treatment (group 1, n = 12), UUO with EPO (groups 2, n = 12), and UUO with CEPO (group 3, n = 12). EPO and CEPO were injected subcutaneously at a dose of 5000 u/kg to each respective rat at 1 day pre-UUO and at day 3, 7 and 10 post-UUO. After days 3, 7, and 14 of UUO, TI injury, collagen, alpha-smooth muscle actin (alpha-SMA) positive cell, ED1-positive cell, terminal deoxynucleotidyl transferase (TdT) mediated nick-end labeling (TUNEL)-positive cell, and transforming growth factor-beta1 (TGF-beta1) messenger ribonucleic acid (mRNA) were determined. Bcl-2 expression was also assessed to verify the mechanism of apoptosis. At day 14 UUO caused severe TI injury with a significant increase in collagen, alpha-SMA, ED1-positive cell, TUNEL-positive cell, and TGF-beta1 mRNA expression. Administration of EPO and CEPO significantly attenuated TI injury, collagen, ED1-positive cells, and TUNEL-positive cells. Only CEPO-treated rats had decreased alpha-SMA positive cells and TGF-beta1 mRNA. The expression of Bcl-2 was demonstrated only in EPO-treated rats. The hematocrit levels in EPO-treated rats were higher than the control and CEPO-treated rats.\nQuestion: Erythropoietin and its non-erythropoietic derivative: do they ameliorate renal tubulointerstitial injury in ureteral obstruction?",
        "gt": "EPO and CEPO can limit 14-day UUO-induced TI injury by reducing inflammation, interstitial fibrosis, and tubular apoptosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The independent effect of lipid lowering therapy (LLT) on venous thromboembolism (VTE) risk is uncertain. To test statin and non-statin LLT as potential VTE risk factors. Using Rochester Epidemiology Project resources, we identified all Olmsted County, MN residents with objectively diagnosed incident VTE (cases) over the 13-year period, 1988-2000 (n=1340), and one to two matched controls (n=1538). We reviewed their complete medical records for baseline characteristics previously identified as independent VTE risk factors, and for statin and non-statin LLT. Using conditional logistic regression, we tested the overall effect of LLT on VTE risk and also separately explored the role of statin versus that of non-statin LLT, adjusting for other baseline characteristics. Among cases and controls, 74 and 111 received statin LLT, and 32 and 50 received non-statin LLT, respectively. Univariately, and after individually controlling for other potential VTE risk factors (i.e., BMI, trauma/fracture, leg paresis, hospitalization for surgery or medical illness, nursing home residence, active cancer, central venous catheter, varicose veins, prior superficial vein thrombosis, diabetes, congestive heart failure, angina/myocardial infarction, stroke, peripheral vascular disease, smoking, anticoagulation), LLT was associated with decreased odds of VTE (unadjusted OR=0.73; p=0.03). When considered separately, statin and non-statin LLT were each associated with moderate, non-significant lower odds of VTE. After adjusting for angina/myocardial infarction, each was significantly associated with decreased odds of VTE (OR=0.63, p<0.01 and OR=0.61, p=0.04, respectively).\nQuestion: Is lipid lowering therapy an independent risk factor for venous thromboembolism?",
        "gt": "LLT is associated with decreased VTE risk after adjusting for known risk factors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The differentiation between cardiac and esophageal causes of retrosternal chest pain is notoriously difficult. Theoretically, cardiac and esophageal causes may coexist. It has also been reported that gastroesophageal reflux and esophageal motor abnormalities may elicit myocardial ischemia and chest pain, a phenomenon called linked angina pectoris. The aim of this study was to assess the incidence of esophageal abnormalities as a cause of retrosternal chest pain in patients with previously documented coronary artery disease. Thirty consecutive patients were studied, all of whom had undergone coronary arteriography. The patients were studied after they were admitted to the coronary care unit with an attack of typical chest pain. On electrocardiograms (ECGs) taken during pain, 15 patients (group I) had new signs of ischemia; the other 15 patients (group II) did not. In none of the patients were cardiac enzymes elevated. As soon as possible, but within 2 hours after admission, combined 24-hour recording of esophageal pressure and pH was performed. During chest pain, 12-lead ECG recording was carried out. In group I, all 15 patients experienced one or more pain episodes during admission, 25 of which were associated with ischemic electrocardiographic changes. The other two episodes were reflux-related. Only one of the 25 ischemia-associated pain episodes was also reflux-related, ie, it was preceded by a reflux episode. In group II, 19 chest pain episodes occurred in 11 patients. None of these was associated with electrocardiographic changes, but 8 were associated with reflux (42%) and 8 with abnormal esophageal motility (42%).\nQuestion: Esophageal dysfunction as a cause of angina pectoris (\"linked angina\"): does it exist?",
        "gt": "Linked angina is a rare phenomenon.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess if arylsulfatase A activity (ASA) and sulfatide (SL) concentration in the human endometrium can be predictive of the development of endometrial polyps over the years, since ASA activity reflects the endometrial sensitivity to hormones. ASA activity and SL concentration were determined by biochemical procedures on endometrial samples collected between 1990 and 1994 in non-menopausal women. These women underwent a new endometrial sampling following the clinical indication some years after the first endometrial sampling. The histological assessment of the second endometrial specimens found four patients with normal endometrial pattern and 10 patients with one or more endometrial polyps. ASA activity/years elapsed and SL concentration/years elapsed were compared using two tailed Mann-Whitney test for unpaired data between patients with normal pattern and patients with endometrial polyps. Median ASA activities were 2.62 (normal pattern) versus 1.85 (endometrial polyps) nmol hydrolized substrate/min. Median activity/years elapsed is higher in patients with second endometrial sample presenting normal pattern (p=0.006) and median SL concentration/years elapsed does not differ significantly among groups, even if median SL concentration seems to be higher in patients who subsequently developed polyps (1031 \u00b5g/g of fresh tissue versus 341,5 \u00b5g/g of fresh tissue).\nQuestion: Can endometrial arylsulfatase A activity predict the onset of endometrial polyps over the years?",
        "gt": "ASA activity can predict the onset of endometrial polyps over the years.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Given the paucity of literature on the time course of recovery of erectile function (EF) after radical prostatectomy (RP), many publications have led patients and clinicians to believe that erections are unlikely to recover beyond 2 years after RP. We sought to determine the time course of recovery of EF beyond 2 years after bilateral nerve sparing (BNS) RP and to determine factors predictive of continued improved recovery beyond 2 years. EF was assessed prospectively on a 5-point scale: (i) full erections; (ii) diminished erections routinely sufficient for intercourse; (iii) partial erections occasionally satisfactory for intercourse; (iv) partial erections unsatisfactory for intercourse; and (v) no erections. From 01/1999 to 01/2007, 136 preoperatively potent (levels 1-2) men who underwent BNS RP without prior treatment and who had not recovered consistently functional erections (levels 1-2) at 24 months had further follow-up regarding EF. Median follow-up after the 2-year visit was 36.0 months. Recovery of improved erections at a later date: recovery of EF level 1-2 in those with level 3 EF at 2 years and recovery of EF level 1-3 in those with level 4-5 EF at 2 years. The actuarial rates of further improved recovery of EF to level 1-2 in those with level 3 EF at 2 years and to level 1-3 in those with level 4-5 EF at 2 years were 8%, 20%, and 23% at 3, 4, and 5 years postoperatively, and 5%, 17%, and 21% at 3, 4, and 5 years postoperatively, respectively. Younger age was predictive of greater likelihood of recovery beyond 2 years.\nQuestion: Time course of recovery of erectile function after radical retropubic prostatectomy: does anyone recover after 2 years?",
        "gt": "There is continued improvement in EF beyond 2 years after BNS RP. Discussion of this prolonged time course of recovery may allow patients to have a more realistic expectation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Some men with premature ejaculation (PE) and normal erectile function record contradictory response/s to The Sexual Health Inventory for Men (SHIM) and may be incorrectly categorized as suffering from erectile dysfunction (ED). The aim of this study was to evaluate the frequency of false positive SHIM diagnosis of ED in men with lifelong PE. SHIM, stopwatch intravaginal ejaculation latency time (IELT). A prospective observational study of men with normal erectile function and lifelong PE, diagnosed using the ISSM definition of lifelong PE, was conducted. The SHIM was self-administered at Visit 1. Mean per subject stopwatch IELT was determined from four subsequent intercourse attempts. Seventy-eight subjects with a mean age of 33.2 +/- 8.3 years and a geometric mean IELT of 15.9 +/- 2.3 seconds were enrolled. The mean SHIM score for all subjects was 20.4 +/- 6.0. Fifty-two subjects (66.7%) have SHIM scores of>21 (mean 24.3 +/- 1.1), consistent with normal erectile function, and a geometric mean IELT of 18.3 +/- 2.2 seconds. Twenty-six subjects (33.3%) had SHIM scores<22 (mean 12.7 +/- 3.7), consistent with a false positive diagnosis of ED, and a geometric mean IELT of 10.5 +/- 2.3 seconds. The incidence of false positive SHIM diagnosis of ED (SHIM<22) was inversely related to the IELT. Although the geometric mean IELT for subjects with SHIM scores<22 was significantly less than that of all subjects and subjects with SHIM scores>21, there were no significant differences between the geometric mean IELT or the IELT distribution of all subjects vs. the normal erectile function IELT (SHIM>21) cohort.\nQuestion: Screening for erectile dysfunction in men with lifelong premature ejaculation--Is the Sexual Health Inventory for Men (SHIM) reliable?",
        "gt": "This study demonstrates a 33.3% false positive SHIM diagnosis of ED in men with PE. This is likely to limit subject recruitment in clinical trials by exclusion of subjects with low-range IELTs but is unlikely to result in significantly different baseline IELTs or IELT distributions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Diabetes or insulin resistance, overweight, arterial hypertension, and dyslipidaemia are recognized risk factors for cardiovascular (CV) disease. However, their predictive value and hierarchy in elderly subjects remain uncertain. We investigated the impact of cardiometabolic risk factors on mortality in a prospective cohort study of 331 elderly high-risk subjects (mean age+/-SD: 85+/-7 years). Two-year total mortality was predicted by age, diabetes, low BMI, low diastolic blood pressure (DBP), low total and HDL cholesterol, and previous CV events. The effect of diabetes was explained by previous CV events. In non-diabetic subjects, mortality was predicted by high insulin sensitivity, determined by HOMA-IR and QUICKI indices. In multivariate analyses, the strongest mortality predictors were low BMI, low HDL cholesterol and previous myocardial infarction. Albumin, a marker of malnutrition, was associated with blood pressure, total and HDL cholesterol, and HOMA-IR. The inflammation marker CRP was associated with low total and HDL cholesterol, and high HOMA-IR.\nQuestion: Cardiometabolic determinants of mortality in a geriatric population: is there a \"reverse metabolic syndrome\"?",
        "gt": "In very old patients, low BMI, low DBP, low total and HDL cholesterol, and high insulin sensitivity predict total mortality, indicating a \"reverse metabolic syndrome\" that is probably attributable to malnutrition and/or chronic disorders. These inverse associations limit the relevance of conventional risk factors. Previous CV events and HDL cholesterol remain strong predictors of mortality. Future studies should determine if and when the prevention and treatment of malnutrition in the elderly should be incorporated into conventional CV prevention.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The primary purpose of this study is to explore primary care physicians' (PCPs') knowledge, attitudes and self-reported activities provided to patients for smoking cessation. The secondary purpose is to identify the relationships between physician-related characteristics and knowledge, attitudes and self-reported activities for smoking cessation. A national cross-sectional web survey was conducted in Italy from April through September 2012. 722 PCPs completed the questionnaire. The great majority indicated the correct proportion of smokers among patients with lung cancer, the smoking abstention required for risk reduction after smoking cessation, and tobacco as a known major risk factor for chronic obstructive pulmonary disease (COPD), whereas 28.7% knew the Fagerstrom test for the assessment of nicotine dependence. Almost all PCPs reported that they ask all patients if they smoke, inform about the dangers of smoking and recommend to quit smoking, whereas prescription of recommended drugs for smoking cessation varied from 37.7% for nicotine replacement therapy to 4.9% for varenicline.\nQuestion: Are primary care physicians prepared to assist patients for smoking cessation?",
        "gt": "Despite a positive attitude, Italian PCPs are not prepared to deliver effective interventions for smoking cessation in their patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It is unclear whether proactive telephone support enhances smoking cessation beyond the provision of nicotine replacement therapy alone. We randomly assigned 330 low-income women smokers to receive either free nicotine patches (control condition) or free nicotine patches with up to 16 weeks of proactive telephone support (experimental condition). All participants were assessed by telephone at baseline and at 2 weeks, 3 months, and 6 months post-baseline to determine smoking status. Results revealed a significant effect for the telephone support at 3 months, with 43% of experimental versus 26% of control condition women reporting 30-day point prevalent abstinence (P = 0.002). The difference was no longer significant at 6 months. A metaanalysis conducted with five randomized studies revealed a slight but non-significant long-term benefit of proactive telephone support when added to the provision of free nicotine patches for smoking cessation.\nQuestion: Does extended proactive telephone support increase smoking cessation among low-income women using nicotine patches?",
        "gt": "This is the second study to demonstrate a short-term effect for proactive telephone support added to free nicotine replacement therapy; however, neither the current study, nor the metaanalysis including the four other published trials, confirmed a longer-term benefit.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Enteroviruses are seasonally prevalent each year in Southeast Asia. Elevated C-reactive protein (CRP) levels have been noted in minor populations of patients, and antibiotics may be prescribed under the impression of a suspected bacterial infection. This prescription might be inappropriate, resulting in further bacterial resistance and medical expense. The aim of this study was to delineate how effective antibiotics are for children suffering from enterovirus infection complicated with a high CRP level. The medical records of children hospitalized between January 2008 and December 2012 with herpangina or hand, foot and mouth disease were reviewed retrospectively. The children enrolled were divided into three groups, A, B, and C, by CRP level, which were<40, 40-80, and \u2265 80 mg/l, respectively. A case-control study of group C divided into subgroups according to the prescription of antibiotics for at least 24h during the admission was conducted for further analysis. A total 3566 cases were identified; 214 were in group C and 71.0% of them received a prescription for antibiotics. There was a linear trend between a relatively higher CRP level and a higher proportion of antibiotics prescribed in the three groups (p=0.001). In the case-control study, there were no significant differences in age, sex, mean CRP, or febrile days. However, a relatively longer stay of hospitalization was recorded in the subgroup with an antibiotic prescription (p=0.020).\nQuestion: Are antibiotics beneficial to children suffering from enterovirus infection complicated with a high C-reactive protein level?",
        "gt": "The present study indicated that antibiotics might not be beneficial in treating these patients, even those with a high CRP level. Clinicians should be more prudent in antibiotic use when no obvious evidence of bacterial infection is found.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Treatment of anemia is an important issue in the palliative care setting. Blood transfusion is generally used for this purpose in supportive care. However the place of blood transfusion in terminally ill cancer cases is less far established. We aimed to outline the use of transfusions and to find the impact of blood transfusion on survival in patients with advanced cancer and very near to death. Patients dying in 2010-2011 with advanced cancer were included in the study. We retrospectively collected the data including age, type of cancer, the duration of last hospitalisation, ECOG performance status, Hb levels, transfusion history of erythrocytes and platelets, cause and the amount of transfusion. The anaemic patients who had transfusion at admission were compared with the group who were not transfused. Survival was defined as the time between the admission of last hospitalisation period and death. Three hundred and ninety eight people with solid tumours died in 2010-2011 in our clinic. Ninety percent of the patients had anemia at the time of last hospitalisation. One hundred fifty three patients had erythrocyte transfusion at admission during the last hospitalisation period (38.4%). In the anaemic population the duration of last hospitalisation was longer in patients who had erythrocyte transfusion (15 days vs 8 days, p<0.001).\nQuestion: Use of blood transfusion at the end of life: does it have any effects on survival of cancer patients?",
        "gt": "Patients who had blood transfusion at the end of life lived significantly longer than the anaemic patients who were not transfused. This study remarks that blood transfusions should not be withheld from terminal cancer patients in palliative care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Despite the implementation of a Quebec immunization program against influenza and pneumococcal disease (PQIIP), vaccine coverage has remained low. There have been many studies on personal barriers to vaccination, but few have explored other kinds of barriers. To explore the presence of barriers in relation to the organization of the health care system and to propose recommendations for increasing vaccine coverage. Within a mixed protocol, a phone survey of 996 people in the target population and a case study implicating the follow-up of the PQIIP with all the site and actor categories via 43 semistructured interviews and 4 focus groups were realized. Survey data underwent a descriptive statistical analysis. Qualitative analysis followed the Miles and Huberman approach. The results indicate the presence of barriers with regard to information accessibility. These include access to: the physicians' recommendation, knowledge of the efficacy or the security of vaccines, and admissibility of clients to the PQIIP. Organizational barriers were also found to limit access to vaccination, especially in terms of restricted choices of time and location. Coordination and incentives mechanisms are not optimal. Removal of organizational barriers depends more on strategic rather than structural factors.\nQuestion: Do organizational barriers to pneumococcal and influenza vaccine access exist?",
        "gt": "Addressing organizational barriers should be an important component of strategies aimed at improving vaccine coverage. Public health authorities should focus on strategic management of the information and inter-organizational environment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To describe the successful implementation of an evidence-based, integrated quality improvement mental health program in a primary care setting. Intermountain Healthcare (IHC) has aligned resources around a conceptual framework that emphasizes clinic and community accountability, family and consumer health focused on recovery rather than disease, and enhanced decision making through partnerships and automation. The mental health integration system includes an integrated team led foremost by the patient and family with vital defined roles for primary care providers, care managers, psychiatrists, advanced practice registered nurses, support staff, and the National Alliance for the Mentally Ill. Pharmacists have assumed training functions on the team and have the potential to play more vital roles.\nQuestion: Can mental health integration in a primary care setting improve quality and lower costs?",
        "gt": "The IHC experience demonstrates that mental health services can be effectively integrated into everyday practice in a primary care setting. Clinical and financial burden can be decreased for the health care team, patients, and family.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Almost half of all children in South Asia are stunted. Although agriculture has the potential to be a strong driver of undernutrition reduction and serves as the main source of livelihood for over half of South Asia's population, its potential to reduce undernutrition is currently not being realized. The Leveraging Agriculture for Nutrition in South Asia (LANSA) research consortium seeks to understand how agriculture and agrifood systems can be better designed to improve nutrition in South Asia. In 2013 and 2014, LANSA carried out interviews with stakeholders influential in, and/or knowledgeable of, agriculture-nutrition policy in India, Pakistan, and Bangladesh, to gain a better understanding of the institutional and political factors surrounding the nutrition sensitivity of agriculture in the region. Semistructured interviews were carried out in India, Bangladesh, and Pakistan with a total of 56 stakeholders representing international organizations, research, government, civil society, donors, and the private sector. The findings point to mixed perspectives on countries' policy sensitivity toward nutrition. There was consensus among stakeholders on the importance of political commitment to nutrition, improving nutrition literacy, strengthening capacities, and improving the use of financial resources.\nQuestion: Is There an Enabling Environment for Nutrition-Sensitive Agriculture in South Asia?",
        "gt": "Although there are different ways in which South Asian agriculture can improve its impact on nutrition, sensitizing key influencers to the importance of nutrition for the health of a country's population appears as a critical issue. This should in turn serve as the premise for political commitment, intersectoral coordination to implement nutrition-relevant policies, adequately resourced nutrition-specific and nutrition-sensitive programs, and sufficient capacities at all levels.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare regional body fat distribution and sex hormone status of postmenopausal women with NIDDM with those of age- and BMI-matched normoglycemic women. The regional body fat distribution and sex hormone status of 42 postmenopausal women with NIDDM were compared with those of 42 normoglycemic women matched for age and BMI, who served as control subjects. Body composition was measured by dual-energy X-ray absorptiometry, and sex hormone-binding globulin (SHBG) and testosterone were measured in serum. Although the levels of total body fat were similar between the two groups, the women with NIDDM had significantly less lower-body fat (LBF) (P<0.01) than the control subjects matched for age and BMI. This pattern of fat deposition in women with NIDDM was accompanied by an androgenic hormone profile, with decreased SHBG concentration and an increased free androgen index (P<0.05 and P<0.01, respectively).\nQuestion: Do postmenopausal women with NIDDM have a reduced capacity to deposit and conserve lower-body fat?",
        "gt": "A reduced capacity to deposit and/or conserve LBF may be an independent factor associated with (or may be a marker of) the metabolic manifestations of the insulin resistance syndrome in women with NIDDM. The possibility that the smaller relative accumulation of LBF is a consequence of the androgenic hormonal profile should be investigated in future studies.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Clinically valid cardiac evaluation via treadmill stress testing requires patients to achieve specific target heart rates and to successfully complete the cardiac examination. A comparison of the standard Bruce protocol and the ramped Bruce protocol was performed using data collected over a 1-y period from a targeted patient population with a body mass index (BMI) equal to or greater than 30 to determine which treadmill protocol provided more successful examination results. The functional capacity, metabolic equivalent units achieved, pressure rate product, and total time on the treadmill as measured for the obese patients were clinically valid and comparable to normal-weight and overweight patients (P<0.001). Data gathered from each protocol demonstrated that the usage of the ramped Bruce protocol achieved more consistent results in comparison across all BMI groups in achieving 80%-85% of their age-predicted maximum heart rate.\nQuestion: Comparison of Bruce treadmill exercise test protocols: is ramped Bruce equal or superior to standard bruce in producing clinically valid studies for patients presenting for evaluation of cardiac ischemia or arrhythmia with body mass index equal to or greater than 30?",
        "gt": "This study did not adequately establish that the ramped Bruce protocol was superior to the standard Bruce protocol for the examination of patients with a BMI equal to or greater than 30.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The association between chronic idiopathic urticaria (CIU) and autoimmune thyroiditis (AT) is known, as well as major prevalence of antithyroid antibodies in the allergical subjects and other autoimmune diseases. We have evaluated the effects of l-thyroxine on clinical symptoms of CIU in AT patients suggesting the hypothesis of a new thyroid-stimulating hormone (TSH) role in immune system. In 20 female patients with CIU + AT, both hypothyroid and euthyroid, we have investigated the therapeutic effects of l-thyroxine dosed to suppress the TSH. Free-T3, Free-T4, TSH, antithyroperoxidase and antithyroglobulin antibodies, total immunoglobulin (Ig)E, Rheuma test and eritro-sedimentation rate were monitored during treatment. In 16 patients a strong decrease of urticaria symptoms has happened after 12 weeks. The TPO Ab and HTG Ab clearly decreased in 14 patients. Furthermore, in two patients with rheumatoid arthritis and in two patients with pollen allergy a strong decrease of rheuma test titer and total IgE has happened.\nQuestion: Improvement of chronic idiopathic urticaria with L-thyroxine: a new TSH role in immune response?",
        "gt": "The reason of AT is associated to CIU and others allergical and autoimmune diseases is poorly known. The exclusive hormonal therapy reduces the symptoms of CIU and inflammatory response in many chronic diseases associated to AT. We suggest a stimulatory effect of TSH able to produce considerable changes of the immune response and immune tolerance in patients with AT causing target organs damage. The causal mechanism involves immune, nervous and endocrine system, sharing a common set of hormones, cytokines and receptors, in a unique totally integrated loop (the neuro-immuno-endocrine axis).",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We analyzed the impact of immunoglobulin M (IgM) positivity on the relapse-free interval post completed course of cyclophosphamide (CYC) treatment in patients with steroid-dependent nephrotic syndrome (SDNS) and minimal change disease (MCD). This was a retrospective chart review of all children who received CYC for SDNS and MCD between 1988 and 2009. Patients were divided into three groups based on kidney biopsy: MCD without immunoglobulin M (IgM) positivity (IgM-), MCD with IgM-positive immunofluorescence (IF) only (IgM+), and MCD with IgM-positive IF and electron-dense deposits on electron microscopy (IgM++). The relapse-free time interval to the first relapse post-CYC therapy or up to 48 months of follow-up (if no relapse occurred) was used for survival analysis. Forty children aged 1.5-12.3 years (15 were IgM-, 16 were IgM+, 9 were IgM++) received a cumulative CYC dose of 175 \u00b1 30 mg/kg. The overall relapse-free survival time was 75 % at 12 months, 64 % at 24 months, 59 % at 36 months, and 56 % at 48 months, with no significant differences between the IgM groups (p = 0.80).\nQuestion: Is cyclophosphamide effective in patients with IgM-positive minimal change disease?",
        "gt": "Based on our results, we conclude that more than 50% of our SDNS patients with MCD remained relapse-free 4 years post-CYC treatment. No significant difference in the response to CYC was observed between patients with or without IgM positivity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study explores active learning algorithms as a way to reduce the requirements for large training sets in medical text classification tasks. Three existing active learning algorithms (distance-based (DIST), diversity-based (DIV), and a combination of both (CMB)) were used to classify text from five datasets. The performance of these algorithms was compared to that of passive learning on the five datasets. We then conducted a novel investigation of the interaction between dataset characteristics and the performance results. Classification accuracy and area under receiver operating characteristics (ROC) curves for each algorithm at different sample sizes were generated. The performance of active learning algorithms was compared with that of passive learning using a weighted mean of paired differences. To determine why the performance varies on different datasets, we measured the diversity and uncertainty of each dataset using relative entropy and correlated the results with the performance differences. The DIST and CMB algorithms performed better than passive learning. With a statistical significance level set at 0.05, DIST outperformed passive learning in all five datasets, while CMB was found to be better than passive learning in four datasets. We found strong correlations between the dataset diversity and the DIV performance, as well as the dataset uncertainty and the performance of the DIST algorithm.\nQuestion: Active learning for clinical text classification: is it better than random sampling?",
        "gt": "For medical text classification, appropriate active learning algorithms can yield performance comparable to that of passive learning with considerably smaller training sets. In particular, our results suggest that DIV performs better on data with higher diversity and DIST on data with lower uncertainty.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: With the development of high-performance computer programs, transcutaneous electrogastrography has experienced a renaissance in the last few years and is widely recommended as a non-invasive diagnostic tool to evaluate functional gastric disorders. We assessed the clinical value of electrogastrography in symptomatic and asymptomatic patients after a variety of procedures of the upper gastrointestinal (GI) tract. Electrogastrography tracings were recorded with a commercially available data logger using a recording frequency of 4 Hz. A standard meal was given between a 60 min preprandial and a 60 min postprandial period. The following parameters were analyzed pre- and postprandially utilizing Fourier and spectral analysis: Regular gastric activity (2-4 cycles/minute), bradygastria (0.5-2 cycles/minute), tachygastria (4-9 cycles/minute), dominant frequency and power of the dominant frequency. Nineteen asymptomatic healthy volunteers served as a control group. Forty-nine patients, who had undergone upper intestinal surgery, were included in the study (cholecystectomy n = 10, Nissen fundoplication n = 10, subtotal gastrectomy n = 8, truncal vagotomy, and gastric pull-up as esophageal replacement n = 6). Twenty of these patients complained of epigastric symptoms post-operatively, while 12 of these 20 patients also had a scintigraphic gastric emptying study with Tc99m labeled semisolid meal. Preprandial gastric electric activity was between 2 and 4 cycles/minute in 60-90% of the study time in healthy volunteers. In all study groups the prevalence and power of normal electric activity increased significantly after the test meal (p<0.001). After cholecystectomy, Nissen fundoplication, subtotal gastrectomy or vagotomy and gastric pull-up pre- and postprandial gastric electric activity showed a greater variability compared to normal volunteers (p<0.05), but no typical electrogastrography pattern could be identified for the different surgical procedures. There was no significant difference in the electrogastrography pattern between asymptomatic and symptomatic patients and patients with normal or abnormal scintigraphic gastric emptying curves.\nQuestion: Transcutaneous electrogastrography: a non-invasive method to evaluate post-operative gastric disorders?",
        "gt": "There is no specific electrogastrography pattern to differentiate between typical surgical procedures or epigastric symptoms. To date, electrogastrography does not contribute to the diagnosis and analysis of gastric motility disorders after upper intestinal surgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate whether self reporting of psychological demands and control at work is as valid for psychologically distressed subjects as for subjects with psychological wellbeing. Self reported demands and control (according to the model of Karasek) were compared to expert assessments through direct observations of each subject's work conditions concerning time pressure, hindrances, qualification for work tasks, and possibility of having influence. The comparison was made between respondents reporting and not reporting psychological distress as measured by the general health questionnaire with 12 questions (GHQ-12). The sample consisted of 203 men and women in 85 occupations. No systematic differences between self reported and externally assessed working conditions for respondents reporting different levels of psychological distress were found.\nQuestion: Does psychological distress influence reporting of demands and control at work?",
        "gt": "Over-reporting of work demands or under-reporting of work control is unlikely at the levels of psychological distress studied.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Many researchers have speculated that markers of malnutrition such as albumin, prealbumin, cholesterol, and transferrin are influenced by inflammation. The mechanism of this interaction has not been well understood. This was a prospective cross-sectional study. We evaluated 72 male patients older than 60 years admitted to a geriatric rehabilitation unit. Subjects with severe hepatic or renal diseases were excluded. We measured body mass index, caloric intake, serum albumin, prealbumin, cholesterol, transferrin, hemoglobin, and total lymphocyte count. To detect inflammation, we measured C-reactive protein, Westergren sedimentation rate, fibrinogen, and cytokines including tumor necrosis factor-alpha (TNF-alpha), interleukin-1 beta (IL-1 beta), IL-6, IL-2, and the soluble IL-2 receptor. Soluble IL-2 receptor was negatively associated with albumin (r = -.479, p<.0001), prealbumin (r = -.520, p =<.0001), cholesterol (r = -.487, p = .0001), transferrin (r = -.455, p = .0002), and hemoglobin (r = -.371, p = .002). TNF-alpha, IL-1 beta, IL-6, and IL-2 were not associated with these measures.\nQuestion: Is malnutrition overdiagnosed in older hospitalized patients?",
        "gt": "Inflammation increases the incidence of hypoalbuminemia and hypocholesterolemia, potentially leading to overdiagnosis of malnutrition. We suggest that albumin, cholesterol, prealbumin, and transferrin be used with caution when assessing the nutritional status of older hospitalized patients. In the future, soluble IL-2 receptor levels might be used to correct for the impact of inflammation on these markers of malnutrition.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To study the effectiveness of combined integral somatic and psychiatric treatment in a medical-psychiatric unit (MPU). Retrospective case-note study. The case notes of all patients admitted to the MPU at the VU Medical Center, Amsterdam, in 2011 were analysed. Data on reasons for referral and somatic and psychiatric diagnoses were collected. Using a global clinical assessment scale and the Health of the Nations Outcome Scales (HoNOS), data on psychiatric symptomology and limitations, behavioural problems, social problems and limitations associated with physical health problems were collected on both admission and discharge. In this way the effect of the admission period on various problems was determined. In 2011 there were 139 admissions to the MPU with a wide variation of somatic and psychiatric diagnoses. The average admission period was 9 days. Global clinical evaluation of the treatment goals set for somatic and psychiatric conditions showed that more than 90% and 85% of the treatment goals, respectively, were completely achieved. HoNOS scores showed a reduction in severity of both psychiatric and somatic problems. The total HoNOS-core was significantly reduced by nearly 3.5 points - a large effect size.\nQuestion: A medical-psychiatric unit in a general hospital: effective combined somatic and psychiatric care?",
        "gt": "The MPU has succeeded in its goal to deliver integral care to a very diverse group of patients with somatic and psychiatric co-morbidities. It is able to offer care to a vulnerable patient group in which it can be presumed that treatment on a non-integrated unit could not have been delivered or not delivered adequately, due to the complexity of their somatic and behavioural problems.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine if patients with non-small cell lung carcinoma (NSCLC) and positive supraclavicular nodes (SN+) have a similar outcome to other patients with Stage IIIB NSCLC (SN-) when treated with modern chemoradiotherapy. Using the Radiation Therapy Oncology Group (RTOG) database, data were retrospectively analyzed from five RTOG trials studying chemoradiotherapy for 88-04, 88-08 (chemo-RT arm), 90-15, 91-06, 92-04. Comparisons were made between the SN+ and SN- subgroups with respect to overall survival, progression-free survival (PFS), and metastases-free survival (MFS) using the log rank test. Cox multivariate proportional hazards regression analysis was used to determine the effect of several potential confounding variables, including histology (squamous vs. nonsquamous), age (>60 vs.<or = 60), Karnofsky Performance Status (KPS) (<90 vs.>or = 90), weight loss (>or = 5% vs.<5%), and gender. A total of 256 Stage IIIB patients were identified, of whom 47 had supraclavicular nodes (SN+) and 209 did not (SN-). Statistically significantly more SN+ patients had nonsquamous histology (p = 0.05); otherwise, known prognostic factors were well balanced. The median survival for SN+ patients was 16.2 months, vs. 15.6 months for SN- patients. The 4-year actuarial survival rates were 21% and 16% for SN+ and SN- patients respectively (p = 0.44). There was no statistically significant difference in the 4-year PFS rates (19% vs. 14%, p = 0.48). The Cox analysis did not show the presence or absence of supraclavicular nodal disease to be a prognostic factor for survival, MFS, or PFS. The only statistically significant factor on multivariate analysis was gender, with males having a 40% greater risk of mortality than females (p = 0.03). There were no clinically significant differences in toxicity when comparing SN+ vs. SN- patients. Among the 47 SN+ patients, there were no reported cases of brachial plexopathy or other>or = Grade 2 late neurologic toxicity.\nQuestion: Is prolonged survival possible for patients with supraclavicular node metastases in non-small cell lung cancer treated with chemoradiotherapy?",
        "gt": "When treated with modern chemoradiotherapy, the outcome for patients with supraclavicular metastases appears to be similar to that of other Stage IIIB patients. SN+ patients should continue to be enrolled in trials studying aggressive chemoradiotherapy regimens for locally advanced NSCLC.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Several studies have reported higher prevalence of obesity in patients suffering from bipolar disorder (BD). To study the relation of elevated body mass index (BMI) in patients with BD more closely, we investigated differences in sociodemographic, clinical, and medical characteristics with respect to BMI, with the hypothesis that BMI is related to prognosis and outcome. We measured the BMI of 276 subjects of a tertiary care sample from the Maritime Bipolar Registry. Subjects were 16 to 83 years old, with psychiatric diagnoses of bipolar I disorder (n = 186), bipolar II disorder (n = 85), and BD not otherwise specified (n = 5). The registry included basic demographic data and details of the clinical presentation. We first examined the variables showing a significant association with BMI; subsequently, we modeled the relationship between BMI and psychiatric outcome using structural equation analysis. The prevalence of obesity in our sample was 39.1%. We found higher BMI in subjects with a chronic course (p<0.001) and longer duration of illness (p = 0.02), lower scores on the Global Assessment of Functioning Scale (p = 0.02), and on disability (p = 0.002). Overweight patients had more frequent comorbid subthreshold social (p = 0.02) and generalized anxiety disorders (p = 0.05), diabetes mellitus type II (p<0.001), and hypertension (p = 0.001). Subjects who achieved complete remission of symptoms on lithium showed significantly lower BMI (p = 0.01).\nQuestion: Can body mass index help predict outcome in patients with bipolar disorder?",
        "gt": "Our findings suggest that BMI is associated with the prognosis and outcome of BD. Whether this association is causal remains to be determined.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether the behavioral participation in muscle-strengthening activity (MSA) or the strength outcome produces the largest reduction in all-cause mortality risk. The 1999-2002 National Health and Nutritional Examination Survey was used, with follow-up of up to 12.6 years (mean, 9.9 years) (N=2773 adults aged \u226550 years). Participants were placed into 4 groups based on 2 dichotomously categorized variables: lower-extremity strength (LES) of the knee extensors (top quartile) and adherence to MSA guidelines (\u22652 MSA sessions per week). Approximately 21% of the population died during follow-up. Compared with individuals not meeting MSA guidelines and not in top quartile for LES, the adjusted hazard ratios (HRs) and 95% CIs were as follows: (1) meets MSA guidelines but not in top quartile for LES (HR=0.96; 95% CI, 0.63-1.45; P=.84), (2) in top quartile for LES but does not meet MSA guidelines (HR=0.54; 95% CI, 0.42-0.71; P<.001), and (3) in top quartile for LES and meets MSA guidelines (HR=0.28; 95% CI, 0.12-0.66; P=.005). Further analyses revealed that individuals in\u00a0the top quartile for LES who also met MSA and moderate to vigorous physical activity guidelines were at even further reduced risk for premature all-cause mortality (HR=0.23; 95% CI, 0.08-0.61; P=.005).\nQuestion: Determining the Importance of Meeting Muscle-Strengthening Activity Guidelines: Is the Behavior or the Outcome of the Behavior (Strength) a More Important Determinant of All-Cause Mortality?",
        "gt": "These results demonstrate that muscle strength seems to be more important than the behavioral participation in MSA for reducing the risk of premature all-cause mortality.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Depression is a common problem, often being recurrent or becoming chronic. The National Service Framework for Mental Health (published by the Department of Health, 1999) states that people with depression should continue to be predominantly managed in primary care. There is much evidence that the detection and management of depression by GPs could be improved, but little work has focused on GPs' views of their work with depressed patients. This was a qualitative study exploring GP attitudes to the management of patients with depression. Views of GPs in socio-economically deprived areas are compared with those serving more affluent populations. Semi-structured interviews were conducted with two groups of GPs in north-west England. One group of GPs (22) were practising in inner-city areas, and a second group (13) in suburban and semi-rural practices. All were Principals in practices that participated in undergraduate teaching. The interviews were audio-taped and subsequently transcribed verbatim. Analysis was by constant comparison until category saturation of each theme was achieved. Subjects conceptualized depression as an everyday problem of practice, rather than as an objective diagnostic category. Thematic coding of their accounts suggests a tension between three kinds of views of depressed people: (i) That depression is a common and normal response to life events or change and that it reflects the medicalization of these conditions; (ii) That the label or diagnosis of depression offers a degree of secondary gain to both patients and doctors, particularly to those GPs practising in inner-city areas and (iii) That inner-city GPs experienced on-going management of depressed people as an interactional problem, in contrast to those GPs serving a less deprived population who saw depression as a treatable illness and as rewarding work for the GP.\nQuestion: Managing depression in primary care: another example of the inverse care law?",
        "gt": "Depression is commonly presented to GPs who feel that the diagnosis often involves the separation of a normal reaction to environment and true illness. For those patients living in socio-economically deprived environments, the problems, and therefore the depression, are seen to be insoluble. This has an important implication for the construction of educational interventions around improving the recognition and treatment of depression in primary care: some doctors may be reluctant to recognize and respond to such patients in depth because of the much wider structural and social factors that we have suggested in this paper. That it is the doctors working with deprived populations who express these views, means that the 'Inverse care law' [Tudor Hart J. The inverse care Law. Lancet 1971; 1(7696): 405-412] operates in the management of depression.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In recent years, due to a high persistence, biomagnification in food webs, presence in remote regions, and potential toxicity, perfluorochemicals (PFCs) have generated a considerable interest. The present study was aimed to determine the levels of perfluorooctane sulfonate (PFOS), perfluorooctanoic acid (PFOA), and other PFCs in drinking water (tap and bottled) and river water samples from Tarragona Province (Catalonia, Spain). Municipal drinking (tap) water samples were collected from the four most populated towns in the Tarragona Province, whereas samples of bottled waters were purchased from supermarkets. River water samples were collected from the Ebro (two samples), Cortiella, and Francol\u00ed Rivers. After pretreatment, PFC analyses were performed by HPLC-MS. Quantification was done using the internal standard method, with recoveries between 68% and 118%. In tap water, PFOS and PFOA levels ranged between 0.39 and 0.87 ng/L (0.78 and 1.74 pmol/L) and between 0.32 and 6.28 ng/L (0.77 and 15.2 pmol/L), respectively. PFHpA, PFHxS, and PFNA were also other detected PFCs. PFC levels were notably lower in bottled water, where PFOS could not be detected in any sample. Moreover, PFHpA, PFHxS, PFOA, PFNA, PFOS, PFOSA, and PFDA could be detected in the river water samples. PFOS and PFOA concentrations were between<0.24 and 5.88 ng/L (<0.48 and 11.8 pmol/L) and between<0.22 and 24.9 ng/L (<0.53 and 60.1 pmol/L), respectively. Assuming a human water consumption of 2 L per day, the daily intake of PFOS and PFOA by the population of the area under evaluation was calculated (0.78-1.74 and 12.6 ng, respectively). It was found that drinking water might be a source of exposure to PFCs as important as the dietary intake of these pollutants.\nQuestion: Levels of perfluorochemicals in water samples from Catalonia, Spain: is drinking water a significant contribution to human exposure?",
        "gt": "The contribution of drinking water (tap and bottled) to the human daily intake of various PFCs has been compared for the first time with data from dietary intake of these PFCs. It was noted that in certain cases, drinking water can be a source of exposure to PFCs as important as the dietary intake of these pollutants although the current concentrations were similar or lower than those reported in the literature for surface water samples from a number of regions and countries.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We sought to determine whether location of the second internal thoracic artery (ITA) graft used for bilateral ITA grafting affects mortality and morbidity of patients with 3-system coronary artery disease and to identify factors associated with second ITA location. From January 1972 to June 2006, 3611 patients with 3-system coronary artery disease underwent bilateral ITA grafting with one graft anastomosed to the left anterior descending system and the second to either the circumflex (n=2926) or right coronary artery (n=685) system. Follow-up was 9.2+/-7.2 years. Propensity score methodology was used to obtain risk-adjusted outcome comparisons between patients with the second ITA to circumflex versus right coronary artery. Hospital mortality (0.34% versus 0.58%; P=0.4), stroke (0.96% versus 0.88%; P=0.8), myocardial infarction (1.3% versus 0.73%; P=0.2), renal failure (0.44% versus 0.29%; P=0.6), respiratory insufficiency (3.5% versus 3.8%; P=0.7), and reoperation for bleeding (3.4% versus 3.2%; P=0.8) were similar in patients who received the second ITA to circumflex or right coronary artery and remained similar after propensity score adjustment. Late survival (86% versus 87% at 10 years) was also similar. Despite this, there was a gradual decline in ITA to right coronary artery grafting.\nQuestion: Does location of the second internal thoracic artery graft influence outcome of coronary artery bypass grafting?",
        "gt": "Contrary to prevailing wisdom that the second ITA graft should be anastomosed to the next most important left-sided coronary artery in 3-system coronary artery disease, it may be placed to either the circumflex or right coronary artery system with similar early and late outcomes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We assessed the outcome of vesicoureteral reflux after augmentation cystoplasty in patients with neurogenic bladder. Since May 1992, 112 male and 18 female patients with neurogenic bladder have undergone augmentation cystoplasty with a generous detubularized segment of bowel and no effort to correct existing reflux. Patients were treated conservatively at the beginning but the response was unsatisfactory. All patients had various degrees of vesicoureteral reflux (197 refluxing units). Mean age at operation was 21.6 years (range 1.5 to 57). Preoperatively assessment included urinalysis, urine culture, kidney function tests, voiding cystourethrography, urodynamic evaluation, ultrasonography or excretory urography and cystoscopy when indicated. The status of vesicoureteral reflux, renal hydronephrosis and clinical pyelonephritis were studied during an average followup of 44.5 months. Of the 130 patients 111 (85.4%) no longer had reflux, 14 (10.8%) had improvement, 4 (3%) had no change and 1 (0.8%) had worsening reflux. All refluxing units with grades I to III, 105 of 120 with grade IV (87.5%) and 8 of 13 with grade V (61.5%) showed complete cessation of reflux. Renal hydronephrosis improved in 127 renal units (97.7%). In 8 individuals (6.2%) without reflux after cystoplasty episodes of clinical pyelonephritis occurred.\nQuestion: Is ureteral reimplantation necessary during augmentation cystoplasty in patients with neurogenic bladder and vesicoureteral reflux?",
        "gt": "Augmentation cystoplasty without ureteral reimplantation is effective and adequate treatment for high pressure, noncompliant neurogenic bladder when conservative management fails.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the incidence and type of biliary complications in liver transplantation after biliary reconstruction with or without a biliary tutor. A prospective, non-randomized study of 128 consecutive patients undergoing elective liver transplantation was performed. Retransplantations, emergency transplantations, hepaticojejunostomy and patients who died within 3 months of causes other than biliary complications were excluded. Group I (n = 64) underwent termino-terminal choledochocholedochostomy with a Kehr tube and group II (n = 64) underwent choledochocholedochostomy without Kehr tube. Complications, therapeutic procedures, reoperations and survival free of biliary complications were analyzed. The overall rate of biliary complications was 15% (17% in group I and 14% in group II). Types of complication (overall and in groups I and II, respectively) consisted of fistulas 4% (6% vs. 3%), stenosis 8% (4% vs. 12%), and Kehr dysfunction 3%. The mean number of therapeutic procedures, including endoscopic retrograde cholangiopancreatography, percutaneous transhepatic cholangiography, trans-Kehr cholangiography and drainage of collections, was 2.1 vs. 2 per complicated patient. The overall reoperation rate was 5% (2% vs. 9%) (p<0.05). One-year survival free of biliary complications was 85% vs. 82% (Log Rank = 0.5).\nQuestion: Biliary reconstruction in liver transplantation: is a biliary tutor necessary?",
        "gt": "No statistically significant differences were found in complications after choledocho-choledocho anastomosis with or without a biliary tutor. However, the patient group that did not receive a biliary tutor required more complex procedures for treatment of complications, as well as a greater number of reoperations.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The increasing incidence of hip fractures in our aging population challenges orthopedic surgeons and hospital administrators to effectively care for these patients. Many patients present to regional hospitals and are transferred to tertiary care centres for surgical management, resulting in long delays to surgery. Providing timely care may improve outcomes, as delay carries an increased risk of morbidity and mortality. We retrospectively reviewed the cases of all patients with hip fractures treated in a single Level 1 trauma centre in Canada between 2005 and 2012. We compared quality indicators and outcomes between patients transferred from a peripheral hospital and those directly admitted to the trauma centre. Of the 1191 patients retrospectively reviewed, 890 met our inclusion criteria: 175 who were transferred and 715 admitted directly to the trauma centre. Transfer patients' median delay from admission to operation was 93 hours, whereas nontransfer patients waited 44 hours (p<0.001). The delay predominantly occurred before transfer, as the patients had to wait for a bed to become available at the trauma centre. The median length of stay in hospital was 20 days for transfer patients compared with 13 days for nontransfer patients (p<0.001). Regional policy changes enacted in 2011 decreased the median transfer delay from regional hospital to tertiary care centre from 47 to 27 hours (p = 0.005).\nQuestion: A comparison of surgical delays in directly admitted versus transferred patients with hip fractures: opportunities for improvement?",
        "gt": "Policy changes can have a significant impact on patient care. Prioritizing patients and expediting transfer will decrease overall mortality, reduce hospital stay and reduce the cost of hip fracture care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The optimal management of patients with ureteric obstruction in advanced pelvic malignancy is unclear. Effective judgment is required to decide which patients would benefit most from decompression of the urinary tract. The objective of our study was to assess survival and complication rates post-percutaneous nephrostomy (PCN) in patients with ureteric obstruction due to advanced pelvic malignancy. A detailed retrospective case review of all patients who underwent PCN for ureteric obstruction due to pelvic malignancy in one calendar year was conducted to assess indication, survival time, length of stay post-procedure and complications. Thirty-six nephrostomies were performed on 22 patients with prostate cancer being the commonest primary (55 %). Renal failure was the commonest mode of presentation (56 %). Eight patients (36 %) presented without a prior diagnosis of cancer. All PCNs except one were initially technically successful, and 56 % of renal units were able to be antegradely stented and rendered free of nephrostomy. Median survival post-nephrostomy was 78 days (range 4-1,137), with the subset of bladder cancer patients having the poorest survival. Dislodgement of the nephrostomy tube was the most common troublesome complication which led to the greatest morbidity, sometimes requiring repeat nephrostomy insertion. Patients stayed for a median of 23 (range 3-89) days in hospital, which amounted to 29 % of their remaining lifetime spent in hospital.\nQuestion: Percutaneous nephrostomy for ureteric obstruction due to advanced pelvic malignancy: have we got the balance right?",
        "gt": "Although effective in improving renal function, PCN is a procedure not without associated morbidity and does not always prolong survival. Therefore, the decision to decompress an obstructed kidney with advanced pelvic malignancy should not be taken lightly. We recommend that such cases be discussed in a multidisciplinary setting, and a decision is taken only after a full informed discussion involving patients and their relatives.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to determine the effectiveness of Kinesio taping (KT) application added to the exercise treatment of subacromial impingement syndrome (SIS). Thirty-eight (25 female, 13 male) patients with SIS were randomly divided into therapeutic KT (n=19) and sham KT (n=19) groups. All patients received the same exercise therapy in addition to therapeutic or sham KT at 3-day intervals for 12 days. The groups were compared according to pain, range of motion (ROM), muscle strength and DASH and Constant scores before treatment and at the 5th and 12th treatment days. Within group comparisons showed significant improvements in both groups at the 5th and 12th day evaluations (p<0.05). In comparisons between the groups, pain with movement and DASH scores in the therapeutic group were significantly lower at the 5th day (p<0.01). There were significant improvements in night pain, pain with movement, DASH score, shoulder external rotation muscle strength, and pain free shoulder abduction ROM in the therapeutic group at the 12th day (p<0.05). Passive shoulder flexion ROM increased more in the sham group at the 12th day (p<0.05).\nQuestion: Does Kinesio taping in addition to exercise therapy improve the outcomes in subacromial impingement syndrome?",
        "gt": "The addition of KT application to the exercise program appears to be more effective than the exercise program alone for the treatment of SIS.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the time course of major vessel recanalization under IV thrombolysis in relation to functional outcome in acute ischemic stroke. A total of 99 patients with an acute anterior circulation vessel occlusion who underwent IV thrombolysis were included. All patients had a standardized admission and follow-up procedure. Color-coded duplex sonography was performed on admission, 30 minutes after thrombolysis, and at 6 and 24 hours after onset of symptoms. Recanalization was classified as complete, partial, and absent. Functional outcome was rated with the modified Rankin Scale on day 30. Complete recanalization occurred significantly more frequently in patients with multiple branch occlusions compared to those with mainstem occlusion (OR 5.33; 95% CI, 2.18 to 13.05; p<0.0001) and was associated with lower NIH Stroke Scale (NIHSS) scores (p<0.001). Not the specific time point of recanalization at 6 or 24 hours after stroke onset, but recanalization per se within 24 hours (OR 7.8; 95% CI 2.2 to 28.2; p = 0.002) was significantly associated with a favorable outcome. Multivariate analysis revealed recanalization at any time within 24 hours and NIHSS scores on days 1 and 7 together explaining 75% of the functional outcome variance 30 days after stroke.\nQuestion: Recanalization after intravenous thrombolysis: does a recanalization time window exist?",
        "gt": "Complete recanalization up to 24 hours after stroke onset is significantly associated with the short-term clinical course and functional outcome 30 days after acute stroke.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Accelerated coronary artery disease (ACAD), a serious consequence after heart transplantation, is characterized by diffuse, concentric myointimal proliferation in the arteries. Increasing evidence supports the existence of a local renin-angiotensin system and the role of angiotensin-II in smooth muscle cell proliferation. We investigated the effect of angiotensin-II blocker candesartan and angiotensin-converting enzyme (ACE) inhibitor enalapril on experimental ACAD in a rat model. After heterotopic cardiac transplantation (Fisher to Lewis), recipients received 20 mg/kg/day candesartan or 40 mg/kg/day enalapril per os. Two groups of animals received additional pre-treatment with candesartan or enalapril 7 days before transplantation, and treatment was continued after grafting. All study groups including the controls received 3 mg/kg/day of sub-cutaneous cyclosporine for immunosuppression. A syngeneic group (Lewis to Lewis), serving as extra control, did not receive any treatment. Eighty days after grafting, we assessed the extent of ACAD in large and small arteries, using digitizing morphometry and expressed as mean vascular occlusion (MVO). In enalapril and candesartan pre- and post-treated animals, we observed significant reduction of MVO of intramyocardial arteries compared with the cyclosporine group (p<0.005), to levels similar to the syngeneic transplants. MVO of epicardial arteries in enalapril and candesartan pre- or posttreated animals did not significantly differ from cyclosporine controls (p>0.05).\nQuestion: Do vascular compartments differ in the development of chronic rejection?",
        "gt": "Our results support the hypothesis of 2 proliferative compartments in the development of ACAD, with differing receptor or enzyme distribution: the compartment of small, intramyocardial arteries in which ACAD can be reduced by ACE or AT(1) blockade, and that of large, epicardial arteries in which inhibition fails.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The right ventricle (RV) supports the systemic circulation in patients who have had an intraatrial repair of transposition of the great arteries or have congenitally corrected transposition. There is concern about the ability of a systemic RV to support the additional volume load of pregnancy, and previous studies have reported deterioration in RV function following pregnancy. However, conditions with a systemic RV are also associated with progressive RV dysfunction over time. To date, no study has examined whether the deterioration associated with pregnancy is due to the physiological changes of pregnancy itself, or is part of the known deterioration that occurs with time in these patients. Women who had undergone pregnancy under the care of the Adult Congenital Heart Disease Unit at the Queen Elizabeth Hospital were retrospectively identified and matched to separate male and nulliparous female controls. Functional status (New York Health Association [NYHA]), RV function, and systemic atrioventricular valve regurgitation were recorded for each group at baseline, postpregnancy (or at 1 year for control groups) and at latest follow-up. Eighteen women had 31 pregnancies (range 1-4) resulting in 32 live births. There were no maternal but one neonatal death. At baseline, there was no significant difference in NYHA class or RV function between pregnancy and control groups. In postpregnancy, there was a significant deterioration in the pregnant group alone for both NYHA class (P = 0.004) and RV function (P = 0.02). At latest follow-up, there was a significant deterioration in RV function in all three groups. There was still a reduction from baseline in NYHA of women who had undergone pregnancy (P = 0.014), which again was not seen in the controls groups.\nQuestion: Long-term outcome following pregnancy in women with a systemic right ventricle: is the deterioration due to pregnancy or a consequence of time?",
        "gt": "This study suggests that pregnancy is associated with a premature deterioration in RV function in women with a systemic RV. These women are also more symptomatic, with a greater reduction in functional class compared with patients with a systemic RV who do not undergo pregnancy. This study will allow this cohort of women to be more accurately counseled as to the potential long-term risks of pregnancy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Non traumatic epistaxis seems to be clustering in different periods. This paper tries to find out if there is any relationship between incidence of epistaxis and the year season, month, week, day, hour and/or lunar phase. We have retrospectively studied 754 episodes seen between May 2001 and April 2002 in our Hospital. The following parameters were registered in each patient: age, sex, number of episodes, season, month, week, day, hour and lunar phase. Epistaxis represented 12.1% of the total otolaryngological emergencies. That means an incidence of 0.1% of non traumatic epistaxis which needed hospital specialized attention. We found statistical differences (p = 0.003) in the number of epistaxis per day and the different months (greater in june and november). No differences were found in the remaining periods studied.\nQuestion: Does clustering exist in non-traumatic epistaxis?",
        "gt": "This paper shows monthly clustering of epistaxis episodes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine the health consequences of exposure to income inequality. Secondary analysis employing data from several publicly available sources. Measures of individual health status and other individual characteristics are obtained from the March Current Population Survey (CPS). State-level income inequality is measured by the Gini coefficient based on family income, as reported by the U.S. Census Bureau and Al-Samarrie and Miller (1967). State-level mortality rates are from the Vital Statistics of the United States, other state-level characteristics are from U.S. census data as reported in the Statistical Abstract of the United States. We examine the effects of state-level income inequality lagged from 5 to 29 years on individual health by estimating probit models of poor/fair health status for samples of adults aged 25-74 in the 1995 through 1999 March CPS. We control for several individual characteristics, including educational attainment and household income, as well as regional fixed effects. We use multivariate regression to estimate the effects of income inequality lagged 10 and 20 years on state-level mortality rates for 1990, 1980, 1970, and 1960. Lagged income inequality is not significantly associated with individual health status after controlling for regional fixed effects. Lagged income inequality is not associated with all cause mortality, but associated with reduced mortality from cardiovascular disease and malignant neoplasms, after controlling for state fixed-effects.\nQuestion: Is exposure to income inequality a public health concern?",
        "gt": "In contrast to previous studies that fail to control for regional variations in health outcomes, we find little support for the contention that exposure to income inequality is detrimental to either individual or population health.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the discrepancies between outcomes for competence (can do) and actual performance (do do) in activities of daily living (ADLs). Baseline measurements of a population-based follow-up study. Leiden 85-Plus Study, the Netherlands. Five hundred and ninety-nine persons, age 85. The response rate was 86%. Face-to-face interviews. Measurements of competence and actual performance were based on the Groningen Activity Restriction Scale. Help received was assessed for several domains. Prevalence rates for disability were assessed according to the concepts of both competence and actual performance. Analysis was performed separately for basic activities of daily living (BADLs) and instrumental activities of daily living (IADLs). Seventy-seven percent of the oldest old were competent to perform all the BADLs and performed them regularly. Fifteen percent were not competent to perform certain BADLs independently but performed them regularly with help from others. The prevalence of disability defined as inability in one or more BADLs was 22% for women and 10% for men. The prevalence of disability defined as inactivity in one or more BADLs was 16% for women and 17% for men. Only 5% of the oldest old were competent to perform all IADLs and performed them regularly. In spite of being competent, 70% did not perform certain IADLs regularly. The prevalence of disability defined as inability in one or more IADLs was 64% for women and 55% for men. The prevalence of disability defined as inactivity in one or more IADLs was 92% for women and 98% for men.\nQuestion: Disability in the oldest old: \"can do\" or \"do do\"?",
        "gt": "The structural discrepancies between the outcomes of competence and actual performance have important consequences when estimating disability in old people. Promoting actual performance in IADLs may reduce disability.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To analyze outcomes in simultaneous kidney-pancreas transplantation (SKPT) recipients who retain C-peptide production at the time of SKPT. This retrospective analysis of SKPTs from January 2002 through January 2007 compared outcomes between patients with absent or low C-peptide levels (<2.0 ng/mL, group A) with those having levels>or =2.0 ng/mL (group B). Among 74 SKPTs, 67 were in group A and seven in group B (mean C-peptide level 5.7 ng/mL). During transplantation, group B subjects were older (mean age 51 vs 41 years, P = .006); showed a later age of onset of diabetes (median 35 vs 13 years, P = .0001); weighed more (median 77 vs 66 kg, P = .24); had a greater proportion of African-Americans (57% vs 13%, P = .004); and had a longer pretransplant duration of dialysis (median 40 vs 14 months, P = .14). With similar median follow-up of 40 months, death-censored kidney (95% group A vs 100% group B, P = NS) and pancreas (87% group A vs 100% group B, P = NS) graft survival rates were similar, but patient survival (94% group A vs 71% group B, P = .03) was greater in group A. At 1-year follow-up, there were no significant differences in rejection episodes, surgical complications, infections, readmissions, hemoglobin A1C or C-peptide levels, serum creatinine, or MDRD GFR levels.\nQuestion: Do pretransplant C-peptide levels influence outcomes in simultaneous kidney-pancreas transplantation?",
        "gt": "Diabetic patients with measurable C-peptide levels before transplant were older, overweight, more frequently African-American and had a later age of onset of diabetes, longer duration of pretransplant dialysis, and reduced patient survival compared to insulinopenic patients undergoing SKPT. The other outcomes were similar.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Prior research has suggested that patients who travel out of their neighborhood for elective care from specialized medical centers may have better outcomes than local patients with the same illnesses who are treated at the same centers. We hypothesized that this phenomenon, often called \"referral bias\" or \"distance bias,\" may also be evident in curative-intent cancer trials at specialized cancer centers. We evaluated associations between overall survival and progression-free survival and the distance from the patient residence to the treating institution for 110 patients treated on one of four phase II curative-intent chemoradiotherapy protocols for locoregionally advanced squamous cell cancer of the head and neck conducted at the University of Chicago over 7 years. Using Cox regression that adjusted for standard patient-level disease and demographic factors and neighborhood-level economic factors, we found a positive association between the distance patients traveled from their residence to the treatment center and survival. Patients who lived more than 15 miles from the treating institution had only one-third the hazard of death of those living closer (hazard ratio [HR]= 0.32, 95% confidence interval [CI] = 0.12 to 0.84). Moreover, with every 10 miles that a patient traveled for care, the hazard of death decreased by 3.2% (HR = 0.97, 95% CI = 0.94 to 0.99). Similar results were obtained for progression-free survival.\nQuestion: Is patient travel distance associated with survival on phase II clinical trials in oncology?",
        "gt": "Results of phase II curative-intent clinical trials in oncology that are conducted at specialized cancer centers may be confounded by patient travel distance, which captures prognostic significance beyond cancer stage, performance status, and wealth. More work is needed to determine what unmeasured factors travel distance is mediating.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We compare the performance of a wrist blood pressure oscillometer with the mercury standard in the triage process of an emergency department (ED) and evaluate the impact of wrist blood pressure measurement on triage decision. Blood pressure was successively measured with the standard mercury sphygmomanometer and with the OMRON-RX-I wrist oscillometer in a convenience sample of 2,493 adult patients presenting to the ED with non-life-threatening emergencies. Wrist and mercury measures were compared using criteria of the Association for the Advancement of Medical Instrumentation (AAMI) and the British Hypertension Society (BHS). The impact on triage decisions was evaluated by estimating the rate of changes in triage decisions attributable to blood pressure results obtained with the wrist device. Wrist oscillometer failed to meet the minimal requirements for recommendation by underestimating diastolic and systolic blood pressure. Mean (+/-SD) differences between mercury and wrist devices were 8.0 mm Hg (+/-14.7) for systolic and 4.2 mm Hg (+/-12.0) for diastolic measures. The cumulative percentage of blood pressure readings within 5, 10, and 15 mm Hg of the mercury standard was 32%, 58%, and 72% for systolic, and 40%, 67%, and 83% for diastolic measures, respectively. Using the wrist device would have erroneously influenced the triage decision in 7.6% of the situations. The acuity level would have been overestimated in 2.2% and underestimated in 5.4% of the triage situations.\nQuestion: Can wrist blood pressure oscillometer be used for triage in an adult emergency department?",
        "gt": "The performance of the OMRON-RX-I wrist oscillometer does not fulfill the minimum criteria of AAMI and BHS compared with mercury standard in the ED triage setting.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Tracheal stenosis and dehiscence of anastomosis due to excessive tension are well-known problems after long-segment tracheal resections. The aim of this study was to evaluate the efficacy of the W-plasty technique to prevent these two complications. Animals were divided into a study and a control group. Each group consisted of 6 animals. In the control group, we performed a 5-cm tracheal segment resection, and then reconstruction was performed with an interrupted technique with 6/0 Prolene sutures. In the study group, we used the W-plasty technique with 6/0 Prolene interrupted sutures. The animals were sacrificed on the 30th day postoperatively and tracheal resection including the entire anastomosis site was performed. The traction and pullout test was applied to each specimen and all the specimens were analysed histopathologically. The intraluminal diameter and the thickness of the tracheal wall at the level of anastomoses were measured by using a micrometer. The pattern of the reaction and localization were recorded. The traction and pullout test results were 131.6 +/- 4.3 g and 187.5 +/- 6.4 g in the control and the study group, respectively, which was a significant difference (p = 0.004). The intraluminal diameters were 3.3 +/- 1.2 mm and 4.3 +/- 0.9 mm in the control and study group, respectively (p = 0.134). In contrast to the control group, early inflammatory and late fibroblastic reactions were negative in the study group.\nQuestion: W-plasty technique in tracheal reconstruction: a new technique?",
        "gt": "Considering the outcomes of this study, we think that the W-plasty technique has much more advantages than the standard techniques in terms of anastomosis durability and development of stenosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In order to treat children with Attention-deficit/Hyperactivity Disorder (ADHD) with a once-a-day stimulant several galenic approaches have been tried. The long acting methylphenidate (MPH, Medikinet-Retard) is a preparation with a two-step dynamic to release MPH (step one: acute; step two: prolonged). The efficacy of Medikinet-Retard, a new long-acting methylphenidate preparation, is analyzed based on the assessment of parents in the afternoon. In a multicenter drug treatment study (placebo controlled, randomized, double-blind) 85 children (normal intelligence, age 6 to 16 years, diagnosis of ADHD according to DSM-IV) were investigated over 4 weeks with weekly visits. Forty-three children received Medikinet-Retard and forty-two children placebo. The weekly dose titration depending on body weight and symptomatology allowed a final maximum of 60 mg. The effects on ADHD as perveived by the parents were assessed weekly with a German symptom checklist for ADHD according to DSM-IV and ICD-10 (FBB-HKS). The differences between baseline and last week of treatment were compared statistically between groups. There was a large and statistically significant positive drug effect on ADHD symptomatology. The effect size of these differences was d = 1.2 (total score). Effects were found on inattention, hyperactivity and impulsity on the respective subscales. The efficacy of Medikinet-Retard was evaluated by the parents on an average as good. The rate of responders was four-times higher in the verum-group. The correlations of the changed scores in the parent ratings with the respective change scores in the teacher ratings were in the medium range.\nQuestion: Does a morning dose of Methylphenidate Retard reduce hyperkinetic symptoms in the afternoon?",
        "gt": "This is the first study with a German long-acting methylphenidate preparation (Medikinet-Retard). According to data based on parents' assessments, the drug showed very good clinical efficacy and safety in children with ADHD. Its two step galenic release of methylphenidate seems to be appropriate for a once-a-day (morning) stimulant in schoolchildren.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There have been no definite indications for additional surgical resection after endoscopic submucosal dissection (ESD) of submucosal invasive colorectal cancer (SICC). The aims of this study were to evaluate the feasibility of ESD for nonpedunculated SICC and to determine the need for subsequent surgery after ESD. A total of 150 patients with nonpedunculated SICC in resected specimens after ESD were analyzed. Among them, 75 patients underwent subsequent surgery after ESD. Clinical outcomes of ESD and histopathological risk factors for lymph node (LN) metastasis were evaluated. The en-bloc resection and complete resection (R0) rates of ESD were 98% (147/150) and 95.3% (143/150), respectively. None of the patients had delayed bleeding after ESD. Perforations occurred in seven patients (4.7%), which were successfully treated by endoscopic clipping. After subsequent surgery for 75 patients, LN metastases were found in 10 cases (13.3%). The incidence of LN metastasis was significantly higher in tumors featuring submucosal invasion of at least 1500 \u03bcm, lymphovascular invasion, and tumor budding. Multivariate analysis showed that lymphovascular invasion (P=0.034) and tumor budding (P=0.015) were significantly associated with LN metastasis. Among the 150 patients, no local recurrence or distant metastasis was detected, except one patient with risk factors and who refused subsequent surgery, during the overall median follow-up of 34 months (range, 5-63 months).\nQuestion: Endoscopic submucosal dissection for nonpedunculated submucosal invasive colorectal cancer: is it feasible?",
        "gt": "ESD is feasible and may be considered as an alternative treatment option for carefully selected cases of nonpedunculated SICC, provided that the appropriate histopathological curative criteria are fulfilled in completely resectable ESD specimens.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether women are proportionately underselected at the level of the annual residency match. Data were obtained from the Royal College of Physicians and Surgeons of Canada and the Canadian Residency Matching Service. The odds of men being rejected from their top choice of surgical discipline were compared with the corresponding odds for women for the surgical specialties of general surgery, orthopedic surgery, neurosurgery, otolaryngology, urology, cardiac surgery and plastic surgery. Women continue to be underrepresented among surgery residents and surgeons in practice; however, the number of women has increased. Neither sex was overselected among the surgical specialties examined.\nQuestion: Does sex affect residency application to surgery?",
        "gt": "There was no evidence of overselection of either sex at the level of the annual resident selection committee.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We sought to study the individual and integrative role of amino-terminal pro-brain natriuretic peptide (NT-proBNP) and parameters of renal function for prognosis in heart failure. Amino-terminal pro-BNP and renal impairment both predict death in patients with heart failure. Worsening of renal function in heart failure even defines the \"cardiorenal syndrome.\" Seven hundred twenty subjects presenting with acute heart failure from 4 university-affiliated medical centers were dichotomized according to NT-proBNP concentration and baseline glomerular filtration rate. In addition, patients were divided according to changes in renal function. The primary end point was 60-day mortality. The combination of a glomerular filtration rate (GFR)<60 ml/min/1.73 m2 with an NT-proBNP>4,647 pg/ml was the best predictor of 60-day mortality (odds ratio 3.46; 95% confidence interval 2.13 to 5.63). Among subjects with an NT-proBNP above the median, those with a GFR<60 ml/min/1.73 m2 or a creatinine rise>or =0.3 mg/dl had the worst prognosis, whereas in subjects with a NT-proBNP below the median, prognosis was not influenced by either impaired renal function at presentation or the development of renal impairment during admission.\nQuestion: Amino-terminal pro-brain natriuretic Peptide, renal function, and outcomes in acute heart failure: redefining the cardiorenal interaction?",
        "gt": "The combination of NT-proBNP with measures of renal function better predicts short-term outcome in acute heart failure than either parameter alone. Among heart failure patients, the objective parameter of NT-proBNP seems more useful to delineate the \"cardiorenal syndrome\" than the previous criteria of a clinical diagnosis of heart failure.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: An adult trial reported the efficacy of recombinant human erythropoietin in critically ill patients with a 19% decrease in red blood cell transfusion. Our aim was to evaluate the relevance of this prophylactic treatment in children hospitalized in a pediatric intensive care unit (PICU). Cohort study from January 1995 to December 2004. University hospital PICU. Children between 1 month and 18 yrs of age. We searched through a prospective databank for all children hospitalized in the PICU for>or =4 days (potential recipients of erythropoietin, as proposed in the adult trial) and transfused with red blood cells after day 7 following PICU entry (in whom erythropoietin might prevent anemia, according to results of the adult trial). We found that 799 of 2,578 children (31%) were hospitalized for>or =4 days. The study group comprised 787 patients who were hospitalized for>or =4 days in the PICU and for whom full records were available. One hundred eighty-three children in this study group were transfused during their stay in the PICU (median age, 7 months; weight, 6.60 kg). Hemoglobin levels before transfusion (mean +/- sd) were 7.7 +/- 1.5 g/dL. These transfused children represented 23% of the study group and 7% of the total PICU admissions. Forty-seven children (6% of the study group, 2% of the total PICU admissions) were transfused with red blood cells after 7 days of hospitalization and could have benefited from a prophylactic treatment with erythropoietin. Relative risk to benefit of a prophylactic treatment by erythropoietin was higher in cases of mechanical ventilation (relative risk, 1.18) and inotropic treatment (relative risk, 1.72) and if the main diagnosis involved dermatological (relative risk, 3.03) or oncologic disease (relative risk, 3.94).\nQuestion: Is a prophylactic treatment by erythropoietin relevant to reduce red blood cell transfusion in the pediatric intensive care unit?",
        "gt": "If we applied the results of the adult trial to our PICU, we would have to treat 31% of the children with prophylactic erythropoietin and thereby expect a reduction of one red blood cell transfusion for every 17 treated patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It would be important to better identify heart failure (HF) patients most likely to respond to cardiac resynchronization therapy (CRT). Because endothelial progenitor cells (EPCs) play a crucial role in the maintenance of vascular endothelium integrity, we hypothesize that patients who have higher circulating EPCs levels have greater neovascularization potential and are more prone to be responders to CRT. Prospective study of 30 consecutive patients, scheduled for CRT. Echocardiographic evaluation was performed before implant and 6 months after. Responders to CRT were defined as patients who were still alive, have not been hospitalized for HF management, and demonstrated \u226515% reduction in left ventricular end-systolic volume (LVESV) at the 6-month follow-up. EPCs were quantified before CRT, from peripheral blood, by flow cytometry using five different conjugated antibodies: anti-CD34, anti-KDR, anti-CD133, anti-CD45, and anti-CXCR4. We quantified five different populations of angiogenic cells: CD133(+) /CD34(+) cells, CD133(+) /KDR(+) cells, CD133(+) /CD34(+) /KDR(+) cells, CD45(dim) CD34(+) /KDR(+) cells, and CD45(dim) CD34(+) /KDR(+) /CXCR4(+) cells. The proportion of responders to CRT at the 6-month follow-up was 46.7%. Responders to CRT presented higher baseline EPCs levels than nonresponders (0.0003 \u00b1 0.0006% vs 0.0001 \u00b1 0.0002%, P = 0.04, for CD34(+) /CD133(+) /KDR(+) and 0.0006 \u00b1 0.0005% vs 0.0003 \u00b1 0.0003%, P = 0.009, for CD45(dim) CD34(+) /KDR(+) /CXCR4(+) cells). In addition, baseline levels of CD45(dim) CD34(+) /KDR(+) /CXCR4(+) cells were positively correlated with the reduction of LVESV verified 6 months after CRT (r = 0.497, P = 0.008).\nQuestion: Circulating endothelial progenitor cells as a predictor of response to cardiac resynchronization therapy: the missing piece of the puzzle?",
        "gt": "High circulating EPCs levels may identify the subset of HF patients who are more likely to undergo reverse remodeling and benefit from CRT. Addition of EPCs levels assessment to current selection criteria may improve the ability to predict CRT response.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It has been shown previously that mortality from acute chronic obstructive pulmonary disease (COPD) is higher at small hospitals than at large teaching hospitals. To examine mortality at this acute stage and referral for further treatment by specialities in Finland, and trends in these between the 1990s and 2000s. Data on all periods of treatment for patients over 44 years of age with a principal or subsidiary diagnosis of COPD beginning and ending in 1995-2004 were extracted from the Finnish hospital discharge register. Particular attention was paid to acute-stage treatment periods managed by a general practitioner, pulmonary specialist, or specialist in internal medicine that had begun as emergency admissions and had a principal diagnosis of COPD, and to any further treatment immediately following these. General practitioners referred 5.1% of their acute-stage patients to a specialist in secondary care in 1995-2004. Of the total of 77,445 acute-stage treatment periods, 3% (2328) ended in the death of the patient, implying the loss of 8.3% of the patients involved. The age- and sex-adjusted risk of death attached to treatment periods managed by a general practitioner relative to those managed by a pulmonary specialist was 0.83 (95% CI 0.75-0.91).\nQuestion: Does place of treatment affect prognosis for chronic obstructive pulmonary disease (COPD)?",
        "gt": "It is quite possible to treat acute exacerbations of COPD efficiently and safely in a health centre hospital ward. New treatment modalities and health service structures seem to have led to a decrease in acute exacerbations of COPD since the year 2000, even though the number of patients with this disease has increased as a consequence of ageing of the population. Further research is required on the efficacy of treatment by a general practitioner, e.g., with data on re-hospitalization.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Numerous correlational studies have examined whether perceptions of vulnerability or worry are better predictors of health-related behavior. The aim of this experimental study was to explore some of the potential causal relationships involved: Are the effects of a brief smoking cessation intervention (for women attending for cervical smear tests) on intention to stop smoking mediated by perceived vulnerability or worry about cervical cancer? A mediation analysis of an experimental study. Perceived vulnerability to and worry about cervical cancer, and intention to stop smoking in the next month. Questionnaires were completed by 172 (71%) women at 2-week follow-up. Compared with women in the control group, those in the intervention group had higher perceptions of vulnerability, worry, and intention to stop smoking. Personal vulnerability (p<.01) and comparative vulnerability (p<.05) were significant mediators of the relationship between study group and intention to stop smoking. Worry about cervical cancer was not related to intention.\nQuestion: Do perceptions of vulnerability and worry mediate the effects of a smoking cessation intervention for women attending for a routine cervical smear test?",
        "gt": "Worry may be a less important construct in relation to disease prevention behaviors such as smoking cessation. More experimental studies comparing different behaviors are needed to determine the causal relationship between worry and outcomes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A severe degree of ureteral obstruction is viewed as a predictor of poor outcome in shockwave lithotripsy (SWL). Impacted stones are often considered a contraindication to in-situ SWL. Impaction in our study was defined as failure to visualize the ureter distal to the calculus with proximal hold-up of contrast for as long as 3 hours on an intravenous urogram (IVU). We evaluated 30 patients with impacted ureteral calculi, who were compared with a second unimpacted group matched for stone size and stone location. The calculi were reorganized into<or =10-mm and>10-mm groups. The results were compared in terms of clearance rates, number of shockwaves, number of sessions, and number of days between the start of SWL and clearance. Between January 1998 and December 2001, 30 impacted stones were treated with lithotripsy. Complete clearance rates in the impacted as well as the non-impacted group were 76.7%. There was no statistical difference in the number of shockwaves, sessions, or time to clearance. The results were poorer in lower-ureteral than upper-ureteral calculi, but this difference did not reach statistical significance. However, the differences between the<or =10-mm and>10-mm stones were statistically significant.\nQuestion: Does failure to visualize the ureter distal to an impacted calculus constitute an impediment to successful lithotripsy?",
        "gt": "Impaction on an IVU does not affect the results of lithotripsy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Thyroid surgery is done in Germany in a considerable numbers of operations (about 110,000 per year). To perform thyroid operations by so called \"generalists\" or \"specialists\" have been discussed intensively, however, this issue have not been analyzed in detail. Study material comprised 16,500 consecutive thyroid operations with 30,000 operated sites that have been prospectively documented in the German Thyroid Multicenter Study performed 1998 through 2001. Quality of surgery were analyzed by calculating the inverse relationship between volume and outcome (complication rate). To achieve complication rates (permanent unilateral recurrent laryngeal nerve paralysis and hypocalcemia) of<1 % (primary surgery) or<3 % (redo surgery) the minimum number of thyroid operations of lower level of experience (e. g. benign nodular goiter) per year was n=30. The minimum number of operations with higher level of experience was significantly lower (n=3-12) due to the higher level of experience of operating surgeons. In contrast to the rates of postoperative hypocalcemia the rates of postoperative recurrent laryngeal nerve paralysis was clearly related to the number of thyroid operations performed.\nQuestion: Thyroid surgery: generalist or specialist?",
        "gt": "The high number of thyroid operations in Germany with about 20 % of operations of high level experience are requiring surgical curricula and hospital structures that offer as well generalists as specialists to treat the broad spectrum of thyroid diseases accordingly. To lower the complication rate especially of difficult thyroid operations the level of specialization in Germany have to be increased.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether the frequency of soft sonographic aneuploidy markers varies by fetal sex. We identified all singleton fetuses with known sex undergoing genetic sonography at 17 weeks' to 21 weeks 6 days' gestation in a single perinatal center from January 1, 2000, to December 31, 2003. Markers studied were biparietal diameter/femur length, transcerebellar diameter, ear length, echogenic bowel, femur length, humerus length, absent middle fifth phalanx, nuchal fold, renal pelvis dilatation, echogenic cardiac focus, and choroid plexus cysts. Additional information extracted from the prospectively ascertained database included maternal age, referral indications, and chromosomal analyses. Multiple gestations and fetuses with structural or chromosomal abnormalities were excluded. The study received exempt review status by the Institutional Review Board. Dichotomous variables were compared by the chi(2) or Fisher exact test; continuous variables were compared by the unpaired t test. In total, 4057 eligible fetuses, 2103 male and 1954 female, were examined at 18.9 +/- 0.9 weeks (mean +/- SD). Referral indications included maternal age of 35 years or older (n = 2983), abnormal second-trimester serum screen results (n = 610), soft marker on sonography (n = 583), prior aneuploid offspring (n = 24), and other (n = 125). More than 1 referral indication was possible for a given fetus. Overall, male fetuses exhibited echogenic fetal bowel (odds ratio, 1.76; 95% confidence interval [CI], 1.14-2.72; P = .009) and renal pelvis dilatation (odds ratio, 2.00; 95% CI, 1.30-3.09; P = .001) significantly more often than female fetuses. However, when fetuses were evaluated for single isolated markers, only male predominance of renal pelvis dilatation persisted (odds ratio, 2.32; 95% CI, 1.32-4.09; P = .003). No markers had increased frequency in female offspring.\nQuestion: Does the frequency of soft sonographic aneuploidy markers vary by fetal sex?",
        "gt": "Male fetuses exhibit a significantly increased frequency of renal pelvis dilatation compared with female fetuses. Sex-specific adjustment of sonographically derived aneuploidy risk does not appear to be indicated. However, a larger series of fetuses with trisomy 21 and pyelectasis is required to assess sex-specific risk adjustment for this marker.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The feasibility of a side-to-side jejunoileal anastomosis (SJA) to control type 2 diabetes mellitus (T2DM) was studied in non-obese diabetic Goto-Kakizaki (GK) rats. Seventeen 14-week-old male GK rats were divided into three groups: SJA bypassing 60% of the small bowel length, sham-operated jejunoileal bypass (Sham group), and control animals. Rats were observed for 10 weeks after surgery. Fasting blood glucose (FBG) levels and oral glucose tolerance test (OGTT) were measured before and after the procedure. Animals with SJA exhibited normalization of FBG levels from the 1st and up to the 10th postoperative week when the experiment terminated. OGTT compared with sham-operated and control groups was also significantly better at 3 and 8 weeks postoperatively.\nQuestion: Is a Simple Food-Diverting Operation the Solution for Type 2 Diabetes Treatment?",
        "gt": "A simple SJA, diverting the food and biliopancreatic secretion to the distal small bowel, was able to normalize both FBG levels and OGTT in a non-obese diabetic rat model.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The ACGME requires the assessment of resident competency in 6 domains. Global evaluations covering all 6 competencies are routinely used. Evaluators may be overly influenced by resident affability and availability, thereby resulting in a halo effect. We hypothesized that the Interpersonal Skills and Communications (ICS) and Professionalism (PR) competencies would unduly influence other competency scores. General surgery resident evaluations are performed by staff and peers on a rotational basis using competency-based questions. Each question is scored using a 5-point Likert scale. Mean individual composite scores for each competency were calculated and then correlated with other mean composite competency scores. Data from patient evaluations were similarly analyzed. A final correlation of competency scores to ABSITE scores, as an objective, standardized measure of a specific competency, Medical knowledge (MK) was also performed. Results were available for 37 residents (PGY 1-5). There was a significant association between ICS scores and higher scores in MK (r = 0.52, p = 0.004), PR (r = 0.826, p<0.0001) and patient care (PC) (r = 0.619, p<0.0001). No correlation, however, was found between patient evaluations of residents and their faculty/peer-based ICS scores. We found no association between ICS scores and improved patient evaluations. Lastly, we found no association between ICS or MK scores and ABSITE scores.\nQuestion: Are the communication and professionalism competencies the new critical values in a resident's global evaluation process?",
        "gt": "It was difficult to ascertain whether residents with better ICS scores had higher PR, PC, and MK scores because of the halo effect, improper completion of evaluations, or whether those residents were truly performing better clinically. External measures of resident performance did not correlate with faculty/peer evaluations of ICS and PR. Residency programs should consider adopting a more standardized way to objectively evaluate residents.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study was undertaken to evaluate the efficacy of metformin in women with anovulation who do not have evidence for hyperandrogenism and classic polycystic ovary syndrome. A randomized trial of metformin (1500 mg daily) and placebo in 24 anovulatory women was undertaken for 3 months. Assessments of changes in hormone levels and insulin sensitivity were carried out. Abnormal hormonal values were defined by levels exceeding the range in normal ovulatory controls. Anovulatory women had normal androgen levels and luteinizing hormone but had higher serum insulin and lower insulin sensitivity compared with controls. Over 3 months, there were 16 ovulatory cycles with metformin and only 4 with placebo ( P<.05). Success of ovulation did not correlate with changes in androgen, insulin, or insulin sensitivity parameters.\nQuestion: Does metformin induce ovulation in normoandrogenic anovulatory women?",
        "gt": "Metformin may be useful for inducing ovulation in anovulatory women who do not have hyperandrogenism. This effect may be independent of a lowering of androgen or insulin levels.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the effectiveness of lignocain 2% and oxymetazoline 0.025% compared to oxymetazoline 0.025% alone when administered prior to fibreoptic nasendoscopy in paediatric patients. Prospective, randomized controlled, double-blind study. A group of 56 children, undergoing nasendoscopy to determine adenoidal size, were randomized into two groups and received either lignocain 2% and oxymetazoline 0.025% or oxymetazoline 0.025% alone prior to fibreoptic nasendoscopy. A tertiary care Paediatric Hospital. The endoscopist recorded the ease of performance of the procedure, cooperation of patient and quality of the view achieved using a visual analogue scale (VAS). The pain and anxiety levels of the child were recorded before, during and immediately after the procedure, using a VAS. The duration of performing the procedure was recorded from insertion of the endoscope into the nostril until removal. All 56 children were able to undergo the endoscopy and the full anxiety and pain assessment was done. Three children were excluded because they have undergone nasendoscopies before. Of the 53 patients included, 27 children received solution A (oxymetazoline 0.025%) and 26 children received solution B (oxymetazoline 0.025% and lignocain 2%). There was no statistical difference between the two groups regarding the duration of the endoscopy, quality of view, ease of performance and cooperation of the patients. The median pain and anxiety scores were not significantly different between the two groups.\nQuestion: Is topical local anaesthesia necessary when performing paediatric flexible nasendoscopy?",
        "gt": "This study concludes that the use of a decongestant (oxymetazoline) for paediatric nasendoscopy is just as effective as the use of oxymetazoline with lignocain. Pain and anxiety is not increased in the absence of lignocain.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Hydrocephalus is a common pediatric problem. Ventriculoperitoneal shunts (VPS) are the most frequent operative procedures used to treat hydrocephalic children. The peritoneal end is usually placed in the general peritoneal cavity. We present an alternative site of peritoneal end placement in the suprahepatic space in an attempt to reduce the abdominal complications. All patients with a diagnosis of congenital hydrocephalus were included in the study. In group 1, the lower end of the VPS was placed in the suprahepatic space. Patients were evaluated for abdominal complications like pseudocyst formation, intestinal obstruction and blockage of the lower end of the VPS. The data were compared with those patients in whom the peritoneal end was placed in the general peritoneal cavity (group 2). The total number of patients in groups 1 and 2 was 133 and 175, respectively. Complications in group 1 were dislodgement of the shunt in the general peritoneal cavity in 28 (21.05%), suprahepatic pseudocyst formation in 2 (1.5%) and blocked lower end in 2 patients (1.5%). In group 2, complications noted were pseudocyst formation in 5 (2.8%), blocked lower end in 25 (14.2%), intestinal obstruction in 9 (5.1%), inguinoscrotal migration in 10 (5.7%) and perforation of viscera in 6 patients (3.4%). The overall follow-up period ranged from 1 to 7 years.\nQuestion: Placement of the peritoneal end of a ventriculoperitoneal shunt in the suprahepatic space: does it improve prognosis?",
        "gt": "Placement of the lower end of the shunt in the suprahepatic space can be advantageous to placing it in the general peritoneal cavity. The procedure is simple and results can be rewarding.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether criminals go to the hospital when they are shot. Such information is needed to check on the accuracy of using hospital emergency room data to estimate non-fatal gunshot wounds. Five jails across the US. A survey of inmates being booked into jail, administered by in-house health care staff. Over 90% of over 300 criminals who had been wounded sometime before their incarceration reported going to a hospital for treatment after being shot. These results are consistent with previous findings from one jail.\nQuestion: Do criminals go to the hospital when they are shot?",
        "gt": "Jail inmates who had previously been shot were likely to have been treated in a hospital. This limited finding is consistent with the proposition that hospital/emergency department data may miss only a small percentage of gunshot wounds to criminals.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Standard electrophysiologic techniques generally allow discrimination among mechanisms of paroxysmal supraventricular tachycardia. The purpose of this study was to determine whether the response of paroxysmal supraventricular tachycardia to atrial and ventricular overdrive pacing can help determine the tachycardia mechanism. Fifty-three patients with paroxysmal supraventricular tachycardia were studied. Twenty-two patients had the typical form of atrioventricular (AV) junctional (nodal) reentry, 18 patients had orthodromic AV reentrant tachycardia, 10 patients had atrial tachycardia, and 3 patients had the atypical form of AV nodal reentrant tachycardia. After paroxysmal supraventricular tachycardia was induced, 15-beat trains were introduced in the high right atrium and right ventricular apex sequentially with cycle lengths beginning 10 msec shorter than the spontaneous tachycardia cycle length. The pacing cycle length was shortened in successive trains until a cycle of 200 msec was reached or until tachycardia was terminated. Several responses of paroxysmal supraventricular tachycardia to overdrive pacing were useful in distinguishing atrial tachycardia from other mechanisms of paroxysmal supraventricular tachycardia. During decremental atrial overdrive pacing, the curve relating the pacing cycle length to the VA interval on the first beat following the cessation of atrial pacing was flat or upsloping in patients with AV junctional reentry or AV reentrant tachycardia, but variable in patients with atrial tachycardia. AV reentry and AV junctional reentry could always be terminated by overdrive ventricular pacing whereas atrial tachycardia was terminated in only one of ten patients (P<0.001). The curve relating the ventricular pacing cycle length to the VA interval on the first postpacing beat was flat or upsloping in patients with AV junctional reentry and AV reentry, but variable in patients with atrial tachycardia. The typical form of AV junctional reentry could occasionally be distinguished from other forms of paroxysmal supraventricular tachycardia by the shortening of the AH interval following tachycardia termination during constant rate atrial pacing.\nQuestion: The response of paroxysmal supraventricular tachycardia to overdrive atrial and ventricular pacing: can it help determine the tachycardia mechanism?",
        "gt": "Atrial and ventricular overdrive pacing can rapidly and reliably distinguish atrial tachycardia from other mechanisms of paroxysmal supraventricular tachycardia and occasionally assist in the diagnosis of other tachycardia mechanisms. In particular, the ability to exclude atrial tachycardia as a potential mechanism for paroxysmal supraventricular tachycardia has important implications for the use of catheter ablation techniques to cure paroxysmal supraventricular tachycardia.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Poststroke depression (PSD) is the most common neuropsychiatric consequence of stroke. A large number of studies have focused on the pathogenesis of PSD, but only a few aimed to characterize its psychopathology; these studies yielded results that are difficult to compare because of the different methods utilized. The current study aimed to characterize the symptom profile of PSD in an attempt to better understand the disease and allow a more accurate diagnosis. The study sample comprised 64 patients divided into three groups: stroke patients without diagnosis of depression (n = 33), stroke patients diagnosed with PSD (PSD group, n = 14) and patients diagnosed with major depression (MD) but with no clinical comorbidity (MD group, n = 17). All patients were diagnosed using the Structured Clinical Interview for DSM-IV Axis I Disorders (SCID-I). The initial diagnostic interview was complemented by the Mini Mental State Examination (MMSE), the Rankin Scale, and four scales for the assessment of the intensity of symptoms of anxiety and depression: the Beck Depression Inventory (BDI), the Hospital Anxiety and Depression General Scale (HADS), the Hamilton Depression Rating Scale (HAM-D) and the Hamilton Rating Scale for Anxiety (HAM-A). The Star Plot, a graphical method of data visualization, was used to analyze the results. The t test was used for independent samples (two-tailed analysis). As measured by the BDI, HAM-D and HAM-A scales and HADS depression subscale, the average total scores of symptoms for the sample of patients diagnosed with MD without clinical comorbidity was significantly higher than that of the PSD patients (p<0.05). Similar results were obtained by plotting the BDI data on Star Plot. The PSD patients showed mild typical depressive symptoms such as less depressed mood, anhedonia, disinterest, guilt, negative thoughts, depreciation, suicidal ideation and anxiety, when evaluated by the HAM-A scale. Moreover, the somatic symptoms of depression did not lead to increased diagnosis of major depression in stroke patients.\nQuestion: Is poststroke depression a major depression?",
        "gt": "The results indicate that the PSD clinical picture comprised, in general, symptoms of mild/moderate intensity, especially those considered as pillars for the diagnosis of depression: depressed mood, loss of pleasure and lack of interest. Given the imprecision of boundaries that separate the clinical forms of depression from subclinical and nonpathological forms, or even from the concepts of demoralization and adjustment disorders, we situate PSD in a complex biopsychosocial context in which a better understanding of its psychopathological profile could provide diagnostic and therapeutic alternatives best suited to the difficult reality experienced by stroke patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the feasibility of using incontinence-associated dermatitis (IAD) tools in routine clinical practice by asking nursing home staff (RNs and non-RN caregivers) and tissue viability specialty (TVS) nurses to evaluate 3 instruments and a 4-point severity scoring system for describing and grading IAD examples captured in photographs of skin underneath absorptive pads in nursing home patients. Feasibility study. Twelve female nursing home residents whose incontinence was managed with pads and who had previously been identified as experiencing IAD were recruited, along with 16 nursing home staff (6 RNs and 10 non-RNs) and 10 TVS nurses. Weekly high-quality photographs were taken of the skin beneath absorptive pads of nursing home residents for 8 weeks yielding a library of 78 photographs. A subset of 10 representative photographs was chosen. The 16 nursing home staff and 10 TVS nurses were then asked to describe and grade the IAD in the 10 photographs using 3 IAD instruments and simple severity scoring system (SSS) developed for this study. Particular attention was paid to identifying any practical challenges staff encountered in conducting their task. The TVS nurses were able to use all 3 IAD instruments and the SSS and reported that they could incorporate them into their clinical practice with relative ease. Although the RNs were able to use the 3 instruments adequately with some initial assistance, they generally felt that they were too busy to complete them. By contrast, they reported that they found the SSS simple and quick enough to incorporate into their routine practice. The caregivers had difficulty with the text-based instruments, especially if English was not their first language, and they were only able to use the SSS. The caregivers' SSS scores for a given photograph varied more than TVS nurse scores, but the correlation between the mean TVS scores, which were operationally defined as the gold standard for purposes of this study, and the mean RN and caregiver scores (R = 0.811) were fairly high.\nQuestion: Is it Feasible to Use Incontinence-Associated Dermatitis Assessment Tools in Routine Clinical Practice in the Long-term Care Setting?",
        "gt": "Existing IAD instruments are too time-consuming and linguistically complex for use in routine clinical practice in nursing homes. We found that staff generally found the SSS easy to judge IAD severity based on pictures used in the study. This finding suggests that the SSS could be improved by adding reference photographs of skin illustrating each of the 4 points on the scale. Such an instrument could be designed and validated with an emphasis on integration into current clinical practice pathways.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A 2008 report by the American Psychological Association found no evidence that an induced abortion causes mental health problems in adult women. No conclusions were drawn with respect to adolescents because of a scarcity of evidence. Data from the National Longitudinal Study of Adolescent Health were used to examine whether abortion in adolescence was associated with subsequent depression and low self-esteem. In all, 289 female respondents reported at least one pregnancy between Wave 1 (1994-1995) and Wave 2 (1996) of the survey. Of these, 69 reported an induced abortion. Population-averaged lagged logistic regression models were used to assess associations between abortion and depression and low self-esteem within a year of the pregnancy and approximately five years later, at Wave 3 (2001-2002). Abortion was not associated with depression or low self-esteem at either time point. Socioeconomic and demographic characteristics did not substantially modify the relationships between abortion and the outcomes.\nQuestion: Do depression and low self-esteem follow abortion among adolescents?",
        "gt": "Adolescents who have an abortion do not appear to be at elevated risk for depression or low self-esteem in the short term or up to five years after the abortion.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: According to the International Union Against Cancer (UICC), R1 is defined as the microscopic presence of tumor cells at the surface of the resection margin (RM). In contrast, the Royal College of Pathologists (RCP) suggested to declare R1 already when tumor cells are found within 1\u00a0mm of the RM. The aim of this study was to determine the significance of the RM concerning the prognosis of pancreatic ductal adenocarcinoma (PDAC). From 2007 to 2009, 62 patients underwent a curative operation for PDAC of the pancreatic head. The relevance of R status on cumulative overall survival (OS) was assessed on univariate and multivariate analysis for both the classic R classification (UICC) and the suggestion of the RCP. Following the UICC criteria, a positive RM was detected in 8\u00a0%. Along with grading and lymph node ratio, R status revealed a significant impact on OS on univariate and multivariate analysis. Applying the suggestion of the RCP, R1 rate rose to 26\u00a0% resulting in no significant impact on OS in univariate analysis.\nQuestion: Can the new RCP R0/R1 classification predict the clinical outcome in ductal adenocarcinoma of the pancreatic head?",
        "gt": "Our study has shown that the RCP suggestion for R status has no impact on the prognosis of PDAC. In contrast, our data confirmed the UICC R classification of RM as well as N category, grading, and lymph node ratio as significant prognostic factors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: With regard to the workplace, to examine restrictions on smoking, smoking at work, attitudes toward and reactions to restrictions, and workplace programmes in the context of the legislative environment. Population-based telephone interview survey of adult residents of the jurisdictions of Metropolitan Toronto, Ontario, Canada. Workers within the City of Toronto (n = 374) were compared with other workers (n = 536), because their legislative environments with regard to workplace smoking were markedly different, with workplaces in the City of Toronto being covered by a much more stringent bylaw. In comparison with other workers, City of Toronto workers reported workplace restrictions to be more common and widespread. These workers were also less likely to smoke at work, and more likely to smoke less at work and to have cut down on smoking at work. Quit-smoking rates, however, were similar. There was evidence of some compensatory smoking outside work, but additional compensation in association with more stringent restrictions was not found. City workers and other workers were similar in their support for smoke-free workplaces, in their attitudes to the role of governments in regulating workplace smoking, and in their perceptions of conflict between smokers and non-smokers. Reports of quit-smoking programmes and educational interventions in the workplace were similarly uncommon, although both groups of workers indicated strong support for the role of business and industry in helping people quit.\nQuestion: Smoking in the workplace: do smoking patterns and attitudes reflect the legislative environment?",
        "gt": "Restrictions on smoking and smoking patterns reflected the legislative environment; a more stringent environment was associated with more restrictions and less smoking at work.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Two hundred seven patients with severe painful endometriosis-related symptoms entered the study. At enrolment time, the baseline values of painful symptoms were assessed by Visual Analogue Scale (VAS) for dysmenorrhoea, non-menstrual pelvic pain, and dyspareunia. According to VAS, pain severity was scored from 0-10; 0 indicating the absence of pain, and 1-4, 5-7 and 8-10 mild, moderate and severe respectively. A gluten-free diet was submitted to all patients and a new evaluation was performed after 12 months of diet. Student t test was used for statistical analysis. At 12 month follow-up, 156 patients (75%) reported statistically significant change in painful symptoms (P<0.005), 51 patients (25%) reported not improvement of symptoms. No patients reported worsening of pain. A considerable increase of scores for all domains of physical functioning, general health perception, vitality, social functioning, and mental health was observed in all patients (P<0.005).\nQuestion: Gluten-free diet: a new strategy for management of painful endometriosis related symptoms?",
        "gt": "In our experience, painful symptoms of endometriosis decrease after 12 months of gluten free diet.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Activation of the cardiac catheterization laboratory prior to patient arrival at the hospital, based on a prehospital 12-lead electrocardiogram (ECG), reduces door-to-balloon time by 10-55 minutes for patients with ST-segment elevation myocardial infarction (STEMI). In emergency medical services (EMS) systems where transmission of the ECG to the emergency department (ED) is not feasible, the ability of paramedics to accurately read 12-lead ECGs is crucial to the success of a prehospital catheterization laboratory activation program. Objective. To determine whether paramedics can accurately diagnose STEMI on a prehospital 12-lead ECG and decide to activate the cardiac catheterization laboratory appropriately. Five chest pain scenarios were generated, with standardized prehospital ECGs accompanying each: three STEMI cases that should result in catheterization laboratory activation and two non-STEMI cases that should not. A convenience sample of paramedics in an urban/suburban EMS system examined each scenario and ECG, and indicated whether the patient had STEMI and whether they would activate the catheterization laboratory. A series of demographic and operational questions were also asked of each participant. We report diagnostic statistics, agreement (kappa), and 95% confidence intervals (CIs). A convenience sample of 103 of 147 eligible paramedics (70%) was enrolled. For STEMI diagnosis, paramedics' sensitivity was 92.6% (95% CI 88.9-95.1) and specificity was 85.4% (79.7-89.8); for catheterization laboratory activation, sensitivity was 88.0% (83.8-91.3) and specificity was 88.3% (83.0-92.2). False-positive activation of the catheterization laboratory occurred in 8.1% (5.4-12.0) of cases. Of the STEMI cases, 94.1% were correctly read as STEMI, and 91.0% had the catheterization laboratory appropriately activated. Of the non-STEMI cases, 14.9% were incorrectly read as STEMI, and 12.0% had the catheterization laboratory inappropriately activated. The paramedics' comfort with calling a \"chest pain alert\" with no resulting catheterization laboratory activation (the current practice in this system) was not statistically different from their comfort with calling a chest pain alert if that call were to automatically result in catheterization laboratory activation (p>0.05).\nQuestion: Can paramedics read ST-segment elevation myocardial infarction on prehospital 12-lead electrocardiograms?",
        "gt": "Paramedics in an urban/suburban EMS system can diagnose STEMI and identify appropriate cardiac catheterization laboratory activations with a high degree of accuracy, and an acceptable false-positive rate, when tested using paper-based scenarios.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Fast-track protocols may facilitate early patient discharge from the site of surgery through the implementation of more expedient pathways. However, costs may merely be shifted towards other parts of the health care system. We aimed to investigate the consequence of patient transfers on overall hospitalisation, follow-up and readmission rate after cardiac surgery. A single-centre descriptive cohort study using prospectively entered registry data. The study included 4,515 patients who underwent cardiac surgery at Aarhus University Hospital during the period 1 April 2006 to 31 December 2012. Patients were grouped and analysed based on type of discharge: Directly from site of surgery or after transfer to a regional hospital. The cohort was obtained from the Western Denmark Heart Registry and matched to the Danish National Hospital Register. Median overall length of stay was 9 days (7.0;14.4). Transferred patients had longer length of stay, median difference of 2.0 days, p<0.001. Time to first outpatient consultation was 41(30;58) days in transferred patients vs. 45(29;74) days, p<0.001. 18.6% was readmitted within 30 days. Mean time to readmission was 18.4 \u00b1 6.4 days. Median length of readmission was 3(1,6) days. There was no difference in readmissions between groups. Leading cause of readmission was cardiovascular disease with 48%.\nQuestion: Relocation of patients after cardiac surgery: is it worth the effort?",
        "gt": "Transfer of patients does not overtly reduce health care costs, but overall LOS and time to first outpatient consultation are substantially longer in patients transferred to secondary hospitals than in patients discharged directly. Readmission rate is high during the month after surgery, but with no difference between groups.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this work is to determine whether high -value ( = 3,000 s/mm ) diffusion-weighted (DW) imaging is superior to low -value ( = 1,000 s/mm ) DW imaging for the detection of cerebral infarctions older than 6 h. Echo planar DW imaging was performed at 1.5 T in 26 consecutive patients (mean age 66 years) referred for clinical diagnosis of definite acute/subacute cerebral infarction (6 h to 14 days old). The DW imaging sequences were performed using matched parameters (TR = 10,000 ms, TE (eff)= 97 ms, FOV = 24 cm, 128 x 192 matrix, slice = 5 mm, NEX = 2) with values of 1,000 and 3,000 s/mm. Areas of infarction were compared visually by two experienced neuroradiologists. Quantitative measures of MR signal and noise levels in the infarcted areas compared with contralateral normal brain were also obtained. The median time after infarction was 2.5 days (range 10 h to 14 days). By visual inspection, all infarctions were reliably identified on both the = 1,000 and the = 3,000 images. The gross signal ratio (infarct/normal brain) was approximately 33% higher in the = 3,000 images, but the = 3,000 images were rated as noticeably \"noisier\" by both observers in every case. This visual observation was confirmed quantitatively: The signal-to-noise (SNR) and contrast-to-noise (CNR) ratios were 70% and 51% higher in the = 1,000 than the = 3,000 images (p<0.0005 for both).\nQuestion: Diffusion-weighted imaging of cerebral infarctions: are higher B values better?",
        "gt": "For the evaluation of late acute/subacute cerebral infarctions, high -value ( = 3,000 s/mm(2) ) DW imaging offers no apparent diagnostic advantages compared with = 1,000 images and is significantly inferior in terms of SNR and CNR.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Dosage of serum AFP (alpha-fetoprotein) is widely used for HCC screening in patients with chronic liver disease. Virus-related chronic liver disease is the main cause of cirrhosis and HCC in Western and Far Eastern countries, but the relationship between viral etiology and AFP levels in HCC is still unclear. The aim of this study was to verify, in Western patients with post-viral chronic liver disease, the usefulness of AFP dosage for the detection of HCC, and the influence of viral etiology on AFP levels in HCC. The study population included 350 patients with post viral chronic liver disease that underwent liver biopsy, serum AFP determination and ultrasound liver evaluation. Seven patients had normal liver histology, 197 had chronic hepatitis, 72 had cirrhosis, and 74 had cirrhosis and HCC. ROC (receiver operating characteristic) analysis was used to assess the best diagnostic AFP threshold value for HCC detection. Logistic regression analysis was performed to individuate independent predictors of HCC diagnosis. No difference was observed in AFP levels between HCV- and HBV-positive patients, neither in the whole population nor in the HCC patients only. ROC area under curve for AFP was 0.801 (95% CI: 0.721-0.867). The analysis individuated a best accurate AFP threshold value for HCC diagnosis of 50 ng/mL. HCC was detected with specificity>or = 95% only for AFP>100 ng/mL. The sensitivity however was poor (25%). Male sex, age>60, and AFP were independent predictors of HCC diagnosis.\nQuestion: Utility of alpha-fetoprotein (AFP) in the screening of patients with virus-related chronic liver disease: does different viral etiology influence AFP levels in HCC?",
        "gt": "Serum AFP levels in HCC patients are not influenced by virus B or C hepatitis pattern. AFP dosage should not be used for HCC diagnosis in non-cirrhotic patients. Male patients with cirrhosis should be regarded with a more \"aggressive\" screening program compared to females.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Many epidemiological studies indicate a positive correlation between cataract surgery and the subsequent progression of age-related macular degeneration (AMD). Such a correlation would have far-reaching consequences. However, in epidemiological studies it is difficult to determine the significance of a single risk factor, such as cataract surgery. We performed a retrospective case-control study of patients with new onset exudative age-related macular degeneration to determine if cataract surgery was a predisposing factor. A total of 1496 eyes were included in the study: 984 cases with new onset of exudative AMD and 512 control eyes with early signs of age-related maculopathy. Lens status (phakic or pseudophakic) was determined for each eye. There was no significant difference in lens status between study and control group (227/984 [23.1 %] vs. 112/512 [21.8 %]pseudophakic, p = 0.6487; OR = 1.071; 95 % CI = 0.8284-1.384). In cases with bilateral pseudophakia (n = 64) no statistically significant difference of the interval between cataract surgery in either eye and the onset of exudative AMD in the study eye was found (225.9 +/- 170.4 vs. 209.9 +/- 158.2 weeks, p = 0.27).\nQuestion: Does cataract surgery increase the risk of exudative age-related macular degeneration?",
        "gt": "Our results provide evidence that cataract surgery is not a major risk factor for the development of exudative AMD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In this retrospective review, we evaluated the advantages and disadvantages of LADG for patients of heavier weight with early gastric cancer. LADG has been used to treat early gastric cancer. We and others have reported less operative blood loss, less pain, early recovery of bowel activity, early restart of oral intake, and a shorter hospital stay with LADG compared with a conventional open method. There is, however, little information on the advantages of LADG for obese patients with early gastric cancer. Between January 1996 and March 2002, 76 patients with preoperatively diagnosed early gastric carcinoma underwent LADG in our department. We classified these patients into 2 groups on the basis of body mass index (BMI). Nineteen patients had a high-BMI (>/= 24.2 kg/m2), and 57 patients had a normal-BMI (<24.2 kg/m2). We collected data by retrospectively reviewing the medical charts. Extension of the minilaparotomic incision or conversion to laparotomy was needed in 6 (32%) of the 19 patients in the high-BMI group, whereas only 3 (5%) of 57 patients in the normal-BMI group required either. In the high-BMI group, Roux-en-Y anastomosis rather than Billroth I anastomosis was adopted more often than in the normal-BMI group, due to the difficulty of the reconstruction (58% versus 4%, P = 0.001). Significantly longer operative time (370 +/- 61 minutes versus 317 +/- 58 minutes, P = 0.015) and prolonged recovery of bowel activity (3.5 +/- 1.0 days versus 2.6 +/- 1.0 days, P = 0.007) were observed in the patients in the high-BMI group.\nQuestion: Laparoscopy-assisted distal gastrectomy for early gastric cancer: is it beneficial for patients of heavier weight?",
        "gt": "In the current study, LADG in patients of heavier weight was accompanied by more technical difficulties, and the disadvantages of longer operative time and delayed recovery of bowel activity was observed in patients of heavier weight. Heavier weight appears to be an ominous factor in the successful completion of LADG and should be considered in the decision to use LADG. There are still benefits of a decreased incidence of serious wound and hernia complications in successful cases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Borderline personality disorder (BPD) is characterized by a pervasive pattern of instability and impulsivity. There is a high prevalence of BPD patients among those admitted to the emergency department for suicide attempts. However, little empirical research exists to assist clinicians in deciding whether to hospitalize a suicidal patient. Some authors have argued that hospitalization does not prevent suicide and could actually harm these patients, thereby leading to psychosocial regression. Parasuicidal behaviors could be reinforced by the attention given during hospitalization. Our purpose was to determine whether the hospitalization of suicidal patients who have a high risk of BPD after discharge from the emergency department is associated with a recurrence of suicidal behavior at 6months. We designed a prospective study, acquiring patients from three emergency hospitals. The participants were suicidal subjects admitted for voluntary drug intoxication and were 18years of age or older. The participants completed the Personality Disorder Questionnaire (PDQ-4+) to assess BPD symptomatology. Information on the recurrence of suicidal behavior at 6months was obtained by interview of patients and the review of the charts from the 3\u00a0hospitals involved in the study. Other assessments included the BDI-13 (severity of depression), the Hopelessness Scale (hopelessness), the TAS-20 (alexythymia), the AUDIT (alcohol disorder) and the MINI (axis I disorders). A total of 606\u00a0subjects admitted for a suicide attempt participated in this study. A total of 320 (52.8\u00a0%) of the subjects completed the PDQ-4+. The sample was divided into three groups: participants at high risk of having at least one BPD (n=197), a group at high risk of having at least one non-BPD PD (n=84) and a group with low risk of having a PD (n=39). Hospitalization following an emergency was not associated with a recurrence of suicide attempts at 6months among patients at high risk of BPD. A logistical regression analysis showed pre-hospitalization antidepressant prescription to be associated with recidivism (OR=2.1, P=.037).\nQuestion: Should hospitalization be required after the emergency discharge of patients with borderline personality disorder who have attempted suicide (FRENCH CRISIS cohort)?",
        "gt": "Our exploratory study suggests that hospitalization may not increase suicide attempts among patients with BPD when the health organization does not include a specific device such as DBT.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Replies to a questionnaire were received from 2,191 practitioners and 297 thyroid specialists between June 1 and September 30, 2005. The hypothetical cases and their modifications described multinodular goiters of different sizes with and without toxic nodules. In the workup, TSH determination and thyroid sonography were found to be standard procedures. Scintigraphy was selected by 80.2% of practitioners and 92.9% of specialists (p<0.001), in preference to fine needle aspiration cytology (17.9% of practitioners and 34.5% of the specialists, p<0.001). Only 6.1% of practitioners and 24.4% of specialists (p<0.001) advocated calcitonin screening. Euthyroid multinodular goiter (50-80 ml) was treated medically by 67.1% of practitioners and 65.6% of specialists, the combination of levothyroxine with iodine being clearly preferred (54.5% of practitioners, 52.3% of specialists). For toxic nodular goiter the preference for radioiodine therapy was significantly higher (p<0.001) among specialists (67.7%) than among practitioners (47.5%). Referral to surgery was recommended for cold nodules with negative cytology by 64.9% of practitioners and 73.5% of specialists (p = 0.004).\nQuestion: Management of multinodular goiter in Germany (Papillon 2005): do the approaches of thyroid specialists and primary care practitioners differ?",
        "gt": "Treatment and diagnostic procedures are used to nearly the same extent in primary care and specialist institutions, but the opinions diverge over the issues of calcitonin screening and referral for radioiodine therapy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Neutropenia is a major factor affecting continuation of chemotherapy for colorectal cancer. In many clinical trials, a neutrophil count of>1500 is targeted for continuation; for a count of<1500, medication is commonly discontinued. However, there is no definitive evidence supporting the need for a neutrophil count of 1500 for continuation of chemotherapy. In the clinical trials that we conducted, we discontinued chemotherapy when the neutrophil count was<1000 (grade 3); for a count of 1000-1500 (grade 2), chemotherapy was continued. Therefore, even practical treatment uses the same setting. Our aim was to examine neutrophil counts during continuation of chemotherapy in colorectal cancer patients with counts of 1000-1500 and to assess the need for discontinuation of medication for neutrophil counts in this range. Moreover, we examined neutrophil counts during the previous course of chemotherapy when they fell below 1000. The study included 144 patients who received XELOX + bevacizumab therapy and XELOX therapy for advanced or recurrent colorectal cancer. Thirty (20.8 %) patients had neutrophil counts of 1000-1500. One (3.3 %) of 30 patients had a neutrophil count of<1000 during the following course of chemotherapy. Moreover, among the patients with neutrophil counts of<1000, 27.3 % had counts of 1000-1500 during the previous course of chemotherapy and 72.7 % had counts of>1500.\nQuestion: Can grade 2 neutropenia predict the risk of grade 3 neutropenia in metastatic colorectal cancer patients treated with chemotherapy?",
        "gt": "Based on these results, grade 2 neutropenia cannot predict the risk of grade 3 neutropenia. Continuation of chemotherapy in patients with neutrophil counts of 1000-1500 may be appropriate, and discontinuation of therapy is not always required.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Environmental factors are believed to play a role in the development of atopic allergy. This is likely to be important very early in life, at the fetal stage. The in utero environment could be affected by maternal allergy and in turn could influence the immune system of the baby. To investigate how cord blood mononuclear blood cells (CBMCs) from children of women with and without allergy respond to microbial stimuli. PBMCs from women with (n = 9) and without allergy (n = 10) and CBMCs from their newborn babies were stimulated in vitro with LPS and peptidoglycan. Cells were analyzed with flow cytometry for expression of CD14, Toll-like receptor (TLR)-2, and TLR4. The release of cytokines and chemokines (IL-1beta, IL-6, IL-8, IL-10, IL-12p70, TNF-alpha) and soluble CD14 into culture supernatants was measured with Cytometric Bead Array and ELISA, respectively. Cord blood (CB) monocytes from children with mothers with allergy had significantly lower expression of TLR2 and TLR4 compared with maternal monocytes both before and after microbial stimulation, in contrast with CB monocytes from children with mothers without allergy. Further, CBMCs from children with mothers with allergy had a lower ( P = .03) IL-6 response after stimulation with peptidoglycan than CBMCs from children with mothers without allergy.\nQuestion: Neonatal immune responses to microbial stimuli: is there an influence of maternal allergy?",
        "gt": "Our results imply that CB monocytes and CBMC immune responses are influenced by maternal allergy. On the basis of these findings, we speculate that monocytes from children with mothers with allergy have a reduced capacity to respond to microbial stimuli.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The recent trend for treatment of certain cases of type II Hangman's fracture has been towards motion preserving surgery. This is claimed to be achieved with placement of pedicle screws across the fracture fragments. However, the long term outcome in clinical scenario is not yet clear, neither are the factors determining suitability of such a technique. We have retrospectively analyzed the results of 11 patients of type II Hangman's fracture, according to the extent of translation. Nine patients underwent stabilization of fracture with C2 pedicle screws and 2 were managed with halo immobilization. The conservative management failed in one and this patient underwent internal fixation using pars-pedicle screw as well. The long term clinical and radiological (CT and dynamic X-rays) outcome was analyzed. All patients including the one with halo immobilization, showed solid fusion across the fracture fragments. With the exception of one patient none had any clinical symptoms. This lone patient complained of restricted neck movements. Three different types of radiological results were observed. Two patients with translation>8mm showed C2-3 body fusion. Three of 6 patients with minimal translational (3-4mm) showed facet fusion. Three patients with moderate translational dislocation (4.5-5.5mm) showed persisting C2-3 angular instability.\nQuestion: Are C2 pars-pedicle screws alone for type II Hangman's fracture overrated?",
        "gt": "The C2 pedicle screw is a good technique for osteosynthesis. However, the claimed long term advantage of motion segment preservation with this technique remains doubtful. It may be suitable for those fractures with minimal translation (<4mm), where the superiority of surgery, itself, over external immobilization is questionable. C2-3 fusion is preferable for those fractures with translation>4mm as these are unstable and C2 pedicle screws alone are likely to have less desirable results.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the nuclear morphometric features of breast columnar cell lesions (CCLs) observed on mammotome core biopsies, to determine if there are significant measurable differences between those with atypia and those without. Correlation with follow-up open excision specimens was made. Mammotome core biopsies performed on patients that contained CCLs were derived from the departmental case files. Histological material was reviewed and foci of CCLs demarcated for nuclear morphometric assessment, which was accomplished using an imaging system. Nuclear parameters studied were nuclear area and perimeter, circularity factor and feret's diameter. Statistical analysis used the GraphPad Prism software, with p<0.05 indicating significance. On examination of core biopsies of 40 patients with CCLs, 8 lesions were benign, 4 showed atypical lobular hyperplasia, 8 showed CCLs with nuclear atypia, 19 disclosed atypical ductal hyperplasia (ADH) and 1 showed ductal carcinoma in situ (DCIS). The nuclear area, perimeter and feret's diameter of CCLs with atypia were significantly greater than those without (p = 0.04, 0.03 and 0.019, respectively), whereas no difference was observed in the circularity factor. Follow-up open excision biopsy specimens in 24 patients showed upgrading to DCIS in 40% of cases diagnosed initially with ADH on core biopsy compared with 20% of CCLs with atypia.\nQuestion: Nuclear morphometry in columnar cell lesions of the breast: is it useful?",
        "gt": "Nuclear morphometry in CCLs confirms nuclear size as the key parameter in the assessment of nuclear atypia. Whether it can be potentially used as an adjunctive tool depends on the establishment of appropriate cut-offs.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A total of 123 patients with proximal ureteral stones were investigated in this prospective study performed in a 10-month period. The patients were divided into the group I--86 patients treated with extracorporeal shock wave lithotripsy (ESWL) and the group II--37 patients treated with \"Swiss\" Lithoclast. In the group I, 49 stones (57%) were classified as impacted, while 20 stones (23.3%) were larger than 100 mm2. In the group II, 26 stones (70.3%) were impacted, and 11 stones (29.7%) were larger than 100 mm2. Stones were defined as impacted by the radiographic, echosonographic as well as endoscopic findings in the group II of patients. Stone size was presented in mm2. Chemical composition of stones were almost the same in both groups of the patients. Generally, there was no statistically significant difference in the treatment success between the groups. However, stones larger than 100 mm2 were statistically more successfully treated endoscopically, while there was no statistical difference in the treatment success of impacted stones between these two groups.\nQuestion: Do stone size and impaction influence therapeutic approach to proximal ureteral stones?",
        "gt": "ESWL can by considered as primary first therapeutic approach in treatment of all proximal ureteral stones except for stones larger than 100 mm2 that should primarily be treated endoscopically.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Paroxysmal kinesigenic dyskinesia (PKD) is characterized by brief episodes of dystonia and choreoathetosis triggered by sudden voluntary movements. Disease onset is seen in the first or second decade. The attacks typically last less than one minute. Three autosomal dominant PKD loci are identified: EKD1, EKD2 and EKD3. EKD1 has an overlap with the locus of the \"Infantile Convulsion and Choreoathetosis (ICCA) syndrome\". The favorable natural history, the episodic nature of the symptoms and their sensitivity to anticonvulsant therapy suggest channelopathy as a mechanism of PKD. We reviewed the clinical features, the family history, the treatment response, the evolution and the technical investigations in 19 affected individuals. All cases were idiopathic. Ten patients had a positive familial history. Three patients suffered from ICCA syndrome. Some atypical features were seen, such as the association of kinesigenic and nonkinesigenic attacks and the presence of migraine, ataxia, seizures and myoclonus. Acetazolamide responsiveness was seen in two patients.\nQuestion: Paroxysmal kinesigenic dyskinesia: a channelopathy?",
        "gt": "The coexistence of PKD and nonkinesigenic dyskinesia in several patients confirms the earlier described presence of intermediary forms, nonrepresented in the current classification of paroxysmal dyskinesias. Our study results suggest channel dysfunction and basal ganglia involvement in the pathophysiology of PKD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We present alternative operationalizations of trust calibration and examine their associations with predictors and outcomes. It is thought that trust calibration (correspondence between aid reliability and user trust in the aid) is a key to effective human-automation performance. We propose that calibration can be operationalized in three ways. Perceptual accuracy is the extent to which the user perceives the aid's reliability accurately at one point in time. Perceptual sensitivity and trust sensitivity reflect user adjustment of perceived reliability and trust as the aid's actual reliability changes over time. One hundred fifty-five students completed an X-ray screening task with an automated screener. Awareness of the aid's accuracy trajectory and error type was examined as predictors, and task performance and aid failure detection were examined as outcomes. Awareness of accuracy trajectory was significantly associated with all three operationalizations of calibration, but awareness of error type was not when considered in conjunction with accuracy trajectory. Contrary to expectations, only perceptual accuracy was significantly associated with task performance and failure detection, and combined, the three operationalizations accounted for only 9% and 4% of the variance in these outcomes, respectively.\nQuestion: Are well-calibrated users effective users?",
        "gt": "Our results suggest that the potential importance of trust calibration warrants further examination. Moderators may exist.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the coverage and equity of the Expanded Programme on Immunisation (EPI) and its effect on age schedule, seasonality of malaria risk, and linked intermittent preventive treatment (IPT) in West Africa. Secondary analyses of data from a trial of IPT in Ghana. The potential effectiveness and impact of EPI-linked IPT in West Africa was calculated using the coverage of Diptheria Pertussis Tetanus vaccination obtained from national surveys and the reported protective efficacies of IPT. In West Africa, where the transmission of malaria is highly seasonal, only 10% of malaria episodes in infants would be averted with the current coverage of EPI.\nQuestion: Is the Expanded Programme on Immunisation the most appropriate delivery system for intermittent preventive treatment of malaria in West Africa?",
        "gt": "In this setting, the EPI-linked IPT is not necessarily the most appropriate approach and alternative IPT schedules and delivery systems are needed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Knowledge about the stability of drugs and metabolites in biological fluids is important information when the analytical results are evaluated and interpreted. This study examines changes in blood-ethanol concentration (BEC) during the storage of specimens for up to 12 months at 4 degrees C. Venous blood samples were taken from drunk drivers in evacuated glass tubes containing sodium fluoride and potassium oxalate as chemical preservatives. The concentrations of ethanol in blood were determined in duplicate by headspace gas chromatography on arrival at the laboratory and again after storage in a refrigerator at 4 degrees C for up to 12 months. The relationship between the standard deviation (SD) of analysis of ethanol at concentration intervals of 0.2 mg/g (BEC) was defined by the linear regression equation SD=0.00243+0.0104 BEC (r=0.99). At a mean BEC of 1.64 mg/g, the SD was 0.019 mg/g which corresponds to a coefficient of variation of 1.1%. The mean decrease in BEC (+/-SD) between first and second analysis was 0.105+/- 0.0686 mg/g (t=19.3, d.f.=158, p<0.001) and the loss of alcohol was positively correlated with the duration (days) of storage (r=0.44, p<0.001), although with large inter-tube variations. A correlation also existed (r=0.23, p<0.01) between the loss of ethanol and the starting BEC. When blood samples (n=49) were opened 17 times to remove aliquots for analysis over 6.5 months, the BEC decreased by 0.217+/-0.054 mg/g compared to a fall of 0.101+/-0.076 mg/g in tubes kept unopened. None of the blood samples showed a significant increase in BEC after storage.\nQuestion: Are changes in blood-ethanol concentration during storage analytically significant?",
        "gt": "To be considered analytically significant, the BEC had to decrease by 0.013 (2.6%), 0.028 (1.9%) and 0.045 mg/g (1.8%), respectively at starting concentrations of 0.5, 1.5 and 2.5 mg/g.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The high infant and child morbidity and mortality in most sub-Saharan African countries, and Nigeria in particular, is a prominent global concern. The objective of this study was to assess factors influencing, and the prevalence of, the experience of child death among rural Nigerian mothers, with the specific aim to investigate whether household headship had an impact on child death. Using data from the 2008 Nigeria Demographic and Health Survey, multivariate logistic regression methods were used to assess the influence of household headship and other associated variables among rural women who experienced child death (n=13 203) in the 5 years preceding the survey. A total of 5632 women (43%) whose most recent birth occurred in the 5 years preceding the survey had reported the death of a child. Women who utilized health services were less likely to report child death than those who never utilized health services. Women who delivered their most recent child at home were more likely (46%; n=4565) to report child death compared with those who delivered in a health facility (32%; n=997). The women who resided in male-headed households had a significantly higher (43%; n=5143) prevalence of child death than women from female-headed households (37%; n=489). After controlling for all covariates in the multivariate logistic regression models, women from female-headed households were 17% less likely to experience child death (odds ratio=0.83; 95% confidence interval 0.71, 0.98) than women from male-headed households.\nQuestion: Does living in a female-headed household lower child mortality?",
        "gt": "The occurrence of child death is not unusual in rural Nigeria. Multiple frameworks are needed to account for differentials in child mortality. After controlling for other explanatory variables such as age, wealth status, region and place of delivery of recent birth, this study found that household headship remained a strong predictor of child mortality. Recommendations are provided according to the complex interplay of socio-cultural, economic, and situational factors affecting the survival of children in rural Nigeria.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The standard treatment for locally advanced cervical cancer (LACC) is concomitant chemoradiotherapy. In the majority of patients with LACC after properly executed concomitant chemoradiotherapy local control of the disease is achieved, and consequently distant relapse becomes the main cause of death for these patients. In an attempt to improve the outcome of patients with LACC, we designed a regimen of concomitant chemobrachyradiotherapy with cisplatin and ifosfamide followed by consolidation chemotherapy. Between 1999 and 2012, 118 patients diagnosed with LACC, The International Federation of Gynecology and Obstetrics (FIGO) stages IB2-IVA, regardless of histology, were treated with concomitant chemobrachyradiotherapy and consolidation chemotherapy at our Institution. Chemotherapy consisted of two cycles of cisplatin and ifosfamide applied concomitantly with two intracavitary low-dose rate brachytherapy applications, and of four cycles of the same drug combination as an adjuvant/consolidation part of the treatment. The primary outcome in this analysis was distant disease-specific survival. A total of 18 patients had documented relapse of cervical cancer, with only three local recurrences observed; 15 patients developed only distant recurrence, and one patient developed both local and distant recurrence. The distant disease-specific survival after a median follow-up of 96 months was 86.4%.\nQuestion: Adjuvant Chemotherapy in Locally Advanced Cervical Cancer After Treatment with Concomitant Chemoradiotherapy--Room for Improvement?",
        "gt": "Consolidation or adjuvant chemotherapy that follows concomitant chemoradiotherapy has a potential role in further improving control of the disease, especially distant control of the disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Endoscopic removal of colon polyps is the main tool in colorectal cancer prevention programs. Although several quality indicators and guidelines have been proposed, polypectomy practices are still subject to great variation among endoscopist and little data is available regarding polypectomy practices in real life settings. The records of the 1061 screening colonoscopies performed in 2010 in a tertiary care teaching hospital in Bucharest were reviewed and all colonoscopies where at least one polyp was detected were selected for analysis. The number of detected polyps, the resection rate and method used for polypectomy were studied and compared to colonoscopy quality indicators previously reported in literature. 941 polyps were detected in 395 patients. Invasive colorectal cancer was found in 42 patients. 548 polyps (58.23%) were removed endoscopically, with at least one polyp being resected in 283 patients (71.5%), resulting in a polypectomy rate of 26.67% in the entire study population. Cold forceps resection was the most commonly used method for the resection of polyps less than 5 mm in size, while for larger polyps hot snare was the preferred method. Concomitant invasive carcinoma and a larger number of polyps were predictive of incomplete removal of all detected polyps.\nQuestion: Polypectomy practices in a real life setting. Do we do enough for our patients?",
        "gt": "Most quality indicators were met in our study group, with suboptimal performance regarding histological documentation of detected polyps and establishing a polyp-free colon.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Laboratory cue reactivity (CR) assessments are used to assess smokers' responses to cues. Likewise, EMA recording is used to characterize real-world response to cues. Understanding the relationship between CR and EMA responses addresses the ecological validity of CR. In 190 daily smokers not currently quitting, craving and smoking responses to cues were assessed in laboratory CR and by real-world EMA recording. Separate CR sessions involved 5 smoking-relevant cues (smoking, alcohol, negative affect, positive affect, smoking prohibitions), and a neutral cue. Subjects used EMA to monitor smoking situations for 3 weeks, completing parallel situational assessments (presence of others smoking, alcohol consumption, negative affect, positive affect, and smoking prohibitions, plus current craving) in smoking and non-smoking occasions (averaging 70 and 60 occasions each). Analyses correlated CR craving and smoking cue responses with EMA craving and smoking correlations with similar cues. Although some cues did not show main effects on average craving or smoking, a wide range of individual differences in response to cues was apparent in both CR and EMA data, providing the necessary context to assess their relationship. Laboratory CR measures of cue response were not correlated with real-world cue responses assessed by EMA. The average correlation was 0.03; none exceeded 0.32. One of 40 correlations examined was significantly greater than 0.\nQuestion: Does laboratory cue reactivity correlate with real-world craving and smoking responses to cues?",
        "gt": "Laboratory CR measures do not correlate with EMA-assessed craving or smoking in response to cues, suggesting that CR measures are not accurate predictors of how smokers react to relevant stimuli in the real world.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It is generally accepted that with experience clinicians develop the ability to identify patients who present with malignancy prior to a formal diagnosis. This ability cannot be quantified, nor is it a plausible substitute for investigation. This study aimed to evaluate the association between instinct and head and neck cancer diagnosis. A prospective study of patients requiring urgent diagnostic procedures for suspected cancer between August and December 2010 was performed. Risk factors, symptoms, signs and the clinician's impression were recorded. These were graded and subsequently correlated with histology findings. Twenty-seven patients, with a mean age of 62.2 years, underwent a diagnostic procedure. Thirty per cent of patients were referred under the two-week pathway and 18.5 per cent had a previous history of head and neck cancer. A diagnosis of cancer was made in 37 per cent of patients. There was a positive correlation between clinical suspicion and cancer diagnosis (Kendall's tau-b = 0.648749).\nQuestion: Gut instinct: a diagnostic tool?",
        "gt": "This study highlights the importance of clinical suspicion in cancer diagnosis. Although clinical suspicion cannot be quantified, it should be regarded as an integral part of patient assessment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the prevalence of polycystic ovary syndrome (PCOS) according to the three major diagnostic criteria previously described in an unselected group of women from Spain and to identify the most common phenotypes of the disease. An observational, transversal prevalence study was carried out between July 1 2014 and October 31 2014. All participants received a questionnaire and underwent a physical and trans-vaginal ultrasound examination. Blood samples were also collected for analysis of metabolic markers and hormones. PCOS was diagnosed according to three major criteria: NIH, Rotterdam and AE-PCOS criteria. Following diagnosis women with PCOS were assigned to one of four phenotypes. A total of 242 women were involved in the study. The prevalence for each major criteria was as follows: National Institute of Health (NIH) criteria had a prevalence of 1 4.88%, Rotterdam criteria had a prevalence of 29.34% and Androgen Excess and PCOS Society criteria presented a prevalence of 17.36%. The prevalence for each phenotype was: A, 40.85%; B, 25.35%; C, 8.45%; and D, 25.35%. PCOS women had more prevalence of hirsutism (36.61 %), infertility (25.35%), obesity (21.1 2%) and metabolic syndrome (11 .26%) than controls (7.01%, 6.43%, 5.84% and 2.33% respectively).\nQuestion: Polycystic ovary syndrome: is there a rise in the prevalence?",
        "gt": "There is a rise in the prevalence of PCOS in Caucasian population with the classic phenotype (oligo-anovulation, hyperandrogenism, polycystic ovaries) being the most common presentation of the syndrome.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Stage IIIC epithelial ovarian cancer is generally associated with upper abdominal tumor implants of greater than 2 cm and carries a grave prognosis. A subset of patients is upstaged to Stage IIIC because of lymph node metastases, in which prognosis is not well defined. We undertook this study to describe the clinical behavior of occult Stage IIIC. All consecutive patients found to have Stage IIIC epithelial ovarian cancer during a 9-year period (1994-2002) were analyzed for surgical procedures, pathology, and disease-free (DFS) and overall survival (OS). Thirty-six patients were upstaged to Stage IIIC by virtue of positive nodes. Nine had small volume upper abdominal disease (IIIA/B before upstaging), 15 had disease limited to the pelvis and 12 had disease confined to the ovaries. 32/36 patients had no gross residual disease at the conclusion of surgery. The 5-year DFS and OS survivals were 52% and 76% respectively, for all patients. We observed no significant difference in outcomes between patients upstaged from IIIA/B versus I-II stage disease. The outcomes were superior to a control group of patients cytoreduced to either no gross RD or RD<1 cm, who had large volume upper abdominal disease at beginning of surgery (p<0.001).\nQuestion: Is it justified to classify patients to Stage IIIC epithelial ovarian cancer based on nodal involvement only?",
        "gt": "Patients upstaged to Stage IIIC epithelial ovarian cancer for node involvement have an excellent 5-year OS relative to all patients with Stage IIIC disease. These data demonstrate the necessity for stratifying patients classified as having Stage IIIC disease based solely on nodal disease when comparing outcomes. This information is particularly valuable when counseling patients regarding prognosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Reliable method to predict lymph node metastasis is not yet available. In the present study, therefore, we examined LI-cadherin expression in human gastric cancer and attempted to find its relationship with clinicopathologic data, especially with lymph node metastasis. We also analyzed the expression in preoperative biopsy specimen to uncover its possibility of prognostication for lymph node metastasis. The paired preoperative endoscopic biopsy and postoperative resected specimens from 208 patients who had surgically been treated for gastric cancer were retrospectively analyzed immunohistochemically for expression of LI-cadherin. There were 47 (22.6%) and 161 (77.4%) tumors which had positive and negative LI-cadherin expression, respectively. LI-cadherin expression was significantly correlated with tumor histology and lymph node metastasis: Furthermore, reduced expression of LI-cadherin was closely associated with tumor progression and lymph node metastasis in human gastric carcinoma. LI-cadherin expressions in both resected tumor and preoperative endoscopic tissues were found to be independent factors associated with lymph node metastasis.\nQuestion: Expression of liver-intestine cadherin and its correlation with lymph node metastasis in gastric cancer: can it predict N stage preoperatively?",
        "gt": "There is a close association between reduced expression of LI-cadherin and lymph node metastasis in human gastric cancer. Immunohistochemical study of LI-cadherin is relatively simple compared to sentinel node navigation surgery, and it could be a practical prediction method for lymph node metastasis in patients with this malignancy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Considerable debate exists concerning whether the presence of low preoperative IQ should be a contraindication for focal resective epilepsy surgery. We examined the relationship between baseline IQ scores and seizure outcome in 1,034 temporal lobectomy cases from eight epilepsy surgery centers participating in the Bozeman Epilepsy Consortium. Those patients who continued to have seizures following surgery had statistically lower preoperative IQ scores than those who were seizure-free (p<0.009), but only by 2.3 points. This small but statistically significant relationship was fairly robust; it was observed across seven of the eight centers, and indicates that the findings can be generalized. Among patients with IQ scores of<or = 75, 32.8% continued to have seizures following surgery, whereas 23.8% and 16.9% were not seizure-free when IQ scores were between 76 and 109 and>or = 110, respectively. Relative risk analyses revealed no significant increase in risk among patients with low IQ scores who had no structural lesions other than mesial temporal sclerosis. However, patients with IQ scores of<or = 75 had nearly a fourfold (390%) increase in risk for continued seizures as compared with those with higher IQ scores if structural lesions were present.\nQuestion: Does presurgical IQ predict seizure outcome after temporal lobectomy?",
        "gt": "While our results suggest that preoperative IQ scores alone are not good predictors of seizure outcome and should not be used to exclude patients as potential surgical candidates. IQ scores can be useful for counseling patients and their families concerning the relative risks of surgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The focus on evidence-based medicine has led to calls for increased levels of evidence in surgical journals. The purpose of the present study was to review the levels of evidence in articles published in the foot and ankle literature and to assess changes in the level of evidence over a decade. All of the articles in the literature from the years 2000, 2005, and 2010 in Foot&Ankle International and Foot and Ankle Surgery, as well as all foot and ankle articles from The Journal of Bone and Joint Surgery (JBJS, American [A] and British [B]Volumes) were analyzed. Animal, cadaver, and basic science articles; editorials; surveys; special topics; letters to the editor; and correspondence were excluded. Articles were ranked by a five-point level-of-evidence scale, according to guidelines from the Centre for Evidence-Based Medicine. A total of 720 articles from forty-three different countries were analyzed. The kappa value for interobserver reliability showed very good agreement between the reviewers for types of evidence (\u03ba = 0.816 [p&lt; 0.01]) and excellent agreement for levels of evidence (\u03ba = 0.869 [p&lt; 0.01]). Between 2000 and 2010, the percentage of high levels of evidence (Levels I and II) increased (5.2% to 10.3%) and low levels of evidence (Levels III, IV, and V) decreased (94.8% to 89.7%). The most frequent type of study was therapeutic. The JBJS-A produced the highest proportion of high levels of evidence.\nQuestion: Levels of evidence in foot and ankle surgery literature: progress from 2000 to 2010?",
        "gt": "There has been a trend toward higher levels of evidence in foot and ankle surgery literature over a decade, but the differences did not reach significance.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Meniscus replacement by a polymer meniscus prosthesis in dogs resulted in generation of new meniscal tissue. Optimal functioning of the prosthesis would involve realistic deformation and motion patterns of the prosthesis during knee joint motion. Controlled laboratory study. The movements of the meniscus were determined during knee joint flexion and extension with and without internal and external tibial torque by means of roentgen stereophotogrammetric analysis. Subsequently, the meniscus in 6 human cadaveric knee joints was replaced by a meniscus prosthesis. All different parts of the meniscus showed a posterior displacement during knee joint flexion. The anterior horn was more mobile than the posterior horn. The prosthesis mimicked the movements of the meniscus. However, the excursions of the prosthesis on the tibial plateau were less. The knee joint laxity was not significantly higher after replacement with the meniscus prosthesis.\nQuestion: Prosthetic replacement of the medial meniscus in cadaveric knees: does the prosthesis mimic the functional behavior of the native meniscus?",
        "gt": "The prosthesis approximated the behavior of the native meniscus. Improvement in both the gliding characteristics of the prosthetic material and the fixation of the prosthesis may improve the function.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Vitamin C acts as a potent antioxidant; however, it can also be a prooxidant and glycate protein under certain circumstances in vitro. These observations led us to hypothesize that a high intake of vitamin C in diabetic persons might promote atherosclerosis. The objective was to examine the relation between vitamin C intake and mortality from cardiovascular disease. We studied the relation between vitamin C intake and mortality from total cardiovascular disease (n = 281), coronary artery disease (n = 175), and stroke (n = 57) in 1923 postmenopausal women who reported being diabetic at baseline. Diet was assessed with a food-frequency questionnaire at baseline, and subjects initially free of coronary artery disease were prospectively followed for 15 y. After adjustment for cardiovascular disease risk factors, type of diabetes medication used, duration of diabetes, and intakes of folate, vitamin E, and beta-carotene, the adjusted relative risks of total cardiovascular disease mortality were 1.0, 0.97, 1.11, 1.47, and 1.84 (P for trend<0.01) across quintiles of total vitamin C intake from food and supplements. Adjusted relative risks of coronary artery disease were 1.0, 0.81, 0.99, 1.26, and 1.91 (P for trend = 0.01) and of stroke were 1.0, 0.52, 1.23, 2.22, and 2.57 (P for trend<0.01). When dietary and supplemental vitamin C were analyzed separately, only supplemental vitamin C showed a positive association with mortality endpoints. Vitamin C intake was unrelated to mortality from cardiovascular disease in the nondiabetic subjects at baseline.\nQuestion: Does supplemental vitamin C increase cardiovascular disease risk in women with diabetes?",
        "gt": "A high vitamin C intake from supplements is associated with an increased risk of cardiovascular disease mortality in postmenopausal women with diabetes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the feasibility and efficacy of catheter-directed thrombolysis with recombinant tissue plasminogen activator (rt-PA) for acute limb embolism in patients with recent cerebral embolism due to atrial fibrillation. Eight patients (six men, two women; mean age 63.5 years) with acute embolic occlusion of two left common iliac arteries, four femoral arteries (three left; one right), and two right popliteal arteries were treated. All patients had a history of recent cerebral embolism (mean 6 days, range 5-15 days) and all had a history of atrial fibrillation (duration 5-10 years). Catheter-directed thrombolysis started a few hours (mean 6.2h; range 3-10h) after the onset of arterial embolism. Two 5mg boluses of rt-PA were injected into the proximal clot through a 5 F end-hole catheter and, subsequently, two additional boluses of 5mg rt-PA were injected into the emboli. In patients with residual emboli, infusion with rt-PA (1mg/h) was continued. Percutaneous transluminal angioplasty was performed in three patients, and a stent was deployed in one patient. Technical success was achieved in all patients. Clinical success rate was 87.5% (7/8). The one clinical failure was secondary to chronic occlusion of outflow runoff vessels. The mean duration of continuous rt-PA infusion was 3.6h, the mean total dose of rt-PA administered was 23.6 mg (range 20-28 mg). There was no significant change in stroke scale scores during thrombolysis and no intracerebral haemorrhage was found at computed tomography (CT) after thrombolysis. Minor complications included haematomata at puncture sites (6/8), bleeding around the vascular sheath (2/8), and haematuria (1/8). During the follow-up period of 3-6 months, one patient suffered from recurrent cerebral embolism and died.\nQuestion: Can catheter-directed thrombolysis be applied to acute lower extremity artery embolism after recent cerebral embolism from atrial fibrillation?",
        "gt": "Catheter-directed thrombolysis with rt-PA is an option for acute lower extremity arterial embolism in patients with recent cerebral embolism and a history of atrial fibrillation. Further studies should be undertaken to determine the risk of intracerebral haemorrhage caused by catheter-directed thrombolysis in individual stroke patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cystic lesions of the pancreas (CLP) are of different origin and behaviour. Mucinous lesions with the risk of invasive cancer represent an important subgroup. The key point in differential diagnosis of CLP is to distinguish malignant and benign lesions and also correct indication for surgery in order to minimize the impact of serious complications after resection. Different and unsatisfying predictive values of each of the examinations make proper diagnosis challenging. We focused on overall diagnostic accuracy of preoperative imaging and analytic studies. We studied the accuracy of distinguishing between non-neoplastic vs. neoplastic and bening vs. malignant lesions. We retrospectively analyzed all of the patients (N=72) with CLP (median of age 58 years, range 22-79) recommended for surgery. CT, EUS, ERCP, MRCP findings, cytology and aspirate analysis were used to establish preoperative diagnosis. Finally, preoperative diagnoses were compared with postoperative pathological findings to establish overall accuracy of preoperative assessment. During 5 years, 72 patients underwent resection for CLP. We performed 66 (92%) resection and 6 (8%) palliative procedures with 32% morbidity and 7% of one hospital stay mortality. All the patients were examined by CT and EUS. FNA was performed in 44 (61%) patients. Cytology was evaluable in 39 (88%) cases. ERCP was done in 40 (55%) patients. Pathology revealed non-neoplastic CLP in 25 (35%) and neoplastic lesions in 47 (65%) specimens. Mucinous lesions accounted for 25%. Malignant or potentially malignant CLP were found in 37 (51%) patients. Sensitivity, specificity and diagnostic accuracy of preoperative diagnosis for distinguishing between inflammatory and neoplastic, and benign and malignant was 100%, 46%, 85% and 61%, 61%, 44%, respectively.\nQuestion: Is accurate preoperative assessment of pancreatic cystic lesions possible?",
        "gt": "Correct and accurate preoperative assessment of CLP remains challenging. Despite the wide range of diagnostic modalities, the definitive preoperative identification of malignant or high-risk CLP is inaccurate. Because of this, a significant portion of the patients undergo pancreatic resection for benign or inflammatory lesions that are not potentially life-threatening. Possible serious complications after pancreatic surgery are the main reason for precise selection of patients with cystic affections recommended for surgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adjuvant chemoradiotherapy (CRT) for patients with gastric cancer after D2 lymphadenectomy remains controversial. The objective of the present meta-analysis was to analyze efficacy and safety of postoperative CRT and establish a consensus on whether it is suitable for the patients. We searched PubMed, Ovid, Cochrane, and Web of Science. Statistical analysis was carried out by STATA version 12.0 software. The quality of evidence was assessed by Jadad and the Newcastle-Ottawa quality assessment scale. Six studies involving 2135 patients were included for the meta-analysis. The results showed that, compared with non-CRT, postoperative adjuvant CRT was associated with a significant improvement in 5-year overall survival (OS) (HR = 0.79, 95% CI 0.68-0.92, P = 0.002) and 5-year relapse-free survival (RFS) (HR = 0.81, 95% CI 0.70-0.93, P = 0.004). However, there were no differences in distant metastasis (RR = 0.93, 95% CI 0.82-1.06, P = 0.304) and treatment-related toxicity between the two groups.\nQuestion: Is postoperative adjuvant chemoradiotherapy efficacious and safe for gastric cancer patients with D2 lymphadenectomy?",
        "gt": "From the results of our study, postoperative adjuvant CRT may be associated with longer 5-year OS and 5-year RFS in patients with D2 lymphadenectomy, but might not improve 5-year disease-free survival compared to non-CRT. Methodologically high-quality comparative studies are needed for further evaluation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It has been noted that after tubularized incised plate urethroplasty (TIP) repair, the final meatal position is glanular but not at the optimum position. Inner preputial inlay graft combined with tubularized incised plate (G-TIP) has been proposed for redo urethroplasty. We extended this indication to be the standard technique for primary hypospadias repair. We conduct this prospective study to obtain a wide, slit-like appearance neomeatus at the optimum position in the glans proper and to judge if hypospadias repair complications differ from TIP repair in the published data in the literature. This prospective study included 230 consecutive patients who underwent this technique. The study was conducted from November 2011 to August 2014 for all hypospadias cases to be repaired in a single stage regardless of the width and depth of urethral plate or the glans size and shape. Localization of the meatus was glanular in 13 patients, coronal in 75, distal penile in 112, mid penile in 25 and proximal in five. The urethral plate was incised deeply and extended distally beyond the end of the plate by 3 mm in glans proper. The mucosal graft was harvested from the inner prepuce, inlayed and quilted in the incised urethral plate. The neourethra was created over a urethral catheter in two layers. The vascular dartos flap was mobilized dorsally and moved ventrally to cover the neourethral suture line as a barrier. The follow-up period ranged from 5 to 36 months. Excellent cosmetic and functional results were achieved in 221 of 230 patients (96.09%). Neither meatal stenosis nor urethral diverticulum were encountered. An excellent glanular position of a wide slit-like neomeatus was achieved using this technique. Nine patients (3.91%) developed urethrocutaneous fistula. Excellent urinary stream was reported by parents.\nQuestion: Is combined inner preputial inlay graft with tubularized incised plate in hypospadias repair worth doing?",
        "gt": "Combined inner preputial graft with TIP urethroplasty secures the optimal glanular position of a wide slit-like neomeatus because of extension of the incision beyond the end of the plate, thus optimizing functional and cosmetic outcome with no meatal stenosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This population-based study investigated the different forms, magnitude and risk factors of men's violence against women in intimate relationships in a rural part of northern Vietnam and whether a difference in risk factors were at hand for the different forms of violence. Vietnam has undergone a rapid transition in the last 20 years, moving towards a more equal situation for men and women however, Confucian doctrine is still strong and little is known about men's violence against women within the Vietnamese family. This is a cross-sectional population-based study that used a questionnaire developed by the World Health Organisation for investigating women's health and violence against women in different settings. Face-to face structured interviewing was performed and 883 married women, aged 17 to 60 participated. Bi- and multivariate analyses was used for risk factor assessment. The lifetime prevalence of physical violence was 30.9 percent and past year prevalence was 8.3 per cent, while the corresponding figures for physical and sexual violence combined was 32.7 and 9.2 percent. The lifetime prevalence was highest for psychological abuse (27.9 percent) as a single entity. In most cases the violence was of a severe nature and exercised as repeated acts over time. Woman's low educational level, husband's low education, low household income and the husband having more than one wife/partner were risk factors for lifetime and past year physical/sexual violence. The pattern of factors associated with psychological abuse alone was however different. Husband's low professional status and women's intermediate level of education appeared as risk factors.\nQuestion: Intimate partner violence against women in rural Vietnam--different socio-demographic factors are associated with different forms of violence: need for new intervention guidelines?",
        "gt": "Men's violence against women in intimate relationships is commonly occurring in rural Vietnam. There is an obvious need of preventive and treatment activities. Our findings point at that pure psychological abuse is different from physical/sexual violence in terms of differing characteristics of the perpetrators and it might be that also different strategies are needed to reduce and prevent this violence.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To prospectively investigate whether preoperative functional flexion axis in patients with osteoarthritis- and varus-alignment changes after total knee arthroplasty and whether a correlation exists both between preoperative functional flexion axis and native limb deformity. A navigated total knee arthroplasty was performed in 108 patients using a specific software to acquire passive joint kinematics before and after implant positioning. The knee was cycled through three passive range of motions, from 0\u00b0 to 120\u00b0. Functional flexion axis was computed using the mean helical axis algorithm. The angle between the functional flexion axis and the surgical transepicondylar axis was determined on frontal (\u03b1 (F)) and axial (\u03b1 (A)) plane. The pre- and postoperative hip-knee-ankle angle, related to femur mechanical axis, was determined. Postoperative functional flexion axis was different from preoperative only on frontal plane, while no differences were found on axial plane. No correlation was found between preoperative \u03b1 (A) and native limb deformity, while a poor correlation was found in frontal plane, between \u03b1 (F) and preoperative hip-knee-ankle angle.\nQuestion: Does total knee arthroplasty modify flexion axis of the knee?",
        "gt": "Total knee arthroplasty affects functional flexion axis only on frontal plane while has no effect on axial plane. Preoperative functional flexion axis is in a more varus position respect to the transepicondylar axis both in pre- and postoperative conditions. Moreover, the position of the functional axis on frontal plane in preoperative conditions is dependent on native limb alignment, while on axial plane is not dependent on the amount of preoperative varus deformity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is limited evidence to evaluate the influence of competitive food and beverage legislation on school meal program participation and revenues. A representative sample of 56 California high schools was recruited to collect school-level data before (2006\u20132007) and the year after (2007\u20132008) policies regarding limiting competitive foods and beverages were required to be implemented. Data were obtained from school records, observations, and questionnaires. Paired t-tests assessed significance of change between the two time points. Average participation in lunch increased from 21.7% to 25.3% (p<0.001), representing a 17.0% increase, while average participation in breakfast increased from 8.9% to 10.3% (p = 0.02), representing a 16.0% increase. There was a significant (23.0%) increase in average meal revenue, from $0.70 to $0.86 (per student per day) (p<0.001). There was a nonsignificant decrease (18.0%) in average sales from \u00e0 la carte foods, from $0.45 to $0.37 (per student per day). Compliance with food and beverage standards also increased significantly. At end point, compliance with beverage standards was higher (71.0%) than compliance with food standards (65.7%).\nQuestion: Does competitive food and beverage legislation hurt meal participation or revenues in high schools?",
        "gt": "Competitive food and beverage legislation can increase food service revenues when accompanied by increased rates of participation in the meal program. Future studies collecting expense data will be needed to determine impact on net revenues.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The study aimed at evaluating the expression of androgen receptor (AR) and nuclear survivin (NS) in periocular sebaceous gland carcinoma (SGC) and to determine whether this expression is associated with histopathological features, markers of apoptosis and proliferation and with clinical outcomes. This was a retrospective, comparative case series which included 56 patients with a biopsy-proven periocular SGC. Immunohistochemical staining for AR, survivin, p53 and Ki-67 was analysed in all cases. All patients expressed AR, p53 and Ki-67 in the nucleus of tumour cells. Twenty-four patients (42.8%) had a high AR score, and 32 patients (57.2%) had a low AR score. Twenty-four (42.8%) patients expressed survivin in the nucleus of tumour cells. Nine (37.5%) had a high NS score, and 15 (62.5%) had a low NS score. Patients with a high AR score had a greater recurrence (p<0.005), higher expression of Ki-67 (p<0.0001) and a lower p53 expression (p<0.005). Nuclear expression of survivin correlated with a high Ki-67 labelling index (0.0001) and low p53 expression (<0.005). Neither nuclear expression of survivin nor the NS score correlated with any clinicopathological features.\nQuestion: Periocular sebaceous gland carcinoma: do androgen receptor (NR3C4) and nuclear survivin (BIRC5) have a prognostic significance?",
        "gt": "Expression of AR significantly impacts prognosis and is thus promising prognostic marker in periocular SGC.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aetiology of idiopathic intracranial hypertension (IIH) is not known, but its association with obesity is well-recognized. Recent studies have linked obesity with abnormalities in circulating inflammatory and adiposity related cytokines. The aim of this study was to characterize adipokine and inflammatory cytokine profiles in IIH. Paired serum and cerebrospinal fluid (CSF) specimens were collected from 26 patients with IIH and compared to 62 control subjects. Samples were analysed for leptin, resistin, adiponectin, insulin, IL-1beta, IL-6, IL-8 (CXCL8), TNFalpha, MCP-1 (CCL2), hepatocyte growth factor, nerve growth factor and PAI-1 using multiplex bead immunoassays. CSF leptin was significantly higher in patients with IIH (P = 0.001) compared to controls after correction for age, gender and body mass index (BMI). In the control population, BMI correlated with serum leptin (r = 0.34; P = 0.007) and CSF leptin (r = 0.51; P<0.0001), but this was not the case for the IIH population. Profiles of other inflammatory cytokines and adipokines did not differ between IIH patients and controls once anthropometric factors had been accounted for.\nQuestion: Elevated cerebrospinal fluid (CSF) leptin in idiopathic intracranial hypertension (IIH): evidence for hypothalamic leptin resistance?",
        "gt": "IIH was characterized by significantly elevated CSF leptin levels which did not correlate with BMI. We suggest that CSF leptin may be important in the pathophysiology of IIH and that obesity in IIH may occur as a result of hypothalamic leptin resistance.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate safety and efficacy of Trans-Arterial Ethanol-Lipiodol Embolization (TAELE) compared with conventional Trans-Arterial Chemo-Embolization (cTACE) in the treatment of small intermediate-HCC (BCLC-Stage B). A random sample of 87 patients (37.93% male; 62.07% female; age range, 36-86 years) with documented small intermediate-HCC and treated with TAELE (mixture 1:1 of Ethanol and Lipiodol) or cTACE (mixture of 50mg-Epirubicin and 5cc-Lipiodol) were retrospectively studied in an institutional review board approved protocol. The two procedures were compared with \u03c72-test, \u03c72-test with Yates correction, McNemar's exact test, ANOVA test and log-rank test. TAELE and cTACE therapies were performed in 45 and 42 patients, respectively. Thirty days after the procedure, a Multi-Detector Computed Tomography (MDCT) showed no significant difference in the number of patients with partial and complete response between the two groups (p-value = 0.958), according to mRECIST. Contrary, significant differences were found in tumor-devascularization, lesion-reduction and post-embolization syndrome occurrence (p-value = 0.0004, p-value = 0.0003 and p-value = 0.009, respectively). Similar survival was observed during 36-month follow-up (p-value = 0.884).\nQuestion: Use of Ethanol in the Trans-Arterial Lipiodol Embolization (TAELE) of Intermediated-Stage HCC: Is This Safer than Conventional Trans-Arterial Chemo-Embolization (c-TACE)?",
        "gt": "Compared to cTACE, TAELE showed a better toxicity profile with similar 36-month survival and similar one-month anti-tumor effects, which makes it better tolerated by patients, especially in case of more than one treatment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Acute rejection following kidney transplantation (KTx) is still one of the challenging complications leading to chronic allograft failure. The aim of this study was to investigate the role of microdialysis (MD) in the early detection of acute graft rejection factor following KTx in porcine model. Sixteen pigs were randomized after KTx into case (n = 8, without immunosuppressant) and control groups (n = 8, with immunosuppressant). The rejection diagnosis in our groups was confirmed by histopathological evidences as \"acute borderline rejection\". Using MD, we monitored the interstitial concentrations of glucose, lactate, pyruvate, glutamate and glycerol in the transplanted grafts after reperfusion. In the early post-reperfusion phase the lactate level in our case group was significantly higher comparing to the control group and remained in higher levels until the end of monitoring. The lactate to pyruvate ratio showed a considerable increase in the case group during the post-reperfusion phase. The other metabolites (glucose, glycerol, glutamate) were nearly at the same levels at the end of our monitoring in both study groups.\nQuestion: Is microdialysis useful for early detection of acute rejection after kidney transplantation?",
        "gt": "The increase in lactate and lactate to pyruvate ratios seems to be an indicator for early detection of acute rejection after KTx. Therefore, MD as a minimally invasive measurement tool may help to identify the need to immunosuppression adjustment in the early KTx phase before the clinical manifestation of the rejection.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adverse drug events represent the most common cause of preventable nonsurgical adverse events in medicine but may remain undetected. Our objective is to determine the proportion of drug-related visits emergency physicians attribute to medication-related problems. This prospective observational study enrolled adults presenting to a tertiary care emergency department (ED) during 12 weeks. Drug-related visits were defined as ED visits caused by adverse drug events. The definition of adverse drug event was varied to examine both narrow and broad adverse drug event classification systems. Clinical pharmacists evaluated all patients for drug-related visits, using standardized assessment algorithms, and then followed patients until hospital discharge. Interrater agreement for the clinical pharmacist diagnosis of drug-related visit was assessed. Emergency physicians, blinded to the clinical pharmacist opinion, were interviewed at the end of each shift to determine whether they attributed the visit to a medication-related problem. An independent committee reviewed and adjudicated all cases in which the emergency physicians' and clinical pharmacists' assessments were discordant, or either the emergency physician or clinical pharmacist was uncertain. The primary outcome was the proportion of drug-related visits attributed to a medication-related problem by emergency physicians. Nine hundred forty-four patients were enrolled, of whom 44 patients received a diagnosis of the narrowest definition of an adverse drug event, an adverse drug reaction (4.7%; 95% confidence interval [CI] 3.5% to 6.2%). Twenty-seven of these were categorized as medication-related by emergency physicians (61.4%; 95% CI 46.5% to 74.3%), 10 were categorized as uncertain (22.7%; 95% CI 12.9% to 37.1%), and 7 categorized as a non-medication-related problem (15.9%; 95% CI 8.0% to 29.5%). Seventy-eight patients (8.3%; 95% CI 6.7% to 10.2%) received a diagnosis of an adverse drug event caused by an adverse drug reaction, a drug interaction, drug withdrawal, a medication error, or noncompliance. Emergency physicians attributed 49 of these to a medication-related problem (62.8%; 95% CI 51.7% to 72.7%), were uncertain about 15 (19.2%; 95% CI 12.0% to 29.4%), and attributed 14 to non-medication-related problems (17.9%; 95% CI 11.0% to 27.9%). Twenty-five of 29 (86.2%; 95% CI 69.3% to 94.4%) adverse drug events not considered medication related by emergency physicians were rated at least moderate in severity.\nQuestion: Do emergency physicians attribute drug-related emergency department visits to medication-related problems?",
        "gt": "A significant proportion of drug-related visits are not deemed medication related by emergency physicians. Drug-related visits not attributed to medication-related problems by emergency physicians may be missed in ongoing outpatient adverse drug event surveillance programs intended to develop strategies to enhance drug safety. Further research is needed to determine what the effect may be of not attributing adverse drug events to medication-related problems.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the effectiveness of 4.5F ultrathin semirigid ureteroscope (ultrathin-URS) in the management of ureteral stones in prepubertal children without active or passive ureteral dilatation. Records of 36 children undergoing ureteroscopy with ultrathin-URS were retrospectively reviewed in 2 different centers for ureteral calculi between November 2011 and December 2013. Stones were fragmented with holmium:yttrium-aluminum-garnet laser and pneumatic lithotripter. Patients' demographics, stone location and size, active dilatation, passive dilatation, postoperative stenting, stone-free rates, and complications were noted. Patients consisted of 21 girls and 15 boys with a mean age of 5.33\u00b13 years. Stones were located in the distal, mid, and proximal ureter in 26, 5, and 5 patients, respectively. All ureteroscopies were performed with no active or passive dilatation. Ultrathin-URS was able to provide a stone-free status in the first procedure except 1 patient whose stone was too proximal. Postoperative ureteral stents (post-stenting) had initially been placed in 16 procedures at the end of the procedure to maintain the ureteral passage. However, after increasing occupational experience and learning that ureteral traumas were minimal with ultrathin-URS, no postoperative stent was used in the following procedures. As to complications, only 3 patients had mild hematuria, and 1 patient had febrile urinary tract infection, and 1 stone migration. No ureteral perforation, obstruction and avulsion were encountered.\nQuestion: The effectiveness of 4.5F ultrathin semirigid ureteroscope in the management of ureteral stones in prepubertal children: is there a need for any ureteral dilatation?",
        "gt": "In ureteral stone management, ultrathin-URS along with either holmium:yttrium-aluminum-garnet laser or pneumatic lithotripter can be safely and effectively used with a minimal morbidity as a first-line treatment in prepubertal children without active or passive ureteral dilatation and postoperative stenting.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Sleep-disordered breathing (SDB) is associated with reduced nocturnal dipping of blood pressure (BP) and sleep disruption in adults, and these features confer an increased risk of cardiovascular events. As SDB prevalence in children peaks during the preschool years, we investigated nocturnal dipping and sleep fragmentation in preschool children with SDB. Children (3-5 years; n=163) grouped by obstructive apnoea hypopnoea index (OAHI): control, no snoring history and OAHI \u22641 event/h; primary snoring, OAHI \u22641 event/h; mild SDB,>1-\u22645 events/h; moderate-severe SDB,>5 events/h. Pulse transit time (PTT), an inverse continuous indicator of BP changes, and heart rate (HR) during total sleep time and the first period of rapid eye movement (REM), non-REM (NREM)1/2 and NREM3/4 sleep were expressed as percentage change from wake before sleep onset. The sleep fragmentation index (SFI) was calculated as the number of sleep stage transitions or awakenings per hour of sleep. There were no group differences in the change in PTT or HR from wake to total sleep time or to individual sleep stages or in the proportion of children in the quartile with the smallest change in PTT during total sleep. Children with moderate-severe SDB had higher SFI than primary snoring (PS) or mild SDB groups (p<0.05 for both) and controls (p=0.07).\nQuestion: Sleep-disordered breathing does not affect nocturnal dipping, as assessed by pulse transit time, in preschool children: evidence for early intervention to prevent adverse cardiovascular effects?",
        "gt": "In contrast to adults, nocturnal dipping is preserved in young children with SDB, despite increased sleep fragmentation. As there is evidence that nocturnal dipping is similarly preserved at the school age, childhood may pose a window of opportunity for resolution of SDB when the cardiovascular effects are less marked.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Intellectual deficits are commonly found in schizophrenia patients. These intellectual deficits have been found to be heritable. However, whether the intellectual deficits change over time and, if so, whether the change is related with an increased genetic risk for the disease are not known. We investigated change of intelligence quotient (IQ) in a twin sample of chronically ill schizophrenia patients, the discordant co-twins and healthy controls during a follow-up period of 5 years. A total of 52 twins completed two IQ assessments: nine patients [three monozygotic (MZ) and six dizygotic (DZ)], 10 unaffected co-twins (three MZ and seven DZ) and 33 healthy control twins (21 MZ and 12 DZ). A significant interaction effect over time was found between IQ measurement and illness (F=4.22, df=1, p<0.05), indicating that change in IQ over time is significantly different between the groups. A stable course in IQ over time was found in the patients with schizophrenia (mean IQ from 109.78 at baseline to 108.44 at follow-up) relative to both the healthy control twins who showed a small increase (from 114.61 at baseline to 119.18 at follow-up) (t=2.06, p<0.05) and the unaffected co-twins (from 111.60 to 117.60, t=-2.32, p<0.05). IQ change in the unaffected co-twins of schizophrenia patients was comparable with that in healthy control twins (t=-0.49, p=0.63).\nQuestion: Is there change in intelligence quotient in chronically ill schizophrenia patients?",
        "gt": "Patients with schizophrenia in the chronic phase of the disease, but not the discordant co-twins, show a lack of increase in IQ, which is probably due to environmental (non-genetic) factors related to the disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A total of 571 consecutive patients were observed for 12 months between July 2001 and June 2004. Inclusion criteria were a confirmed diagnosis Graves' disease, compensation of hyperthyroidism and withdrawal of antithyroid drugs two days before preliminary radioiodine-testing and RIT. The intended dose was 250 Gy and the therapeutically achieved dose was calculated from serial uptake measurements. The end-point measure was thyroid function 12 months after RIT; success was defined as elimination of hyperthyroidism. The relation between success rate and the achieved dose, thyroid volume, age and sex of patients, TSH- and TRAb-values and presence of ophthalmopathy was analysed. Relief from hyperthyroidism was achieved in 96% of patients who received more than 200 Gy, even for thyroid volumes>40 ml. The success of ablative RIT was not influenced by age or sex of patients, or by TSH- or TRAb values or concomitant ophthalmopathy. The mean achieved dose in the thyroid was 298 Gy with a standard deviation of 74.6 Gy.\nQuestion: Graves' disease and radioiodine therapy. Is success of ablation dependent on the achieved dose above 200 Gy?",
        "gt": "To achieve a dose of over 200 Gy with the above standard deviation, we recommend calculating an intended dose of 250 Gy and using a dosimetric approach with early and late uptake values in the radioiodine test, to allow early therapeutic intervention should the posttherapeutic thyroid dose fall unexpectedly below 200 Gy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether the incidence of gout is higher in 1995-1996 compared to 1977-1978. Using the Rochester Epidemiology Project computerized medical record system, all potential cases of acute gout in the city of Rochester, Minnesota during the time intervals of 1977-1978 and 1995-1996 were identified. The complete medical records of all potential cases were screened and all who fulfilled the 1977 American College of Rheumatology proposed criteria for gout were included as incidence cases. Demographic data, body mass index, clinical presentation, and associated comorbid conditions were abstracted. The overall and age-gender adjusted incidence rates from the 2 cohorts were calculated and compared. A total of 39 new cases of acute gout were identified during the 2 year interval 1977-1978 representing an age and sex-adjusted annual incidence rate of 45.0/100,000 (95% CI: 30.7, 59.3). For the interval 1995-1996, 81 cases were diagnosed, representing an annual incidence rate of 62.3/100,000 (95% CI: 48.4, 76.2). There was a greater than 2-fold increase in the rate of primary gout (i.e., no history of diuretic exposure) in the recent compared to the older time periods (p = 0.002). The incidence of secondary, diuretic related gout did not increase over time (p = 0.140).\nQuestion: Epidemiology of gout: is the incidence rising?",
        "gt": "Our results indicate that the incidence of primary gout has increased significantly over the past 20 years. While this increase might be a result of improved ascertainment of atypical gout, it may also be related to other, as yet unidentified, risk factors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Crosslinked UHMWPE as a bearing surface in total joint arthroplasty has higher wear resistance than conventional UHMWPE but lower strength and toughness. To produce crosslinked UHMWPE with improved mechanical properties, the material can be treated before crosslinking by tension to induce molecular alignment (texture).QUESTIONS/ We asked how (1) the microstructure of UHMWPE evolves when subjected to tension and (2) whether the new microstructure (texture) increases strength and toughness. We analyzed microstructure evolution of UHMWPE by small- and wide-angle xray scattering and scanning electron microscopy. We then developed a method to characterize the local strength and toughness of undeformed and textured UHMWPEs by means of nanoscratch tests along and perpendicular to the specimen axis. In three samples we determined the scratch characteristics in terms of deformation mode, coefficient of friction (\u03bc), and viscoelastic recovery (r). Before the tensile process, the scratch behavior of UHMWPE was characterized by a \u03bc ranging from 0.64 to 0.68, no cracking, and r ranging from 0.58 to 0.60. Microfibrillar morphologic features resulted from the tensile process. The new microstructure had an increased strength (r=0.78) and decreased toughness (cracking+\u03bc=0.77) perpendicular to the fibril axis and decreased strength (r=0.53) and increased toughness (no cracking+\u03bc=0.55) parallel to the fibril axis.\nQuestion: Does texturing of UHMWPE increase strength and toughness?",
        "gt": "Textured UHMWPE behaves like a fiber composite with high strength and toughness in well-defined directions. However, the effect of crosslinking on these specific properties is unknown and therefore it is important to verify that the properties are retained. If wear resistance of crosslinked-textured UHMWPE is at least as high as that of crosslinked UHMWPE, novel medical devices made of crosslinked-textured UHMWPE could be developed and clinically tested.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To present our experience using a twice-daily radiotherapy (RT) technique, including hyperfractionated and accelerated-hyperfractionated RT, on nasopharyngeal carcinoma (NPC) patients. The dose to the primary tumor was increased in the hope that local control could be increased without the cost of increased late complications. We analyzed acute and late complications and local control and compared the results with the results of NPC patients treated during the same period using conventional once-daily RT. Between October 1991 and July 1998, 222 histologically confirmed, Stage M0, previously unirradiated NPC patients completed RT at our hospital. Most patients had American Joint Committee on Cancer (AJCC) 1992 Stage III and IV disease. Among them, 88 received altered fractionated, twice-daily RT; 76 patients received hyperfractionated RT and 12 accelerated-hyperfractionated RT. The remaining 134 patients received a conventional once-daily regimen. Hyperfractionated RT was delivered using 120 cGy b.i.d. separated by 6-h intervals throughout the course. For the accelerated-hyperfractionated patients, 160 cGy b.i.d. was given, also at 6-h intervals. The median dose in the twice-daily group was 7810 cGy (range 6840-8200). In the once-daily regimen, RT was delivered using 180-200 cGy q.d. The median tumor dose to the primary tumor was 7000 cGy (range 6560-8100) given during about 8 weeks. The median follow-up time was 70.5 and 72 months for the twice-daily and once-daily groups, respectively. The incidence of acute toxicities was higher in the twice-daily group with more severe mucositis and moist desquamation than in the once-daily group. Both groups had a similar incidence of late complications, except for 3 cases of temporal lobe necrosis in the twice-daily group, all in patients treated with 160 cGy. No difference was noted in recurrence-free local control between the two groups when the individual T stage was compared using AJCC 1992 or 1997 criteria (p = 0.51 and 0.59, respectively). The 5-year local control rate for T1-3 (AJCC 1997) was 93.2% for the twice-daily group and 86.4% for the once-daily group (p = 0.45). In Stage T4 (AJCC 1997) patients, the local control rate dropped drastically to 43.5% and 36.9% for the twice-daily and once-daily groups, respectively. The overall neck control rate at 5 years was 87.3% and 80.3% for the twice-daily and once-daily patients, respectively (p = 0.16). The overall locoregional control rate was 82.7% for the twice-daily group and 66.6% for the once-daily group. The difference was again not statistically significant, but showed a tendency in favor of the twice-daily regimen (p = 0.055). Locoregional failure occurred mainly in Stage T4 patients with central nervous invasion for whom local control was particularly poor, with a failure rate of about 60%.\nQuestion: Dose escalation using twice-daily radiotherapy for nasopharyngeal carcinoma: does heavier dosing result in a happier ending?",
        "gt": "The present data suggest that NPC patients can be safely treated using a 120-cGy twice-daily program with a 6-h interval up to 8000 cGy. The accelerated-hyperfractionated technique is not recommended. A large discrepancy in local control between patients with T1-3 and T4 disease was noted. For T1-3 disease, an excellent local control rate>90% was achieved using the twice-daily regimen. In contrast, failure in the T4 patients was as high as 55% in the twice-daily group and reached 65% in the once-daily group. More rigorous treatment is needed using either additional dose escalation or other strategies for T4 NPC patients. With a dose escalation of 1000 cGy using 120-cGy twice-daily RT, a trend toward better locoregional control and disease-specific survival was noted in the twice-daily group. Whether this difference was truly the result of an increased dose needs additional confirmation in studies with larger patient numbers.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Some, but not all, patients with renal dysfunction suffer from side effects after morphine administration because of accumulation of the active metabolite morphine-6-glucuronide (M6G). The current study aims to identify genetic causes that put patients at risk for, or protect them from, opioid side effects related to high plasma M6G. Candidate genetic causes are the single nucleotide polymorphism (SNP) A118G of the mu-opioid-receptor gene (OPRM1), which has recently been identified to result in decreased potency of M6G, and mutations in the MDR1-gene coding P-glycoprotein, of which morphine and M6G might be a substrate. Two men, aged 87 and 65 yr, with renal failure (creatinine clearance of 6 and 9 ml/min) received 30 mg/day oral morphine for pain treatment. Both patients had sufficient analgesia from morphine. However, while one patient tolerated morphine well despite high plasma M6G of 1735 nM, in the patient with M6G plasma concentrations of 941 nM it caused severe sleepiness and drowsiness. Patients were genotyped for known SNPs of the OPRM1 and MDR1 genes. The patient who tolerated morphine well despite high plasma M6G was a homozygous carrier of the mutated G118 allele of the mu-opioid-receptor gene, which has been previously related to decreased M6G potency. In contrast, the patient who suffered from side effects was \"wild-type\" for this mutation. No other differences were found between the OPRM1 and MDR1 genes.\nQuestion: Does the A118G polymorphism at the mu-opioid receptor gene protect against morphine-6-glucuronide toxicity?",
        "gt": "The authors hypothesize that the A118G single nucleotide polymorphism of the mu-opioid-receptor is among the protective factors against M6G-related opioid toxicity. The observation encourages the search for pharmacogenetic reasons that cause interindividual variability of the clinical effects of morphine.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To study the levels of procalcitonin (PCT) in various inflammatory states seen in an internal medicine department and to evaluate the possible discriminative role of PCT in differentiating bacterial infection from other inflammatory processes. PCT, C reactive protein (CRP), and white blood cell count (WBC) were measured in patients admitted to the department for fever or biological inflammatory syndrome, or both. The serum of 173 consecutive patients was analysed according to the aetiological diagnosis. The patients were divided into two groups: group I (n=60) with documented bacterial or fungal infection; group II (n=113) with abacterial inflammatory disease. PCT levels were>0.5 ng/ml in 39/60 (65%) patients in group I. In group II, three patients with a viral infection had slightly increased PCT levels (0.7, 0.8, and 1.1 ng/ml) as did two others, one with crystal arthritis and the other with vasculitis (0.7 ng/ml in both cases). All other patients in group II had PCT levels<0.5 ng/ml. In this study a value of PCT>0.5 ng/ml was taken as the marker of bacterial infection (sensitivity 65%, specificity 96%). PCT values were more discriminative than WBC and CRP in distinguishing a bacterial infection from another inflammatory process.\nQuestion: Can procalcitonin measurement help in differentiating between bacterial infection and other kinds of inflammatory processes?",
        "gt": "PCT levels only rose significantly during bacterial infections. In this study PCT levels>1.2 ng/ml were always evidence of bacterial infection and the cue for starting antibiotic treatment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To validate previously proposed findings and to develop an objective, feasible and efficient bifactorial (risk factors: gait impairment and balance disorders) fall risk assessment. Prospective follow-up study Setting: Nursing homes (Halle/Saale, Germany). One hundred and forty-six nursing home residents (aged 62-101 years) were recruited. Gait data were collected using a mobile inertial sensor-based system (RehaWatch). Postural regulation data were measured with the Interactive Balance System. Falls were recorded in standardized protocols over a follow-up period of 12 months. Gait parameters (e.g. spatial-temporal parameters), posturographic parameters (e.g. postural subsystems), number of falls. Seventeen (12%) of the participants had more than two falls per year. The predictive validity of the previously selected posturographic parameters was inadequate (sensitivity: 47%). The new measurement tool defined 67 participants showing an increased risk of falls. In reality, only 8 participants actually fell more than twice during the follow-up period (positive predictive value (PPV): 12%). The negative predictive value (NPV) was 88%. The posturographic frequency range F2-4 (peripheral-vestibular system), stride time and standard deviation of landing phase were the most powerful parameters for fall prediction. Gait and postural variability were larger in the high-risk group (e.g. gait speed; confidence interval (CI)(high): 0.57-0.79 vs. CI(low): 0.72-0.81 m/s).\nQuestion: Can falls be predicted with gait analytical and posturographic measurement systems?",
        "gt": "RehaWatch and the Interactive Balance System are able to measure two of the most important fall risk factors, but their current predictive ability is not satisfactory yet. The correlation with physiological mechanisms is only shown by the Interactive Balance System.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study is to emphasize on the diagnostic effectiveness of fetal MRI that led to increased utilization in fetal medicine as well as its value in prognosis and decision making in the modern obstetric practice. One hundred five (n = 105) pregnant women were referred for a fetal MRI examination after a high detailed ultrasound examination revealed a fetal abnormality. Fetal MRI was performed using 1, 5 Tesla units, with T1, T2-weighted and diffusion-weighted images. The findings were analyzed in comparison to the previous ultrasound findings, according to the fetal organ affected and the value of the MRI for therapeutic decision making was addressed. A statistical analysis was performed. The fetal MRI provides a more accurate diagnosis compared to ultrasound examination, and when the ultrasound detects fetal anomalies, the MRI can efficiently either confirm or reject the finding, proving its high value for prenatal diagnosis and perinatal and management. The sensitivity, specificity and positive predictive value of fetal MRI as a screening tool approaches 100%.\nQuestion: Fetal MRI: is it really helpful?",
        "gt": "Despite the fact that ultrasound is the method of choice for fetal screening, MRI can add up significantly to the diagnosis and management of congenital abnormalities and the indications for MRI continue to increase as new sequences and shorter acquisition times evolve.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Some studies suggest that epidural analgesia prolongs labor and increases the incidence of cesarean section, especially if it is administered before 5 cm cervical dilation. The purpose of the current study was to determine whether early administration of epidural analgesia affects obstetric outcome in nulliparous women who are receiving intravenous oxytocin. Informed consent was obtained from healthy nulliparous women with a singleton fetus in a vertex presentation, who requested epidural analgesia while receiving intravenous oxytocin at at least 36 weeks' gestation. Each patient was randomized to receive either early or late epidural analgesia. Randomization occurred only after the following conditions were met: (1) the patient requested pain relief at that moment, (2) a lumbar epidural catheter had been placed, and (3) the cervix was at least 3 but less than 5 cm dilated. Patients in the early group immediately received epidural bupivacaine analgesia. Patients in the late group received 10 mg nalbuphine intravenously. Late-group patients did not receive epidural analgesia until they achieved a cervical dilation of at least 5 cm or until at least 1 h had elapsed after a second dose of nalbuphine. Early administration of epidural analgesia did not prolong the interval between randomization and the diagnosis of complete cervical dilation, and it did not increase the incidence of malposition of the vertex at delivery. Also, early administration of epidural analgesia did not result in an increased incidence of cesarean section or instrumental vaginal delivery. Thirteen (18%) of 74 women in the early group and 14 (19%) of 75 women in the late group underwent cesarean section (relative risk for the early group 0.94; 95% confidence interval 0.48-1.84). Patients in the early group had lower pain scores between 30 and 120 min after randomization, and were more likely to experience transient hypotension. Infants in the late group had lower umbilical arterial and venous blood pH and higher umbilical arterial and venous blood carbon dioxide tension measurements at delivery.\nQuestion: Does early administration of epidural analgesia affect obstetric outcome in nulliparous women who are receiving intravenous oxytocin?",
        "gt": "Early administration of epidural analgesia did not prolong labor or increase the incidence of operative delivery, when compared with intravenous nalbuphine followed by late administration of epidural analgesia, in nulliparous women who were receiving intravenous oxytocin.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Postconditioning may prove to be a suitable method to decrease ischemia-reperfusion injury of intestine after mesenteric arterial occlusion. Toll-like-receptor-4 is involved in the pathophysiology of organ damage after ischemia-reperfusion; therefore, the aim of our study was to investigate the effect of postconditioning on the mucosal expression of toll-like-receptor-4. Male Wistar rats (n\u00a0=\u00a010/group) underwent 60\u00a0minutes of superior mesenteric artery occlusion followed by 6\u00a0hours of reperfusion in 3 groups: sham-operated, ischemia-reperfusion, and a postconditioned group. Postconditioning was performed by 6 alternating cycles of 10\u00a0seconds of reperfusion/reocclusion. Blood and tissue samples were collected at the end of reperfusion. Intestinal histopathologic changes and immunohistochemical expression of mucosal caspase-3, antioxidant status, and protein levels of high-mobility group box-1 and toll-like-receptor-4 were assessed. Immunofluorescent labeling and confocal microscopic analysis of toll-like-receptor-4 were performed. Mucosal and serum levels of interleukin-6 and tumor necrosis factor-\u03b1 protein were measured. Histologic alterations in the postconditioned group were associated with decreased caspase-3 positivity, less toll-like-receptor-4 mRNA, and less protein expression of high-mobility group box-1 and toll-like-receptor-4 in the intestinal villi compared with the ischemia-reperfusion group. Furthermore, a significantly improved antioxidant state of the intestinal mucosa and less mucosal and serum protein levels of interleukin-6 and tumor necrosis factor-\u03b1 were detected in the postconditioned group.\nQuestion: Postconditioning: \"Toll-erating\" mesenteric ischemia-reperfusion injury?",
        "gt": "Small intestinal ischemia-reperfusion injury in male Wistar rats caused by the occlusion of the superior mesenteric artery was ameliorated by the use of postconditioning, showing a more favorable inflammatory response, which may be attributed to the decreased mucosal expression of toll-like-receptor-4.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is concern that diagnostic labels for psychiatric disorders may invoke damaging stigma, stereotypes and misunderstanding. This study investigated clinicians' reactions to diagnostic labelling by examining their positive and negative reactions to the label borderline personality disorder (BPD). Mental health professionals (n = 265) viewed a videotape of a patient suffering from panic disorder and agoraphobia undergoing assessment. Prior to viewing the videotape, participants were randomly allocated to one of three conditions and were given the following information about the patient: (a) general background information; (b) additional descriptive information about behaviour corresponding to BPD; and (c) additional descriptive information about behaviour corresponding to BPD, but explicitly adding BPD as a possible comorbid diagnostic label. All participants were then asked to note things they had seen in the videotape that made them feel optimistic or pessimistic about treatment outcome. Participants in the group that were explicitly informed that the patient had a BPD diagnostic label reported significantly fewer reasons to be optimistic than the other two groups.\nQuestion: An experimental Investigation of the Impact of Personality Disorder Diagnosis on Clinicians: Can We See Past the Borderline?",
        "gt": "Diagnostic labels may negatively impact on clinicians' judgments and perceptions of individuals and therefore clinicians should think carefully about whether, and how, they use diagnoses and efforts should be made to destigmatize diagnostic terms.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Peer-assisted learning (PAL) is recognised as an effective learning tool and its benefits are well documented in a range of educational settings. Learners find it enjoyable and their performances in assessments are comparable with those of students taught by faculty tutors. In addition, PAL tutors themselves report the development of improved clinical skills and confidence through tutoring. However, whether tutoring leads to actual improvement in performance has not been fully investigated. As high-achieving students are already en route to succeeding in final examinations, we wanted to examine whether participation in a peer-tutoring programme in itself leads to better final-year examination performance. We conducted a retrospective analysis of results on final-year written and clinical examinations at University College London Medical School during 2010-2012. Z-scores were calculated and the performances of PAL tutors and students who were not PAL tutors were compared using analysis of covariance (ancova). Year 4 examination results were used as indicators of previous academic attainment. Of the 1050 students who attempted the final examination, 172 were PAL tutors in the final year. Students who acted as PAL tutors outperformed students who did not in all examination components by 1-3%. Z-scores differed by approximately 0.2 and this was statistically significant, although the significance of this difference diminished when controlling for Year 4 results. Students who acted as PAL tutors who had scored in the top quartile in Year 4 examinations scored significantly better in a long-station objective structured clinical examination (LSO).\nQuestion: Do peer-tutors perform better in examinations?",
        "gt": "Although students who acted as PAL tutors performed better than students who did not in final-year examinations, this difference was small and attributable to the students' background academic abilities. High-achieving students appear to be self-selecting as peer-tutors and their enhanced performance in LSOs may reflect their inherent academic abilities. Although peer-tutoring in itself did not lead to enhanced examination performance, further studies are required as many factors, such as the proximity of examinations and previous tutoring, can potentially affect the relationship between peer-tutoring experience and examination performance.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In 1999, the Korean government introduced the National Cancer Screening Program (NCSP) to increase the cancer-screening rate, particularly among the low-income population. This study investigates how the NCSP has decreased both relative and absolute income inequalities in the uptake of cancer screening in South Korea. A nationally representative cross-sectional repeated data from the Korea National Health and Nutrition Examination Survey 1998-2012, managed by the Ministry of Health and Welfare, was used to assess changes over time and the extent of discontinuity at the NCSP-recommended initiation age in the uptake of screening for breast, colorectal, and gastric cancers across income quartiles. Relative inequalities in the uptake of screening for all cancers decreased significantly over the policy period. Absolute inequalities did not change for most cancers, but marginally increased from 9 to 14% points in the uptake of screening for colorectal cancer among men. At the recommended initiation age, absolute inequalities did not change for breast and colorectal cancers but increased from 5 to 16% points for gastric cancer, for which relative inequality significantly decreased.\nQuestion: Has the National Cancer Screening Program reduced income inequalities in screening attendance in South Korea?",
        "gt": "The NCSP, which reduced out-of-pocket payment, may not decrease absolute gap although it leads to overall increases in the uptake of cancer screening and decreases in relative inequalities. Further investigations are needed to understand barriers that prevent the low-income population from attending cancer screening.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Concerns for morbidity after a pancreaticoduodenectomy (PD) has led to practitioners adopting endoscopic resection or ampullectomy in the treatment of T1 ampullary cancer (AC). It was hypothesized that survival for patients undergoing local resection of AC was inferior to those undergoing a PD. All the data of patients with AC reported in the Surveillance, Epidemiology and End Results (SEER) database between 2004 and 2010 were collected. Five-year survival rates according to nodal disease and histological type were compared. There were 1916 cases of AC; 421 (22%) had T1 disease. Among those with T1 disease, 217 (51%) received endoscopic surveillance, 21 (5%) underwent local resection/ampullectomy, 20 (5%) underwent ampullectomy with regional lymphadenectomy and 163 (39%) underwent PD. For patients with complete nodal staging (PD, n = 163), 35 (22%) had metastatic disease in the nodes. Grade was significantly associated with node positivity (P = 0.007). In multivariate models, survival was improved with either an ampullectomy with regional lymphadenectomy [hazard ratio (HR) 0.19; 95% confidence interval (CI) 0.05-0.61, P<0.005] or a PD (HR 0.23; 95% CI 0.15-0.36, P<0.001).\nQuestion: Is local resection adequate for T1 stage ampullary cancer?",
        "gt": "Patients with T1 AC have a high risk for nodal metastases especially if they are higher-grade lesions. Nodal clearance with a lymphadenectomy or a PD is essential for long-term survival in these patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A-gliadin residues 31-49 (peptide A) binds to HLA-DQ2 and is toxic to coeliac small bowel. Analogues of this peptide, which bind to DQ2 molecules but are non-toxic, may be a potential route to inducing tolerance to gliadin in patients with coeliac disease. Toxicity was investigated with small bowel organ culture in six patients with untreated coeliac disease, four with treated coeliac disease and six controls. Analogue peptides comprised alanine substituted variants of peptide A at L31 (peptide D), P36 (E), P38 (F), P39 (G) and P42 (H). Peptides D and E were toxic in biopsies from some patients. Peptides F, G and H were not toxic.\nQuestion: A non-toxic analogue of a coeliac-activating gliadin peptide: a basis for immunomodulation?",
        "gt": "Peptide F, which binds to DQ2 more strongly than peptide A, is not toxic in patients with coeliac disease in-vitro; this could be an initial step towards investigation of the induction of tolerance to gliadin in patients affected by coeliac disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate whether there is an association between use of antibiotics and breakthrough pregnancy. The study was performed in a population-based prescription database (IADB.nl). We computed case-crossover odds ratios of 397 cases of defined breakthrough pregnancy comparing the use of antibiotics in the exposure window with the use of antibiotics in two control windows. We defined a control group consisting of 29\u2009022 other pregnancies. We computed case-control odds ratios of the use of antibiotics in cases as compared with controls in the different time windows. The case-crossover odds ratios comparing the use of antibiotics in the exposure window with both control windows were 2.21 (95%CI\u2009=\u20091.03-4.75) and 1.65 (95%CI\u2009=\u20090.78-3.48), respectively. The traditional case-control odds ratios after adjustment for age were 1.71 (95%CI\u2009=\u20091.09-2.66) in the exposure window, 0.81 (95%CI\u2009=\u20090.44-1.47) 2 months before the exposure window, and 1.04 (95%CI\u2009=\u20090.61-1.78) 12 months before the exposure window.\nQuestion: Are antibiotics related to oral combination contraceptive failures in the Netherlands?",
        "gt": "We did find a relationship between the use of antibiotics and breakthrough pregnancy in a population-based prescription database. The results did not hold for broad-spectrum antibiotics or in a sensitivity analysis. The results are partly not the same as those found in a pharmacoepidemiological study with a similar design using two US pregnancy databases. Both studies can suffer from bias and confounding, but these will be different because of the use of different databases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate bladder urothelium by confocal laser endomicroscopy (CLE) and correlate microscopic findings with standard histopathology. Fresh bladder urothelium tissue specimens were topically stained with acriflavine for instantaneous microscopic imaging. A single-line laser in a handheld CLE probe delivered an excitation wavelength of 488 nm providing a high resolution of 0.7 \u00b5m and an adjustable imaging depth of 0-250 \u00b5m. Resection specimens of 18 patients were investigated with 1000-fold magnification and ex vivo findings were compared with targeted histopathology (haematoxylin and eosin staining). Typical tumour growth patterns such as altered nuclear to cytoplasmic ratio, pseudopapillar tissue stratification and neoangiogenesis were readily visible. Nuclear and subnuclear architecture of healthy bladder tissue could be discriminated against neoplastic tissue.\nQuestion: Confocal laser endomicroscopy for the diagnosis of urothelial bladder neoplasia: a technology of the future?",
        "gt": "In addition to white light cystoscopy, CLE is a promising novel tool for the in vivo microscopic visualization of bladder cancer; first results of the present study show its potential to define microscopic characteristics of bladder cancer tissue. Further in vivo studies are necessary to determine sensitivity and specificity of the technique.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A delayed myocardial protection extends between 24 and 96 h after ischemic preconditioning in animals. To test for this phenomenon in humans, subjects with stable angina were subjected to exercise test-induced myocardial ischemia and the effect of this \"preconditioning\" ischemic insult on the exercise-induced myocardial ischemia with the re-exercise after 24-96 hours was studied. Forty-eight males with a history of infarction and positive exercise test were recruited to the study. After baseline symptom-limited exercise test, the subjects were randomized to four experimental groups (n = 12/group). The groups were allowed to recover for 24 h, 48 h, 72 h or 96 h before performing the second exercise test. Variables analyzed were heart rate-systolic blood pressure product at 1 mm ST segment depression, time to 1 mm ST segment depression, maximum ST segment depression, exercise duration, and the total ischemic time. There were no intergroup differences in baseline values for these variables. All variables were significantly improved at 24 h, the improvement peaked usually at 48 h (maximum increase in the variables by 31-46%), and the variables returned to baseline by 96 h after the first test.\nQuestion: Delayed attenuation of myocardial ischemia with repeated exercise in subjects with stable angina: a possible model for the second window of protection?",
        "gt": "The exercise-induced ischemia caused transient attenuation of myocardial ischemia with re-exercise. Although the time-window and the time-course of this effect shows striking resemblance to those of the delayed preconditioning in animals, its mechanism remains speculative. The most probable mechanisms that may be involved include increased myocardial perfusion and/or some adaptive changes in the myocardium, the delayed preconditioning being one possibility.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Surgeons may prescribe oral quinolones after auricular procedures to prevent postoperative infections, especially those caused by Pseudomonas aeruginosa. This study compares the efficacy of levofloxacin and local wound care to local wound care alone in preventing postoperative infection of auricular second-intention wounds. This study was a prospective, randomized trial of 84 consecutive patients (82 in the final analysis) who underwent Mohs micrographic surgery for an auricular neoplasm and had a wound left to heal by second intention. After surgery, patients were randomly assigned to receive either local wound care or local wound care with concurrent 500 mg of levofloxacin by mouth daily. Overall, 85.4% of patients had no complications. Complications included 12.2% of patients with inflammatory chondritis and 2.4% of patients with infection. No infections with P. aeruginosa were observed. No statistical significance was observed between the two treatment groups.\nQuestion: Is levofloxacin necessary to prevent postoperative infections of auricular second-intention wounds?",
        "gt": "Levofloxacin is not necessary to prevent postoperative infections of auricular second-intention wounds after Mohs surgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate a brief training program on suicide prevention for front-line general hospital personnel in terms of its impact on their attitudes and beliefs towards suicidality. Forty non-clinical (e.g., security staff), and 102 clinical (e.g., nursing attendants) professionals employed in a university hospital in Brazil were evaluated with the Suicide Behavior Attitude Questionnaire [SBAQ] before the start and immediately after a 3-hour training on suicide prevention. Surprisingly, there were no significant differences for the great majority of the SBAQ items (i.e., 20 of 21) between clinical and non-clinical staff both pre- and post-training. Furthermore, their attitudes and beliefs towards suicidality were significantly improved after training in the majority of SBAQ items, with p-values ranging from 0.01 to<0.0001. Relatively small sample size, and absence of a randomized controlled design and long-term follow-up.\nQuestion: Does a brief training on suicide prevention among general hospital personnel impact their baseline attitudes towards suicidal behavior?",
        "gt": "Our study suggests that attitudes and beliefs of clinical and non-clinical general hospital personnel towards suicidality were unexpectedly similar, and reinforces the need for suicide awareness training programs in the general hospital setting. Additionally, we have shown that it is feasible to provide such basic knowledge concerning suicidal behavior to this specific population. This is particularly important for the development of suicide prevention programs in under-resourced countries. However, our results are preliminary, and further studies are needed to address a number of important questions in the field.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine the hypothesis that hypothalamic-pituitary-adrenal responses to stress vary across gender, contributing to gender differences in the prevalence of depression. This study examined gender differences between depressed (n = 21) and control (n = 20) adolescents in adrenocorticotropic hormone (ACTH) and cortisol response to two ovine corticotropin-releasing hormone (oCRH) tests, at baseline and following a cognitive stressor. Boys had higher (p<.05) measures of ACTH than girls, regardless of depression status, whereas corresponding cortisol parameters were similar in both groups. Cortisol measures were higher (p<.05) at time 1 than at time 2 in both groups, a phenomenon that might reflect the novelty of the situation.\nQuestion: Response to oCRH in depressed and nondepressed adolescents: does gender make a difference?",
        "gt": "Gender differences in hormone responses may be related to differences in peripheral metabolism of ACTH, resulting in changes of immunoreactivity but not bioactivity or a different set point of the hypothalamic-pituitary-adrenal axis. The pattern of ACTH and cortisol responses to oCRH and the 24-hour excretion of free cortisol was normal in adolescents with depression, probably reflecting normal negative feedback mechanisms at this age or that most of these patients suffer from atypical rather than melancholic depression.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Drains are usually left after thyroid surgery to prevent formation of hematoma and seroma in the thyroid bed. This is done to reduce complications and hospital stay. Objective evaluation of the amount collected in the thyroid bed by ultrasonography (USG) can help in assessing the role of drains. A randomized prospective control study was conducted on 94 patients undergoing 102 thyroid surgeries, over a period of fifteen months. Patients included in the study were randomly allocated to drain and non-drain group on the basis of computer generated random number table. The surgeon was informed of the group just before the closure of the wound Postoperatively USG neck was done on first and seventh postoperative day by the same ultrasonologist each time. Any swelling, change in voice, tetany and tingling sensation were also recorded. The data was analyzed using two-sample t-test for calculating unequal variance. Both groups were evenly balanced according to age, sex, and size of tumor, type of procedure performed and histopathological diagnosis. There was no significant difference in collection of thyroid bed assessed by USG on D1&D7 in the two groups (p = 0.313) but the hospital stay was significantly reduced in the non-drain group (p = 0.007). One patient in the drain group required needle aspiration for collection in thyroid bed. No patient in either group required re-operation for bleeding or haematoma.\nQuestion: Is the routine drainage after surgery for thyroid necessary?",
        "gt": "Routine drainage of thyroid bed following thyroid surgery may not be necessary. Not draining the wound results in lesser morbidity and decreased hospital stay.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Mass insecticide treated bed net (ITN) deployment, and its associated coverage of populations at risk, had \"pushed\" a decline in malaria transmission. However, it is unknown whether malaria control is being enhanced by zooprophylaxis, i.e., mosquitoes diverted to feed on hosts different from humans, a phenomenon that could further reduce malaria entomological transmission risk in areas where livestock herding is common. Between May and July 2009, we collected mosquitoes in 104 houses from three neighboring villages with high ITN coverage (over 80%), along Lake Victoria. We also performed a census of livestock in the area and georeferenced tethering points for all herds, as well as, mosquito larval habitats. Bloodmeal contents from sampled mosquitoes were analyzed, and each mosquito was individually tested for malaria sporozoite infections. We then evaluated the association of human density, ITN use, livestock abundance and larval habitats with mosquito abundance, bloodfeeding on humans and malaria sporozoite rate using generalized linear mixed effects models. We collected a total of 8123 mosquitoes, of which 1664 were Anopheles spp. malaria vectors over 295 household spray catches. We found that vector household abundance was mainly driven by the number of householders (P\u2009<\u20090.05), goats/sheep tethered around the house (P\u2009<\u20090.05) and ITNs, which halved mosquito abundance (P\u2009<\u20090.05). In general, similar patterns were observed for Anopheles arabiensis, but not An. gambiae s.s. and An. funestus s.s., whose density did not increase with the presence of livestock animals. Feeding on humans significantly increased in all species with the number of householders (P\u2009<\u20090.05), and only significantly decreased for An. arabiensis in the presence of cattle (P\u2009<\u20090.05). Only 26 Anopheles spp. vectors had malaria sporozoites with the sporozoite rate significantly decreasing as the proportion of cattle feeding mosquitoes increased (P\u2009<\u20090.05).\nQuestion: Push by a net, pull by a cow: can zooprophylaxis enhance the impact of insecticide treated bed nets on malaria control?",
        "gt": "Our data suggest that cattle, in settings with large ITN coverage, have the potential to drive an unexpected \"push-pull\" malaria control system, where An. arabiensis mosquitoes \"pushed\" out of human contact by ITNs are likely being further \"pulled\" by cattle.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Several studies have demonstrated associations of birth weight with metabolic and reproductive abnormalities in adults. The aim of this study was to investigate the birth weight in women with PCOS and its correlation with clinical and biochemical characteristics of the syndrome. We studied 288 women with PCOS according to the NIH criteria and 166 women with normal cycle and without clinical hyperandrogenism. Birth weight and anthropometric characteristics were recorded, and levels of serum androgens, SHBG, insulin and fasting glucose were measured. Birth weight data were available for 243/288 women with PCOS and age- and BMI-matched 101/166 controls. No differences were found (p>0.05) in birth weight among women with PCOS and normal controls. Birth weight of PCOS women was negatively correlated with DHEAS levels (p = 0.031, r = -0.143) and positively correlated with waist circumference (p<0.001, r = 0.297) and body mass index (BMI) (p = 0.040, r = 0.132). Birth weight of controls was negatively correlated with SHBG levels (p = 0.021, r = -0.234). Women from both groups were further divided in 6 categories according to birth weight (A.<2.500 gr, B. 2.501-3.000 gr, C. 3.001-3.500 gr, D. 3.501-4.000 gr, E. 4.001-4.500 gr, F.>4.500 gr). No statistically significant differences were observed in the distribution percentages between PCOS women and controls. (A. 7% vs 7.9%, B. 26.8% vs 20.8%, C. 39.1% vs 48.5%, D. 21.4% vs 20.8%, E. 4.9% vs 2%, F. 0.8% vs 0%), (in all comparisons, p>0.05).\nQuestion: Birth weight and polycystic ovary syndrome in adult life: is there a causal link?",
        "gt": "Women with PCOS do not differ from controls in birth weight distribution. However, birth weight may contribute to subtypes of the syndrome that are characterized by adrenal hyperandrogenism and central obesity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A retrospective observational study was performed to test the hypothesis that a lower incidence of atrial fibrillation (AF) would be observed in patients treated with either angiotensin converting enzyme (ACE) inhibitors or angiotensin II receptor antagonists (AIIRAs) than those without these drugs, 1-year following implantation of a dual chamber pacemaker for all indications. One hundred and sixty consecutive patients who underwent implantation of a dual chamber pacemaker between January and August 2002 were identified and their case notes were retrospectively analysed. The primary endpoint was the presence of persistent AF (confirmed by 12-lead ECG recorded from the visit to the pacemaker clinic) at 12-month follow-up. Overall, 8% patients developed new onset persistent AF at 1-year follow-up. The incidence of AF at 1-year was 4% in patients treated with ACE inhibitors, 8% in patients taking AIIRAs or 5% on either drug. Although a trend towards a higher incidence of AF was observed at 1-year (10%) in patients not receiving either of these drugs, this was not statistically significant (P = 0.21, drug vs. no drug). The incidence of AF in patients with a previous history of paroxysmal AF or cardioversion was significantly higher (23%) than those patients without (5%), P<0.0001. An odds ratio (95% CI) of 7.9 (2.3-27.8) was obtained.\nQuestion: Does treatment with ACE inhibitors or angiotensin II receptor antagonists prevent atrial fibrillation after dual chamber pacemaker implantation?",
        "gt": "To confirm these interesting initial results and to investigate this important relationship further, larger prospective randomised controlled studies are required.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Poor children have higher rates of mental health problems than more affluent peers, also in progressive welfare states such as Norway. Temperamental characteristics may render some children more sensitive to the adverse influence of poor economy. This study examined the direct associations between family income-to-needs and mental health and assessed moderation by early temperamental characteristics (i.e., emotionality). Using data from the Norwegian Mother and Child Cohort Study, associations between income-to-needs across children's first 3 years and internalizing and externalizing problems when children were 5 years old were examined. Differential sensitivity to family income-to-needs was assessed by investigating how emotionality, when children were one-and-a-half and 3 years old, moderated these associations. Significant main effects of income-to-needs and emotionality and a significant interaction effect between income-to-needs and emotionality were found for externalizing problems, but not for internalizing problems.\nQuestion: Low Family Income and Behavior Problems in Norwegian Preschoolers: Is Child Emotionality a Marker for Sensitivity of Influence?",
        "gt": "Children in poor families with an emotionally reactive temperament had higher scores on externalizing problems when they were 5 compared with their less emotionally reactive peers.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To understand patient loyalty to providers over time, informing effective population health management. Patient care-seeking patterns over a 6-year timeframe in Minnesota, where care systems have a significant portion of their revenue generated by shared-saving contracts with public and private payers. Weibull duration and probit models were used to examine patterns of patient attribution to a care system and the continuity of patient affiliation with a care system. Clustering of errors within family unit was used to account for within-family correlation in unobserved characteristics that affect patient loyalty. The payer provided data from health plan administrative files, matched to U.S. Census-based characteristics of the patient's neighborhood. Patients were retrospectively attributed to health care systems based on patterns of primary care. I find significant patient loyalty, with past loyalty a very strong predictor of future relationship. Relationships were shorter when the patient's health status was complex and when the patient's care system was smaller.\nQuestion: Patient loyalty in a mature IDS market: is population health management worth it?",
        "gt": "Population health management can be beneficial to the care system making this investment, particularly for patients exhibiting prior continuity in care system choice. The results suggest that co-located primary and specialty services are important in maintaining primary care loyalty.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Sixty-two percent of patients would like their doctor to recommend a specific web site to find health information, but only 3% of patients receive such recommendations. We investigated whether providing patients with an Internet web-site link recommended by their physician would improve patient knowledge and satisfaction. Our hypothesis was that directing patients to a reliable web site would improve both. Sixty patients with a new diagnosis of carpal tunnel syndrome were prospectively randomized into two groups. Twenty-three patients in the control group had a traditional physician office visit and received standard care for carpal tunnel syndrome. Thirty-seven patients in the treatment group received a handout that directed them to the American Society for Surgery of the Hand (ASSH) web page on carpal tunnel syndrome in addition to the standard care provided in the office visit. Patients later completed a ten-question true-or-false knowledge questionnaire and a six-item satisfaction survey. Differences in scores were analyzed using two-sample t tests. Less than half (48%) of the patients who were given the Internet directive reported that they had visited the recommended web site. The mean scores on the knowledge assessment (6.84 of 10 for the treatment group and 6.96 of 10 for the control group) and the satisfaction survey (4.49 of 5 for the treatment group and 4.43 of 5 for the control group) were similar for both groups. The mean score for knowledge was similar for the patients who had used the ASSH web site and for those who had not (6.89 and 6.97 respectively). Moreover, compared with patients who had not used the Internet at all to learn about carpal tunnel syndrome, patients who used the Internet scored 6.6% better (mean score, 7.14 for those who used the Internet compared with 6.70 for those who had not; p>0.05). Regardless of Internet usage, most patients scored well on the knowledge assessment and reported a high level of satisfaction.\nQuestion: Does a Directive to an Internet Site Enhance the Doctor-Patient Interaction?",
        "gt": "Whether the patient was given a handout or had visited the ASSH or other Internet web sites, the knowledge and satisfaction scores for all patients were similar. Since the physician was the common denominator in both groups, the results indicate that the patient-physician relationship may be more valuable than the Internet in providing patient education.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate regenerated articular cartilage quantitatively by introducing an ultrasonic probe into the knee joint under arthroscopy and analysing the A-mode echogram by means of wavelet transformation. Three experimental rabbit models (spontaneous repair model, large cartilage defect model, treatment model) were examined using our ultrasonic evaluation system and a histological grading scale. From resulting wavelet map, the percentage of maximum magnitude was selected as the quantitative index of the ultrasonic evaluation system. The percentage maximum magnitude in the spontaneous repair model was 61.1%, that in the large defect model was 29.8% and that in the treatment model was 36.3%. There was modest correlation between the percentage maximum magnitude and the histological grading scale (r = -0.594)\nQuestion: Can ultrasound predict histological findings in regenerated cartilage?",
        "gt": "Our findings indicate that ultrasound analysis can predict the microstructure of regenerated cartilage.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study assesses parents' literacy skills and evaluates how literacy levels influenced the effectiveness of a health communication intervention designed to improve safety knowledge in low-income, urban families. A total of n = 450 parents of children aged 4 to 66 months completed the Rapid Estimate of Adult Literacy in Medicine (REALM) and participated in a randomized trial of an injury prevention intervention delivered via computer kiosk in a pediatric emergency department. A safety knowledge test was administered by telephone 2 to 4 weeks later. More than one-third of parents were assessed by the REALM to have marginal (30%) or inadequate (8%) reading levels; the remaining 62% of parents had adequate reading levels. REALM scores were independently associated with knowledge gains for poison storage and smoke alarms.\nQuestion: Does Health Literacy Level Influence the Effectiveness of a Kiosk-Based Intervention Delivered in the Pediatric Emergency Department?",
        "gt": "Participants reading level had an independent and significant effect on safety knowledge outcomes. Literacy level should be considered in all patient education efforts.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Both locus of control and alexithymia have been considered personality factors fostering health concerns and behaviors. This study investigates the relationship between the health locus of control and alexithymia. Seventy-eight psychiatric outpatients were administered the Wallston Health Locus of Control Scale (HLC), the Toronto Alexithymia Scale (HLC), and the Five Factor Inventory, which measures neuroticism, extraversion, openness, agreeableness, and conscientiousness. Depressive and anxious affect was also measured. Regression models were developed to assess the influence of the above variables upon alexithymia. Although there was a significant bivariant correlation between an external locus of control and increased alexithymia, regression models found that HLC did not significantly predict TAS. Neuroticism, however, provided the most significant contribution to predict increased alexithymia.\nQuestion: Is alexithymia distinct from health locus of control?",
        "gt": "Neuroticism may link HLC and TAS due to the face validity of each construct. A sense of vulnerability is stated in each measure. This may foster somatic preoccupation. The data suggest HLC and TAS to be separate phenomena and further support the validity of alexithymia as a unique personality trait.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It is recommended that general practitioners (GPs) offer cessation advice and pharmacological interventions to smokers with acute coronary syndrome (ACS). The study objective was to describe the extent to which this is done, and to describe outcomes by smoking status. Patients aged 30+ hospitalised for troponin-positive ACS from 2002 to 2009, discharged home alive, were identified in the Myocardial Ischaemia National Audit Project registry. Patient data were linked to the General Practice Research Database, Hospital Episode Statistics, and Office of National Statistics mortality data, enabling a unique perspective of longitudinal smoking data. Patients who smoked prior to the hospitalisation had GP interventions and quitting status established in the 3 months following discharge, and were followed up for major clinical outcomes. The outcomes evaluated included death, repeat ACS, stroke, heart failure, and major adverse cardiac events (MACE). Of the 4834 patients included, 965 (20%) were smokers at the time of their ACS. After the ACS event, only 225 (24%) received any GP smoking intervention within 3 months, with 82 (9%) receiving advice only, and 143 (15%) receiving a pharmacological intervention. Patients who quit (320; 33%) were at a decreased risk of mortality (relative risk (RR) 0.49; 95% confidence interval (CI) 0.35-0.69) and MACE (RR 0.61; 0.46-0.80) compared with patients who did not.\nQuestion: Smoking cessation interventions following acute coronary syndrome: a missed opportunity?",
        "gt": "Whilst a high proportion of patients with ACS are smokers, there is a low level of GP cessation intervention following hospital discharge. This missed opportunity of patient care is important given the decreased risk of mortality and MACE found amongst those who quit.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To describe the clinical, histological, immunohistochemical and behavioural patterns of the metastases of renal cell carcinoma to the skin. In a retrospective review of 132 cases of renal cell carcinoma submitted for examination to the Anticancer Institute 'St Savas' nine patients with metastatic disease to the skin were discovered. Clinical data and follow-up information were collected and correlated to tumour behaviour and patient survival. Immunohistochemical studies with epithelial membrane antigen (EMA), vimentin, keratin and carcino-embryonic antigen (CEA) were performed. In six of the nine patients the skin metastasis was the first evidence of a tumour. Histology of the skin nodule led to identification of the primary site. Histological proof of the renal origin of the tumour was obtained using the above immunohistochemical studies. All patients died from their disease within 3 years of presenting with the skin metastases.\nQuestion: Renal cell carcinoma metastases to the skin: a not so rare case?",
        "gt": "Metastases to the skin from a renal cell carcinoma as first evidence of the disease may not be as rare as the literature describes. Definite proof of the origin of the tumour requires specialized immunohistochemical techniques.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate if thyroid-stimulating hormone (TSH) levels are associated with any differences in glycaemic control or diabetes-related complications in individuals with Type 1 diabetes. This observational, cross-sectional and multicentre study included patients with Type 1 diabetes for \u2265 5\u00a0years, with a recent TSH measurement and without a known previous thyroid disease. Patients were divided into three groups according to TSH levels: 0.4-2.5\u00a0mU/l; 2.5-4.4\u00a0mU/l; and \u2265 4.5\u00a0mU/l. We included 1205 individuals with a mean \u00b1 sd age of 23.8\u00a0\u00b1\u00a011.3\u00a0years. Seven patients had TSH levels<0.4\u00a0mU/l and were excluded from the comparison between groups. HbA1c levels, systolic and diastolic blood pressure, LDL cholesterol and disease duration were similar in all groups (P\u00a0=\u00a00.893, P\u00a0=\u00a00.548, P\u00a0=\u00a00.461, P\u00a0=\u00a00.575 and P\u00a0=\u00a00.764, respectively). The rates of diabetic retinopathy and GFR<60/mL/min/1.73\u00a0m(2) differed between groups (P\u00a0=\u00a00.006 and P\u00a0<\u00a00.001, respectively) and were lower in those with lower TSH levels. Multivariate analysis confirmed these associations. The frequencies of retinopathy and GFR<60\u00a0mL/min/1.73\u00a0m(2) were higher not only in patients with TSH \u2265 4.5\u00a0mU/l (odds ratio 1.878 and 2.271, respectively) but also in those with TSH levels of 2.5-4.4\u00a0mU/l (odds ratio 1.493 and 2.286, respectively), when compared with patients with TSH levels of 0.4-2.5\u00a0mU/l.\nQuestion: Should thyroid-stimulating hormone goals be reviewed in patients with type 1 diabetes mellitus?",
        "gt": "TSH levels of 0.4-2.5\u00a0mU/l are associated with a lower risk of diabetic retinopathy and renal failure in individuals with Type 1 diabetes, independently of glycaemic control and duration of the disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Our purpose was to determine whether intrapartum obstetric interventions are associated with umbilical cord prolapse. A computer search identified patients who had intrapartum umbilical cord prolapse. Thirty-seven cases were identified between 1990 and 1994 (incidence of 1.85 per 1000). These women were randomly matched to control patients with intact membranes. Patients with umbilical cord prolapse were delivered earlier (34.8 vs 37.1 weeks, p = 0.05). Otherwise, there were no differences between groups regarding the use of cervical ripening, incidence of labor induction, or the use of amnioinfusion and amniotomy. Although cervical dilatation and station were similar between groups at the time of admission, women with umbilical cord prolapse did not have as much descent of the presenting part associated with cervical dilatation and progressive labor compared with control patients.\nQuestion: Are obstetric interventions such as cervical ripening, induction of labor, amnioinfusion, or amniotomy associated with umbilical cord prolapse?",
        "gt": "By themselves, obstetric interventions of cervical ripening, labor induction, amnioinfusion, and amniotomy do not increase the likelihood that a patient will have umbilical cord prolapse.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Atopic dermatitis (AD) can be traumatizing to family life. Little is known about the relationship between quality of life in AD and disease severity. To document family quality of life and relate this to severity of AD in children, for a 6-month period from a given point in time. These data are part of a longitudinal study conducted in two parts of the UK to investigate risk factors for AD severity and its impact on quality of life. and methods Thetargetedpopulation comprised children with AD aged 5-10 years in a primary-care setting. The general practitioners identified potential subjects and the UK diagnostic criteria for AD were used to verify the diagnosis. Both the children and their parents were interviewed. Eczema severity was assessed using a modified form of the SCORAD (SCORe Atopic Dermatitis) Index (SCORAD-D) from which parents' score of itching and sleep loss were excluded. The quality of family life was quantified by the Dermatitis Family Impact (DFI) questionnaire. These two parameters were evaluated on two occasions 6 months apart. Multiple regression analysis was used to investigate the relationship between the quality of family life and the severity of the AD in the children, at a specific point in time and over the following 6-month period. Of the 116 children attending the first visit, mean age 8 years, 106 attended the second visit (91%) and were included in the analysis. Quality of family life was shown to be significantly affected in 48 (45%) cases at the first visit and 38 (36%) cases at the second visit. The initial means of the DFI and SCORAD-D were 2.4 and 8.2, respectively. Six months later the mean final DFI and SCORAD-D were 1.9 and 7.7, respectively. Using multiple regression on the first and second visits, each unit increase in SCORAD-D was associated with 0.21 [95% confidence interval (CI) 0.06-0.37 P = 0.008] and 0.37 (95% CI 0.15-0.59, P = 0.001) units increase in quality of family life, respectively. This relationship remained significant even after adjustment for potential confounders (black skin, social class, sex, child's age, family size and location) each unit increase in SCORAD-D led to a 0.25 unit (95% CI 0.11-0.4, P = 0.001) and 0.23 unit (95% CI 0.05-0.42, P = 0.014) increase in DFI on the first and second visits, respectively. Changes in the DFI scores were significantly related to changes in the SCORAD-D scores (regression coefficient; 0.17 (95% CI 0.06-0.29, P = 0.002).\nQuestion: Are quality of family life and disease severity related in childhood atopic dermatitis?",
        "gt": "We show that quality of family life is related to the severity of AD in children. This confirms the importance of parental assessment of the impact of the disease in the management of AD, because the disease affects the entire family. Also, these results show the response of DFI to change predictably with disease severity. This may imply that the DFI questionnaire could be used as an extra measure of outcome in everyday clinical practice as well as in research studies.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We studied the association between early life conditions and asthma in adolescence. We conducted a population-based birth cohort study involving 2250 male 18-year-olds residing in Brazil. Approximately 18% of the adolescents reported having asthma. Several childhood factors were found to be significantly associated with increased asthma risk: being of high socioeconomic status, living in an uncrowded household, and children being breastfed for 9 months or longer.\nQuestion: Do risk factors for childhood infections and malnutrition protect against asthma?",
        "gt": "The present results are consistent with the \"hygiene hypothesis,\" according to which early exposure to infections provides protection against asthma. The policy implications of our findings are unclear given that risk factors for asthma protect against serious childhood diseases in developing countries.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Novel breast cancer risk-reducing strategies for individuals with germline mutations of the BRCA1 and/or BRCA2 genes are urgently needed. Identification of antigenic targets that are expressed in early cancers, but absent in normal breast epithelium of these high-risk individuals, could provide the basis for the development of effective immunoprophylactic strategies. Cancer testis (CT) antigens are potential candidates because their expression is restricted to tumors, and accumulating data suggest that they play important roles in cellular proliferation, stem cell function, and carcinogenesis. The objective of this study was to examine the expression of CT antigens and their frequency in BRCA-associated breast cancers. Archived breast cancer tissues (n\u00a0=\u00a026) as well as morphologically normal breast tissues (n\u00a0=\u00a07) from women carrying deleterious BRCA 1 and/or 2 mutations were obtained for antigen expression analysis by immunohistochemistry. Expression of the following CT antigens was examined: MAGE-A1, MAGE-A3, MAGE-A4, MAGE-C1.CT7, NY-ESO-1, MAGE-C2/CT10, and GAGE. CT antigens were expressed in 16/26 (61.5%, 95% CI 43-80%) of BRCA-associated cancers, including in situ tumors. Thirteen of twenty-six (50%) breast cancers expressed two or more CT antigens; three cancers expressed all seven CT antigens. MAGE-A was expressed in 13/26 (50%) of cancers, NY-ESO-1 was expressed in 10/26 (38%) of tumors. In contrast, none of the CT antigens were expressed in adjacent or contralateral normal breast epithelium (P\u00a0=\u00a00.003).\nQuestion: Expression of cancer testis antigens in human BRCA-associated breast cancers: potential targets for immunoprevention?",
        "gt": "We report a high CT antigen expression rate in BRCA-associated breast cancer as well as the lack of expression of these antigens in benign breast tissue of carriers, identifying CT antigens as potential vaccine targets for breast cancer prevention in these high-risk individuals.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the associations between household motor vehicle ownership and weight status among Colombian adults. Secondary analysis of data from the 2005 Demographic and HealthSurvey of Colombia. Height, weight and waist circumference were objectively measured in 49,079 adults, ages 18 to 64 that resided in urban settings. Abdominal obesity was defined as a waist circumference>80 cm in women and>90 cm in men. Prevalence was 19.9% for motor vehicle ownership in household, 33.1% for BMI between 25 and 29.9 kg/m(2), 14.4% for BMI>30 kg/m(2), and 46% for abdominal obesity. Males reporting any household motor vehicle ownership were more likely to be overweight or obese, and to have abdominal obesity (p for genderexposure variables interaction=<0.001).\nQuestion: Household motor vehicle use and weight status among Colombian adults: are we driving our way towards obesity?",
        "gt": "Household motor vehicle ownership is associated with overweight, obesity, and abdominal obesity among Colombian men but not women.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Suboptimally debulked patients with advanced ovarian cancer who are treated with a combination of cisplatin plus paclitaxel (TP therapy) have a better survival as compared to patients treated with a combination of cisplatin plus cyclophosphamide (CP therapy), but this advantage has not been demonstrated in optimally debulked patients. We performed a retrospective study to compare the effectiveness of TP therapy and CP therapy in optimally debulked patients. From 1991 to 1996, 87 consecutive patients with advanced ovarian cancer treated in the University Hospital Utrecht and the St. Antonius Hospital were included in the study. Overall survival (OS) of patients treated with TP or CP were compared. Multivariable Cox-regression analysis was used to calculate a hazard rate ratio (HRR) for OS. In the study period, 51 patients were treated with CP, and 36 patients were treated with TP. In the 18 patients with a tumorrest>2cm, there was a clear, but not statistically significant benefit from TP. In 69 patients with a tumorrest<or=2cm, life expectancy was not increased in patients treated with TP as compared to patients treated with CP (HRR 0.9 (95% CI 0.4-1.9)).\nQuestion: Is platinum-based chemotherapy with paclitaxel effective in optimally debulked patients with advanced ovarian cancer?",
        "gt": "We could not show that ovarian cancer patients with residual disease of<or=2cm who were treated with TP had better survival as compared to patients who were treated with CP. Taking into account the high costs of treatment with TP, a randomized trial comparing the effects of TP therapy and CP therapy in optimally debulked patients is warranted.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Studies evaluating the return to sports and work after shoulder arthroplasty are rare, and there are no studies evaluating return to work after total shoulder arthroplasty (TSA). Patients undergoing TSA will be able to return to their preoperative sports levels and occupations. Case series; Level of evidence, 4. A total of 154 patients with 170 TSAs for primary glenohumeral arthritis were included. Two subgroups were formed: patients who had participated in sports during the 5 years before surgery (group 1; n = 105 [68%]) and patients who had never participated in sports (group 2; n = 49 [32%]). The return-to-work rate in patients who had not retired after surgery were also analyzed, as were responses to a survey. The mean age at the time of surgery was 71 years (range, 33-88 years) in group 1 and 76 years (range, 54-88 years) in group 2. Mean follow-up time was 6.2 years (range, 2.5-12.6 years). Fifty-seven patients (54%) in group 1 participated in sports right up to the time of surgery. All 57 (100%) returned to sports after surgery. A further 3 patients (3%) from group 1 resumed sporting activity after surgery; swimming was the most popular sport. No patient in group 2 started sports activity after shoulder replacement surgery. Many of the patients, 14% of the entire group, had retired by final follow-up because of TSA. Fourteen percent of patients in group 1 and group 2 were pursuing their work at the time of most recent follow-up. Thirty patients of the entire cohort (19.5%) had to change their occupations because of surgery.\nQuestion: Do patients return to sports and work after total shoulder replacement surgery?",
        "gt": "Patients who participated in sports before TSA were successfully able to return to sports activities after surgery. Patients who did not participate in sports just before surgery were unlikely to start sports after surgery. Fourteen percent of the entire cohort was able to return to work after surgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Studies about the association between birth weight and circulating cortisol level have been published from 1998 onwards. However, their findings were inconsistent. To quantitatively assess the overall association between birth weight and circulating cortisol level, we aimed to perform a meta-analysis of the published literature. A literature search was conducted in PubMed, and selected papers were systematically reviewed. A pooled regression coefficient was calculated for the entire group as well as for males and females separately. Data from 11 study populations were pooled (n = 2301). These populations differed with respect to geographical area, age, sex distribution, inclusion criteria and gestational age. We found a statistically significant inverse association between birth weight and circulating cortisol level: a 1 kg lower birth weight was associated with a 25.3 nmol/l (95% confidence interval (CI): 5.9-44.8) higher cortisol level. Separate results were reported for males and females in six study populations. The association in males was 20.6 nmol/l per kg (95% CI: 4.2-37.0) and in females it was 30.9 nmol/l per kg (95% CI: 7.4-54.4).\nQuestion: Could cortisol explain the association between birth weight and cardiovascular disease in later life?",
        "gt": "Differences between study populations hampered the comparability of the included studies. Although the majority of studies were underpowered, by using a meta-analytic approach we found an inverse association between birth weight and circulating cortisol level. Thus, our findings suggest that there is some evidence for a possible role of the hypothalamus-pituitary-adrenal axis in the epidemiological association between birth weight and cardiovascular disease. However, the strength of the overall association between birth weight and circulating cortisol level was weak.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: One result of the advancement in prenatal diagnosis is an increase in the need for second trimester pregnancy terminations. Extra-amniotic infusion of prostaglandins is a common technique used for such pregnancy termination. Since prostaglandins cause strong uterine contractions, many practitioners are hesitant to use this technique on women with a uterine scar. In this study we tried to evaluate the effectiveness and safety of the technique for women with a previous uterine scar. This retrospective study included all women with a complete medical record who underwent a second trimester pregnancy termination at our institution by extra amniotic prostaglandin E2, during a 6 year period. The study group included all women with a previous uterine scar. The group of women without such a scar served as the control group. Three hundred and forty women had their pregnancy terminated, but only in 282 cases was the medical information complete (research population). The study group (35 women) characteristics were similar to those of the control group (247 women). We found no difference in the abortion interval, the need to use an additional method, the need for curettage and in bleeding complication between the two groups. There was no case of uterine rupture. The group of women with multiple uterine scars was too small for analysis.\nQuestion: Induced second trimester abortion by extra-amniotic prostaglandin infusion in patients with a cesarean scar: is it safe?",
        "gt": "Our results suggest that extra amniotic prostaglandin infusion is an effective and safe technique in women with a uterine scar.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Carotid endarterectomy (CEA) has proven to be effective in the prevention of stroke in patients with significant internal carotid artery (ICA) stenosis. However, whether increased cerebral blood flow after CEA improves the cerebral metabolism in patients with asymptomatic ICA flow lesions is unknown. Localized in vivo proton magnetic resonance spectroscopy ((1)H-MRS) has been used to measure the metabolic status of the human brain in a totally noninvasive manner. The aim of this study was to investigate the cerebral metabolism after CEA in patients with asymptomatic ICA flow lesions and no visible infarction on magnetic resonance imaging (MRI). We designed a prospective study to investigate the metabolic changes in the middle cerebral artery (MCA) territory with (1)H-MRS for 18 consecutive patients with asymptomatic severe stenosis of the ICA (>70% reduction in diameter) and for 16 healthy control subjects. The 18 patients with ICA flow lesion and no visible infarction on MRI who underwent CEA were evaluated before and 7 days after surgery (CEA group). The 16 control subjects had never had a cerebral event, and brain MRI and carotid duplex scan study results were normal in all (control group). Preoperative ICA volume flow was severely decreased to less than 150 mL/min in all 18 patients, in comparison with our laboratory normal value of matched age group of 250 to 300 mL/min. After CEA, ICA volume flow was increased to greater than 300 mL/min in all patients (P =.00). For patients in the CEA group, preoperative N-acetylaspartate/creatine and choline/creatine ratios in the MCA territory were slightly decreased compared with the healthy subjects in the control group but were within normal limits. However, the postoperative values of N-acetylaspartate/creatine and choline/creatine ratios in the ipsilateral MCA territory were significantly increased as compared with the preoperative values (P<.05). In the contralateral side, the postoperative increase of choline/creatine ratio and the decrease of myo-inositol/creatine ratio were statistically significant as compared with the preoperative values (P<.05).\nQuestion: Can carotid endarterectomy improve metabolic status in patients with asymptomatic internal carotid artery flow lesion?",
        "gt": "CEA seems to improve the cerebral metabolic status in patients with asymptomatic ICA flow lesions and no visible infarction on MRI.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Neoadjuvant chemotherapy (NAC) may allow breast-conserving therapy (BCT) in patients who require mastectomy at presentation. Breast MRI is more accurate than mammography in assessing treatment response, but combined test reliability in identifying BCT candidates after NAC is not well described. We evaluated whether post-NAC breast MRI alone and with mammography accurately identifies BCT candidates. In this retrospective study of 111 consecutive breast cancer patients receiving NAC, all had pre- and postchemotherapy MRI, followed by surgery. Posttreatment MRI and mammography results were correlated with surgical outcomes and pathologic response. Fifty-one of 111 (46\u00a0%) patients presented with multicentric or inflammatory breast cancer and were not BCT candidates. The remaining 60 (54\u00a0%) were considered BCT candidates after downstaging (mean age: 47\u00a0years). All 60 had at least a partial response to NAC and were suitable for BCT on MRI after NAC. Forty-five of 60 (75\u00a0%) underwent lumpectomy; 15 of 60 (25\u00a0%) chose mastectomy. Forty-one of 45 (91\u00a0%) of lumpectomies were successful; 4 of 45 (9\u00a0%) required mastectomy. Twelve of 15 (80\u00a0%) patients choosing mastectomy could have undergone BCT based on pathology; 3 of 15 (20\u00a0%) did require mastectomy. Two of these three patients had extensive microcalcifications on mammogram, indicating the need for mastectomy despite MRI suitability for BCS. MRI alone correctly predicted BCS in 53 of 60 (88\u00a0%) patients. MRI plus mammography was correct in 55 of 60 (92\u00a0%), although only 9 of 45 (20\u00a0%) BCT patients and 4 of 15 (27\u00a0%) potentially conservable mastectomy patients had complete pathologic responses.\nQuestion: Do MRI and mammography reliably identify candidates for breast conservation after neoadjuvant chemotherapy?",
        "gt": "Posttreatment MRI plus mammography is an accurate method to determine whether BCT is possible after NAC is given to downstage disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In the present study, the transmission of sunlight trough the human skin barrier into the living tissue was investigated in the spectral region between 280 and 700 nm. The experiments were performed with a fiber-based spectrometer on sliced skin obtained from volunteers with different skin types. One fiber was positioned directly on the skin surface and the second one underneath the skin samples. The distribution of the sunlight under the epidermis was determined. Significant differences were found in the absorption properties of the different skin types, which were mainly determined by the variations in melanin concentration and distribution. It was found that sunscreens for specific ethnic groups need different combinations of UV filters, if a balanced relation between ultraviolet B (UVB) and ultraviolet A (UVA) protection is to be obtained. On the other hand, it could be demonstrated that the human skin is also well protected against visible and near-infrared light by melanin.\nQuestion: Do different ethnic groups need different sun protection?",
        "gt": "The higher the skin type category, the better the protection in the visible part of the spectrum of the sun. This stimulates the hot discussion at the present time, as to whether sunscreens should also contain protection compounds in the visible and near-infrared parts of the spectrum.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether a rigorous antiseptic hand washing of bare hands with 4% chlorhexidine and alcohol reduced fingertip microbial colonization as compared with the use of boxed, clean, nonsterile latex gloves. In addition, to investigate if aseptic donning technique and/or a prior hand washing would reduce the level of glove contamination. Prospective, randomized, crossover design, with each subject serving as his/her own control. University intensive care unit. Forty-three intensive care nurses. The fingertips of 20 nurses were cultured before and after a strict antiseptic hand washing and before and after the routine and aseptic donning of sterile gloves. Subsequently, the fingertips of 43 nurses were cultured before and after the casual donning of nonsterile gloves over unwashed hands and before and after a strict antiseptic hand washing. Fingertip cultures were plated directly on agar, incubated for 24 hrs, and counted and recorded as the number of colony-forming units (cfu) for each hand. Different colony types were then subcultured. Hand washing with antiseptic reduced colonization from 84 to 2 cfu (p<.001). The proportion of cases with>or = 200 cfu/hand was reduced from 30% to 9%. Aseptic or casual donning of sterile gloves, with or without prior antiseptic hand washing, resulted in consistently low glove counts between 0 and 1.25 cfu. Nonsterile gloves casually donned over washed or unwashed bare hands diminished the bioburden to 2.17 and 1.34 cfu, respectively. No qualitative difference was found in the microorganisms recovered from gloved or bare hands.\nQuestion: Is hand washing really needed in an intensive care unit?",
        "gt": "Antiseptic hand washing and the use of nonsterile gloves over unwashed hands confer similar reductions in the number of microorganisms. There is no additional benefit with the use of aseptic donning technique, prior antiseptic hand washing, or the use of individually packaged sterile gloves.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Previous research on alcohol mixed with energy drinks (AmED) suffers from measurement problems. Missing from the research literature are studies that assess caffeine-alcohol co-ingestion in natural drinking environments. This field study collected data in a U.S. college bar district from 328 randomly selected patrons. Anonymous data were obtained from face-to-face interviews and self-administered surveys, and from breath tests. Cola-caffeinated alcoholic beverage consumers left bars in a more highly intoxicated state than those who consumed alcohol only. There was no significant difference between the intoxication level of the AmED group and the cola-caffeinated alcoholic beverage group. Results from a multivariate regression model indicated that quantity of caffeinated alcoholic beverage consumption had a significant, positive association with bar patron intoxication after adjusting for potential confounders.\nQuestion: Is there a misplaced focus on AmED?",
        "gt": "Findings indicate that caffeine may have a dose-dependent relationship with alcohol intoxication in the bar/nightclub setting. In addition, results revealed that cola-caffeinated alcoholic drinks may pose similar levels of risk to bar patrons as those associated with AmED beverage consumption. Product labeling requirements about alcohol risks may need to be extended not only to energy drinks, but to caffeinated soft drinks as well.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This secondary analysis of data from a randomised controlled trial explores associations between common symptom clusters and evaluates pre-treatment to post-treatment changes in clinical levels of these symptoms following cognitive behaviour therapy for insomnia (CBT-I). Baseline data from 113 participants with insomnia were explored to establish rates of and associations between clinical levels of fatigue, anxiety and depression across the sample. Effects of CBT-I on this symptom cluster were also explored by examining changes in pre-treatment to post-treatment levels of fatigue, anxiety and depression. At baseline, the most common symptom presentation was insomnia\u2009+\u2009fatigue, and 30% of the sample reported at least three co-morbid symptoms. Post-CBT, the number of those experiencing clinical insomnia and clinical fatigue decreased. There were no changes in anxiety rates from baseline to post-treatment in the CBT group and modest reductions in rates of those with clinical depression. Seven individuals (9.6%) from the CBT group were completely symptom free at post-treatment compared with 0% from the treatment as usual condition. Chi-square analysis revealed a significant relationship between group allocation and changes in symptoms of insomnia and fatigue. No such relationship was found between group allocation and mood variables.\nQuestion: Does cognitive behaviour therapy for insomnia reduce clinical levels of fatigue, anxiety and depression in cancer patients?",
        "gt": "These findings confirm the high rate of symptom co-morbidities among cancer patients and highlight strong associations between sleep and fatigue. CBT-I appears to offer generalised benefit to the symptom cluster as a whole and, specifically, is effective in reducing fatigue, which exceeded clinical cut-offs prior to implementation of the intervention. This has implications for the diagnosis/management of common symptoms in cancer patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Children with closed head injuries diagnosed as concussion alone or concussion with brief loss of consciousness are admitted routinely for observation despite a normal central nervous system finding, negative computed tomography (CT) scan, and a Glasgow Coma Score (GCS) of 15. Recent studies have questioned the necessity of such an admission. The purpose of this study was to review a large pediatric database and study the length of stay as well as any required procedures or complications in these children. The hypothesis was that routine admission is unnecessary in this population. The National Pediatric Trauma Registry-Phase II was reviewed for the period from October 1988 to January 1996. Entry criteria included age less than 18 and an isolated closed head injury after blunt trauma with an admission GCS of 15. Variables studied included age, gender, mechanism of injury, length of stay, procedures, and outcome. A total of 1,033 children met criteria for this study. The average age was 8.3 years. Males predominated at 61.9%. Falls, sports, and motor vehicle crashes were the most common mechanisms of injury. The average length of stay was 1.19 days, and 60 children were not admitted. A total of 583 children had no procedures performed, whereas 386 received a CT scan, and 148 had x-rays. None required neurosurgical intervention, and all were discharged alive.\nQuestion: Mandatory admission after isolated mild closed head injury in children: is it necessary?",
        "gt": "These findings indicate that routine admission may not be necessary for children with isolated mild closed head injuries with a negative CT scan and a normal neurologic finding and allows for a prospective randomized trial to confirm this.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Infants in utero during the terrorist attacks of September 11, 2001 may have been negatively affected by maternal stress. Studies to date have produced contradictory results. Data for this retrospective cohort study were obtained from the Department of Defense Birth and Infant Health Registry and included up to 164,743 infants born to active-duty military families. Infants were considered exposed if they were in utero on September 11, 2001, while the referent group included infants gestating in the same period in the preceding and following year (2000 and 2002). We investigated the association of this acute stress during pregnancy with the infant health outcomes of male:female sex ratio, birth defects, preterm birth, and growth deficiencies in utero and in infancy. No difference in sex ratio was observed between infants in utero in the first trimester of pregnancy on September 11, 2001 and infants in the referent population. Examination of the relationship between first-trimester exposure and birth defects also revealed no significant associations. In adjusted multivariable models, neither preterm birth nor growth deficiencies were significantly associated with the maternal exposure to the stress of September 11 during pregnancy.\nQuestion: Does acute maternal stress in pregnancy affect infant health outcomes?",
        "gt": "The findings from this large population-based study suggest that women who were pregnant during the terrorist attacks of September 11, 2001 had no increased risk of adverse infant health outcomes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The clinical records from 8 consecutive years (2005-2013) were analyzed retrospectively. Cases of cesarean delivery with general anesthesia were analyzed and compared with an age-matched group of female patients undergoing non-obstetric abdominal or gynecological surgery with rapid sequence induction. Poor laryngeal visualization (Cormack-Lehane grade III or IV) and failed intubation were recorded. The records of 6393 cesarean deliveries including 851 with general anesthesia were analyzed. In 175 cases insufficient or delayed onset of regional anesthesia led to requirement for general anesthesia. The rate of poor laryngoscopic view in parturient women undergoing cesarean delivery was 14/851, and 4/814 in the reference group (P\u2009=\u20090.023). Failed intubation occurred in three patients undergoing cesarean delivery (0.4%) and in one non-obstetric patient (0.1%; P\u2009=\u20090.339).\nQuestion: Adverse airway events in parturient compared with non-parturient patients. Is there a difference?",
        "gt": "The rate of failed intubations in patients undergoing cesarean delivery may be equivalent to non-obstetric patients. In time-challenging cesarean deliveries, delay of conversion from non-successful neuroaxial anesthesia to general anesthesia in order to avoid adverse airway events does not appear to be justified.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare the prevalence and intensity of victimisation from bullying and the characteristics of the victim of bullying, comparing adolescents with and adolescents without chronic conditions (CC). School survey. Postmandatory schools. A total of 7005 students (48% females) aged 16-20 years, distributed into adolescents with CC (728, 50% females) and controls (6277, 48% females). Chronic condition was defined as having a chronic disease and/or a physical disability. Prevalence of bullying-intensity of bullying-and sociodemographic, biopsychosocial, familial, school and violence context characteristics of the victims of bullying. The prevalence of bullying in our sample was 13.85%. Adolescents with CC were more likely to be victims of bullying (adjusted OR 1.53), and to be victims of two or three forms of bullying (adjusted OR 1.92). Victims of bullying with CC were more likely than non-victims to be depressed (RR 1.57), to have more physical symptoms (RR 1.61), to have a poorer relationship with their parents (RR 1.33), to have a poorer school climate (RR 1.60) and to have been victims of sexual abuse (RR 1.79) or other forms of violence (RR 1.80). Although these characteristics apply to victims in general, in most cases, they are less pronounced among victims without CC.\nQuestion: Are adolescents with chronic conditions particularly at risk for bullying?",
        "gt": "CC seems to be a risk factor for victimisation from bullying. Therefore, as adolescents with CC are increasingly mainstreamed, schools should be encouraged to undertake preventive measures to avoid victimisation of such adolescents.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients with obsessive-compulsive disorder (OCD) have impaired memory and executive functions, but it is unclear whether these functions improve after cognitive behavioural therapy (CBT) of OCD symptoms. The primary aim of this study was to investigate whether memory and executive functions change after CBT in patients with OCD. We assessed 39 patients with OCD before and after CBT with neuropsychological tests of memory and executive functions. To correct for practice effects, 39 healthy controls (HCs) were assessed at two parallel time intervals with the neuropsychological tests. There were no changes in memory and executive functions after CBT in patients with OCD when results were corrected for practice effects. Patients performed worse on a test of visuospatial memory and organisational skills (Rey complex figure test [RCFT]) compared to HCs both before and after CBT (ps = .002-.036).\nQuestion: Are there reliable changes in memory and executive functions after cognitive behavioural therapy in patients with obsessive-compulsive disorder?",
        "gt": "The finding of persistent poor RCFT performances indicates that patients with OCD have impaired visuospatial memory and organisational skills that may be trait-related rather than state-dependent. These impairments may need to be considered in treatment. Our findings underline the importance of correcting for practice effects when investigating changes in cognitive functions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A prospective registry was used for data review. Patients with anastomotic leakage following compression anastomosis between November 2008 and September 2013 were included. In all, 197 (92 female) patients were operated using a novel compression device. Early leakage was found in 10 (5.1%) patients after a median of 5 (3-14) days. The radiologist was able to detect leakage using CT in nine out of 10 cases unequivocally. Removal of the ring was necessary in eight of the 10 cases, and salvage of the anastomosis was feasible on six occasions. In all diverted cases with a low anastomosis, a transanal repair of the defect was feasible in three cases, including a single patient with complete separation of the anastomosis.\nQuestion: Diagnosis, management and outcome of early anastomotic leakage following colorectal anastomosis using a compression device: is it different?",
        "gt": "Artefacts on the CT scan caused by the compression ring did not hamper the diagnosis of anastomotic leakage. Removal of the ring in the early postoperative period is not associated with complete separation of the bowel ends. Salvage of anastomosis is feasible in most cases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Ramstedt pyloromyotomy is a common operation in infants and is often done by general surgeons. We wished to determine whether there are any differences in outcome when this procedure is done by subspecialist pediatric general surgeons as compared with general surgeons. All Ramstedt pyloromyotomies in the province of Ontario between 1993 and 2000 were reviewed. Children with complex medical conditions or prematurity were excluded. Cases done by general surgeons were compared with those done by pediatric surgeons, specifically examining hospital stay and complications. Of 1777 eligible infants, 67.9% were operated on by pediatric surgeons and 32.1% by general surgeons. Total and postoperative lengths of stay were longer in the general surgeon group compared with the pediatric surgeons (4.31 vs 3.50 days for length of stay; 2.95 vs 2.25 days for postoperative length of stay). The general surgeons had a higher overall complication rate (4.18% vs 2.58%). The incidence of duodenal perforation among general surgeons was almost 4 times that of pediatric surgeons (relative risk: 3.65; 95% confidence interval: 1.43-9.32). Of the 4 infants who required repeat surgery because of an incomplete pyloromyotomy, all were originally operated on by a general surgeon. Analysis of the effect of surgeon volume on outcomes suggested that higher volume resulted in better outcome in both groups.\nQuestion: Does pediatric surgical specialty training affect outcome after Ramstedt pyloromyotomy?",
        "gt": "Subspecialist pediatric general surgeons achieve superior outcomes for children who undergo Ramstedt pyloromyotomy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We sought to determine if disparities in survival and health-related quality of life (HRQOL) occurred after solid organ transplantation at our institution. Data were extracted from a database including information regarding transplants that took place from 1990 to 2002. The HRQOL was assessed in patients by using the Karnofsky functional performance (FP) index and the Medical Outcomes Study Short Form 36 (SF-36) questionnaire. Data were collected on recipients of liver (n = 413), heart (n = 299), kidney (n = 892), and lung (n = 156). Blacks represented a minority of recipients: liver 7%, heart 8%, kidney 23%, and lung 6%. There were no statistically significant differences in patient survival between blacks and whites. Graft survival differed in kidney only with a 5-year survival: 72% for blacks versus 79% for whites (P<0.001). The FP and HRQOL improved (P<0.05) after transplantation in both groups. There were no differences on measures of the FP or HRQOL.\nQuestion: Is there racial disparity in outcomes after solid organ transplantation?",
        "gt": "Blacks had comparable survival and improvement in FP and HRQOL in comparison with whites.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate whether P1 and N1 evoked by ERP tasks could appropriately reflect primary visual processing in Parkinson's disease (PD). We recorded ERPs in 13 PD patients with duration of illness less than 5 years and 18 age-matched normal control subjects. P1 and N1 from Oz were evoked by a visual oddball and a delayed matching S1-S2 task. The effect of different events on P1 and N1 was studied. All patients were given an ECD-SPECT examination, and the SPECT images were overlaid on the 3D-MRI. The correlation of P1 or N1 to the regional cerebral blood flow (rCBF) was studied. P1 was not influenced by different events. There was no significant P1 differences between the PD and the normal group. N1 was significantly shorter and smaller in the patients than that in the normal group. N1 amplitude after the waveform subtraction (target-frequent) in the PD group did not show significant difference with that in the normal controls, nor with the N1 before the subtraction. Nd, the subcomponent of N1 after the subtraction in the patients was significantly earlier and smaller than that in the normal controls. P1 only weakly correlated with the rCBF in the occipital lobe. N1 was correlated with the rCBF in a global region.\nQuestion: Do P1 and N1 evoked by the ERP task reflect primary visual processing in Parkinson's disease?",
        "gt": "The results provided some evidence that P1 might reflect the primary visual processing, and N1 might be involved in both primary and cognitive visual processing. The altered N1 in the PD patients might be due to the deformed Nd.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the organizational perspectives on the effectiveness of their attendance management policies for chronically ill employees. A mixed-method approach was employed involving questionnaire survey with employees and in-depth interviews with key stakeholders of the organizational policies. Participants reported that attendance management polices and the point at which systems were triggered, posed problems for employees managing chronic illness. These systems presented risk to health: employees were more likely to turn up for work despite feeling unwell (presenteeism) to avoid a disciplinary situation but absence-related support was only provided once illness progressed to long-term sick leave. Attendance management polices also raised ethical concerns for 'forced' illness disclosure and immense pressures on line managers to manage attendance.\nQuestion: Sickness absence management: encouraging attendance or 'risk-taking' presenteeism in employees with chronic illness?",
        "gt": "Participants felt their current attendance management polices were unfavourable toward those managing a chronic illness. The policies heavily focused on attendance despite illness and on providing return to work support following long-term sick leave. Drawing on the results, the authors conclude that attendance management should promote job retention rather than merely prevent absence per se. They outline areas of improvement in the attendance management of employees with chronic illness.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Due to their relative scarcity and to limit single-center bias, multi-center data are needed to study femoral hernias. The aim of this study was to evaluate outcomes and quality of life (QOL) following laparoscopic vs. open repair of femoral hernias. The International Hernia Mesh Registry was queried for femoral hernia repairs. Laparoscopic vs. open techniques were assessed for outcomes and QOL, as quantified by the Carolinas Comfort Scale (CCS), preoperatively and at 1, 6, 12, and 24\u00a0months postoperatively. Outcomes were evaluated using the standard statistical analysis. A total of 80 femoral hernia repairs were performed in 73 patients: 37 laparoscopic and 43 open. There was no difference in mean age (54.7\u00a0\u00b1\u00a014.6\u00a0years), body mass index (24.2\u00a0\u00b1\u00a03.8\u00a0kg/m2), gender (60.3\u00a0% female), or comorbidities (p\u00a0>\u00a00.05). The hernias were recurrent in 21\u00a0% of the cases with an average of 1.23\u00a0\u00b1\u00a00.6 prior repairs (p\u00a0>\u00a00.1). Preoperative CCS scores were similar for both groups and indicated that 59.7\u00a0% of patients reported pain and 46.4\u00a0% had movement limitations (p\u00a0>\u00a00.05). Operative time was equivalent (47.2\u00a0\u00b1\u00a021.2 vs. 45.9\u00a0\u00b1\u00a014.8\u00a0min, p\u00a0=\u00a00.82). There was no difference in postoperative complications, with an overall 8.2\u00a0% abdominal wall complications rate (p\u00a0>\u00a00.05). The length of stay was shorter in the laparoscopic group (0.5\u00a0\u00b1\u00a00.6 vs. 1.3\u00a0\u00b1\u00a01.6\u00a0days, p\u00a0=\u00a00.02). Follow-up was somewhat longer in the open group (23.8\u00a0\u00b1\u00a010.2 vs. 17.3\u00a0\u00b1\u00a010.9\u00a0months, p\u00a0=\u00a00.02). There was one recurrence, which was in the laparoscopic group (3.1 vs. 0\u00a0%, p\u00a0=\u00a00.4). QOL outcomes at all time points demonstrated no difference for pain, movement limitation, or mesh sensation. Postoperative QOL scores improved for both groups when compared to preoperative scores.\nQuestion: Quality of life and outcomes for femoral hernia repair: does laparoscopy have an advantage?",
        "gt": "In this prospective international multi-institution study of 80 femoral hernia repairs, no difference was found for operative times, long-term outcomes, or QOL in the treatment of femoral hernias when comparing laparoscopic vs. open techniques. After repair, QOL at all time-points postoperatively improved compared to QOL scores preoperatively for laparoscopic and open femoral hernia repair. While international data supports improved outcomes with laparoscopic approach for femoral hernia repair, no data had existed prior to this study on the difference of approach impacting QOL. In the setting where recurrence and complication rates are equal after femoral hernia repair for either approach, surgeons should perform the technique with which they are most confident, as the operative approach does not appear to change QOL outcomes after femoral hernia repair.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare the proportion of airway and vascular access procedures performed by referring hospital staff on critically ill children in two discrete time periods, before and after widespread use of a specialised paediatric retrieval service. Transport data were obtained from retrieval logs of all children for whom a paediatric retrieval team was launched in each of two time periods (October 1993 to September 1994; and October 2000 to September 2001). The overall intubation rate was similar in the first and second time periods (83.9% v 79.1%). However, 31/51 (61%) retrieved children were intubated by referring hospital staff in 1993-94, compared to 227/269 (84%) in 2000-01. Referring hospital staff gained central venous access in 11% v 18% and arterial access in 22% v 19% of retrieved children in the first and second time periods respectively. This was in spite of a significant reduction in the proportion of children on whom these procedures were performed.\nQuestion: Does the use of a specialised paediatric retrieval service result in the loss of vital stabilisation skills among referring hospital staff?",
        "gt": "Referring hospital staff are performing a greater proportion of initial airway and vascular access procedures undertaken in the stabilisation of sick children retrieved by a specialised paediatric retrieval team. The provision of this service has not resulted in the loss of vital skills at the local hospital.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The release of metal ions (Al, Ag, Au, Ca, Cd, Co, Cr, Cu, Mg, Mo, Ni, Pd, Pt, Ti, and Zn) from the commercial gold/platinum (Au/Pt) dental alloy of declared composition was studied. Au/Pt was soaked in pH 6.0 phosphate buffer, 3.5 pH phosphate buffer and pH 3.5 mixture of lactic, formic and acetic acid, and incubated at 37 degrees C for 1, 2, 3, 4, 5, 6, 7, 14, 21, and 30 days. Six samples (n = 6) of every solution were prepared for any time period. Inductively coupled plasma atomic emission spectroscopy was used for analysis of the released elements. Results demonstrated release of only Cr, Cu, Fe, and Zn from the tested Au/Pt dental alloy (ANOVA, p<0.001 for buffer, time, and interaction, respectively); however, only Cu and Zn were declared.\nQuestion: Ion release from gold/platinum dental alloy: could release of other elements be accountable in the contact allergy attributed to the gold?",
        "gt": "The undeclared chromium from Au/Pt dental alloy, or some other element might be responsible for the contact allergy thus far attributed to the gold.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine whether actual nurse staffing predicts missed nursing care, controlling for other unit characteristics. This study utilized a cross-sectional, descriptive design. Ten hospitals in the Midwestern region of the USA. Nursing staff members with direct care responsibilities (n = 4288) on 110 care units. The MISSCARE Survey was utilized to capture respondents' perceptions of missed nursing care as well as other unit characteristics (i.e. demographics, work schedules and absenteeism). Actual staffing data (hours per patient day [HPPD], registered nurse hours per patient day [RN HPPD], skill mix) and unit level case mix index were collected from the participating hospitals for the mean scores of 2 months during survey distribution. HPPD was a significant predictor of missed nursing care (\u03b2 = -0.45, P = 0.002).\nQuestion: Do staffing levels predict missed nursing care?",
        "gt": "Findings from this study suggest that missed nursing care may explain, at least in part, the relationship between staffing levels and patient outcomes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We conducted a study using a case-crossover design to clarify the risk of acute effects of zolpidem and benzodiazepine on all-sites of fractures in the elderly. Case-crossover design. Elderly enrollees (n = 6010) in Taiwan's National Health Insurance Research Database with zolpidem or benzodiazepine use were analyzed for the risk of developing fractures. After adjusting for medications such as antipsychotics, antidepressants, and diuretics, or comorbidities such as hypertension, osteoarthritis, osteoporosis, rheumatoid arthritis and depression, neither zolpidem nor benzodiazepine was found to be associated with increased risk in all-sites fractures. Subjects without depression were found to have an increased risk of fractures. Diazepam is the only benzodiazepine with increased risk of fractures after adjusting for medications and comorbidities. Hip and spine were particular sites for increased fracture risk, but following adjustment for comorbidities, the associations were found to be insignificant.\nQuestion: Is Zolpidem Associated with Increased Risk of Fractures in the Elderly with Sleep Disorders?",
        "gt": "Neither zolpidem nor benzodiazepine was associated with increased risk of all-site fractures in this case cross-over study after adjusting for medications or comorbidities in elderly individuals with insomnia. Clinicians should balance the benefits and risks for prescribing zolpidem or benzodiazepine in the elderly accordingly.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the effect of drafting on running time, physiological response, and rating of perceived exertion (RPE) during 3000-m track running. Ten elite middle- and long-distance runners performed 3 track-running sessions. The 1st session determined maximal oxygen uptake and maximal aerobic speed using a lightweight ambulatory respiratory gas-exchange system (K4B2). The 2nd and the 3rd tests consisted of nondrafting 3000-m running (3000-mND) and 3000-m running with drafting for the 1st 2000 m (3000-mD) performed on the track in a randomized counterbalanced order. Performance during the 3000-mND (553.59\u00b122.15 s) was significantly slower (P<.05) than during the 3000-mD (544.74\u00b118.72 s). Cardiorespiratory responses were not significantly different between the trials. However, blood lactate concentration was significantly higher (P<.05) after the 3000-mND (16.4\u00b12.3 mmol/L) than after the 3000-mD (13.2\u00b15.6 mmol/L). Athletes perceived the 3000-mND as more strenuous than the 3000-mD (P<.05) (RPE=16.1\u00b10.8 vs 13.1\u00b11.3). Results demonstrate that drafting has a significant effect on performance in highly trained runners.\nQuestion: Drafting's improvement of 3000-m running performance in elite athletes: is it a placebo effect?",
        "gt": "This effect could not be explained by a reduced energy expenditure or cardiorespiratory effort as a result of drafting. This raises the possibility that drafting may aid running performance by both physiological and nonphysiological (ie, psychological) effects.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The physicochemical properties of diamorphine (3,6-diacetylmorphine) enhance its bioavailability compared with more lipid-soluble opioids when administered into the epidural space. However, the influence of concentration, volume or mass on the clinical efficacy of diamorphine is not known. In this double-blind, randomized, prospective study, 62 women in active labour and</=5 cm cervical dilatation were recruited to determine whether the mode of action of diamorphine in the epidural space is concentration-dependent. After insertion of a lumbar epidural catheter, patients received epidural diamorphine 3 mg either as a high-volume, low-concentration solution (group A) or a low-volume, high-concentration solution (group B). The concentration of diamorphine was determined by the response of the previous patient in the same group using up-down sequential allocation. Pain corresponding to the previous contraction was assessed using a 100-mm visual analogue score and effective analgesia was defined as</=10 mm within 30 min of epidural injection. There was no significant difference in EC50 for diamorphine between the groups: the difference was 15.0 microg ml(-1) (95% CI -40.3 to 10.3). The EC50 for group A was 237.5 microg ml(-1) (95% CI 221.2 to 253.8) and the EC50 for group B was 252.5 microg ml(-1) (95% CI 232.2 to 272.8). The EC50 ratio was 0.95 (95% CI 0.87 to 1.06). The groups exhibited parallelism (P=0.98). The overall EC50 for all data was 244.2 microg ml(-1) (95% CI 230.8 to 257.2).\nQuestion: Is the clinical efficacy of epidural diamorphine concentration-dependent when used as analgesia for labour?",
        "gt": "We conclude that diamorphine provides analgesia in labour by a concentration-dependent effect.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adding or incorporating clinical interpretative comments on biochemistry results is widespread in UK laboratories; although this consumes considerable human resource, there is still little evidence to suggest that it is either effective or appreciated by our clinical colleagues. I therefore decided to survey our local general practitioners (GPs) and nurse practitioners to analyse whether they found biochemistry comments on reports helpful. A simple questionnaire was designed and sent to 159 GPs and 81 nurse practitioners asking them whether they found this activity useful for the limited range of test groups that we routinely comment on and also whether they would like to see commenting on more groups of tests. Overall, 49.6% of questionnaires were returned. Of these, there was overwhelming support for commenting on reports and 77% would like to see comments on a greater range of tests.\nQuestion: Are biochemistry interpretative comments helpful?",
        "gt": "Although adding clinical interpretative comments is very time-consuming for senior laboratory staff, there is overwhelming support of this activity among our GPs and nurse practitioner users; therefore, our local policy of routinely adding clinical comments will remain for the foreseeable future.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Several models have been proposed to explain the association between ethnicity and health. It was investigated whether the association between Roma ethnicity and health is fully mediated by socioeconomic status in Hungary. Comparative health interview surveys were performed in 2003-04 on representative samples of the Hungarian population and inhabitants of Roma settlements. Logistic regression models were applied to study whether the relationship between Roma ethnicity and health is fully mediated by socioeconomic status, and whether Roma ethnicity modifies the association between socioeconomic status and health. The health status of people living in Roma settlements was poorer than that of the general population (odds ratio of severe functional limitation after adjustment for age and gender 1.8 (95% confidence interval 1.4 to 2.3)). The difference in self-reported health and in functionality was fully explained by the socioeconomic status. The less healthy behaviours of people living in Roma settlements was also related very strongly to their socioeconomic status, but remained significantly different from the general population when differences in the socioeconomic status were taken into account, (eg odds ratio of daily smoking 1.6 (95% confidence interval 1.3 to 2.0) after adjustment for age, gender, education, income and employment).\nQuestion: Does socioeconomic status fully mediate the effect of ethnicity on the health of Roma people in Hungary?",
        "gt": "Socioeconomic status is a strong determinant of health of people living in Roma settlements in Hungary. It fully explains their worse health status but only partially determines their less healthy behaviours. Efforts to improve the health of Roma people should include a focus on socioeconomic status, but it is important to note that cultural differences must be taken into account in developing public health interventions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate whether dementia incidence has changed over the last 2 decades. We compared dementia incidence in 2 independent subcohorts of persons aged 60-90 years from the Rotterdam Study, a population-based cohort study. The first subcohort started in 1990 (n = 5,727), the second in 2000 (n = 1,769). Participants were dementia-free at baseline and followed for at maximum 5 years. We calculated age-adjusted dementia incidence rates for the 2 subcohorts in total, in 10-year age strata, and for men and women separately. We also compared mortality rates, differences in prevalence of vascular risk factors, and medication use. Finally, we compared brain volumes and the extent of cerebral small vessel disease in participants who underwent brain imaging 5 years after the baseline examinations. In the 1990 subcohort (25,696 person-years), 286 persons developed dementia, and in the 2000 subcohort (8,384 person-years), 49 persons. Age-adjusted dementia incidence rates were consistently, yet nonsignificantly, lower in the 2000 subcohort in all strata, reaching borderline significance in the overall analysis (incidence rate ratio 0.75, 95% confidence interval [CI] 0.56-1.02). Mortality rates were also lower in the 2000 subcohort (rate ratio 0.63, 95% CI 0.52-0.77). The prevalence of hypertension and obesity significantly increased between 1990 and 2000. This was paralleled by a strong increase in use of antithrombotics and lipid-lowering drugs. Participants in 2005-2006 had larger total brain volumes (p<0.001) and less cerebral small vessel disease (although nonsignificant in men) than participants in 1995-1996.\nQuestion: Is dementia incidence declining?",
        "gt": "Although the differences in dementia incidence were nonsignificant, our study suggests that dementia incidence has decreased between 1990 and 2005.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The overall effect of swaddling has been controversial for centuries. Its positive effect on the psychological development of the infant has popularized it in European and North American countries, but its negative effect on the development of the hip is of great concern. In our experiment, the influence of straight-leg swaddling in an animal model was observed radiographically and histologically. One hundred and twelve neonatal rats were divided into a control group and three experimental groups that were swaddled with use of surgical tape in a manner simulating the human practice for the first five days of life (early swaddling), the second five days (late swaddling), and the first ten days (prolonged swaddling). Hip dislocation and subluxation were evaluated on anteroposterior pelvic radiographs, and histological studies were performed to further observe the morphology of the hips. Rats in the prolonged swaddling group had the highest prevalence of hip dysplasia (thirty-six of forty-four), followed by the early swaddling group (twenty-one of forty-four). Most of the dysplastic hips in the prolonged swaddling group were dislocated, whereas subluxation dominated in the late swaddling group. Differences between the sexes were significant only in the early swaddling group, and differences between sides were not significant in any group. Appositional growth of the acetabular cartilage and deformity of the triradiate cartilage complex were observed in the dislocated and subluxated hips.\nQuestion: Does swaddling influence developmental dysplasia of the hip?",
        "gt": "Straight-leg swaddling was demonstrated to increase the prevalence of developmental dysplasia of the hip in this animal model, especially if the swaddling was early or prolonged. The severity of hip impairment varied, with early and prolonged swaddling both leading to more dislocations than subluxations. Sex differences also existed but a side preference was not observed. Appositional growth of acetabular cartilage and a deformed triradiate cartilage complex were the pathological basis of the hip dysplasia in this animal model.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This is the second Active Healthy Kids Wales Report Card. The 2016 version consolidates and translates research related to physical activity (PA) among children and youth in Wales, and aims to raise the awareness of children's engagement in PA and sedentary behaviors. Ten PA indicators were graded using the Active Healthy Kids-Canada Report Card methodology involving a synthesis and expert consensus of the best available evidence. Grades were assigned as follows: Overall PA, D+; Organized Sport Participation, C; Active and Outdoor Play, C; Active Transportation, C; Sedentary Behaviors, D-; Physical Literacy, INC; Family and Peer Influences, D+; School, B; Community and the Built Environment, C; and National Government Policy, Strategies, and Investments, B-.\nQuestion: Results From Wales' 2016 Report Card on Physical Activity for Children and Youth: Is Wales Turning the Tide on Children's Inactivity?",
        "gt": "Despite the existence of sound policies, programs, and infrastructure, PA levels of children and youth in Wales are one of the lowest and sedentary behavior one of the highest globally. From the 2014 Report Card, the Family and Peer Influences grade improved from D to D+, whereas Community and the Built Environment dropped from B to C. These results indicate that a concerted effort is required to increase PA and decrease sedentary time in children and young people in Wales.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to investigate the hemodynamic effects of thigh compression in patients with deep venous incompetence. This diagnostic test study was set in a municipal general hospital. Twelve patients with venous leg ulcers (CEAP classification, C6 Es Ad Pr; four men and eight women), with a mean age of 56.5 +/- 16.8 years, with popliteal venous reflux of more than 1 second detected with duplex scan, underwent investigation with the following methods: 1, the pressure exerted under thigh-length compression stockings class II and short-stretch adhesive compression bandages was measured with an MST tester (Salzmann, Switzerland) and a CCS 1000 device (Juzo, Germany), respectively; 2, the great saphenous vein and the femoral vein on the thigh were compressed with a pneumatic cuff (0, 20, 40, and 60 mm Hg) containing a window through which the diameters of these veins could be measured with duplex ultrasonography; and 3, with the same thigh-cuff occlusion procedure, the venous filling index (VFI) for each experiment was measured with air plethysmography. These values reflected the presence and extent of venous reflux in each experiment depending on the degree of venous narrowing. The mean pressure of a class II compression stocking was about 15 mm Hg at the thigh level, and adhesive bandages achieved a pressure of more than 40 mm Hg in the same location. A statistically significant reduction of the diameters of the great saphenous vein and the femoral vein could be obtained only when the cuff pressure on the thigh was equal to or higher than 40 mm Hg (P<.001). A reduction of the venous reflux (VFI) was achieved only with a thigh pressure of 60 mm Hg (P<.001). No significant reduction was seen of VFI with a thigh pressure in the range of the class II stockings. Previous investigations have shown that, in patients with deep venous incompetence, a pressure cuff on the thigh with 60 to 80 mm Hg is able to reduce ambulatory venous hypertension.\nQuestion: Does thigh compression improve venous hemodynamics in chronic venous insufficiency?",
        "gt": "Thigh compression as exerted with class II thigh-length compression stockings is not able to significantly reduce venous diameter or venous reflux. However, with a pressure of 40 to 60 mm Hg on the thigh that can be achieved with strongly applied short-stretch bandages, considerable hemodynamic improvement, including reduced venous reflux, can be obtained in patients with severe stages of chronic venous insufficiency from deep vein incompetence. The practical value of these preliminary findings should be investigated with further clinical trials.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Does the university experience and environment on two very different campuses create perceptions of advantage or disadvantage despite delivery of the same curriculum by the same tutors? Perhaps more importantly, do different types of universities result in varying achievements in learning given similar students? The Hull York Medical School (HYMS) runs the same curriculum with the same faculty on two very different campuses and randomly allocates most students to one or the other. HYMS therefore offers an exceptional opportunity to investigate these questions about the perceptions of educational environment and actual academic achievement controlling as much as possible for design and delivery of the curriculum. The Dundee Ready Education Environment Measure (DREEM) was administered to students in Year 1 and 2 at HYMS to assess perceptions of the course. Examination results were collected for the cohorts to compare actual academic performance on written and clinical examinations. Minimal differences were found in perceptions of educational environment, with those differences found favouring the less 'prestigious' institution. Examination results for written and clinical exams over the first 2 years were found not to differ between campuses.\nQuestion: Can we create an equivalent educational experience on a two campus medical  school?",
        "gt": "The results of this study indicate that despite perceptions of one university being 'better' than another based on public measures such as league tables, the students' perceptions of educational environment was quite similar and exam performance showed no differences. This suggests that the prestige or ranking of a university based on common measures and perceptions may have far less impact on student learning than careful design and delivery of the curriculum.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The Six-Minute Walk Test (6MWT) is commonly used to assess the fitness level of healthy adults and of older adults with disabilities. It can also be used as an intervention to increase walking endurance. However, its use may be limited in certain rehabilitation settings due to space requirements. If it can be shown that the measured linear distance walked in the 6-minute walk is comparable to the distance walked as measured by a pedometer, the test may be more widely used in a variety of rehabilitation settings. In addition, questions exist as to whether the method of instruction (\"walk as far as you can\" vs \"walk as fast as you can\") can impact the rate of perceived exertion of the person performing the test. The purposes of this study were to assess for differences in the measured linear distance and from the gender-based predicted value when compared to the pedometer measurement. In addition, we assessed the difference, if any, in the rate of perceived exertion (RPE) using the 2 different methods of administration. Furthermore, the distance in meters walked using the 2 different methods of instruction was compared; likewise, comparisons were made of these values to predicted values. A group of 26 older adults participated in this descriptive study. After a practice trial, each person completed 2 linear trials using different methods of instruction, (\"walk as fast as you can\" or \"walk as far as you can\") of the 6MWT while wearing a DIGI-WALKER SW-651 pedometer. Vital signs were taken before and after each trial. Linear distance, pedometer distance, and numeric value RPE were recorded. Paired t tests demonstrated no gender differences. An intraclass correlation coefficient (2,1) of 0.822 was calculated between all dependent variables. A repeated measures MANOVA was conducted to assess for differences between all variables resulting in no differences (F = 1.98; P = .13). Pairwise comparisons were also insignificant for the distance measurements except predicted value and pedometer fast P = .024. Paired t tests also demonstrated differences between RPE between trials (t = 2.15; P = .041).\nQuestion: The 6MWT: will different methods of instruction and measurement affect performance of healthy aging and older adults?",
        "gt": "There was good agreement between these distance measures for the 6MWT. The use of a pedometer was found to be a valid measure of walking distance during the 6MWT. It was also found that the method of instruction made no differences in walking distance. Although the change was minimal on the Borg scale, the RPE was found to be significantly different between far and fast trials in healthy adults. From this study, it appears that that either mode of instruction is valid in healthy community-dwelling populations. Future studies should include populations with impairments.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the association between perirenal fat stranding (PFS) on CT and bladder outlet obstruction (BOO). CT scans from 122 patients who had undergone urodynamic study for lower urinary tract symptoms (LUTS) were registered after exclusion of patients with renal or retroperitoneal disease. Images were independently reviewed by two radiologists and compared with those of 244 age- and sex-matched control patients without LUTS. The PFS severity was scored on a four-point scale, and the interobserver agreement was assessed with kappa statistics. The severity score and incidence was compared between the groups, and the association with baseline characteristics was analyzed. For the LUTS group, an association between PFS severity and urodynamic and laboratory data was evaluated. PFS was more frequent and more severe in the LUTS group than in the control group (p-value\u2009<\u20090.001); its presence was significantly associated with male gender and older age (p-value\u2009<\u20090.001). PFS was predominantly bilateral in both groups (80.1-93.2%). In the LUTS group, PFS severity scores were significantly correlated with the maximum flow rate, maximum detrusor pressure and estimated glomerular filtration rate (p-value\u2009<\u20090.001). Interobserver agreements were excellent for PFS presence (\u03ba\u2009=\u20090.883) and severity (\u03ba\u2009=\u20090.816).\nQuestion: Perirenal fat stranding on CT: is there an association with bladder outlet obstruction?",
        "gt": "Severe PFS was observed in older, male patients with LUTS. PFS severity was associated with the degree of BOO and impaired renal function.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The validation of widely used scales facilitates the comparison across international patient samples. The objective of this study was to translate, culturally adapt and validate the Simple Shoulder Test into Brazilian Portuguese. Also we test the stability of factor analysis across different cultures. The objective of this study was to translate, culturally adapt and validate the Simple Shoulder Test into Brazilian Portuguese. Also we test the stability of factor analysis across different cultures. The Simple Shoulder Test was translated from English into Brazilian Portuguese, translated back into English, and evaluated for accuracy by an expert committee. It was then administered to 100 patients with shoulder conditions. Psychometric properties were analyzed including factor analysis, internal reliability, test-retest reliability at seven days, and construct validity in relation to the Short Form 36 health survey (SF-36). Factor analysis demonstrated a three factor solution. Cronbach's alpha was 0.82. Test-retest reliability index as measured by intra-class correlation coefficient (ICC) was 0.84. Associations were observed in the hypothesized direction with all subscales of SF-36 questionnaire.\nQuestion: Validation of the Simple Shoulder Test in a Portuguese-Brazilian population. Is the latent variable structure and validation of the Simple Shoulder Test Stable across cultures?",
        "gt": "The Simple Shoulder Test translation and cultural adaptation to Brazilian-Portuguese demonstrated adequate factor structure, internal reliability, and validity, ultimately allowing for its use in the comparison with international patient samples.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adequate energy provision and nitrogen losses prevention of critically ill patients are essentials for treatment and recovery. The aims of this study were to evaluate energy expenditure (EE) and nitrogen balance (NB) of critically ill patients, to classify adequacy of energy intake (EI), and to verify adequacy of EI capacity to reverse the negative NB. Seventeen patients from an intensive care unit were evaluated within a 24-hour period. Indirect calorimetry was performed to calculate patient's EE and Kjeldhal for urinary nitrogen analysis. The total EI and protein intake were calculated from the standard parenteral and enteral nutrition infused. Underfeeding was characterized as EI 90% or less and overfeeding as 110% or greater of EE. The adequacy of the EI (EI EE(-1) \u00d7 100) and the NB were estimated and associated with each other by Spearman coefficient. The mean EE was 1515 \u00b1 268 kcal d(-1), and most of the patients (11/14) presented a negative NB (-8.2 \u00b1 4.7 g.d(-1)). A high rate (53%) of inadequate energy intake was found, and a positive correlation between EI EE(-1) and NB was observed (r = 0.670; P = .007).\nQuestion: Can an adequate energy intake be able to reverse the negative nitrogen balance in mechanically ventilated critically ill patients?",
        "gt": "The results show a high rate of inadequate EI and negative NB, and equilibrium between EI and EE may improve NB. Indirect calorimetry can be used to adjust the energy requirements in the critically ill patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Previous studies on the impact of nonworking hours (NWH) have produced conflicting results. We aimed to compare the time to treatment with thrombolysis between NWH and working hours (WH) at an Australian comprehensive stroke center. All acute ischemic stroke patients treated with intravenous alteplase (IV-alteplase) from January 2003 to December 2011 at the Royal Melbourne Hospital were included. Data collected included demographics, serial time points (including onset, presentation to emergency department, neuroimaging, and thrombolysis), and clinical outcomes (modified Rankin Scale [mRS] and death) at 3 months. NWH were defined as weekdays 5 PM-8 AM, weekends, and public holidays. Comparisons were made in the door-to-computed tomography (CT) time, the door-to-needle time, mRS, and mortality within 3 months between the NWH group and WH group. We recruited 388 consecutive patients who received IV-alteplase, 226 patients were in NWH and 162 patients in WH. The median age was 71 years (Interquartile range [IQR] = 60-79), 54.1% of patients were male, and the median National Institutes of Health Stroke Scale score was 13 (IQR = 8-18). No significant differences were observed at baseline between the NWH and WH groups except for prior stroke. There was a 15-minute increase in the median door-to-needle time (80 minutes in the NWH group versus 64.5 minutes in the WH group, 95% confidence interval [CI]: 6.36-23.64, P = .001). No significant differences were noted in the median door-to-CT time (95% CI: -1.16 to 9.16, P = .128) and clinical outcomes at 3 months (P>.05). Both the door-to-CT time and the door-to-needle time became shorter over the period of the study (P<.001).\nQuestion: Thrombolysis for acute ischemic stroke: do patients treated out of hours have a worse outcome?",
        "gt": "Our study showed that the \"NWH effect\" increased the door-to-needle time. The patients treated out of hours did not have a worse outcome.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adiponectin is an adipocyte-derived collagen-like protein, highly specific to adipose tissue and may represent an important link between obesity and atherosclerosis. The present study was designed to investigate a possible association between serum adiponectin levels and early vascular changes in obese patients as determined by intima media thickness (IMT) and arterial pulse-wave contour analysis. Obese subjects (n=47) were evaluated for arterial structure and function, metabolic parameters and serum adiponectin levels. IMT was measured by ultrasound. Arterial elasticity was evaluated using pulse-wave contour analysis. Insulin resistance was assessed by homeostasis model assessment (HOMA-IR). diponectin was significantly, inversely associated with mean IMT (r=-0.369, P=0.011) and significantly positively associated with large artery elasticity index (LAEI) (r=0.467, P=0.001) as well as small artery elasticity index (SAEI) (r=0.462, P=0.001). In separate multivariate models, adiponectin remained significantly associated with mean IMT, LAEI and SAEI even after adjustment for cardiovascular confounders. Among metabolic parameters, adiponectin was significantly positively associated with HDL cholesterol and inversely associated with triglycerides. Adiponectin was significantly inversely associated with fasting insulin and HOMA-IR. In addition, a marginally inverse association between adiponectin and ALT was observed.\nQuestion: Adiponectin and vascular properties in obese patients: is it a novel biomarker of early atherosclerosis?",
        "gt": "In this study, serum adiponectin levels were significantly associated with indices of subclinical atherosclerosis, such as IMT and arterial compliance in obese patients. This association was independent of traditional cardiovascular risk factors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We investigated whether genetic or maternal/environmental risk factors for being born small for gestational age (SGA), e.g. Silver-Russell syndrome, congenital heart defects, infections of mothers or smoking during pregnancy, explain the variation in the first-year growth response to GH therapy. Secondary analysis was made of growth response in 135 short prepubertal German children (66% males) enrolled in a SGA phase III trial. Initial mean patient age was 6.8 +/- 2.6 years; mean patient height SDS -3.8 +/- 1.2, and GH treatment dose was 0.066 mg/kg body weight per day. Growth velocity increased by 4.5 +/- 2.0 cm/year and height SDS by 1.0 +/- 0.5 SDS. Although patient number was limited and variation was high, both growth response (cm/year) and change in height SDS did not appear to differ between subgroups which also did not differ in terms of Studentized residuals set up in the KIGS growth prediction model for SGA. Likewise, in a step-forward multivariate analysis, the variables Silver-Russell syndrome, congenital heart defects, infections of mothers and smoking were not identified as independent factors influencing growth velocity.\nQuestion: Is the response to growth hormone in short children born small for gestational age dependent on genetic or maternal factors?",
        "gt": "The retrospectively analyzed genetic and maternal/environmental risk factors for SGA do not appear to explain the observed patient variance in response to GH. Larger prospective studies are needed, however, to substantiate these preliminary findings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Surgery is the mainstay of treatment of patients with peptic duodenal perforation. With the advent of minimal access techniques, laparoscopy is being used for the treatment of this condition. Retrospective analysis of 120 consecutive patients (mean age 44.5 years; 111 men) with duodenal ulcer perforation who had undergone laparoscopic surgery. 87 patients had history of tobacco consumption, 12 were chronic NSAID users, 72 had Helicobacter pylori infection and 36 had a co-morbid condition. The mean time to surgery from onset of symptoms was 28.4 hours. The median operating time was 46 minutes. All patients underwent laparoscopic closure of the perforation with Graham's patch omentopexy; 12 patients underwent additional definitive ulcer surgery. The morbidity rate was 7.5%; no patient needed conversion to open surgery or died. The mean postoperative hospital stay was 5.8 days.\nQuestion: Laparoscopic management of duodenal ulcer perforation: is it advantageous?",
        "gt": "Results of laparoscopic management of perforated peptic ulcer are encouraging, with no conversion to open surgery, low morbidity and no mortality.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A larger proportion of adopted adolescents receive mental health counseling than do their nonadopted peers. Adoptees might have more problems that require counseling, or their adoptive parents might have a lower threshold for referral (or both). To test the hypothesis that both the extent of adolescents' problems and their adoption status would predict whether adolescents received psychological counseling, after controlling for family demographic characteristics. Two large data sets collected from 1994 through 1996 by the National Longitudinal Study of Adolescent Health (Add Health) were used. In parallel analyses of the 2 data sets, hierarchical logistic regression models were implemented to assess the incremental effects of problem behaviors, family characteristics, and adoption status on adolescents receiving counseling. Selected adolescents' problems and family demographic characteristics were significant predictors for having received counseling, but, after controlling for these variables, adoptees were still about twice as likely as nonadoptees to have received counseling.\nQuestion: Adopted adolescents' overrepresentation in mental health counseling: adoptees' problems or parents' lower threshold for referral?",
        "gt": "Prevalence of problems, adoptive family characteristics, and adoption status must all be taken into account to understand why adoptees are more likely to receive counseling. Clinicians should be sensitive to issues that are especially salient in adoptive families.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Low response rates to surveys are a problem in general practice. There is evidence that offering GPs incentives improves response rates to postal questionnaires. However, there is less evidence about the most effective form of incentive. Our trial aimed to maximize response to a postal questionnaire and to test the most effective form of incentive. The study involved a randomized controlled trial of a postal survey The incentive of a lottery for six bottles of champagne generated a response rate of 79%. Furthermore, one chance of six bottles generated 9% more responses than six chances of one bottle.\nQuestion: Short report: encouraging GPs to complete postal questionnaires--one big prize or many small prizes?",
        "gt": "This study has established that, among incentives for postal questionnaires, one big prize improves the yield more than many small prizes despite the lower odds of winning. It has also confirmed that offering a modest incentive to GPs generates good response rates for postal questionnaires.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The optimal role of bevacizumab (Bev) in the treatment of ovarian cancer has not yet been established. Furthermore, it is unclear whether there is a benefit of Bev after progression on a Bev-containing regimen in ovarian cancer. The objective of this study was to compare response rates, progression-free survival (PFS), and overall survival between patients who were treated with chemotherapy and Bev after progression on Bev (BAB) versus patients who were treated with chemotherapy without Bev (CWOB). We conducted a retrospective chart review of all patients who received treatment with Bev (with or without cytotoxic chemotherapy) for recurrent ovarian cancer at a single institution. Patients who received additional therapy after progression while on Bev were included. Forty-six patients were included (16 CWOB group and 30 BAB). The median number of previous chemotherapy regimens was 2.5 for CWOB compared with 4 for BAB (P = 0.11). Fifty-two percent of patients had an objective response to the first Bev regimen before progressing on Bev. Response rates for the regimen after progression on Bev were 19% (3/16) in the CWOB group and 23% (7/30) in the BAB group (P = 1). Twenty-five percent of the patients who responded to the first Bev regimen and 18% of those who did not respond to the first Bev regimen responded to the second Bev regimen (P = 0.72). The median PFS for patients in the CWOB group was 2.6 months (95% confidence interval [CI], 1.3-5 months), compared with 5.0 months (95% CI, 3.5-7.3 months) for patients in the BAB group (P = 0.01). Overall survival was similar, 9.4 months (95% CI, 5.0-12.0 months) for CWOB versus 8.6 months (95% CI, 5.8-15.5 months) for BAB (P = 0.19). One patient in the BAB group died of a bowel perforation.\nQuestion: Should bevacizumab be continued after progression on bevacizumab in recurrent ovarian cancer?",
        "gt": "In patients previously treated with Bev for recurrent ovarian cancer, the subsequent addition of Bev to cytotoxic chemotherapy increased the PFS compared with patients not receiving a second course of Bev, but did so without an impact on overall survival. The response to the first Bev regimen did not predict whether a patient would respond again to the next Bev regimen. Randomized, larger studies will have to be performed to confirm this observation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Almost every country in the Western world has great difficulties allocating enough financial resources to meet the needs in the care of the increasing elderly population. The main problem is common to all countries and concerns the efforts to meet elderly persons' needs on an individual level while still maintaining society's responsibility for distributing justice. The aim of this study is to elaborate an instrument for measuring the quality of individual care and staff's working time in order to allocate public resources fairly. The present study gives an account of a new classification system named TiC (Time in Care), indicating how it can be used most effectively and also investigating the validity and reliability of the system. All recipients in 13 sheltered homes for elderly care (n = 505) in a Swedish municipality were surveyed regarding the care they needed, in dimensions of General Care, Medical Care, Cognitive Dysfunction and Rehabilitation, and the time required. Construct validity was assessed by means of factor analysis. The inter-rater agreement of two raters concerning 79 recipients was measured using weighted Kappa. The stability of the instrument and its sensitivity to change were investigated through test-retest reliability measurements, conducted once a month during a six-month period. The content validity of the instrument was also assessed. Factor analysis resulted in a reduction of the number of items from 25 to 16 in three dimensions: General Care, Medical Care and Cognitive Dysfunction. The Kappa analysis showed satisfactory to excellent inter-rater agreement. The care need scores were basically stable but showed sensitivity to change in health status.\nQuestion: Can care of elderly be measured?",
        "gt": "The instrument was found to be useful and reliable for assessing individual needs in community health care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The multidrug transporters P-glycoprotein (P-gp) and MRP1 are functionally expressed in several subclasses of lymphocytes. HIV-1 protease inhibitors interact with both; consequently the transporters could reduce the local concentration of HIV-1 protease inhibitors and, thus, influence the selection of viral mutants. To study the effect of the expression of P-gp and MRP1 on the transport and accumulation of HIV-1 protease inhibitors in human lymphocytes and to study the effects of specific P-gp and MRP1 inhibitors. The initial rate and the steady-state intracellular accumulation of radiolabelled ritonavir, indinavir, saquinavir and nelfinavir was measured in three human lymphocyte cell lines: control CEM cells, CEM-MDR cells, which express 30-fold more P-gp than CEM cells, and CEM-MRP cells, which express fivefold more MRP1 protein than CEM cells. The effect of specific inhibitors of P-gp (GF 120918) and MRP1 (MK 571) was also examined. Compared with CEM cells, the initial rates of uptake and the steady-state intracellular concentrations of all protease inhibitors are significantly reduced in CEM-MDR cells. The intracellular concentrations of the protease inhibitors are increased upon co-administration with GF 120918, in some cases to levels approaching those in CEM cells. The intracellular concentrations of the protease inhibitors are also significantly reduced in CEM-MRP cells. Co-administration with MK -571 can partially overcome these effects.\nQuestion: P-Glycoprotein and transporter MRP1 reduce HIV protease inhibitor uptake in CD4 cells: potential for accelerated viral drug resistance?",
        "gt": "The overexpression of multidrug transporters significantly reduces the accumulation of protease inhibitors at this major site of virus replication, which, potentially, could accelerate the acquisition of viral resistance. Targeted inhibition of P-gp may represent an important strategy by which this problem can be overcome.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Recent studies with infliximab indicate the therapeutic potential of tumour necrosis factor alpha blockade in spondyloarthropathy (SpA). Because defective host defence is implicated in the pathogenesis of SpA, the potential side effects of this treatment due to impact on the antimicrobial defence are a major concern. To report systematically the adverse events seen in a large cohort of patients with SpA treated with infliximab, with special attention to bacterial infections. 107 patients with SpA were treated with infliximab for a total of 191.5 patient years. All serious and/or treatment related adverse events were reported. Eight severe infections occurred, including two reactivations of tuberculosis and three retropharyngeal abscesses, and six minor infections with clear bacterial focus. One patient developed a spinocellular carcinoma of the skin. No cases of demyelinating disease or lupus-like syndrome were seen. Two patients had an infusion reaction, which, however, did not relapse during the next infusion. Finally, three patients with ankylosing spondylitis developed palmoplantar pustulosis. All patients recovered completely with adequate treatment, and infliximab treatment had to be stopped in only five patients with severe infections.\nQuestion: Systematic safety follow up in a cohort of 107 patients with spondyloarthropathy treated with infliximab: a new perspective on the role of host defence in the pathogenesis of the disease?",
        "gt": "Although the global safety of infliximab in SpA is good compared with previous reports in rheumatoid arthritis and Crohn's disease, the occurrence of infections such as tuberculosis and retropharyngeal abscesses highlights the importance of careful screening and follow up. Focal nasopharyngeal infections and infection related symptoms, possibly induced by streptococci, occurred frequently, suggesting an impairment of specific host defence mechanisms in SpA.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Recent surveys showed that the major reasons for avoiding vaginal delivery were the fear of childbirth and the concern for postpartum sexual health. Although sexual dysfunction is a disorder that affects a couple rather than an individual, all studies investigating the relationship between the mode of delivery and sexual problems have been conducted only in cohorts of women.AIM: To determine the effect of mode of delivery on quality of sexual relations and sexual functioning of men by using the Golombock-Rust Inventory of Sexual Satisfaction (GRISS). Mean score of sexual function and prevalence of sexual dysfunction in overall and specific areas of the GRISS were compared among the three groups. A total of 107 men accompanying their wives in outpatient clinics of obstetrics and gynecology met inclusion/exclusion criteria. Three groups of men were defined; men whose partners had: (i) \"elective cesarean delivery\" (N = 21; mean age 32.2 +/- 3.8 years); (ii) \"vaginal delivery with mediolateral episiotomy\" (N = 36; mean age 31.4 +/- 4.5 years); and (iii) \"not given birth\" (N = 50; mean age 28.8 +/- 4.0 years). Mean overall sexual function score (normal value<25 points) was 20.5 +/- 8.2 in the elective caesarean group, 19.3 +/- 6.5 in the vaginal delivery group, and 18.8 +/- 9.3 in the nulliparae group (P = 0.731). Prevalence of sexual dysfunction in men was 28.6% in the elective caesarean group, 19.4% in the vaginal delivery group, and 30.0% in the nulliparae group (P = 0.526).\nQuestion: Does mode of delivery affect sexual functioning of the man partner?",
        "gt": "Overall sexual function of men was not affected by their partner's parity and mode of delivery. An elective cesarean section simply because of concerns about sexual function would not provide additional benefit to men, and could deny women a possible vaginal delivery, which is generally assumed to be safer than cesarean section.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Apparent cyclosporin A (CSA) blood levels, as determined by fluorescence polarization immunoassay (FPIA) and enzyme-multiplied immunoassay technique (EMIT), were compared in CSA-treated patients with various degrees of liver dysfunction. FPIA and EMIT were performed in parallel according to test manufacturer instructions in blood from kidney (n = 82), liver (n = 96) and heart transplant (n = 20) patients. The precision of both techniques was greatest in patients with the highest blood levels, and at each blood level greater for the FPIA than for the EMIT. Apparent CSA blood levels, as determined by EMIT, were typically approximately 70% of those determined by FPIA, indicating greater cross-reaction of the antibody in the FPIA with CSA metabolites. However, the ratio of values determined with EMIT and FPIA was very similar in kidney, liver and heart transplant patients. Among liver transplant patients it was also very similar in those without major alterations of hepatic function and in those with impaired excretory (increased bilirubin and gamma GT) or synthetic (i.e., reduced thromboplastin time) function. Extended storage of blood samples for up to 10 days did not affect apparent CSA blood level estimates by EMIT in a clinically relevant manner.\nQuestion: A comparison of EMIT and FPIA methods for the detection of cyclosporin A blood levels: does impaired liver function make a difference?",
        "gt": "We conclude that the greater specificity of the antibody in the EMIT for the CSA parent compound does not translate into a clinically relevant advantage for CSA monitoring.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the role of double-J stent insertion in perinatally detected primary nonrefluxing megaureters as a method to temporize treatment in patients with impaired renal function or to prevent function loss in patients treated expectantly, but deemed at high risk of deterioration. Two neonates and 8 infants with a ureter greater than 10 mm and an obstructive excretion pattern, including 3 cases with renal function less than 40%, were selected to undergo double-J stent insertion for a 6-month period. Patients underwent surgery if the ureter redilated and the excretion pattern was obstructive at reassessment 3 months after stent removal. Stents were placed at a median age of 3 months (range 1 to 6). Open insertion was necessary in 5 cases (50%). Seven patients (70%) developed stent-related complications (five breakthrough urinary infections) requiring early stent removal in 2 (20%). Five patients (50%) underwent surgery at a median age of 14 months (range 13 to 27), including the 3 patients with decreased renal function at presentation. None required ureteral tapering. None experienced any renal function loss with respect to the initial evaluation.\nQuestion: Double-J stent insertion across vesicoureteral junction--is it a valuable initial approach in neonates and infants with severe primary nonrefluxing megaureter?",
        "gt": "Double-J stent insertion across the vesicoureteral junction allows for effective internal drainage of primary nonrefluxing megaureters, but at the cost of a 70% morbidity rate and various technical drawbacks. Therefore, stenting should be considered on a case-by-case basis. The procedure seems valuable to temporize surgery in patients with decreased renal function. However, given the associated morbidity, it seems impractical for patients with preserved function selected in accordance with currently available prognostic indicators.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Long-term follow-up study. To determine whether gastrointestinal transit times (GITTs) and colonic dimensions change during the first or subsequent decades after spinal cord injury (SCI). Aarhus University Hospital, Denmark. GITT and colonic dimensions were evaluated by means of radio-opaque markers. Group A (n=12) was investigated 1 year after SCI and again 13 (range 11-14) years later. Group B (n=10) was studied 19 (range 9-36) years after injury and again 12 (range 11-12) years later. All had been treated with conservative bowel management. In group A, the median GITT 1\u2009year after injury was 4.3 (range 1.1-6.5) days and 13 years later, it was 3.2 (range 1.3-6.5) days, P=0.96. In group B, the median GITT 19\u2009year after injury was 3.4 (range 0.6-5.9) days and 12 years later, it was 3.2 (range 1.9-5.5) days, P=0.77. None of the two groups experienced a significant change in the diameter of the caecum/ascending colon, transverse colon, descending colon or the sigmoid during long-term follow-up. Megacolon was present in four patients at baseline and in five at follow-up.\nQuestion: Do gastrointestinal transit times and colonic dimensions change with time since spinal cord injury?",
        "gt": "GITTs and colonic dimensions did not change, neither during the first decade nor long after SCI.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cardiovascular disease (CVD) rates differ markedly by minority status, with younger Blacks having some of the highest CVD mortality rates in the United States. A major objective of this study was to assess whether socioeconomic position moderates the effects of race or minority status on CVD mortality. The sample included 443 Black and 21,182 White men, and 415 Black and 24,929 White women, 45 years and older, who died of CVD from 1992-1998, and who had lived in the Twin Cities 5-county area. Using individual and neighborhood level measures of socioeconomic position, we hypothesized that socioeconomic position would moderate the effects of race on CVD mortality. Test hypotheses were analyzed using Poisson regression analysis. Socioeconomic position moderated the effects of race on CVD mortality among older men, but not in older women. Older Black men who lived in more impoverished neighborhoods had significantly and disproportionately higher CVD mortality rates than did older White men living in more impoverished neighborhoods; this was not the case among older Black and White men living in less impoverished neighborhoods. Race was independently related to CVD mortality among younger men and women, with younger Black men and women having significantly higher CVD mortality rates than younger White men and women. The Black-White rate for Black women was twice that of White women.\nQuestion: Does socioeconomic position moderate the effects of race on cardiovascular disease mortality?",
        "gt": "Socioeconomic position as measured by neighborhood poverty can moderate the effects of race on CVD mortality in older Black and White men. This may not have been as apparent had socioeconomic position not been treated as a major variable of interest, and measured at multiple levels.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The mechanisms by which folic acid may contribute to reductions in risk of several congenital anomalies are unknown. The data gap includes a lack of information on possible effect modification between maternal folic acid use and other maternal exposures. We hypothesized that effects of congenital anomalies associated with maternal fever, cigarette smoking or alcohol use would be modified by intake of vitamins. We explored case-control data that showed risk reductions among infants and fetuses whose mothers consumed vitamins. Data were from California deliveries of infants and fetuses in the period 1987-1989. Maternal telephone interviews were completed for 207 (87%) conotruncal cases, 489 (85%) orofacial cleft cases, 265 (84%) neural tube defect cases, 165 (82%) limb anomaly cases, and 734 controls (nonmalformed infants). Considering women who reported vitamin use and no periconceptional fever as referents, for each anomaly group we observed elevated effects for the combinations of maternal vitamin use/fever, no use/no fever and no use/fever. Effects were most elevated for the combination of no vitamin use and fever. Adjusted for maternal body mass index, education and race/ethnicity, odds ratios were 2.4 (95% confidence inter-val = 1.0-5.9) for conotruncal defects, 2.9 (1.4-5.8) for cleft lip with or without cleft palate, 1.3 (0.4-3.9) for cleft palate, 3.1 (1.4-6.8) for neural tube defects, and 2.6 (1.0-6.4) for limb-deficiency defects. These interactions were further investigated relative to maternal use of fever-reducing medications. Effects tended to be highest among those women who did not use vitamins, had fevers, and did not use fever-reducing medications. Compared with women who used vitamins and did not smoke periconceptionally, anomaly risks tended to be highest among women who did not use vitamins and smoked. No specific pattern emerged involving alcohol intake.\nQuestion: Maternal periconceptional vitamins: interactions with selected factors and congenital anomalies?",
        "gt": "These data further suggest that the underlying mechanisms of folic acid associated with congenital anomalies may be complex.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: (1) To assess the use and practice of the clock face among surgeons who routinely perform anterior cruciate ligament (ACL) reconstructions, and (2) to assess the accuracy, precision, and reliability of 3 commonly used clock-face schemes in ACL reconstruction. First, 9 surgeons completed a questionnaire assessing the use and definition of the clock-face technique. Next, to assess the accuracy, precision, and reliability of the clock face, each surgeon estimated the \"time\" of 8 artificial femur models with a black dot located on the posterior aspect of the lateral condylar wall. The estimates were performed using 3 different clock-face schemes and were repeated 10 months later. Solutions for each specimen were obtained by use of a computer graphical interface. More than half of the respondents (55%) use the clock face in ACL reconstructions, with the reported mean ideal \"time\" for a femoral tunnel in a right knee of 10:05 (SD, 31 minutes). When we accounted for the different clock definitions, this ideal position was found along the entire lateral condylar wall. In the assessment of the performance of the clock face, the mean error was 32 to 40 minutes (which translates to 3 to 4 mm) among the 3 clock schemes. The maximum error was 4 hours 0 minutes, and the range of responses was 1 hour 0 minutes to 4 hours 0 minutes depending on the specimen and clock scheme. Regardless of the clock scheme used, the intrarater and inter-rater reliabilities were similar-measuring, on average, 0.78 and 0.68, respectively.\nQuestion: Is the clock face an accurate, precise, and reliable measuring tool for anterior cruciate ligament reconstruction?",
        "gt": "The clock face continues to be commonly used in ACL reconstruction. Different clock-face definitions affect the position for the same \"time.\" When the clock-face parameters were strictly defined, there was good reliability with borderline accuracy and poor precision.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In the last years, there has been increasing evidence of cardiac involvement in spinal muscular atrophy (SMA). Autonomic dysfunction has been reported in animal models and in several patients with types I and III SMA, these findings raising the question whether heart rate should be routinely investigated in all SMA patients. The aim of our study was to detect possible signs of autonomic dysfunction and, more generally, of cardiac involvement in types II and III SMA. We retrospectively reviewed 24-hour electrocardiography (ECG) in 157 types II and III SMA patients (age range, 2-74 years). Of them, 82 also had echocardiography. None of the patients had signs of bradycardia, atrial fibrillation, or the other previously reported rhythm disturbances regardless of the age at examination or the type of SMA. Echocardiography was also normal. There were no signs of congenital cardiac defects with the exception of one patient with a history of ventricular septal defects.\nQuestion: Cardiac function in types II and III spinal muscular atrophy: should we change standards of care?",
        "gt": "Our results suggest that cardiac abnormalities are not common in type II and type III SMA. These findings provide no evidence to support a more accurate cardiac surveillance or changes in the existing standards of care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Prediction rules based on clinical information have been developed to support the diagnosis of pneumonia and help limit the use of expensive diagnostic tests. However, these prediction rules need to be validated in the primary care setting. Adults who met our definition of lower respiratory tract infection (LRTI) were recruited for a prospective study on the causes of LRTI, between November 15, 1998 and June 1, 2001 in the Leiden region of The Netherlands. Clinical information was collected and chest radiography was performed. A literature search was also done to find prediction rules for pneumonia. 129 patients--26 with pneumonia and 103 without--were included, and 6 prediction rules were applied. Only the model with the addition of a test for C-reactive protein had a significant area under the curve of 0.69 (95% confidence interval [CI], 0.58-0.80), with a positive predictive value of 47% (95% CI, 23-71) and a negative predictive value of 84% (95% CI, 77-91). The pretest probabilities for the presence and absence of pneumonia were 20% and 80%, respectively.\nQuestion: Can history and exam alone reliably predict pneumonia?",
        "gt": "Models based only on clinical information do not reliably predict the presence of pneumonia. The addition of an elevated C-reactive protein level seems of little value.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Unintentional injury is a leading threat to children's health. Some human factors have been determined as predictor of unintentional injury. Association between Health-Related Quality of Life (HRQOL) as a human factor and unintentional injuries is unclear. The objective of study is to examine the association between HRQOL and unintentional injuries among primary school children. This study was a cross-sectional conducted in Ahwaz, a city in Iran. Overall, 3375 children aged 6-10 years were randomly selected from primary school. HRQOL was measured by 56 items taken from seven domains of Netherlands Organization for Applied Scientific Research Academic Medical Center (TNO AZL) child quality of life (TACQOL) parent form. Parents were interviewed to collect information about incidence, cause and a brief description of injury within the past 12 months prior to the study. The response rate was 3375 of 3792 (89%). There was a significant trend for increasing occurrence of injury with decreasing of HRQOL score (p was less than 0.001). Adjusted OR for injury was significantly higher in very low (2.38, 95% CI: 1.45-3.86), low (2.18, 95% CI: 1.34-3.56), and medium (1.73, 95%CI: 1.06-2.83) HRQOL groups compared to reference group (very high HRQOL). The median of total HRQOL (P less than 0.001) and all its domains (P=0.017) (except autonomous functioning) was lower in injured group compared to uninjured one.\nQuestion: Does health-related quality of life predict injury event?",
        "gt": "This study found an association between HRQOL and unintentional injury among primary school children. This is a preliminary finding and further investigations with a well-defined analytical design are needed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A well-researched leadership style model was applied, which included task, relation and change styles. This is a cross-sectional study using self-administered questionnaires in 47 H/C in 3 districts. 347 STHSs (95%) and 46 ICs (98%) responded. Questions explored background data and perceived leadership behaviour. Style items were factor analysed, and bivariate analyses and hierarchical regressions determined how styles could be explained. Two leadership styles were revealed: \"Trans\" style contained all relation and the majority of task and change items; \"Control\" style focused on health statistics (Health Management Information System), reporting and evaluation. STHS and IC had a median age/median work experience of 34/5 years and 38,5/2 years, respectively. 48% of IC reported having no management training. CHAM H/Cs had the lowest score on \"Control\" style. Distance to referral hospital had no impact on style scores. No contexts or STHS characteristics predicted any leadership styles. For ICs, young age and increasing work experience were significant predictors for both styles, while Nurse ICs were negative predictors for \"Control style\". Management training was not a significant predictor for any style.\nQuestion: \"PHC leadership: are health centres in good hands?",
        "gt": "Frontline PHC leadership may be forced by situation and context to use a comprehensive style which could lack the diversity and flexibility needed for effective leadership. The missing associations between staff characteristics and leadership styles might indicate that this group is not sufficiently considered and included in leadership processes in the PHC organization. Leadership competency for the ICs seems not to be based on formal training, but substituted by young age and work experience. Health centre organization could also influence the options for leadership behaviour. In conclusion this calls for a reassessment of H/C leadership and formal leadership training.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The International Study of Asthma and Allergies in Childhood questionnaire and a separate sleep questionnaire were completed. Of 800 originally distributed questionnaires, 652 were analyzed. Wheezing was present in 89 children (14%). Within this group, 66% reported wheezing in the last 12 months. Wheezing children had a significantly higher presence of snoring, restless sleep, nocturnal awakenings and daytime tiredness. Wheezing was found to be independently associated with restless sleep (odds ratio (OR) = 2.4). There was no association between wheezing and difficulties falling asleep, nocturnal awakenings, apneas, and daytime sleepiness and tiredness. After adjusting for possible confounders, the following significant associations were present: snoring and apneas (OR = 1.6), chronic rhinitis and apneas (OR = 1.6), snoring and restless sleep (OR = 3.2), chronic rhinitis and restless sleep (OR = 2.1), and hayfever and daytime tiredness (OR = 4.3). Wheezing was related to an increased risk of snoring (OR = 2.8) and subjects with chronic rhinitis had also an increased risk of snoring (OR = 1.7), adjusting for possible confounders.\nQuestion: Is wheezing associated with decreased sleep quality in Sri Lankan children?",
        "gt": "The sleep of wheezing children was impaired compared with their non-wheezing peers, resulting in an increased prevalence of daytime tiredness. Upper airway symptoms, such as chronic rhinitis or hayfever, should be carefully considered in these children, as they might be responsible for these sleep problems.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Antineutrophil cytoplasm antibodies (ANCA) are used as diagnostic markers for small-vessel vasculitis of the Wegener Granulomatosis-microscopic polyangiitis (WG-MPA) spectrum, but if testing is applied indiscriminately, its value is diminished. The authors measured the effect of a targeted ANCA testing policy introduced in our institution in an attempt to improve the diagnostic value of testing in patients with suspected vasculitis. The authors measured the rate of ANCA requests at a single regional centre in the year prior to and following the introduction of clinical guidelines to ensure appropriate test usage. The authors also audited clinical outcomes in patients in whom ANCA testing was declined. Following implementation of the antineutrophil cytoplasm antibodies (ANCA) gating policy, the number of monthly ANCA tests carried out fell from 287+/-30 to 143+/-18 (p<0.0001) and was associated with an increased rate of positivity, from 18.5% (95% CI 17.0 to 20.1%) to 30.3% (27.5 to 33.1%; p<0.0001). The authors undertook a careful review of the case records from 263 patients in whom testing was declined according to the gating policy over an 8-month period. After 6 months' follow-up, no diagnoses of small-vessel vasculitis of the WG-MPA spectrum were reached.\nQuestion: Does a gating policy for ANCA overlook patients with ANCA associated vasculitis?",
        "gt": "The rational use of ANCA testing to aid in the diagnosis of vasculitis should include a clinical gating policy to improve diagnostic performance. Adherence to a gating policy for ANCA testing coupled with close liaison between clinician and laboratory does not result in either a missed or delayed diagnosis of small-vessel vasculitis belonging to the WG-MPA spectrum.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To develop an intervention that will enable nursing home personnel to remove physical restraints from nursing-home residents safely and cost effectively. A multicenter prospective pre-post study. Sixteen high-restraint-use nursing homes, four each from California, Michigan, New York, and North Carolina. The 16 facilities have 2075 beds. A 2-year educational demonstration study, including a 2-day workshop, specially prepared written and video materials, and telephone and on-site clinical consultations. Each nursing home designated a nurse to be the clinical coordinator and to lead a multidisciplinary team in conducting a restraint assessment and devising interventions for removal. We compared pre- and post-study aggregate and individual facility rates of restraint use, incidents and accidents, family attitudes, financial impact, serious injuries, and staff attitudes and work patterns.\nQuestion: Can physically restrained nursing-home residents be untied safely?",
        "gt": "Preliminary data suggest that this intervention was well received and appears to be effective in achieving restraint-free care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Mucosal healing has been proposed as an important sign of the efficacy of medical treatment of inflammatory bowel disease; however, direct evidence in ulcerative colitis (UC) is scarce. We evaluated the usefulness of colonoscopy and bowel ultrasound (US) as indexes of response to short-term therapy and as predictors of subsequent outcome in UC. A total of 83 patients with moderate-to-severe UC were recruited; endoscopic and US severity was graded 0-3 at entry according to validated scores. Of the recruited patients, 74, who were clinically responsive to steroids, were followed up with repeated colonoscopy and bowel US at 3, 9, and 15 months from recruitment. Concordance between clinical, endoscopic, and US scores at various visits was determined by kappa statistics. Multiple unconditional logistic regression models were used to assess the predictivity of clinical, endoscopic, and US scores measured at 3 and 9 months on the development of endoscopic UC relapse within 15 months. A variable concordance was found over time between endoscopic and clinical score (weighted kappa between 0.38 and 0.95), with high and consistent concordance between endoscopic and US scores (weighted kappa between 0.76 and 0.90). On logistic regression analysis, moderate-to-severe endoscopic and US scores at 3 months were associated with a high risk of endoscopic activity at 15 months (odds ratio (OR): 5.2; 95% confidence interval (CI): 1.6-17.6 and OR: 9.1; 95% CI: 2.5-33.5, respectively).\nQuestion: Are colonoscopy and bowel ultrasound useful for assessing response to short-term therapy and predicting disease outcome of moderate-to-severe forms of ulcerative colitis?",
        "gt": "Bowel US may be used as a surrogate of colonoscopy in assessing the short-term response of severe forms of UC to therapy. Both US score and endoscopic score after 3 months of steroid therapy predict outcome of disease at 15 months.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: District general hospital scanners have historically been linked to regional neuroscience units for specialist opinions on scans and to make decisions on transfer of patients requiring neurosurgical management. The implementation of digital picture archiving and communication systems (PACS) in all hospitals in the UK has disrupted these dedicated links and technical and information governance issues have delayed reprovision of electronic transfer of images for rapid expert decision making in this group of patients. We studied improvement in image transfer to acute neurosurgery units over a 4-year period. Four-year sequential review of national provision of image transfer facilities into neurosurgery units; observational study of delays associated with image transfer modalities in one representative tertiary referral centre. During the 4 years of study, all hospitals nationally have implemented digital PACS systems for image viewing. Remote image viewing facilities have gradually changed with dedicated image links being replaced by remote PACS access. However, a minority of referrals (12%) still require images to be physically transferred between hospitals using couriers for CD-ROMs. The detailed study within our own unit shows that this adds a mean delay of 5.8 h to decision making.\nQuestion: Patient safety and image transfer between referring hospitals and neuroscience centres: could we do better?",
        "gt": "Image transfer in neuroscience has been neglected following the shift to PACS servers. The recommendations of the 2004 Neuroscience Critical Care Report are unmet and patient safety is being threatened by a continued failure to implement a coordinated solution to this problem.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is evidence that an entity view of ability (where ability is viewed as a fixed entity that cannot be changed) is linked with social comparison goals and poor performance. On the other hand, an incremental view of ability (where ability is viewed as an acquirable skill) is linked with a mastery goal orientation and positive achievement outcomes. On these bases, the present study sought evidence that priming students with an entity view of ability to pursue mastery goals would result in improved performance. Participants were 48 students with an entity view of ability, and 48 students with an incremental view of ability. We used a 2 (views of ability: entity, incremental) x 2 (performance feedback: success, failure) x 2 (goal priming: mastery, social comparison) between-subjects factorial design to examine the effects of goal priming on performance for students with either an incremental or entity view of ability following either success or failure feedback. Prior to, and following, performance feedback, participants completed parallel measures of state anxiety. Participants were then primed for either social comparison goals prior to attempting to solve 16 Unicursal (tracing puzzle) tasks. Their performance on a subsequent set of Unicursal tasks was then examined. Finally participants completed a State Goals Scale assessing their degree of endorsement of social comparison/mastery goals whilst working on the Unicursal tasks. The performance of students with an incremental view of ability was comparable irrespective of whether they were initially exposed to success and failure feedback and irrespective of whether they were primed for mastery or social comparison goals. However the performance of students with an entity view of ability improved when they were primed for mastery relative to social comparison goals irrespective of whether they were initially exposed to success or failure.\nQuestion: Does priming for mastery goals improve the performance of students with an entity view of ability?",
        "gt": "These findings confirm the performance-limiting consequences of social comparison goals for participants with an entity view of ability, suggesting benefits in encouraging these students to pursue mastery goals.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cardiovascular events are responsible for half of all deaths among individuals with diabetes. Immigrants to Western countries may experience an acceleration of cardiovascular risk in the first 10 years of arrival because of a sedentary lifestyle, poor diet, or barriers to accessing care, leading to higher levels of obesity and diabetes. To compare the risk of cardiovascular events and mortality between immigrants to Canada and long-term residents with diabetes and to assess whether immigrants experience acceleration in risk after arrival. We conducted a population-based retrospective cohort study using linked health and immigration data from Ontario, Canada, of 87,707 immigrants who immigrated to Canada between 1985 and 2005 matched to 87,707 long-term residents with diabetes (age \u226520 years). Individuals were followed up from April 1, 2005, until February 29, 2012, for the primary composite outcome of a cardiovascular event (acute myocardial infarction, unstable angina, congestive heart failure, transient ischemic attack, stroke) or all-cause mortality. There was a lower adjusted risk of cardiovascular events or mortality among immigrants (adjusted hazard ratio [HR] 0.76, 95% CI 0.74-0.78) after accounting for differences in baseline age, gender, socioeconomic status, neighborhood, and health care utilization-which persisted beyond 10 years from immigration. However, this healthy immigrant advantage was not found among more recent refugees (HR 0.93, 95% CI 0.81-1.08), immigrants with no previous education (HR 1.08, 95% CI 0.84-1.40), and those who were unmarried (HR 0.80, 95% CI 0.62-1.03).\nQuestion: Risk of cardiovascular events and mortality among a population-based cohort of immigrants and long-term residents with diabetes: Are all immigrants healthier and if so, for how long?",
        "gt": "Immigrants with diabetes are at lower risk for cardiovascular events and mortality compared with long-term residents, an effect that persists more than 10 years after arrival. Not all immigrants demonstrate this health advantage.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: When managing a new neurologic deficit after carotid endarterectomy (CEA), the surgeon is often preoccupied with determining the cause of the problem, requesting diagnostics tests, and deciding whether the patient should be surgically reexplored. The goal of this study was to analyze a series of perioperative neurologic events and to determine if careful analysis of their timing and mechanisms can predict which cases are likely to improve with reoperation. A review of 2024 CEAs performed from 1985 to 1997 revealed 38 patients who manifested a neurologic deficit in the perioperative period (1.9%). These cases form the focus of this analysis. The causes of the events included intraoperative clamping ischemia in 5 patients (13.2%); thromboembolic events in 24 (63.2%); intracerebral hemorrhage in 5 (13.2%); and deficits unrelated to the operated artery in 4 (10.5%). Neurologic events manifesting in the first 24 hours after surgery were significantly more likely to be caused by thromboembolic events than by other causes of stroke (88.0% vs. 12.0%, P<.002); deficits manifesting after the first 24 hours were significantly more likely to be related to other causes. Of 25 deficits manifesting in the first 24 hours after surgery, 18 underwent immediate surgical reexploration. Intraluminal thrombus was noted in 15 of the 18 reexplorations (83. 3%); any technical defects were corrected. After the 18 reexplorations, in 12 cases there was either complete resolution of or significant improvement in the neurologic deficit that had been present (66.7%).\nQuestion: Immediate reexploration for the perioperative neurologic event after carotid endarterectomy: is it worthwhile?",
        "gt": "Careful analysis of the timing and presentation of perioperative neurologic events after CEA can predict which cases are likely to improve with reoperation. Neurologic deficits that present during the first 24 hours after CEA are likely to be related to intraluminal thrombus formation and embolization. Unless another etiology for stroke has clearly been established, we think immediate reexploration of the artery without other confirmatory tests is mandatory to remove the embolic source and correct any technical problems. This will likely improve the neurologic outcome in these patients, because an uncorrected situation would lead to continued embolization and compromise.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Women with metastatic breast cancer and an intact primary tumor are currently treated with systemic therapy. Local therapy of the primary tumor is considered irrelevant to the outcome, and is recommended only for palliation of symptoms. We have examined the use of local therapy, and its impact on survival in patients presenting with stage IV breast cancer at initial diagnosis, who were reported to the National Cancer Data Base (NCDB) between 1990 and 1993. A total of 16,023 patients with stage IV disease were identified in the NCDB during this period, of whom 6861 (42.8%) received either no operation or a variety of diagnostic or palliative procedures, and 9162 (57.2%) underwent partial (3513) or total (5649) mastectomy. The presence of free surgical margins was associated with an improvement in 3-year survival in partial or total mastectomy groups (26% vs 35%, respectively). A multivariate proportional hazards model identified the number of metastatic sites, the type of metastatic burden, and the extent of resection of the primary tumor as significant independent prognostic covariates. Women treated with surgical resection with free margins, when compared with those not surgically treated, had superior prognosis, with a hazard ratio of 0.61 (95% confidence interval 0.58,0.65).\nQuestion: Does aggressive local therapy improve survival in metastatic breast cancer?",
        "gt": "These data suggest that the role of local therapy in women with stage IV breast cancer needs to be re-evaluated, and local therapy plus systemic therapy should be compared with systemic therapy alone in a randomized trial.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Bullying litigation is an emerging area of law that has increased in response to serious cases of bullying at school. Weight-based bullying is prevalent at school, but no research has examined the use of litigation to address this problem. We assessed public support for litigation approaches to address weight-based bullying at school, and whether support for litigation varies according to the reason why a student is bullied. A national sample of 994 adults (49% parents) completed an online questionnaire assessing their support for litigation approaches in response to hypothetical incidents of youth bullying. As many as two thirds of participants supported litigation against schools for failing to intervene and protect students from weight-based bullying. Litigation remedies received slightly higher support in response to bullying due to race or sexual orientation compared to body weight. Participants favored litigation approaches that target schools for inadequate intervention or a bully's parents on behalf of their child's actions.\nQuestion: Combating weight-based bullying in schools: is there public support for the use of litigation?",
        "gt": "Our study offers novel findings about public and parental views of litigation as a potential approach to address weight-based (and other forms of) bullying, and introduces considerations about the potential role of litigation as part of broader remedies to address youth bullying.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cerebral palsy (CP) is the most common cause of physical disability in childhood in developed countries and encompasses a wide range of clinical phenotypes. Classification of CP according to movement disorder or topographical distribution is widely used. However, these classifications are not reliable nor do they accurately predict musculoskeletal pathology. More recently, the Gross Motor Function Classification System (GMFCS) has been introduced and its validity, reliability, and clinical utility have been confirmed. In 2005 it was suggested that children should be described and classified according to the GMFCS in all outcome studies involving children with CP, in the Journal of Pediatric Orthopaedics (JPO). This study aimed to describe utilization of the GMFCS in 3 journals: Journal of Bone and Joint Surgery (JBJS Am), JPO, and Developmental Medicine and Child Neurology (DMCN), over a 7-year period (2005 to 2011), and any relationship to the journal's impact factor. A secondary aim was to establish if differences in methodological quality existed between those studies utilizing GMFCS and those that did not. A targeted literature search of the 3 selected journals using the term \"cerebral palsy\" was conducted using the Medline database. Utilization of the GMFCS was assessed using report of these data in the methods or results section of the retrieved papers. The Methodological Index for Non-Randomized Studies (MINORS) was employed to evaluate the quality of papers published in JPO. One hundred and fifty-four studies met the inclusion criteria and in 85 (68%) the GMFCS was used. Of these, 112 were published in JPO, of which 51 (46%) utilized the GMFCS, compared with 72% for JBJS Am, and 88% for DMCN. In the JPO, utilization of the GMFCS improved from 13% to 80%, over the 7-year study period.\nQuestion: Classifying cerebral palsy: are we nearly there?",
        "gt": "Utilization of the GMFCS has increased rapidly over the past 7 years in the JPO but there is room for further improvement.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There is evidence that patients with chronic fatigue syndrome (CFS) have mild hypocortisolism. The clinical significance of this is unclear. We aimed to determine whether hypocortisolism exerted any effect on the response of CFS to cognitive behavioural therapy (CBT). We measured 24-h urinary free cortisol (UFC) in 84 patients with Centers for Disease Control and Prevention (CDC)-defined CFS (of whom 64 were free from psychotropic medication) who then received CBT in a specialist, tertiary out-patient clinic as part of their usual clinical care. We also measured salivary cortisol output from 0800 to 2000 h in a subsample of 56 psychotropic medication-free patients. Overall, 39% of patients responded to CBT after 6 months of treatment. Lower 24-h UFC output was associated with a poorer response to CBT but only in psychotropic medication-free patients. A flattened diurnal profile of salivary cortisol was also associated with a poor response to CBT.\nQuestion: Does hypocortisolism predict a poor response to cognitive behavioural therapy in chronic fatigue syndrome?",
        "gt": "Low cortisol is of clinical relevance in CFS, as it is associated with a poorer response to CBT. Hypocortisolism could be one of several maintaining factors that interact in the persistence of CFS.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The existence of a male excess among preterm births is interesting because it could shed light on the aetiology of preterm birth. Possible mechanisms are greater body weight, increased susceptibility to complications of pregnancy, sex-linked biochemical processes and earlier conception in the fertile cycle. We measured the association between fetal sex and preterm birth in four original datasets, including a cohort of births after IVF, and 20 populations extracted from published birthweight references. The original samples were also analysed by mode of onset. There were more males among preterm and early preterm births than among term births in most populations, including IVF births (odds ratio: 1.09-1.24). No male excess was observed for two cohorts of black births, induced preterm births in the general population, and spontaneous onset births after IVF.\nQuestion: Fetal sex and preterm birth: are males at greater risk?",
        "gt": "The proportion of male births declines with increasing gestation, even when time of conception is known. This male excess appears to be strongest for spontaneous preterm births. Studying the sex ratio of preterm births by medical risk factors may clarify why the male excess is absent in some populations. The possibility that obstetric decision-making affects the sex ratio of indicated births must be considered.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether functional capacity evaluation (FCE) tests predict future work capacity (WC) of patients with whiplash-associated disorders (WADs) grades I and II who did not regain full WC 6 to 12 weeks after injury. Prospective cohort study. Rehabilitation center. Workers (N=267) listed on workers' compensation with grade I or II WADs 6 to 12 weeks after injury. Patients performed 8 work-related FCE tests. WC (0-100%) measured at baseline and 1, 3, 6, and 12 months after testing. Correlation coefficients between FCE tests and WC were calculated. A linear mixed-model analysis was used to assess the association between FCE and future WC. Mean \u00b1 SD WC increased over time from 20.8%\u00b127.6% at baseline to 32.3%\u00b138.4%, 51.3%\u00b142.8%, 65.6%\u00b142.2%, and 83.2%\u00b135.0% at the 1-, 3-, 6-, and 12-month follow-ups, respectively. Correlation coefficients between FCE tests and WC ranged from r=.06 (lifting low at 12-mo follow-up) to r=.39 (walking speed at 3mo). Strength of the correlations decreased over time. FCE tests did not predict WC at follow-up. The predictors of WC were ln (time) (\u03b2=23.74), mother language (\u03b2=5.49), WC at baseline (\u03b2=1.01), and self-reported disability (\u03b2=-.20). Two interaction terms, ln (time) \u00d7 WC (\u03b2=-.19) and ln (time) \u00d7 self-reported disability (\u03b2=-.21), were significant predictors of WC.\nQuestion: Can functional capacity tests predict future work capacity in patients with whiplash-associated disorders?",
        "gt": "FCE tests performed within 6 to 12 weeks after WADs injury grades I and II are associated with WC at baseline but do not predict future WC, whereas time course, mother language, WC at baseline, and self-reported disability do predict future WC. Additionally, the interaction between time course WC at baseline and self-reported disability predicted future WC.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Active surveillance for low risk prostate cancer has become an acceptable management strategy.  However, a percentage of these patients in active surveillance move on to active treatment.  Our aim was to examine urinary incontinence (UI) rates in men who move on to treatment from active surveillance and compare it to quoted rates in the literature.  We examined the question that a potential delay in the treatment of prostate cancer in those on active surveillance may result in an increase in incontinence rates. From July 1992 to June 2009, 443 men at our institution entered into active surveillance for newly diagnosed prostate cancer.  We reviewed their medical records and data was abstracted from physician-reported medical records.  The mean age of the entire group was 64.1 years old (range 40-80).  Their mean prostate-specific antigen (PSA) was 7.65 (range 0.21-36) and their mean Gleason score was 6.2 (range 4-8).  Of these patients on active surveillance, 150/443 (33.3%) went on to active treatment.  Median time to active treatment was 31.5 months (range 3-180 months).  Only 5 patients went onto active treatment less than 1 year after starting active surveillance.  Of these patients who went onto active treatment, 85 had radiation alone, 48 had a radical prostatectomy (RP), 7 had a RP and radiation, 7 had HIFU alone, 2 had focal ablation and 1 had HIFU followed by salvage RP.  Of those undergoing radiation (92 patients), 66 had external beam and 26 had brachytherapy. Prior to active treatment 25/443 (5.6%) patients had UI documented in their history.  Of those 25 patients only 3 went on to a RP and all had persistent UI after surgery. Two of the 25 patients went on to radiation therapy and their UI resolved.  In the active treatment groups, after RP alone, 14/48 (29.2%) patients had new onset UI that persisted at a mean of 47.2 months (range 11-149 months) postoperatively.  Of these 14 patients, 7 patients (14.6%) had significant leakage (>1 pad/day).  After radiation therapy alone 2/85(2.4%) had new onset persistent UI at 34 and 49 months post radiation.  Only 1/7 (14.3%) patients that had high intensity focused ultrasound (HIFU) alone had persistent UI at 38 months after HIFU.  Of the 7 patients that had both a RP and radiation, 2 had persistent significant UI at 49 and 153 months after surgery.  One patient that had HIFU and a RP had persistent UI at 23 months post surgery.  The 2 patients that had focal ablation were dry.\nQuestion: Active surveillance failure for prostate cancer:  does the delay in treatment increase the risk of urinary incontinence?",
        "gt": "The UI rates in our cohort of active surveillance patients who move on to active treatment are similar to patients who undergo treatment immediately after prostate cancer is diagnosed as quoted in the literature.  This suggests that active surveillance, as an initial mode of therapy, does not increase the risk of UI if active treatment occurs at a later date.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Restenosis after percutaneous angioplasty of peripheral arteries is still an unsolved matter. Previous studies reported an association between flow-mediated dilatation (FMD), a marker of endothelial dysfunction, and restenosis after coronary angioplasty. This study evaluates the influence of FMD and brachial intima-media thickness (B-IMT) on restenosis after angioplasty of peripheral arteries. One hundred and eighty-four patients (124 male) with claudication related to peripheral arterial disease participated in this trial. FMD and B-IMT were assessed before endovascular revascularisation. In a 12-month follow-up duplex ultrasound examinations were performed to detect restenosis. Finally 128 patients (91male, 37 female) were eligible for statistical analysis. Restenosis was found in 54 patients (42.2%). Mean FMD was 3.53\u2009\u00b1\u20093.56%, with no difference between the patients with restenosis (3.55\u2009\u00b1\u20093.64%) and those without (3.52\u2009\u00b1\u20093.48%; p\u2009=\u20090.716). B-IMT had a mean value of 0.326\u2009\u00b1\u20090.134\u00a0mm. B-IMT significantly differed between the patients with restenosis (0.326\u2009\u00b1\u20090.134\u00a0mm) and those without (0.256\u2009\u00b1\u20090.133\u00a0mm; p\u2009=\u20090.007). We confirmed that a B-IMT over 0.21\u00a0mm was an independent risk factor for restenosis [OR 2.9 (1.3-6.3)].\nQuestion: Are flow-mediated vasodilatation and intima-media thickness of the brachial artery associated with restenosis after endovascular treatment of peripheral arterial occlusive disease?",
        "gt": "Endothelial dysfunction is not associated with restenosis. Conversely patients with enlarged B-IMT are at risk of restenosis after angioplasty of peripheral arteries.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study investigated the reliability of carotid duplex ultrasound (DUS) to identify appropriate candidates for carotid endarterectomy (CEA) according to a panel of vascular specialists. Prospective study. 102 patients with 145 carotid bifurcation stenosis or occlusions. All patients who required a carotid angiogram were evaluated using DUS followed by carotid angiography. A blinded panel of four vascular specialists individually decided whether CEA would be appropriate for each patient based on pre-angiographic information. Angiograms were then shown to panelists to see if their management decision was altered by the angiogram. For stenosis>or = 80% on DUS (n = 60), panelists unanimously agreed on CEA without angiography in 57 lesions. In 50 lesions (87.7%), angiography showed>or = 70% stenosis and the management plan remained unchanged. For the other seven lesions, intracranial aneurysms (n = 2), tandem intracranial lesion (n = 1), unsuspected proximal common carotid lesion (n = 1), a 40% stenotic lesion (n = 1), and high carotid bifurcations (n = 2) were seen. In lesions with 50-79% stenosis on DUS (n = 66), none of the panelists recommended CEA without prior angiography. Eighteen (27%) of these lesions were>or = 70% stenosed on angiogram. Complications of angiograms included one stroke, one haematoma, and one severe allergic reaction.\nQuestion: Can duplex ultrasonography select appropriate patients for carotid endarterectomy?",
        "gt": "Carotid duplex ultrasonography without angiography can reliably select lesions appropriate for surgery only when critical stenosis>or = 80% is chosen. Routine angiography is recommended for carotid stenosis of 50-79% when CEA is considered.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Management of difficult to wean patients is a dilemma for health care system. Recently published studies demonstrated efficacy of donepezil to counteract respiratory depression in sleep apnea. However, to the best of our knowledge, pharmaceutical interventions with donepezil to facilitate weaning have not been tested so far. Therefore in the present study, we evaluated the efficacy of using donepezil on weaning course in difficult to wean patients. In this non-randomized interventional clinical study, difficult to wean patients with prior inappropriately depressed respiratory responses were included from two referral intensive care units (ICU) in Iran. Patients with another potentially reasons of weaning failure were excluded from the study. Donepezil was started for eligible patients at dose of 10 mg daily for 2-4 weeks. For the primary outcomes, arterial blood gas (ABG) parameters were also measured before and after intervention to evaluate the possible effects of donepezil on them. In addition, weaning outcomes of patients were reported as final outcome in response to this intervention. Twelve out of 16 studied patients experienced successful results to facilitate weaning with donepezil intervention. The mean duration of donepezil treatment until outcome measurement was 12 days. There were not any significant differences in ABG parameters among patients with successful and failed weaning trial on day of donepezil initiation. However after donepezil intervention, mean of PCO2 and HCO3 decreased in patients with successful weaning trial and mean of PCO2 increased in those with weaning failure.\nQuestion: Can donepezil facilitate weaning from mechanical ventilation in difficult to wean patients?",
        "gt": "Reduced central respiratory drive was infrequently reason of failed weaning attempts but it must be considered especially in patients with hypercapnia secondary to inefficient gas exchange and slow breathing. Our results in the clinical setting suggest that, the use of donepezil can expedite weaning presumably by stimulation of respiratory center and obviate the need to re-intubation in cases of respiratory drive problem in difficult to wean patients. We suggest decrease PCO2 and HCO3 during donepezil steady could be valuable predictors for positive response to donepezil intervention.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It has been demonstrated that there are a lot of different prognostic factors which are worthy of consideration whereas diabetes mellitus (DM) has not been clearly or consistently identified as a prognostic value in advanced non-small cell lung cancer (NSCLC). The aim of this study was to investigate the prognostic significance of the characteristics of patients in advanced NSCLC. Specifically, we investigated the impact of DM for progression-free survival (PFS) and overall survival (OS) in patients receiving first-line platinum-based doublets chemotherapy. We retrospectively reviewed 442 patients with advanced NSCLC. DM and other potential prognostic variables were chosen for analysis in this study. Univariate and multivariate analyses were conducted to identify prognostic factors associated with survival. The results of univariate analysis for OS were identified as having prognostic significance: performance status (p<0.001), stage (p<0.001), DM (p<0.001), liver metastasis (p=0.02) and brain metastasis (p<0.001). Stage, diabetes mellitus, and liver metastasis were identified as having prognostic significance for PFS. Multivariate analysis showed that poor performance status, presence of DM and advanced stage were considered independent negative prognostic factors for OS (p 0.001, p<0.001 and p<0.001 respectively). Furthermore, DM and stage were considered independent negative prognostic factors for PFS (p 0.005 and p 0.001 respectively).\nQuestion: Is diabetes mellitus a negative prognostic factor for the treatment of advanced non-small-cell lung cancer?",
        "gt": "In conclusion, DM at the time of diagnosis was associated with the negative prognostic importance for PFS and OS in the advanced stage patients who were receiving first-line platinum-based doublets chemotherapy. In addition poor performance status and advanced stage were identified as negative prognostic factors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To quantify mothers' social desirability bias with respect to their children's weight in a cross-regional Indian setting. The OBEY-AD was a cross-sectional study which has been realized in 7 Indian cities (Bengaluru, Mumbai, Chennai, Hyderabad, Kolkata, New Delhi and Surat), enroling 1,680 children aged 3-11 y of which 50% were females. Children's BMI scores were computed, standardized according to WHO growth charts and categorized as Normal, Overweight, Obese and Underweight. Mothers were asked to judge the weight status of their children through an iconographic test, indicating the shape, which better mirrors the size of their kids. Socio-demographic data, especially employment, income and education, was accessed by administrating a cross-sectional questionnaire to the mothers, involved for the study. Overall, 369 children resulted as obese or overweight (23.5%). Out of them, 75% (278) were not recognized as such by their mothers. Such figures range from up to 76% in Chennai and Surat down to 72% in Hyderabad, Kolkata, New Delhi and Mumbai. Overall agreement between perceived and desired weight status of children was very poor (p\u2009<\u20090.001). Surprisingly, overall 10% of overweight/obese children were considered as even too lean by their mothers. Misperception of children's weight status seemed to be significantly related to urban differences and socio-economic status.\nQuestion: Is my kid out of size?",
        "gt": "This study quantifies the extent of the so-called social desirability bias, namely mother's unconscious attitude to adapt empirical evidence to more culturally legitimized ideal-types of what their children's weight status is expected to be. Its association with westernized representations of leanness as evaluation criteria for beauty has important policy implications.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The protocol for the treatment of infantile hemangioma with propranolol varies among different clinical centers. Six hundred seventy-nine patients who were 1 to 12 months old were recruited in this prospective study to receive propranolol treatment. The response to the propranolol therapy was classified as 4 levels. The results were primarily evaluated using color Doppler ultrasound examinations before and after propranolol treatment. The response was excellent in 176 (25.9%), good in 492 (72.5%), stable in 5 (0.7%), and poor in 6 (0.9%) of the patients. The mean age at the initiation of the therapy was 3.3 months (range, 1 to 10.9 months) and the mean duration of the therapy was 7.1 months (range, 3-17 months). The mean duration of the follow-up time after the discontinuation of the therapy was 5.3 months (range, 3-17 months). Regrowth of the hemangioma was observed in 92 cases (13.5%). Seventy-nine (11.6%) of the parents complained of their child's minor discomfort during the therapy.\nQuestion: Is Propranolol Safe and Effective for Outpatient Use for Infantile Hemangioma?",
        "gt": "Propranolol (2 mg/kg per day) may significantly reduce the size of a hemangioma. As an outpatient therapy, propranolol was found to be safe for Chinese children and to have minor side effects.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the incidence of postoperative nausea and vomiting (PONV) after oral and maxillofacial surgical procedures and to evaluate the rationale behind prophylactic antiemetic medications. A total of 167 patients, irrespective of age and gender, undergoing oral and maxillofacial surgical procedures under general anesthesia/dissociative anesthesia, were included. Risk factors associated with PONV such as gender, type of anesthetic agent used, nature of surgical procedure, surgical approach used, and duration of surgery and postoperative use of opioids were assessed. A \"watch and wait\" policy was adopted in all cases of recorded PONV with gastric lavage (GL) to be performed in patients with more than 2 episodes of PONV in the 6-hour postoperative period. The efficacy of such an intervention was also assessed. Antiemetic medications were given in only those cases which did not respond favorably to GL. A chi(2) test was performed using SPSS software (Chicago, IL) to determine statistical significance. Of the 167 patients included, 19 patients experienced episodes of PONV. GL was performed in 3 patients, and all showed cessation of emesis after this intervention. No antiemetic medications were administered. A significant association was observed between PONV and female gender, duration of surgery, type of anesthetic agent used, and specific surgical procedures such as oncologic and temporomandibular joint surgeries. The role of surgical approach and the use of opioids in the postoperative period on the incidence of PONV were found to be insignificant.\nQuestion: Prophylactic antiemetics in oral and maxillofacial surgery: a requiem?",
        "gt": "Information regarding the incidence of PONV after oral and maxillofacial surgical procedures remains scanty. We conclude that there does not appear to be a rationale for the prophylactic administration of antiemetic drugs in such surgical procedures. A watch-and-wait policy and simple GL may provide significant relief. Antiemetic medications are to be considered only in case of non-responders and intractable PONV.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this study was to assess the impact of different positions on pelvic diameters by comparing pregnant and nonpregnant women who assumed a dorsal supine and kneeling squat position. In this cohort study from a tertiary referral center in Germany, we enrolled 50 pregnant women and 50 nonpregnant women. Pelvic measurements were obtained with obstetric magnetic resonance imaging pelvimetry with the use of a 1.5-T scanner. We compared measurements of the depth (anteroposterior (AP) and width (transverse diameters) of the pelvis between the 2 positions. The most striking finding was a significant 0.9-1.9 cm increase (7-15%) in the average transverse diameters in the kneeling squat position in both pregnant and nonpregnant groups. The average bispinous diameter in the pregnant group increased from 12.6 cm \u00b1 0.65 cm in the supine dorsal to 14.5 cm \u00b1 0.64 cm (P<.0001) in the kneeling squat; in the nonpregnant group the increase was from 12 cm \u00b1 0.76 cm to 13.9 cm \u00b1 1.04 cm (P<.0001). The average bituberous diameter in the pregnant group increased from 13.6 cm \u00b1 0.93 cm in the supine dorsal to 14.5 cm \u00b1 0.83 cm (P<.0001) in the kneeling squat position; in the nonpregnant women the increase was from 12.6 cm \u00b1 0.92 cm to 13.5 cm \u00b1 0.88 cm (P<.0001).\nQuestion: Does pregnancy and/or shifting positions create more room in a woman's pelvis?",
        "gt": "A kneeling squat position significantly increases the bony transverse and anteroposterior dimension in the mid pelvic plane and the pelvic outlet. Because this indicates that pelvic diameters change when women change positions, the potential for facilitation of delivery of the fetal head suggests further research that will compare maternal delivery positions is warranted.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess trends in smoking status according to gender, age and educational level in the adult Swiss population. Four national health interview surveys conducted between 1992 and 2007 in representative samples of the Swiss population. The prevalence of current smokers increased between 1992 and 1997, decreasing thereafter. In 2007, the prevalence of current smokers (32.0% of men and 23.8% of women) was lower than in 1992 (38.4% and 26.7%, respectively). Whereas the prevalence of current + former smoking decreased from 64.5% in 1992 to 59.3% in 2007 among men, it was similar among women during the same period (44.0% in 1992 and 43.9% in 2007). The prevalence of current + former smokers decreased from 47.2% in 1992 to 46.3% in 2007 in the lower education group (no education + primary), from 54.8% to 52.9% in subjects with secondary level education, and from 55.4% to 48.7% in subjects with university level education. The prevalence of current smokers decreased in all age groups. Finally, the amount of cigarette equivalents smoked per day decreased, but the amount of non-cigarette tobacco (alone or in combination with cigarettes) increased for both sexes.\nQuestion: Smoking trends in Switzerland, 1992-2007: a time for optimism?",
        "gt": "The prevalence of smoking has been decreasing in the Swiss population, for both sexes and for most age groups and educational levels between 1992 and 2007. The health effects of the change in type of tobacco products consumed await further investigation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Verify whether a journal's impact factor is a mechanism that modifies the ethical requirements described in the instructions provided to authors of articles published in Brazilian medical journals. 48 selected journals were divided into two groups: impact-factor (n=24), and no-impact-factor (n=24). The number of ethical requirements was compared between both groups based on a specific research protocol, ranging from zero to six points, analyzing the presence of an approval by a research ethics committee; reference to the fact that the research follows the precepts of the Declaration of Helsinki and the rules of Resolution 196/96; use of an informed consent; information about the authors' conflicts of interest; and a request for registration of clinical trials in the Brazilian Clinical Trials Registry. The average score of the impact-factor group was significantly higher than that of the no-impact-factor group (3.12 \u00b1 1.03 vs. 2.08 \u00b1 1.64, p=0.0121). When each ethical requirement was compared between the groups, there was significant difference only between the requirement of an informed consent and the disclosure of conflicts of interest (p<0.05).\nQuestion: Does impact factor influence the ethics of the instructions provided to journal authors?",
        "gt": "The impact factor is a determinant factor on the ethics included in the instructions to authors of articles in scientific journals, showing that higher-quality journals seek better-designed articles that are conscientious at the beginning of the research.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To prospectively determine the diagnostic accuracy of a biparametric 3T magnetic resonance imaging protocol (BP-MRI) for prostatic cancer detection, compared to a multiparametric MRI protocol (MP-MRI), in a biopsy na\u00efve patient population. Eighty-two untreated patients (mean age 65\u00b17.6years) with clinical suspicion of prostate cancer and/or altered prostate-specific antigen (PSA) levels underwent a MP-MRI, including T2-weighted imaging, diffusion-weighted imaging (with the correspondent apparent diffusion coefficient maps) and dynamic contrast enhanced sequence, followed by prostate biopsy. Two radiologists reviewed both the BP-MRI and the MP-MRI protocols to establish a radiological diagnosis. Receiver operating characteristics curves were obtained to determine the diagnostic performance of the two protocols. The mean PSA level was 8.8\u00b18.1ng/ml. A total of 34 prostatic tumors were identified, with a Gleason score that ranged from 3+3 to 5+4. Of these 34 tumors, 29 were located within the peripheral zone and 5 in the transitional zone. BP-MRI and MP-MRI showed a similar performance in terms of overall diagnostic accuracy, with an area under the curve of 0.91 and 0.93, respectively (p=n.s.).\nQuestion: Biparametric 3T Magnetic Resonance Imaging for prostatic cancer detection in a biopsy-na\u00efve patient population: a further improvement of PI-RADS v2?",
        "gt": "BP-MRI prostate protocol is feasible for prostatic cancer detection compared to a standard MP-MRI protocol, requiring a shorter acquisition and interpretation time, with comparable diagnostic accuracy to the conventional protocol, without the administration of gadolinium-based contrast agent.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Television viewing is associated with an increased risk of mortality, which could be caused by a sedentary lifestyle, the content of television programming (e.g., cigarette product placement or stress-inducing content), or both. We examined the relationship between self-reported hours of television viewing and mortality risk over 30\u00a0years in a representative sample of the American adult population using the 2008 General Social Survey-National Death Index dataset. We also explored the intervening variable effect of various emotional states (e.g., happiness) and beliefs (e.g., trust in government) of the relationship between television viewing and mortality. We find that, for each additional hour of viewing, mortality risks increased 4%. Given the mean duration of television viewing in our sample, this amounted to about 1.2\u00a0years of life expectancy in the United States. This association was tempered by a number of potential psychosocial mediators, including self-reported measures of happiness, social capital, or confidence in institutions. Although none of these were clinically significant, the combined mediation power was statistically significant (P\u00a0<\u00a0.001).\nQuestion: Do the psychosocial risks associated with television viewing increase mortality?",
        "gt": "Television viewing among healthy adults is correlated with premature mortality in a nationally representative sample of U.S. adults, and this association may be partially mediated by programming content related to beliefs or affective states. However, this mediation effect is the result of many small changes in psychosocial states rather than large effects from a few factors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: BK polyomavirus infects most of the general population. However, its clinical manifestations are almost exclusively seen in immunocompromised patients, particularly in kidney and hematopoietic stem cell transplantation recipients. A 15-y-old female suffering from common B-cell acute lymphoblastic leukaemia underwent hematopoietic stem cell transplantation. The patient had reactivation of BKPyV infection and developed an haemorrhagic cystitis. Three months after transplant, BKPyV viremia and viruria increased and she developed a severe nephropathy associated to a polyclonal gammopathy with high levels of isolated IgM.\nQuestion: Polyclonal gammopathy after BKV infection in HSCT recipient: a novel trigger for plasma cells replication?",
        "gt": "This case report describes a rare and unexpected polyclonal gammopathy developed during a polyomavirus-associated nephropathy confirmed by immunohistochemical and laboratory analyses.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Reports from general practitioners (GPs) are requested on applicants for nurse training, but there is no published evidence of the merit of this practice. To assess the benefit of GP report in health assessments of student nurse applicants. An audit was made of information obtained by health declaration form (HDF), nurse's assessment, GP report and, when performed, a physician's assessment for each applicant. Agreement between the health questionnaire and GP report was analysed by kappa statistics. Of 254 applicants, 246 (97%) were declared 'fit to work', four (1.6%) were deemed 'fit with restrictions' and four (1.6%) were considered 'unfit to work'. The most common problems declared were psychiatric and skin problems. The agreement between health declaration and the information provided by GPs was classed as almost perfect for diabetes and only fair to moderate for all other measures. The reports provided additional information on problems not declared by applicants, but all of these were passive problems. The four unfit candidates all had psychiatric illness, but in all cases the occupational health assessment was sufficient to make this decision or to request further information. In the 'fit with restrictions' category, three of the four GP reports (75%) helped in correctly assigning the applicants to this category. In one of these eight cases a passive problem had not been declared.\nQuestion: Is there value in routinely obtaining a report from the general practitioner as part of pre-entry health screening of students for nursing studies?",
        "gt": "The additional information in GP reports does not affect the conclusion regarding fitness for training in most cases and does not provide sufficient information to merit it being sought routinely.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Data were collected prospectively in a pelvic floor database. Patients received pelvic floor retraining either individually or in a small group setting and completed baseline and follow-up questionnaires. Two hundred and fifteen patients were treated, 119 individually and 96 in a small group setting. Scores before and after treatment for the two settings were compared for the Gastrointestinal Quality of Life Index, the Fecal Incontinence Severity Index and the Patient Assessment of Constipation Symptoms. Additionally patients receiving group treatment completed a short questionnaire on their experience. The median change in Gastrointestinal Quality of Life Index score was 5 (range -62 to 73) for individual treatment and 4 (range -41 to 47) for group treatment, both showing statistically significant improvement. However, there was no significant difference between the settings. Similar results were obtained with the Fecal Incontinence Severity Index and Patient Assessment of Constipation Symptoms scores for the faecal incontinence and obstructed defaecation subgroups respectively.\nQuestion: Is group pelvic floor retraining as effective as individual treatment?",
        "gt": "The majority of patients experienced symptomatic improvement following pelvic floor retraining and there was no significant difference in the resulting improvement according to treatment setting. As treatment costs are considerably less in a group setting, group pelvic floor retraining is more cost-effective than individual treatment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study aims to gain experience with continuous electronic registration of data regarding postoperative wound infection following heart surgery. Every patient undergoing cardiac surgery from February 1999 to May 1999 was included in a prospective study and followed for 30 days. Data regarding type of operation, development of postoperative wound infection, risk factors for wound infection and a risk stratification were submitted electronically to a central database. All 180 operations were registered in the database, and risk variables were registered for all patients but one (99.4%). A spot test comprising 32% of 131 operations registered at the time of the spot test, showed a predictive value of a correctly applied diagnosis of wound infection at 78%. Only 4/7 (57%) of infections in the spot test were registered in the database. All deep wound infections were registered during the study period.\nQuestion: Postoperative wound infection: indicator of clinical quality?",
        "gt": "Data, including risk stratification, in relation to postoperative wound infection following heart surgery can be registered continuously in a central database. Registration of all wound infections, however, requires several resources and may be incomplete. The present registration's good level of cover concerning deep wound infection and risk variables indicates, that deep wound infection may provide a meaningful indicator of clinical quality, although good risk variables still need to be developed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether methodological differences explain divergent results in case-control studies examining surgery as a risk factor for Creutzfeldt-Jakob disease (CJD). After case-control studies were systematically identified using PubMed, we performed a homogeneity analysis and applied models to effect sizes (odds ratio [OR] with 95% confidence interval [CI]) using 2 parameters: type of control subject used and consistency of data ascertainment. The hospitals and communities were located in Europe, Japan, and Australia. Patients were CJD case subjects and age- and sex-matched control subjects in the hospital or community. Because of the natural history of the disease, CJD subjects are not considered reliable sources of information for these studies. Therefore, individuals who are considered close to the subjects and who have knowledge of their medical history, including spouses and relatives, are necessarily identified as proxy informants for the surgical record of the case subjects. Overall, the effect sizes lacked homogeneity (P<.0001). Three studies that used control subjects from the community revealed a significantly elevated risk of CJD for patients who underwent surgery (OR, 1.82; 95% CI, 1.41-2.35 [P<.0001]), whereas 3 investigations that used control subjects from the hospital revealed a significantly reduced risk (OR, 0.69; 95% CI, 0.52-0.90 [P=.0069]). Two studies that used proxy informants to acquire information about case subjects and control subjects (consistent ascertainment) found that the risk of CJD was significantly lower in those subjects who underwent surgery (OR, 0.65; 95% CI, 0.48-0.87 [P=.0043]). Conversely, 4 studies in which proxy informants acted only on behalf of case subjects (inconsistent data ascertainment) found a significant positive association between surgery and CJD (OR, 1.67; 95% CI, 1.32-2.12 [P<.0001]). Both models fit the data very well, leaving no remaining variance in effect sizes to explain.\nQuestion: Is surgery a risk factor for Creutzfeldt-Jakob disease?",
        "gt": "Variation in the type of control subjects used and in exposure assessment in case-control studies may partially explain conflicting data regarding the association between surgery and CJD. However, there was almost complete confounding of these 2 parameters, making interpretation more difficult. Planning of future investigations must carefully consider these design elements.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To estimate the utilisation rate, and amount of state subsidy of prescription items per head by age, sex and community Services Card (CSC) for the year ended June 1999. Data from a market research company (IMS Health), Health Benefits Limited, Statistics New Zealand and Work and Income New Zealand were used to calculate average per head per year pharmaceutical utilisation rate and subsidy cost for CSC holders and non-holders. For both sexes, and for all age groups, CSC-holders tended to use more prescription items per head and incur higher subsidy cost than non-holders. The standardised CSC utilisation rate was 2.6 times the non-CSC rate. For children, average per-item subsidy cost for CSC-holders was lower than for non-holders; the reverse was true for adults.\nQuestion: The community services card: does it make a difference to pharmaceutical utilisation?",
        "gt": "CSC holders had higher pharmaceutical utilisation rates than non-holders at a national level (but not necessarily at a local level). If non-uptake of cards and health status were taken into account, however, it is possible that pharmaceutical utilisation rates were suboptimal amongst those most in need of services. Analyses are urgently required to examine prescribing patterns at a regional level.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Classification of pleural effusions into transudates and exudates is based on pleural fluid absolute lactic dehydrogenase value (FLDH), fluid to serum ratio of LDH (LDHR) and fluid to serum ratio of total protein (TPR) used in a parallel combination strategy. Combining multiple tests in a parallel strategy to improve diagnostic accuracy is useful only if the pair-wise correlation of the individual tests is less than 0.75. So far, this concept has not been tested in patients with pleural effusions.MATERIAL/ Biochemical data from our 200-patient series with a known cause of pleural effusion were included in this study. Correlation between the three possible combinations of tests was determined. There were 116 males and 84 females. The mean age was 62+/-1.1 years (mean+/-SEM). Of the 200 effusions, 156 were exudates and 44 were transudates. There was a significant correlation between FLDH and LDHR (r=0.93, p<0.00). However, the correlation between FLDH and TPR (r=0.27) and TPR and LDHR (r=0.22) was not significant.\nQuestion: Do we need all three criteria for the diagnostic separation of pleural fluid into transudates and exudates?",
        "gt": "The operative mechanism for LDHR and FLDH used in the classification of transudate and exudates appears to be similar, and therefore unsuitable for a parallel combination strategy in the diagnostic separation of pleural effusion. FLDH and TPR have a dissimilar operating mechanism, and can therefore be combined in this process. Therefore, the diagnostic separation of pleural effusion can be done cost effectively by utilizing FLDH and TPR alone, as the cost for estimating serum LDH is eliminated in this approach.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the extent to which parental early and late smoking cessation predicts their young adult children's smoking cessation. Parental early smoking cessation status was assessed when children were in 3rd grade, parental late smoking cessation was assessed when children were in 11th grade, and young adult children's smoking cessation was assessed 2 years after high school. Forty Washington State school districts participated in the Hutchinson Smoking Prevention Project. Participants were the 1553 families in which parents were ever regular smokers who had a young adult child smoking at least weekly at 12th grade who also reported their smoking status 2 years later. Questionnaire data were gathered on parents and their young adult children (49% female and 91% Caucasian) in a cohort with a 94% retention rate. Parents who quit early had children with 1.8 (OR = 1.80; 95% CI = 1.22, 2.64) times higher odds of quitting smoking for at least 1 month in young adulthood compared to those whose parents did not quit early. In contrast, there was no association (OR = 0.84; 95% CI = 0.47, 1.51) between parents quitting late and their young adult children's smoking cessation.\nQuestion: Does parental smoking cessation encourage their young adult children to quit smoking?",
        "gt": "Parental early smoking cessation is associated with increased odds of their young adult children's smoking cessation. Parents who smoke should be encouraged to quit when their children are young.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Dimethyl sulfoxide (DMSO) is essential for the preservation of liquid nitrogen-frozen stem cells, but is associated with toxicity in the transplant recipient. In this prospective noninterventional study, we describe the use of DMSO in 64 European Blood and Marrow Transplant Group centers undertaking autologous transplantation on patients with myeloma and lymphoma and analyze side effects after return of DMSO-preserved stem cells. While the majority of centers continue to use 10% DMSO, a significant proportion either use lower concentrations, mostly 5 or 7.5%, or wash cells before infusion (some for selected patients only). In contrast, the median dose of DMSO given (20\u2009mL) was much less than the upper limit set by the same institutions (70\u2009mL). In an accompanying statistical analysis of side effects noted after return of DMSO-preserved stem cells, we show that patients in the highest quartile receiving DMSO (mL and mL/kg body weight) had significantly more side effects attributed to DMSO, although this effect was not observed if DMSO was calculated as mL/min. Dividing the myeloma and lymphoma patients each into two equal groups by age we were able to confirm this result in all but young myeloma patients in whom an inversion of the odds ratio was seen, possibly related to the higher dose of melphalan received by young myeloma patients.\nQuestion: Should the standard dimethyl sulfoxide concentration be reduced?",
        "gt": "We suggest better standardization of preservation method with reduced DMSO concentration and attention to the dose of DMSO received by patients could help reduce the toxicity and morbidity of the transplant procedure.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Rehabilitation of impaired cognitive functions begins to be considered a standard component of medical care after acquired brain injury. Indeed, many evidences support the effectiveness of the two major categories of techniques, i.e. the traditional and computer-assisted ones, which are widely used in cognitive rehabilitative treatment. Aim of this study is to evaluate the effects of pc - cognitive training in brain injury patients. We studied 35 subjects (randomly divided into two groups), affected by traumatic or vascular brain injury, having attended from January 2010 to December 2012 the Laboratory of Robotic and Cognitive Rehabilitation of IRCCS Neurolesi of Messina. Cognitive impairment was investigated through psychometric battery, administered before (T0) and two months (T1) after the cognitive pc-training, which was performed only by the experimental group, in addition to conventional treatment. Statistical analysis was performed using Wilcoxon test with a p\u00a0<\u00a00.01. At time T0, all patients showed language deficits and cognitive alterations in visual attention and memory abilities. After the rehabilitation program we noted a global improvement in both the groups. However, at T1, the experimental group showed a greater cognitive improvement than the control group, with significant differences in nearly all the neuropsychological tests performed.\nQuestion: Is computer-assisted training effective in improving rehabilitative outcomes after brain injury?",
        "gt": "Our data suggest that cognitive pc-training may be a promising methodology to optimize the rehabilitation outcomes following brain injury.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Overnight stays in farming huts are known to pose a risk of malaria infection. However, studies reporting the risk were conducted in the settings of poor net coverage. This study sought to assess whether an overnight stay in a farming hut is associated with an increased risk of malaria infection if insecticide-treated bed nets (ITNs) are properly used. A pair of cross-sectional surveys was carried out in the Lamarm district of Sekong province, Laos, in March (dry season) and August (rainy season) in 2008. Questionnaire-based interviews and blood examinations were conducted with farmers and their household members from three randomly selected villages in March (127 households, 891 people) and August (128 households, 919 people). Logistic regression analysis, adjusted for potential confounding factors, was used to assess the association between malaria infection status and frequency of overnight stays for the two weeks prior to the study in both the seasons. In March, 13.7% of participants reported staying overnight in a farming hut at least once in the previous two weeks. The percentage increased to 74.6% in August. Not only adults but also young children stayed overnight as often as adults. The use of an ITN the preceding night was common both in farming huts (66.3% in March, 95.2% in August), and in main residences (85.8% in March, 92.5% in August). Logistic regression analysis showed no statistical association between malaria infection status and frequency of overnight stays in farming huts in either study period. However, people sharing one family type net with five people or more were significantly more likely to have malaria than those sharing a net with up to two people in the dry season.\nQuestion: Is staying overnight in a farming hut a risk factor for malaria infection in a setting with insecticide-treated bed nets in rural Laos?",
        "gt": "This study showed that staying overnight in farming huts was not associated with an increased risk of malaria infection in the setting where ITNs were widely used in farming huts. It suggests that malaria infection during overnight stays in farming huts might be preventable if ITNs are properly used in rural Laos.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Portal hypertension develops in 15-20% of patients with benign bile duct stricture. Hepaticojejunostomy in such patients is associated with considerable morbidity and mortality. Preliminary portosystemic shunting has been suggested to reduce intra-operative bleeding. We present our experience without preliminary shunting in such patients. Fourteen consecutive cases of biliary stricture with portal hypertension over a 13-year period (1989-2001) were retrospectively analysed. Thirteen patients were operated upon. One patient had a preliminary portosystemic shunt. In another patient, shunt was attempted. One stage hepaticojejunostomy was possible in 11 patients. There were no intra-operative deaths. Nine of the 13 survived and were available for follow-up. One patient had cholangitis. Another had jaundice related both to chronic liver disease and a strictured hepaticojejunostomy. The remaining 7 patients are asymptomatic and anicteric although alkaline phosphatase levels remain elevated in 5 of them.\nQuestion: Post-cholecystectomy benign biliary stricture with portal hypertension: is a portosystemic shunt before hepaticojejunostomy necessary?",
        "gt": "Hepaticojejunostomy without preliminary portosystemic shunting is possible in patients with portal hypertension and benign biliary stricture with acceptable morbidity and mortality rates.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This was a study involving 22 adults on maintenance hemodialysis for more than 6 months. Doppler US examinations of arteriovenous fistula were performed in all subjects. Pre-dialysis and post-dialysis blood samples were obtained at the patient's midweek HD treatment 4 times a month for each direction. Arterial needle was placed in retrograde direction for the first month. On the second month, the direction of arterial needle was converted to antegrade. Means were compared by paired t-test. Mean URR and eKt/Vof retrograde cannulation were 74.2+/-7.2% and 1.57+/-0.33. The results were indifferent statistically from those of antegrade cannulation (73.0+/-8.7% and 1.57+/-0.35 (p=0.123)). Mean fistula blood flow was 931 +/- 483 ml/min. No cannulation complication was observed during the study period for both directions.\nQuestion: Does the direction of arterial needle in AV fistula cannulation affect dialysis adequacy?",
        "gt": "Both antegrade and retrograde arterial needle placement may be preferred according to center experience without concern of HD adequacy. Longterm outcomes of antegrade and retrograde arterial needle placement such as AVF failure, thrombosis, and stenosis warrant further studies.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To see whether a prepregnancy clinic for diabetic women can achieve tight glycaemic control in early pregnancy and so reduce the high incidence of major congenital malformation that occurs in the infants of these women. An analysis of diabetic control in early pregnancy including a record of severe hypoglycaemic episodes in relation to the occurrence of major congenital malformation among the infants. A diabetic clinic and a combined diabetic and antenatal clinic of a teaching hospital. 143 Insulin dependent women attending a prepregnancy clinic and 96 insulin dependent women managed over the same period who had not received specific prepregnancy care. The incidence of major congenital malformation. Compared with the women who were not given specific prepregnancy care the group who attended the prepregnancy clinic had a lower haemoglobin AI concentration in the first trimester (8.4% v 10.5%), a higher incidence of hypoglycaemia in early pregnancy (38/143 women v 8/96), and fewer infants with congenital abnormalities (2/143 v 10/96; relative risk among women not given specific prepregnancy care 7.4 (95% confidence interval 1.7 to 33.2].\nQuestion: Can prepregnancy care of diabetic women reduce the risk of abnormal babies?",
        "gt": "Tight control of the maternal blood glucose concentration in the early weeks of pregnancy can be achieved by the prepregnancy clinic approach and is associated with a highly significant reduction in the risk of serious congenital abnormalities in the offspring. Hypoglycaemic episodes do not seem to lead to fetal malformation even when they occur during the period of organogenesis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Mass media campaigns are widely used in Australia and elsewhere to promote physical activity among adults. Neighbourhood walkability is consistently shown to be associated with walking and total activity. Campaigns may have different effects on individuals living in high and low walkable neighbourhoods. The purpose of this study is to compare pre- and post-campaign cognitive and behavioural impacts of the Heart Foundation's Find Thirty every day\u00ae campaign, in respondents living in high and lower walkable neighbourhoods. Pre- and post-campaign cross-sectional survey data were linked with objectively measured neighbourhood walkability. Cognitive and behavioural impacts were assessed using logistic regression stratified by walkability. Cognitive impacts were significantly higher post-campaign and consistently higher in respondents in high compared with lower walkable neighbourhoods. Post campaign sufficient activity was significantly higher and transport walking significantly lower, but only in residents of lower walkable areas.\nQuestion: Does neighbourhood walkability moderate the effects of mass media communication strategies to promote regular physical activity?",
        "gt": "Cognitive impacts of mass media physical activity campaigns may be enhanced by living in a more walkable neighbourhood.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The probability of in vivo failure of ceramic hip joint implants is very low (0.004-0.05%). In addition to material flaws and overloading, improper handling during implantation can induce fractures of the ceramic ball head in the long term. Identifying the causes of an in vivo fracture contributes to improved understanding and potentially to further reduction of the fracture probability for patients. Asymmetric metal markings on the cone surface of in vivo ball head fractures have been reported. The question, therefore, is whether asymmetric loading is the sole cause or whether additional factors, specifically contamination entrapped in the taper fit, also contribute or are even the main cause. The influence of the asymmetric physiological load configuration on resulting metal markings in the cone surface of an alumina femoral ball head with and without biological contaminants was investigated. Static and cyclic tests on ball heads were carried out in a load configuration of 0\u00b0 (axisymmetric) and 40\u00b0 in a physiological environment. The analysis of the metal marking was carried out to gain a better understanding of the processes that contribute to the generation of metal marking. Fractography was carried out to determine the fracture initiation of failed ball heads. Different types and sizes of residuals entrapped in the conical surface are shown to yield strongly asymmetric metal marking patterns. All heads tested without contaminants exhibited an almost homogenous distribution of residual metal markings around the circumference of the ceramic cone surface at the proximal end of the bore hole. The failure of ball heads that contained entrapped contaminants revealed a common fracture pattern. The site of fracture initiation on two of the failed heads was in the entrance region of the bore hole on the superior half of the head.\nQuestion: Are asymmetric metal markings on the cone surface of ceramic femoral heads an indication of entrapped debris?",
        "gt": "Asymmetric metal markings observed on the ball heads tested in this investigation are most probably caused by the presence of contaminants entrapped in the taper fit. Homogenous metal mark distributions around the circumference indicate proper assembly of the ball head without entrapped contaminants. It should, however, be noted that different taper designs may possibly result in different marking patterns.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Screening to identify hospital inpatients with a short life expectancy may be a way to improve care towards the end of life. The Gold Standards Framework Prognostic Indicator Guidance is a screening tool that has recently been advocated for use in the hospital setting.AIM: To assess the clinical utility of the Gold Standards Framework Prognostic Indicator Guidance as a screening tool in an acute hospital setting. Mortality at 6 and 12 months and sensitivity, specificity and predictive value of the Gold Standards Framework Prognostic Indicator Guidance at 1 year. Prospective cross-sectional study of 501 adult inpatients in a tertiary New Zealand teaching hospital screened utilising the Gold Standards Framework Prognostic Indicator Guidance. A total of 99 patients were identified as meeting at least one of the Gold Standards Framework Prognostic Indicator Guidance triggers. In this group, 6-month mortality was 56.6% and 12-month mortality was 67.7% compared with 5.2% and 10%, respectively, for those not identified as meeting the criteria. The sensitivity and specificity of the Gold Standards Framework Prognostic Indicator Guidance at 1 year were 62.6% and 91.9%, respectively, with a positive predictive value of 67.7% and a negative predictive value of 90.0%.\nQuestion: Can we predict which hospitalised patients are in their last year of life?",
        "gt": "The sensitivity, specificity and predictive values of the Gold Standards Framework Prognostic Indicator Guidance in this study are comparable to, or better than, results of studies identifying patients with a limited life expectancy in particular disease states (e.g. heart failure and renal failure). Screening utilising the Gold Standards Framework Prognostic Indicator Guidance in the acute setting could be the first step towards implementing a more systematic way of addressing patient need--both current unrecognised and future anticipated--thereby improving outcomes for this population.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To describe the documentation of nutrition-related data and wards referral to dieticians in a Belgian university hospital. Retrospective analysis of 506 nursing records. Body weight and height are documented in 22%. \"Feeding assistance\" and \"usual food intake pattern\" are documented in 68% of all cases, and in 71% it is marked whether the patient is on a diet. Eight percent of the patients are referred to a dietician, but the indications for these referrals are not clear.\nQuestion: Does documentation in nursing records of nutritional screening on admission to hospital reflect the use of evidence-based practice guidelines for malnutrition?",
        "gt": "Given the poor documentation, most likely these patients are not adequately screened for malnutrition as recommended.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To test for the presence of inflammatory biomarkers in blood taken from varicose veins versus antecubital blood of the same patient and compare this to levels in healthy controls. Using a multiplex biochip array method (Randox, United Kingdom), the interleukins (ILs) IL-1\u03b1, IL-1\u03b2, IL-2, IL-4, IL-6, IL-8, and IL-10; vascular endothelial growth factor; interferon \u03b3, tumor necrosis factor \u03b1 ; monocyte chemotactic protein 1 (MCP-1); and epidermal growth factor were measured in citrated plasma samples drawn from the arms and legs of 24 patients with varicose veins and 24 controls. Expressed as median (interquartile range) in pg/mL, leg samples from patients with varicose veins had significantly higher levels of IL-8 and MCP-1 compared to their own arm samples (IL-8: local 2.3 [1.71-3.3] vs systemic 2.3 [1.62-2.98], P = .023; MCP-1: local 114.42 [84.29-139.05] vs systemic 103.56 [79.75-126.42], P<.0005). This was not observed in the control group. Leg samples from both patients with varicose vein and controls had higher levels of IL-6 compared to their own arm samples (patients: local 1.67 [0.82-4.48] vs systemic 1.24 [0.58-3.26], P = .002; controls: local 1.23 [0.83-1.7] vs systemic 1.03 [1.7-1.52], P = .005). No significant differences were detected with the other biomarkers.\nQuestion: Are Inflammatory Biomarkers Increased in Varicose Vein Blood?",
        "gt": "Blood drawn from the site of varicose veins appears to have significantly increased concentrations of IL-6, IL-8, and MCP-1 when compared to the same patient's arm blood. This supports the hypothesis that inflammation is activated from the tissues drained by the varicose veins.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To measure expectations regarding aging among community-residing-older adults, identify characteristics associated with having low expectations regarding aging, and examine whether expectations regarding aging are associated with healthcare-seeking beliefs for age-associated conditions. Self-administered mail survey. Greater Los Angeles. Four hundred twenty-nine of 588 (73%) randomly selected community-residing adults aged 65 to 100 (mean age 76) cared for by 20 primary care physicians; 54% were women, and 76% were white. The Expectations Regarding Aging Survey, a validated survey measuring expectations regarding aging; 13 items measuring care seeking beliefs; and validated measures of health status. More than 50% of participants felt it was an expected part of aging to become depressed, to become more dependent, to have more aches and pains, to have less ability to have sex, and to have less energy. After adjusting for sociodemographic and health characteristics using multivariate regression, older age was independently associated with lower expectations regarding aging (P<.001), as was having lower physical and mental health-related quality of life. Having lower expectations regarding aging was independently associated with placing less importance on seeking health care (P =.049).\nQuestion: Do older adults expect to age successfully?",
        "gt": "Most older adults in this sample did not expect to achieve the model of successful aging in which high cognitive and physical functioning is maintained. Older age was independently associated with lower expectations regarding aging. Furthermore, having low expectations regarding aging was independently associated with not believing it important to seek health care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Upgrades to electronic health record (EHR) systems scheduled to be introduced in the USA in 2014 will advance document interoperability between care providers. Specifically, the second stage of the federal incentive program for EHR adoption, known as Meaningful Use, requires use of the Consolidated Clinical Document Architecture (C-CDA) for document exchange. In an effort to examine and improve C-CDA based exchange, the SMART (Substitutable Medical Applications and Reusable Technology) C-CDA Collaborative brought together a group of certified EHR and other health information technology vendors. We examined the machine-readable content of collected samples for semantic correctness and consistency. This included parsing with the open-source BlueButton.js tool, testing with a validator used in EHR certification, scoring with an automated open-source tool, and manual inspection. We also conducted group and individual review sessions with participating vendors to understand their interpretation of C-CDA specifications and requirements. We contacted 107 health information technology organizations and collected 91 C-CDA sample documents from 21 distinct technologies. Manual and automated document inspection led to 615 observations of errors and data expression variation across represented technologies. Based upon our analysis and vendor discussions, we identified 11 specific areas that represent relevant barriers to the interoperability of C-CDA documents.\nQuestion: Are Meaningful Use Stage 2 certified EHRs ready for interoperability?",
        "gt": "We identified errors and permissible heterogeneity in C-CDA documents that will limit semantic interoperability. Our findings also point to several practical opportunities to improve C-CDA document quality and exchange in the coming years.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the association between previous percutaneous coronary intervention (PCI) and results after coronary artery bypass graft surgery (CABG). Increasing numbers of patients undergoing CABG have previously undergone PCI. We analyzed consecutive first-time isolated CABG procedures within the Australasian Society of Cardiac and Thoracic Surgeons Database from June 2001 to May 2008. Logistic regression and propensity score analyses were used to assess the risk-adjusted impact of prior PCI on in-hospital mortality and major adverse cardiac events. Cox regression model was used to assess the effect of prior PCI on mid-term survival. Of 13,184 patients who underwent CABG, 11,727 had no prior PCI and 1,457 had prior PCI. Mean follow-up was 3.3 +/- 2.1 years. Patients without prior PCI had a higher EuroSCORE value (4.4 +/- 3.3 vs. 3.6 +/- 3.0, p<0.001), were older, and more likely to have left main stem stenosis and recent myocardial infarction. There was no difference in unadjusted in-hospital mortality (1.65% vs. 1.55%, p = 0.78) or major adverse cardiac events (3.0% vs. 3.0%, p = 0.99) between patients with or without prior PCI. After adjustment, prior PCI was not a predictor of in-hospital (odds ratio: 1.22, 95% confidence interval [CI]: 0.76 to 2.0, p = 0.41) or mid-term mortality at 6-year follow-up (hazard ratio: 0.94, 95% CI: 0.75 to 1.18, p = 0.62).\nQuestion: Does prior percutaneous coronary intervention adversely affect early and mid-term survival after coronary artery surgery?",
        "gt": "In this large registry study, prior PCI was not associated with increased short- or mid-term mortality after CABG. Good outcomes can be obtained in the group of patients undergoing CABG who have had previous PCI.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: African-American adolescents have the highest rates of sexually transmitted diseases (STDs) of any racial/ethnic group of adolescents. The objective of this study was to determine the degree to which racial/ethnic differences in sexual behaviors account for African-American adolescents' higher rates of STDs. A secondary analysis of data collected as part of the Youth Risk Behavior Survey supplement to the 1992 National Health Interview Survey was conducted. The sample included 5,189 nationally representative civilian noninstitutionalized sexually experienced United States adolescents 14 to 21 years of age. The age- and sex-adjusted odds ratio (OR) for a reported history of an STD for African-American adolescents was 3.86 (95% confidence interval [CI] = 1.57, 9.50). The STD risk for African-American youth increased with the adjustment for other sociodemographic factors (OR = 4.13; CI = 1.71, 9.99) and decreased with the adjustment for sexual behaviors (OR = 3.67; CI = 1.55,8.66).\nQuestion: Do differences in sexual behaviors account for the racial/ethnic differences in adolescents' self-reported history of a sexually transmitted disease?",
        "gt": "Differences in sexual behaviors do not fully account for African-American adolescents' increased risk for STDs. Interventions designed to reduce sexual risk taking among African-American adolescents may not ameliorate racial/ethnic differences in rates of STDs.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Hip dislocation as a result of neurogenic hip displacement is a common focal motor symptom in children with infantile cerebral palsy (ICP). In addition to contracture of the hip joint, in up to 65\u00a0% of cases patients suffer from pain which leads to further loss of function and often to limitations in important basic functions, such as lying, care, sitting, standing and transfer. In order to avoid hip dislocation and to be able to implement therapy at an early stage, screening programs have been developed in recent years which clearly demonstrate the risks of hip displacement in ICP depending on the ability to walk. An investigation of the natural course is practically impossible because as a rule patients with painful neurogenic hip displacement receive surgical therapy. In this study 96\u00a0patients with high hip dislocation grade IV on the T\u00f6nnis classification were included and 68 could be followed up. The average age at the time of surgery was 10.9\u00a0years and the mean follow-up period was 7.7\u00a0years. In the postoperative course 6 out of 91 reconstructed hips became redislocated and a proximal femoral resection was carried out in one female patient. The migration index according to Reimers was 14.0\u00a0% at the time of the follow-up examination.\nQuestion: Long-term results of reconstructive surgery in infantile cerebral palsy patients with high hip dislocation: is hip screening necessary?",
        "gt": "Revision procedures can be avoided by screening programs. These should be strived for so that the neuro-orthopedic treatment on operation planning is not first initiated when pain occurs and revision procedures, such as angulation osteotomy or proximal femoral resection can be avoided. The reconstruction should also involve minimal deformation of the femoral head. In order to implement this, the interdisciplinary cooperation between neuropediatricians, social pediatriatricians and neuro-orthopedists should be intensified in the future.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate whether tinnitus affects sound localization ability. Prospective controlled study. Tertiary referral center. Forty tinnitus patients (mean age, 36.7 \u00b1 14.3 yr; hearing threshold,<20 dB HL; tinnitus group) and 40 controls (mean age, 39.3 \u00b1 12.9 yr; hearing threshold,<20 dB HL; control group). We performed a sound localization test (SLT) with 7 speakers positioned in a semicircle on the horizontal plane at a distance of 1 m from the subject, at 30-degree intervals. Subjects were asked to identify the stimulus-presenting speaker, through a forced-choice procedure. The error score was calculated by scoring 1 point for each 30 degrees of difference between the stimulus-presenting speaker and the speaker identified by the subject. The mean SLT total error score (TES) of the tinnitus group (18.8 \u00b1 9.2) was significantly higher than that of the control group (13.1 \u00b1 7.5) (p<0.05). Regarding SLT responses for stimulation from speakers located at each side of the listener, mean TES in patients with tinnitus on the same side as the speaker was higher than that in patients with opposite side or bilateral tinnitus. Age showed a positive correlation with TES in the tinnitus (r = 0.44, p<0.05) and control groups (r = 0.35, p<0.05).\nQuestion: Does tinnitus affect the sound localization ability?",
        "gt": "We consider that tinnitus interferes with sound localization ability and that interference is worse for sound originating from the same side as the tinnitus. Age is a worsening factor in sound localization ability.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Current data on cardiac surgery capacity on which to base effective concepts for developing sustainable cardiac surgical programs in Africa are lacking or of low quality. A questionnaire concerning cardiac surgery in Africa was sent to 29 colleagues-26 cardiac surgeons and 3 cardiologists in 16 countries. Further, data on numbers of surgeons practicing in Africa were retrieved from the Cardiothoracic Surgery Network (CTSNet). There were 25 respondents, yielding a response rate of 86.2%. Three models emerged: the Ghanaian/German model with a senior local consultant surgeon (Model 1); surgeons visiting for a short period to perform humanitarian surgery (Model 2); and expatriate surgeons on contract to develop cardiac programs (Model 3). The 933 cardiothoracic surgeons listed by CTSNet translated into one surgeon per 1.3 million people. In North Africa, the figure was three surgeons per 1 million and in sub-Saharan Africa (SSA), one surgeon per 3.3 million people. The identified 156 cardiac surgeons represented a surgeon to population ratio of 1:5.9 million people. In SSA, the ratio was one surgeon per 14.3 million. In North Africa, it was one surgeon per 1.1 million people. Open heart operations were approximately 12 per million in Africa, 2 per million in SSA, and 92 per million people in North Africa.\nQuestion: Cardiac surgery capacity in sub-saharan Africa: quo vadis?",
        "gt": "Cardiothoracic health care delivery would worsen in SSA without the support of humanitarian surgery. Although all three models have potential for success, the Ghanaian/German model has proved to be successful in the long term and could inspire health care policy makers and senior colleagues planning to establish cardiac programs in Africa.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Bronchiectasis is an important component of cystic fibrosis (CF) lung disease but little is known about its development. We aimed to study the development of bronchiectasis and identify determinants for rapid progression of bronchiectasis on chest CT. Forty-three patients with CF with at least four consecutive biennial volumetric CTs were included. Areas with bronchiectasis on the most recent CT were marked as regions of interest (ROIs). These ROIs were generated on all preceding CTs using deformable image registration. Observers indicated whether: bronchiectasis, mucus plugging, airway wall thickening, atelectasis/consolidation or normal airways were present in the ROIs. We identified 362 ROIs on the most recent CT. In 187 (51.7\u00a0%) ROIs bronchiectasis was present on all preceding CTs, while 175 ROIs showed development of bronchiectasis. In 139/175 (79.4\u00a0%) no pre-stages of bronchiectasis were identified. In 36/175 (20.6\u00a0%) bronchiectatic airways the following pre-stages were identified: mucus plugging (17.7\u00a0%), airway wall thickening (1.7\u00a0%) or atelectasis/consolidation (1.1\u00a0%). Pancreatic insufficiency was more prevalent in the rapid progressors compared to the slow progressors (p\u2009=\u20090.05).\nQuestion: The development of bronchiectasis on chest computed tomography in children with cystic fibrosis: can pre-stages be identified?",
        "gt": "Most bronchiectatic airways developed within 2\u00a0years without visible pre-stages, underlining the treacherous nature of CF lung disease. Mucus plugging was the most frequent pre-stage.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Multiple agency sampling and field work which included 'snowballing' using 'privileged access interviewers'. Each subject underwent a structured interview which included the Severity of Dependency Scale (SDS), and completed a confidential, self-report questionnaire. Three contrasting provincial urban locations. Five hundred and eighty-one regular users of the target drugs. Of these, 380 (65%) denied any contact with police or helping agencies in connection with drug use. Most zero-contact users (79%) expressed little or no concern about their drug use, and no wish for help or advice. They were much more likely to use stimulants only; less likely ever to inject any drug or, for those that did, to share equipment; less likely to use opioids, amphetamine or cocaine powder on a daily basis; more likely to use Ecstasy; and yielded significantly lower SDS scores for all target drugs save crack. Prevalence of crack use was lower, but the proportion of daily users was the same as in the contact group. Most (69%) contact users remained concerned about their drug use, but 58% expressed little or no confidence that local services could meet their needs. In both groups, SDS scores for cocaine powder were comparable to those for cannabis, LSD and Ecstasy. Of the 495 cannabis smokers identified (85% of the sample), 72% reported daily consumption.\nQuestion: A comparison of 'visible' and 'invisible' users of amphetamine, cocaine and heroin: two distinct populations?",
        "gt": "The findings are consistent with the hypothesis that 'visible' and 'invisible' drug users are distinct populations in terms of behavioral characteristics, vulnerability to compulsive use, and prevalence of drug-related problems or concern. Purchasers and providers with limited resources should concentrate on improving the range and quality of services for users already in contact rather than attempting to uncover invisible populations. On the basis of SDS scores, cocaine HCI seems to have a relatively modest addictive potential.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We sought to analyze the impact of socioeconomic status (SES) on in-hospital outcomes, cost of hospitalization, and resource use after acute ischemic stroke. We used the 2003-2011 Nationwide Inpatient Sample database for this analysis. All admissions with a principal diagnosis of acute ischemic stroke were identified by using International Classification of Diseases, Ninth Revision codes. SES was assessed by using median household income of the residential ZIP code for each patient. Quartile 1 and quartile 4 reflect the lowest-income and highest-income SES quartile, respectively. During a 9-year period, 775,905 discharges with acute ischemic stroke were analyzed. There was a progressive increase in the incidence of reperfusion on the first admission day across the SES quartiles (P-trend<0.001). In addition, we observed a significant reduction in discharge to nursing facility, across the SES quartiles (P-trend<0.001). Although we did not observe a significant difference in in-hospital mortality across the SES quartiles in the overall cohort (P-trend=0.22), there was a significant trend toward reduced in-hospital mortality across the SES quartiles in younger patients (<75 years) (P-trend<0.001). The mean length of stay in the lowest-income quartile was 5.75 days, which was significantly higher compared with other SES quartiles. Furthermore, the mean adjusted cost of hospitalization among quartiles 2, 3, and 4, compared with quartile 1, was significantly higher by $621, $1238, and $2577, respectively. Compared with the lowest-income quartile, there was a significantly higher use of echocardiography, invasive angiography, and operative procedures, including carotid endarterectomy, in the highest-income quartile.\nQuestion: Outcomes after acute ischemic stroke in the United States: does residential ZIP code matter?",
        "gt": "Patients from lower-income quartiles had decreased reperfusion on the first admission day, compared with patients from higher-income quartiles. The cost of hospitalization of patients from higher-income quartiles was significantly higher than that of patients from lowest-income quartiles, despite longer hospital stays in the latter group. This might be partially attributable to a lower use of key procedures among patients from lowest-income quartile.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Chronic plantar heel pain is a common and potentially debilitating condition, often caused by plantar fasciitis. Plantar calcaneal spurs were originally considered the cause of plantar fasciitis but are now regarded as an incidental finding by most authors. We aimed to test this hypothesis and to investigate predisposing factors for the development of spurs. We reviewed all lateral ankle X rays taken in our institution over a 6-month period and identified all X rays demonstrating calcaneal spurs. Then, we identified a similar number of age- and sex-matched controls without spurs. We contacted both groups by telephone and compared symptoms of heel pain, plantar fasciitis, associated comorbidities, and foot and ankle outcome scores (FAOSs). We reviewed the X rays of 1103 consecutive patients and found a spur prevalence of 12.4%, more common in women and older patients. Questioning of the spur group and control group found a higher body mass index in the spur group. Patients with spurs were 4 times more likely to have diabetes mellitus and 10 times more likely to have lower-limb osteoarthritis. Patients with spurs had more foot pain and poorer FAOS than the control group, even when patients with plantar fasciitis were excluded.\nQuestion: The conundrum of calcaneal spurs: do they matter?",
        "gt": "Our results demonstrate that the presence of a plantar calcaneal spur may be an indicator of foot pain independent of plantar fasciitis. Although spurs may not cause foot pain themselves, they may be an indication of other associated conditions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the association between morphologic condylar changes and temporomandibular disorders (TMDs) in patients with orthognathia. Data from 89 patients were analyzed. TMDs were classified according to the Research Diagnostic Criteria for TMDs. TMD severity was scored according to the Helkimo indices. Calculation of the condylar area, perimeter, and height was performed by using a specific computational method including panoramic radiography. Sixty-five (73%) patients presented with morphologic condylar changes. Decreases in condylar perimeter and area were found to be predictors of postoperative TMDs (P\u00a0=\u00a0.009; odds ratio [OR]\u00a0=\u00a03.66) and disk displacement (P\u00a0=\u00a0.008; OR\u00a0=\u00a04.43), respectively. Condylar area and height decreases were associated with worsening of TMDs (P\u00a0=\u00a0.03 and 0.04).\nQuestion: Are condylar morphologic changes associated with temporomandibular disorders in patients with orthognathia?",
        "gt": "This study demonstrated that in orthognathic patients, postoperative condylar changes are associated with postoperative TMDs as well as with the degree of TMD severity and that preoperative TMDs are associated with such condylar changes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Vascular endothelial growth factor (VEGF) is an important stimulator of choroidal neovascularization (CNV). Bevacizumab (Avastin), ranibizumab (Lucentis) and pegaptanib sodium (Macugen) are anti-VEGF medications that have been used in the treatment of CNV. The purpose of our study is to evaluate the efficacy and safety of intravitreal injections of bevacizumab, ranibizumab and pegaptanib sodium in the treatment of CNV in a rat model. Multiple CNV lesions were induced by laser photocoagulation of the retina in Brown-Norway rats. After 3 weeks, 17 rats were divided into three groups and received intravitreal injections of bevacizumab, ranibizumab or pegaptanib sodium in different dosages. The lesions were evaluated by fluorescein angiography 1, 7, 14, and 28 days later to assess the efficacy of these medications. Different doses of bevacizumab did not show any effect on stopping the leakage on fluorescein angiography on days 1, 7, 14, and 28. Ranibizumab and pegaptanib sodium did not stop the leakage of CNV either. No angiographic or histopathologic toxicity was observed.\nQuestion: Are intravitreal bevacizumab and ranibizumab effective in a rat model of choroidal neovascularization?",
        "gt": "These three anti-VEGF agents did not show any therapeutic effect on stopping CNV leakage in rats. Previous experiments with ranibizumab in monkeys resulted in a significant decrease in leakage of CNV. The difference may be due to the fact that both ranibizumab and bevacizumab are humanized and species-specific. There are several studies evaluating the effect of bevacizumab in non-primates. Since bevacizumab is humanized, the results of studies on non-primates may not be similar to humans and non-human primates.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The hepatitis C virus antibody (anti-HCV) can be identified with third-generation immunoassays. The purpose of this study was to define the correlation or agreement between first and second reactive results of anti-HCV microparticle-based enzyme immunoassay (MEIA) and of chemiluminescence assays (ChLIAs) in blood donors, to determine whether repeat testing is necessary. Commercially available assays, third-generation HCV MEIA (Abbott), third-generation HCV ChLIA (Ortho), and third-generation HCV ChLIA (Abbott), were used to evaluate anti-HCV repeatedly reactive blood obtained from donations made at 23 Mexican blood centers over a period of 1 year. The intraassay correlation between first and second reactive anti-HCV tests with the Pearson r test and the coefficient of variation (CV) were determined. The intraassay correlation of 565 anti-HCV repeatedly reactive samples was 0.996 for the Abbott third-generation HCV MEIA, 0.995 for the Ortho third-generation HCV ChLIA, and 0.993 for the Abbott third-generation HCV ChLIA. The CVs of these assay systems were 2.82, 5.33, and 5.69 percent, respectively.\nQuestion: Hepatitis C antibody intraassay correlation: is retest in duplicate necessary?",
        "gt": "A highly significant intraassay correlation between anti-HCV duplicates was found. Specimens with a single reactive anti-HCV result with the Abbott third-generation HCV MEIA, Ortho third-generation HCV ChLIA, and Abbott third-generation HCV ChLIA assays should be considered as positive and need not be retested. Such a change in the algorithm for blood donor screening is feasible because of the availability of highly automated platforms.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We investigated the prevalence and hazard ratios for insomnia complaints in a large cohort of middle-aged men and women. The Atherosclerosis Risk in Communities Study is a prospective study of cardiovascular disease. Using multivariate regression analysis, we predicted the likelihood of endorsing the insomnia complaints by age, sex, alcohol intake, smoking, diabetes, heart disease, menopausal status, use of hypnotics, hypertension, depressive symptoms, education level, body mass index, respiratory symptoms, and pulmonary function status. We predicted the hazard ratios (HR) of death at 6.3 +/- 1.1 year by endorsement of insomnia complaints and by hypnotic use controlling for covariates. North American communities. 13563 participants aged 45 to 69 years at baseline None. The prevalence of insomnia complaints in this cohort was 23%. Predictors of insomnia complaints were female sex (odds ratio [OR] 0.56, 95% confidence interval [CI]0.45-0.70 for men), annual family income below 50,000 dollars (OR 1.23, CI 1.09-1.40), age 40 to 49 years (OR 1.29, CI 1.11-1.50), depressive symptoms (OR 5.05, CI 4.60-5.55), heart disease (OR 1.89, CI 1.67-2.14), severe airflow obstruction (OR 1.61, CI 1.17-2.22), pulmonary symptoms (OR 1.71, CI 1.5-1.95), and restrictive lung disease (OR 1.27, CI 1.10-1.47). After controlling for covariates, insomnia complaints were not associated with an increased risk for death (OR 1.01, CI 0.85-1.21), nor was the use of hypnotics (OR 1.38, CI 0.90-2.13).\nQuestion: Does insomnia kill?",
        "gt": "In this cohort, the prevalence of insomnia complaints was 23%. After controlling for confounders, neither insomnia complaints nor hypnotic use predicted increased mortality over 6.3 years.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cortical atrophy is correlated with the progression of neuropathological lesions within the medial temporal lobes (MTL) in Alzheimer's disease (AD). Our aim was to determine which local and remote functional changes result from MTL volume loss at the predementia stage. We studied the relationship between entorhinal and hippocampal MR volumes and whole-brain SPECT perfusion via a voxel-based correlative analysis in 19 patients with amnestic mild cognitive impairment with a memory profile suggestive of early AD. Right MTL volumes were positively correlated with remote posterior perfusion of the posterior cingulate cortex, and negatively correlated with remote anterior perfusion of the right medial and dorsolateral prefrontal cortex. There was no local correlation between volumes and perfusion within the MTL.\nQuestion: Effects of medial temporal lobe degeneration on brain perfusion in amnestic MCI of AD type: deafferentation and functional compensation?",
        "gt": "These findings provide further insight into functional changes that result from MTL volume loss during the predementia stage of AD. The positive correlation between MTL volumes and posterior cingulate perfusion may reflect the deafferentation of a temporocingulate network due to mediotemporal degeneration. The paradoxical negative correlation between MTL volumes and prefrontal perfusion may result from recruitment of an alternative anterior temporofrontal network. It remains to be investigated how the \"net sum\" of this perfusion modulation affects memory and other cognitive domains through a possible compensatory perspective.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Developmental co-ordination disorder (DCD) occurs in at least 6% of school-aged children. Researchers agree that motor co-ordination problems evident in DCD are, in part, the result of perceptual and cognitive processes, but the limited research available remains inconclusive. The present study investigated perceptual-motor abilities, with regard to vision, kinaesthesia and cross-modal judgement, in children with and without DCD. A cross-sectional study design was used. Nine children, aged six years (+/- six months) with DCD, and nine children without DCD, matched for age and gender, participated in the study. The children were required to point with the preferred hand to a target in three different positions under four sensory conditions, either with or without vision. Three-dimensional motion analysis was used to investigate trajectory lengths, endpoint error and movement time. The results were analysed using a generalized linear mixed model to examine the systematic effects of group, target position and task. Compared with children without DCD, the children with DCD produced larger endpoint errors, greater movement times and longer trajectories. Children in both groups produced larger endpoint errors, greater movement times and longer trajectories in non-visually guided aiming versus visually guided aiming tasks.\nQuestion: Goal-directed upper limb movements by children with and without DCD: a window into perceptuo-motor dysfunction?",
        "gt": "Children with DCD moved more slowly, with longer movement trajectories and were less accurate than children without DCD when aiming to all target positions under all sensory conditions. The greatest error and trajectory length occurred for both groups when aiming movements were performed in the absence of vision. As children in the DCD group had difficulties with movement executed under kinaesthetic or visual control, the results indicate that the normal advantage of vision displayed by children without DCD is not apparent, and visual and kinaesthetic problems may be present in children with DCD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Economic stresses are a frequently cited reason for children doing farm work. To explore the relationship between economic indicators and child agricultural work hours between January 2001 and October 2003. This ecologic study design compares trends in aggregate child work hours with national and regional economic indicators. Child work hours were obtained from quarterly surveillance data from a randomized field trial of agricultural task guidelines for children. 2,360 children living or working on 845 farms in central New York participated in the original study. The relationship between child work hours and three economic indicators: national all farm index (AFI) ratio, national fuel index, and regional milk prices was analyzed using times series plots, correlation, and multiple linear regression. The AFI ratio was positively correlated with child work hours (r = 0.49, p = 0.008) but there was no significant correlation between child work hours and fuel or milk prices. Multiple linear regression demonstrated that the relationship between AFI and child work hours is independent of a seasonal effect.\nQuestion: Do economic stresses influence child work hours on family farms?",
        "gt": "Increased child work hours may be associated with periods of higher farm sector productivity, rather than economic stress per se. Findings are limited by the ecologic study design, use of national economic indicators, and the limited number of cycles of child work hours available for time series analysis. Economic conditions may influence decisions about children's farm work.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Single cigarette use and its implications have rarely been studied among adults. To assess perceptions, prevalence and correlates of single cigarette purchase behaviour and its relation to harm reduction. Focus group transcripts and cross-sectional data were analysed. Focus groups among convenience samples of adult smokers in two Mexican cities and a population-based sample of 1079 adult smokers from the International Tobacco Control Policy Evaluation Project in four Mexican cities. Purchase of single cigarettes last time cigarettes were bought, frequency of purchasing single cigarettes in the previous month and intention to quit in the next 6 months. Focus group data indicated that smokers bought single cigarettes as a harm reduction strategy. Survey data indicated that 38% of participants purchased single cigarettes in the last month and 10% purchased them the last time they bought cigarettes, with more frequent consumption among young adults and those with lower income. Purchasing single cigarettes was independently associated with the frequency of using single cigarettes to reduce consumption and, less consistently, with the frequency of being cued to smoke after seeing single cigarettes for sale. Using single cigarettes to reduce consumption was positively associated with quit intention, whereas being cued to smoke by single cigarettes was negatively associated with quit intention.\nQuestion: Does the availability of single cigarettes promote or inhibit cigarette consumption?",
        "gt": "Study results suggest that some adult Mexican smokers purchase single cigarettes as a method to limit, cut down on and even quit smoking. Nevertheless, promotion of the availability of single cigarettes as a harm reduction strategy could provide additional smoking cues that undermine quit attempts and promote youth smoking.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine whether histological examination of all tissue removed by general practitioners in minor surgery increases the rate of detection of clinically important skin lesions, and to assess the impact of such a policy on pathologists' workload. Before and after comparison. Stratified random sample of 257 general practitioner partnerships from the catchment areas of 19 English pathology laboratories. Tissue removed in minor surgery by general practitioners during the control period (September 1992 to February 1993) and intervention period (September 1993 to February 1994). General practitioners referred to their local pathology laboratory all solid tissue removed in all minor surgery, irrespective of their previous policy. Numbers of specimens referred for histology by general practitioners during intervention and control periods; numbers of primary malignant melanomas, non-melanoma malignancies, premalignant lesions, and benign lesions. 257/330 partnerships participated (response rate 78%). During the intervention period 5723 specimens were sent, compared with 4430 during the control period. The referral rate increased by an estimated 1.34 specimens per 1000 patient years (95% confidence interval 0.93 to 1.76, P<0.0001). General practitioners sent 204 specimens that were malignant (including 16 malignant melanomas) in the control period and 188 that were malignant (including 15 malignant melanomas) during the intervention period (change in total number of malignancies, -1.0 per 100,000 patient years (-5.9 to 3.8, non-significant).\nQuestion: Is histological examination of tissue removed by general practitioners always necessary?",
        "gt": "The intervention was associated with a substantial increase in laboratory workload, all of which was accounted for by increases in non-serious lesions. This observation should be taken into account when considering the merits of a policy requiring histological examination in every case.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study sought to investigate the independent effect of ethnicity on the utilization of invasive cardiac procedures after acute myocardial infarction (AMI). The precise role of ethnicity in access to cardiovascular procedures is unknown, particularly because of difficulty in isolating ethnicity from financial and other socioeconomic factors. We conducted a retrospective analysis of the use of cardiac catheterization and coronary revascularization procedures after AMI in military health care beneficiaries. The Military Health Services System (MHSS) ensures equal access to care in an environment without financial incentives for procedural utilization; furthermore, socioeconomic differences between patients beyond ethnicity are minimized. Data were analyzed from the Civilian External Peer Review Program representing abstracted chart reviews from 125 military health care facilities worldwide for all patients (1,208 white; 233 nonwhite [155 black]) with the principal or secondary diagnosis of AMI from March to September 1993. Rates of cardiac catheterization were similar in white and nonwhite patients (34.8 vs. 39.1%, p = 0.21). After controlling for age, gender, cardiovascular risk factors and AMI variables, including infarct size and other risk markers, there were no differences in the use of this procedure during the AMI admission in comparisons of white versus nonwhite patients (estimated odds ratio [OR] 0.96, 95% confidence interval [CI]0.69 to 1.34) and white versus black patients (OR 1.19, 95% CI 0.80 to 1.78). However, white patients were significantly more likely than nonwhite patients to be \"considered\" for future cardiac catheterization (OR 1.77, 95% CI 1.19 to 2.61). Coronary revascularization within 180 days was not significantly affected by race in white versus nonwhite (OR 0.90, 95% CI 0.59 to 1.39) and white versus black patients (OR 1.11, 95% CI 0.65 to 1.89). Outcomes (30- and 180-day mortality and readmission rates) were similar for all race groups.\nQuestion: Can characteristics of a health care system mitigate ethnic bias in access to cardiovascular procedures?",
        "gt": "There is a limited relation between ethnicity and the use of invasive cardiac procedures in the MHSS. These data raise the promise that characteristics of a health care system can mitigate ethnic bias in medicine.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To test the ability of Ki-67 to detect cytological lesions in a screening setting and its use as a surrogate marker of human papillomavirus (HPV) infection. A study of liquid based cytology, HPV DNA testing by MY09/MY11 consensus polymerase chain reaction (PCR), type specific PCRs, and Ki-67 immunocytochemistry on a randomly selected series of 147 patients. Comparison of the number of Ki-67 immunoreactive cells/1000 cells in the different cytological groups showed that the HSIL group yielded a significantly higher mean count than did the other groups. The number of Ki-67 immunoreactive cells/1000 cells was significantly higher in HPV-16 positive samples than in samples containing infections with other high risk types. Receiver operating characteristic curves indicated a test accuracy (area under curve) of 0.68, 0.72, and 0.86 for atypical squamous cells of undetermined significance (ASCUS), low grade squamous intraepithelial lesions (LSIL), and high grade squamous intraepithelial lesions (HSIL), respectively. Thresholds for 95% sensitivity were 0.07, 0.08, and 0.15 Ki-67 immunopositive cells/1000 cells for ASCUS, LSIL and HSIL, respectively. The threshold for 95% specificity was 1.9 Ki-67 immunopositive cells/1000 cells.\nQuestion: Ki-67 immunocytochemistry in liquid based cervical cytology: useful as an adjunctive tool?",
        "gt": "Ki-67 immunocytochemistry can be applied to liquid based cytology. The accuracy and diagnostic indices of the test are good when compared with those of other techniques. As part of a panel of screening procedures, it could be used as an adjunct to liquid based cytology to identify HSIL, and as a surrogate marker of HPV-16 infection.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adenotonsillectomy is recognized as an effective therapy for snoring and sleep disorders in children. It is important to understand whether adenotonsillectomy significantly increases the volume of the pharyngeal space. The goal of this study was to evaluate the change in oropharyngeal volume after adenotonsillectomy and the correlation of this change with the objective volume of the tonsils and body mass index. We included 27 subjects (14 males) with snoring caused by tonsil and adenoid hypertrophy. The mean age of the subjects was 7.92 (\u00b12.52) years. Children with craniofacial malformations or neuromuscular diseases or syndromes were excluded. The parents/caregivers answered an adapted questionnaire regarding sleep-disordered breathing. All patients were subjected to weight and height measurements and body mass index was calculated. The subjects underwent pharyngometry before and after adenotonsillectomy and the volume of both excised tonsils together was measured in cm3 in the operating room. Pharyngometric analysis showed that the mean pharyngeal volume was 28.63 (\u00b15.57) cm3 before surgery and 31.23 (\u00b16.76) cm3 after surgery; the volume of the oropharynx was significantly increased post-surgery (p=0.015, Wilcoxon test). No correlation was found between the objective tonsil volume and the post-surgical volume increase (p=0.6885). There was a fair correlation between the oropharyngeal volume and body mass index (p=0.0224).\nQuestion: Is the difference in the volume of the pharyngeal space, as measured by acoustic pharyngometry, before and after tonsillectomy proportional to the volume of the excised tonsils?",
        "gt": "Adenotonsillectomy increases the volume of the pharyngeal space, but this increase does not correlate with the objective tonsil size. Furthermore, greater BMI was associated with a smaller increase in the pharyngeal volume. Oropharyngeal structures and craniofacial morphology may also play a role in the increase in oropharyngeal volume.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Results from previous studies evaluating the effect of nail polish on oxygen saturation (SpO(2)) determined by pulse oximeter monitors are inconsistent. Establishing the effect of nail polish on SpO(2) is relevant to clinical practice, since removing nail polish requires clinical time and supplies. The objective of this study was to determine if fingernail polish affects SpO(2) as measured by two different pulse oximeter machines. Absorption spectra of 10 nail polish colors were obtained by spectrophotometry. Twenty-seven healthy volunteers with SpO(2)>or =95% participated. Using the Nellcor N20 and N595 pulse oximeters, the mean SpO(2) was measured on each of 10 nails with and without nail polish and using a side-to-side configuration. Means were compared using paired t-tests. Mean SpO(2) had a statistically significant decrease with brown and blue nail polish using both machines (p<0.05) but this was not clinically significant (<1% difference). Using the side-to-side configuration, the N595 oximeter had a statistically significant decrease in mean SpO(2) with red nail polish but again this was not clinically significant.\nQuestion: Does fingernail polish affect pulse oximeter readings?",
        "gt": "Fingernail polish does not cause a clinically significant change in pulse oximeter readings in healthy people.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: With increasing age DMARD and TNF-alpha-Inhibitors are less frequently used. The goal of this work was to investigate whether the therapeutic response in elderly patients with rheumatoid arthritis (RA) is diminished. In total, 192 patients admitted to hospital because of active RA were prospectively studied. The improvements in disease activity (RADAI), pain and function (FFbH) three months after release were measured and compared between two age groups. Patients<65 and>or =65 years of age (n=104 and 88, mean age of 52+/-10 and 72+/-5.6 years, respectively) showed comparable improvements of disease activity and pain in the complete group as well as in those who received newly administered DMARD or TNF-alpha-inhibitors (71.2% and 62.6%, respectively, for the two groups). A significant difference was demonstrated for the change in function: While patients<65 years of age in the mean had a moderate improvement of the FFbH, this could not be shown for the older patients (p=0.04). A close correlation of the improvements of RADAI and FFbH could be shown for the younger patients only.\nQuestion: Is the treatment response in elderly patients with rheumatoid arthritis diminished?",
        "gt": "DMARD or TNF-alpha-inhibitors improve disease activity and pain in elderly patients with RA no less than in younger patients. However, in contrast to the younger patients, the older patients profit less in terms of functional impairment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Literature on grading practices largely focuses on clinical or academic grading. Reviewing both as distinct entities may miss a more systemic grading problem. A cross-sectional survey targeted 235 faculty within university and community colleges in a western state. Chi-square tests of independence explored the relation between institutional and faculty variables. The response rate was 34 percent. Results suggest failing to fail may be evident across the sector in both clinical and academic settings: 43 percent of respondents had awarded higher grades than merited; 17.7 percent had passed written examinations they felt should fail; 66 percent believed they had worked with students who should not have passed their previous placement.\nQuestion: Is There Evidence of Failing to Fail in Our Schools of Nursing?",
        "gt": "Failing to fail cuts across instructional settings. Further exploration is imperative if schools are to better engender a climate for rigorously measuring student attainment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Chronic idiopathic pain syndromes are major causes of personal suffering, disability, and societal expense. Dietary n-6 linoleic acid has increased markedly in modern industrialized populations over the past century. These high amounts of linoleic acid could hypothetically predispose to physical pain by increasing the production of pro-nociceptive linoleic acid-derived lipid autacoids and by interfering with the production of anti-nociceptive lipid autacoids derived from n-3 fatty acids. Here, we used a rat model to determine the effect of increasing dietary linoleic acid as a controlled variable for 15 weeks on nociceptive lipid autacoids and their precursor n-6 and n-3 fatty acids in tissues associated with idiopathic pain syndromes. Increasing dietary linoleic acid markedly increased the abundance of linoleic acid and its pro-nociceptive derivatives and reduced the abundance of n-3 eicosapentaenoic acid and docosahexaenoic acid and their anti-nociceptive monoepoxide derivatives. Diet-induced changes occurred in a tissue-specific manner, with marked alterations of nociceptive lipid autacoids in both peripheral and central tissues, and the most pronounced changes in their fatty acid precursors in peripheral tissues.\nQuestion: Dietary linoleic acid-induced alterations in pro- and anti-nociceptive lipid autacoids: Implications for idiopathic pain syndromes?",
        "gt": "The present findings provide biochemical support for the hypothesis that the high linoleic acid content of modern industrialized diets may create a biochemical susceptibility to develop chronic pain. Dietary linoleic acid lowering should be further investigated as part of an integrative strategy for the prevention and management of idiopathic pain syndromes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare the differences in the quality of Mitrofanoff channels created using appendix and re-tubularized small bowel (the Yang-Monti ileovesicostomy). Patients and methods The case-notes were reviewed retrospectively for all patients who underwent a Mitrofanoff procedure using either appendix or small bowel, over a 5-year period from June 1994 to July 1999. In all, 92 patients underwent 94 Mitrofanoff procedures; the appendix was used in 69 and small bowel in 25. The underlying diagnoses were exstrophy-epispadias complex (38), neuropathic bladder (21), anorectal malformations and cloacal anomalies (15), posterior urethral valves (nine) and miscellaneous (nine). The mean (range) age at operation was 9.2 (1.1-18.3) years. The mean (range) follow-up for the appendix group was 37 (6.7-65) months and for the Monti group 25 (6-66) months. Catheterization problems occurred in 18 (27%) patients from the appendix group; two needed an adjustment of technique, six dilatation and 10 revision. Stomal stenosis occurred in 10 (15%) patients, bladder level stenosis in four (6%) and conduit necrosis in two. Catheterization problems were reported in 15 (60%) patients from the Monti group; five needed revision, three dilatation and seven are being managed conservatively. The incidences of stomal stenosis (four, 16%) and bladder level stenosis (two, 8%) were comparable with the appendix group. In addition, two patients had distal channel (sub-stomal) stenosis and two had mid-channel stenosis. The problem unique to the Yang-Monti channel was a pouch-like dilatation in seven patients (28%), all of whom presented with catheterization problems; five are being managed conservatively and two have needed pouch resection. Stomal prolapse occurred in five (7%) patients in the appendix group, but in none of the Monti group.\nQuestion: The Yang-Monti ileovesicostomy: a problematic channel?",
        "gt": "The appendix is the conduit of choice for a Mitrofanoff procedure. Re-tubularized small bowel conduits have a considerably higher incidence of catheterization problems. Anatomical factors may contribute to the unique incidence of pouch formation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether the failure to decrease blood pressure normally during sleep is associated with more prominent target organ damage. Cardiac and vascular structure and function were characterized in 183 asymptomatic, unmedicated hypertensive patients and compared with their ambulatory blood pressures. The 104 patients with a normal (>10%) nocturnal fall in systolic blood pressure (dippers) were similar to the 79 patients with an abnormal fall (nondippers) in sex, race, body size, smoking history, and average awake ambulatory blood pressure. Nondippers tended to be older (57 versus 54 years, P = 0.06). The supine blood pressure upon completion of the ultrasound studies was higher in the nondippers (156/93 versus 146/89 mmHg, P<0.005) as was the variability of the awake diastolic blood pressure. There were no differences between dippers and nondippers in left ventricular mass (170 versus 172 g), mass index (90 versus 91 gm/m2), prevalence of abnormal ventricular geometry, common carotid artery diameter (5.74 versus 5.75 mm), and vascular strain. Although nondippers were more likely to have carotid artery plaque (41 versus 27%, P = 0.053) and an increased intimal-medial thickness (0.84 versus 0.79 mm, P<0.05), adjustment for age rendered the differences insignificant. There were no differences in the relation of awake and sleeping systolic pressures to the left ventricular mass (r = 0.36 and 0.35, respectively, both P<0.005) or to the carotid wall thickness (r = 0.28 and 0.29, respectively, both P<0.005). When the 114 men and 69 women were considered separately, similar findings were obtained. When the 109 whites and 56 blacks (African-Americans and Afro-Caribbeans) were considered separately, there were no differences in left ventricular structure in either group, and differences in vascular structure were confined to the white subgroup.\nQuestion: Is the absence of a normal nocturnal fall in blood pressure (nondipping) associated with cardiovascular target organ damage?",
        "gt": "The lack of a normal nocturnal fall in blood pressure is not associated with an increase in left ventricular mass or in arterial disease independently of age. Age-related changes in carotid artery wall thickness and plaque among nondippers may reflect a contribution of an altered baroreceptor function to the lack of normal nocturnal and supine blood pressure decreases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To provide managers with tools to manage episodes of sick-leave of their employees, the influence of factors such as age, gender, duration of tenure, working full-time or part-time, cause and history of sick-leave, salary and education on sick-leave duration was studied. In a cross-sectional study, data derived from the 2005 sick-leave files of a Dutch university were examined. Odds ratios of the single risk factors were calculated for short spells (<or=7 days), medium spells (8- 42 days), long spells (43-91 days) or extended spells (>or=91 days) of sick-leave. Next, these factors were studied in multiple regression models. Age, gender, duration of employment, cause and history of sick-leave, salary and membership of scientific staff, studied as single factors, have a significant influence on sick-leave duration. In multiple models, this influence remains for gender, salary, age, and history and cause of sick-leave. Only in medium or long spells and regarding the risk for a long or an extended spell do the predictive values of models consisting of psychological factors, work-related factors, salary and gender become reasonable.\nQuestion: Determinants of sick-leave duration: a tool for managers?",
        "gt": "The predictive value of the risk factors used in this study is limited, and varies with the duration of the sick-leave spell. Only the risk for an extended spell of sick-leave as compared to a medium or long spell is reasonably predicted. Factors contributing to this risk may be used as tools in decision-making.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There has been a convergence of models describing schizophrenia as a disconnection syndrome, with a focus on the temporal connectivity of neural activity. Synchronous gamma-band (40-Hz) activity has been implicated as a candidate mechanism for the binding of distributed neural activity. To the authors' knowledge, this is the first study to investigate \"gamma synchrony\" in first-episode schizophrenia. Forty medicated first-episode schizophrenia patients and 40 age- and sex-matched healthy comparison subjects participated in a conventional auditory oddball paradigm. Gamma synchrony, time-locked to target stimuli, was extracted from an ongoing EEG. The magnitude and latency of both early (gamma 1: -150 msec to 150 msec poststimulus) and late (gamma 2: 200 to 550 msec poststimulus) synchrony were analyzed with multiple analysis of variance. First-episode schizophrenia patients showed a decreased magnitude and delayed latency for global gamma 1 synchrony in relation to healthy comparison subjects. By contrast, there were no group differences in gamma 2 synchrony.\nQuestion: \"Gamma synchrony\" in first-episode schizophrenia: a disorder of temporal connectivity?",
        "gt": "These findings suggest that first-episode schizophrenia patients have a global decrease and delay of temporal connectivity of neural activity in early sensory response to task-relevant stimuli. This is consistent with cognitive evidence of perceptual integration deficits in this disorder and raises the possibility that a breakdown in the early synchrony of distributed neural networks is a marker for the onset of schizophrenia.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients older than 65 years have traditionally not been considered candidates for heart transplantation. However, recent studies have shown similar survival. We evaluated immediate and medium-term results in patients older than 65 years compared with younger patients. From November 2003 to December 2013, 258 patients underwent transplantation. Children and patients with other organ transplantations were excluded from this study. Recipients were divided into two groups: 45 patients (18%) aged 65 years and older (Group A) and 203 patients (81%) younger than 65 years (Group B). Patients differed in age (67.0\u2009\u00b1\u20092.2 vs. 51.5\u2009\u00b1\u20099.7 years), but gender (male 77.8 vs. 77.3%; p\u2009=\u20090.949) was similar. Patients in Group A had more cardiovascular risk factors and ischemic cardiomyopathy (60 vs. 33.5%; p\u2009<\u20090.001). Donors to Group A were older (38.5\u2009\u00b1\u200911.3 vs. 34.0\u2009\u00b1\u200911.0 years; p\u2009=\u20090.014). Hospital mortality was 0 vs. 5.9% (p\u2009=\u20090.095) and 1- and 5-year survival were 88.8\u2009\u00b1\u20094.7 versus 86.8\u2009\u00b1\u20092.4% and 81.5\u2009\u00b1\u20095.9 versus 77.2\u2009\u00b1\u20093.2%, respectively. Mean follow-up was 3.8\u2009\u00b1\u20092.7 versus 4.5\u2009\u00b1\u20093.1 years. Incidence of cellular/humoral rejection was similar, but incidence of cardiac allograft vasculopathy was higher (15.6 vs. 7.4%; p\u2009=\u20090.081). Incidence of diabetes de novo was similar (p\u2009=\u20090.632), but older patients had more serious infections in the 1st year (p\u2009=\u20090.018).\nQuestion: Heart Transplantation in Patients Older than 65 Years: Worthwhile or Wastage of Organs?",
        "gt": "Heart transplantation in selected older patients can be performed with survival similar to younger patients, hence should not be restricted arbitrarily. Incidence of infections, graft vascular disease, and malignancies can be reduced with a more personalized approach to immunosuppression. Allocation of donors to these patients does not appear to reduce the possibility of transplanting younger patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate, in a cross-sectional study, the prevalence of anxiety and depression in patients with localised prostate cancer managed by active surveillance, compared with those receiving immediate treatment, as active surveillance is a relatively new approach to managing this disease, designed to avoid 'unnecessary' treatment, but it is unclear whether the approach contributes to psychological distress, given that men are living with untreated cancer. A consecutive series of 764 patients with prostate cancer were approached in outpatient clinics. Of these, 329 men with localized disease (cT1/2, N0/NX, M0/MX) meeting the study entry criteria, completed the Hospital Anxiety and Depression Scale (HADS); 100 were on active surveillance, 81 were currently receiving radical treatment (radiotherapy + neoadjuvant hormone therapy) and 148 had previously received radical radiotherapy. Overall, 16% (51/329) of patients met the HADS criteria for anxiety and 6% (20/329) for depression. Analyses indicated that higher anxiety scores were significantly associated with younger age (P<0.01) and a longer interval since diagnosis (P<0.01), but not with management by active surveillance (P = 0.38). Higher depression scores were significantly associated with a longer interval since diagnosis (P<0.05), but not with management by active surveillance (P = 0.83).\nQuestion: Does active surveillance for men with localized prostate cancer carry psychological morbidity?",
        "gt": "Active surveillance for managing localized prostate cancer was not associated with greater psychological distress than more immediate treatment for prostate cancer.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Define a group of patients with newly diagnosed prostate cancer, whose risk of bone metastasis is low enough to omit a bone scan staging study. From 2003 to 2009, the medical records of patients who were newly diagnosed with prostate cancer were retrospectively reviewed. The data collected included: age, digital rectal examination, serum prostate specific antigen (PSA), Gleason score, clinical T stage, and bone isotope scan. Patients were divided into two groups according to the results of bone isotope scan; positive group and negative group. A univariate and multivariate binary logistic regression was used to analyze the results. Of the 106 patients, 98 had a complete data collection and were entered into the study. The median age of the patients was 70.5 years and patients with a positive bone scan was 74 years, significantly higher than for patients with negative scans (69 years) (p=0.02). Bone metastasis was detected in 39 cases (39.7%). In all patients with clinical T1-2 stage, a Gleason score of<8 and PSA\u226420 ng/mL, the bone isotope scans were negative. In univariate analysis, PSA (>20 ng/mL) and Gleason score (>7) were independently predictive of positive bone scan, while clinical stage was not.\nQuestion: Do all patients with newly diagnosed prostate cancer need staging radionuclide bone scan?",
        "gt": "Staging bone scans can be omitted in patients with a PSA level of \u226420 ng/mL, and Gleason score<8. Our results suggest that by considering the Gleason score and PSA, a larger proportion of patients with prostate cancer could avoid a staging bone scan.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Serum levels of cystatin C, an endogenous inhibitor of cysteine proteases, provide an alternative method to creatinine-based criteria for measuring glomerular filtration rate. Preliminary data suggested that serum cystatin C levels parallel with the stage of liver fibrosis in chronic liver disorders. Our aim has been to evaluate the possible role of serum cystatin C as a marker of liver fibrosis in hepatitis C virus (HCV)-induced chronic liver disease. 100 consecutive patients (56 men, mean age 51.2 \u00b1 9.5 yrs) with HCV-induced chronic liver disease, scheduled for their first liver biopsy and na\u00efve for antiviral therapy were included. Liver fibrosis was evaluated with the METAVIR score. Serum cystatin C and standard laboratory tests were measured simultaneously. Patients with ethanol abuse (>50 g/day), HBV or HIV coinfection or plasma creatinine \u2265 1.20 mg/dL were excluded. In addition, a second group of 16 patients fulfilling the same requisites and diagnosed with HCV-induced compensated cirrhosis by clinical evidence of portal hypertension was included. Serum cystatin C levels significantly increase from F0 to F2 fibrosis stages, remained stable in F3 and F4 stages and increased again in the group of non-biopsied compensated cirrhosis. Serum cystatin C levels were higher in patients with moderate-advanced necroinflammation in the liver biopsy.\nQuestion: Serum cystatin C: a non-invasive marker of liver fibrosis or of current liver fibrogenesis in chronic hepatitis C?",
        "gt": "Serum cystatin C level may reflect current fibrogenic and necroinflammatory activities in chronic HCV-induced liver disease with normal renal function but can not be considered as a non-invasive marker of liver fibrosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine retrospectively whether addition of gadolinium-enhanced T1-weighted magnetic resonance (MR) sequence to T2-weighted turbo spin-echo (SE) MR imaging is valuable for preoperative assessment of T stage and circumferential resection margin in patients with primary rectal cancer. Local institutional review board approved study and waived informed patient consent. Eighty-three patients with operable primary rectal cancer underwent preoperative MR imaging. Retrospectively, two observers independently scored T2-weighted turbo SE MR images and, in a second reading, T2-weighted images combined with gadolinium-enhanced T1-weighted turbo SE MR images for tumor penetration through rectal wall and tumor extension into mesorectal fascia. A confidence level scoring system was used, and receiver operating characteristic (ROC) curves were generated. Histologic findings were standard of reference. Difference in performance of T2-weighted and combined T2-weighted plus gadolinium-enhanced T1-weighted sequences was analyzed by comparing corresponding areas under ROC curves (A(z)) for each observer. Interobserver agreement was calculated by using linear weighted kappa statistics. Addition of contrast-enhanced T1-weighted to T2-weighted MR imaging did not significantly improve diagnostic accuracy for prediction of tumor penetration through rectal wall (A(z) of T2-weighted vs T2-weighted plus T1-weighted images for observer 1, 0.740 vs 0.764; observer 2, 0.856 vs 0.768) and tumor extension into mesorectal fascia (A(z) for observer 1, 0.962 vs 0.902; observer 2, 0.902 vs 0.911). Diagnostic performance (A(z)) of MR and interobserver agreement were high for prediction of tumor extension into mesorectal fascia (kappa = 0.61, 0.74) but only moderate for penetration through rectal wall (kappa = 0.47, 0.45).\nQuestion: Rectal cancer: MR imaging in local staging--is gadolinium-based contrast material helpful?",
        "gt": "Gadolinium-enhanced MR sequences did not improve diagnostic accuracy for assessment of tumor penetration through rectal wall and tumor extension into mesorectal fascia.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Our aim was to investigate the effect of cyclosporine (CsA), which is commonly used in renal transplant patients and causes myocardial fibrosis and elevated arterial tension, on cardiac function. Sixty-six renal transplant patients (RTPs) and 25 healthy controls were included in the study. Renal transplantation patients were divided according to time of CsA exposure: group 1 (0 to 36 months); group 2 (36 to 72 months) and group 3 (>72 months). Systolic peak velocity (Sm, mitral; St, tricuspid) and mitral early (e)/late (a) (Me/a) and tricuspid e/a (Te/a) waves of the right and the left ventricles were measured by pulse-wave (PW) Doppler used for tissue Doppler imaging of both ventricles as well as the ventricle free wall near to the lateral tricuspid and the posterior mitral leaflets. The measurements included conventional diastolic early (E) and late (A) waves and deceleration time (DT) of the E wave, isovolumetric relaxation time (IVRT) of both ventricles, as well as left ventricular systolic ejection fraction (EF). There were no statistically significant differences between the groups with regard to demographic, clinical, and most biochemical characteristics. Left ventricular EF was normal in all groups; there were no statistically significant differences. IVRT and DT of left ventricle and right ventricle DT values were similar among RTPs. On the other hand, values were found to be increased in RTP groups compared with the control group. E/A ratio, Me/a Te/a of both ventricles were similar among RTPs. However, these values were found to be decreased in RTP groups compared with the control group.\nQuestion: Is there a relation between duration of cyclosporine usage and right and left ventricular function in renal transplant patients?",
        "gt": "Although left ventricular systolic functions were normal in all groups, there were statistically significant impairments of biventricular diastolic function parameters among renal transplant recipients compared with the control group.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Conduction disorders appearing after coronary artery bypass surgery (CABG) may have many different causes. In this study, we evaluated the postoperative conduction disorders after CABG with respect to the ante-grade blood cardioplegia and ante-grade plus continuous retrograde cardioplegia delivery methods. This retrospective study included 1824 patients undergoing CABG between January 2001 and December 2005. There were 694 female patients (38%) and 1130 male patients (62%). Myocardial protection was done by isothermic hyperkalemic blood cardioplegia. Patents in Group 1 (n = 704) were operated on using only intermittent antegrade cardioplegia and those in group 2 (n = 1120) were operated on using the antegrade plus retrograde continuous cardioplegia. The postoperative occurrences of a new right bundle branch block, left anterior hemiblock, left posterior hemiblock, left bundle branch block, or third-degree atrioventricular block were evaluated and compared. Total mortality rate was 1.6% (29 patients) without significant difference between the groups. The preoperative and perioperative characteristics were statistically similar in the groups. The occurrence of conduction disorders was significantly higher in group 1 (P = .006, 55 versus 52 patients). The analysis of the patients with conduction disorders showed a significantly increased mortality rate (P<.001) in addition to a significantly increased period of intensive care unit follow-up and duration of postoperative hospitalization (P<.001).\nQuestion: Does combination of antegrade and retrograde cardioplegia reduce coronary artery bypass grafting-related conduction defects?",
        "gt": "The present study demonstrated that the perioperative occurrence of conduction disorders after CABG was decreased by antegrade controlled and retrograde continuous combination cardioplegia.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To compare hospital outcomes of on-pump and off-pump coronary artery bypass surgery. From 1997 to 2000, primary coronary artery bypass grafting was performed in 481 patients off pump and in 3231 patients on pump. Hospital outcomes were compared between propensity-matched pairs of 406 on-pump and 406 off-pump patients. The 2 groups were similar in age (P =.9), left ventricular function (P =.7), extent of coronary artery disease (P =.5), carotid artery disease (P =.4), and chronic obstructive pulmonary disease (P =.5). However, off-pump patients had more previous strokes (P =.05) and peripheral vascular disease (P =.02); on-pump patients had a higher preoperative New York Heart Association class (P =.01). In the matched pairs the mean number of bypass grafts was 2.8 +/- 1.0 in off-pump patients and 3.5 +/- 1.1 in on-pump patients (P<.001). Fewer grafts were performed to the circumflex (P<.001) and right coronary (P =.006) artery systems in the off-pump patients. Postoperative mortality, stroke, myocardial infarction, and reoperation for bleeding were similar in the 2 groups. There was more encephalopathy (P =.02), sternal wound infection (P =.04), red blood cell use (P =.002), and renal failure requiring dialysis (P =.03) in the on-pump patients.\nQuestion: Does off-pump coronary surgery reduce morbidity and mortality?",
        "gt": "Both off- and on-pump procedures produced excellent early clinical results with low mortality. An advantage of an off-pump operation was less postoperative morbidity; however, less complete revascularization introduced uncertainty about late results. A disadvantage of on-pump bypass was higher morbidity that seemed attributable to cardiopulmonary bypass.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Recent reports have indicated that autonomic tone fluctuations measured by heart rate variability (HRV) precede episodes of paroxysmal atrial fibrillation (AF). Little is known about the impact of baseline autonomic tone and the development of new onset AF in a population-based cohort. The purpose of this study was to assess the role of HRV as a predictor of new onset AF. Ambulatory ECG recordings obtained from the Framingham Heart Study subjects attending a routine examination were processed for HRV. The HRV variables analyzed included standard deviation of normal R-R intervals (SDNN), low frequency power (LF), high frequency power (HF), and LF/HF ratio. There were 1434 women and 1142 men (54 +/- 14.1 years) eligible for the study. In 12 years of follow-up, 65 women and 67 men had new onset AF. The study had 80% power to detect a hazard ratio (HR) of 1.3 per standard deviation (SD) decrement in HRV. A one SD decrement in log LF/HF was associated with increased risk of developing AF (HR = 1.23; 95% confidence intervals (CI) = 1.06-1.44) in age- and sex-adjusted models; the association was no longer significant (HR = 1.15; 95% CI = 0.98-1.35) after adjusting for potential confounders.\nQuestion: Is baseline autonomic tone associated with new onset atrial fibrillation?",
        "gt": "Autonomic dysregulation at baseline, as reflected by an altered HRV is associated with risk of AF; however, this association does not persist after adjusting for potential confounders. Much of the apparent association between HRV and AF is mediated by traditional risk factors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We conducted a survey to determine whether hernia surgeons follow evidence-based medicine (EBM) criteria in their daily routine. All chiefs of general surgery in Styria (Austria) received a short, simple, two-page, 10-item questionnaire. We analyzed completed surveys from 15 departments reporting 2441 hernia repairs with a mean patient age of 57.5 +/- 11.6 years. Although five techniques accounted for 96.6% of procedures, the frequency of use of each technique varied considerably among the hospitals. There were high numbers of laparoscopic (36.8%) and sutured (19.9%) repairs.\nQuestion: Do we follow evidence-based medicine recommendations during inguinal hernia surgery?",
        "gt": "Because of the great variance among the evaluated hospitals as to surgical methods and indications, this survey showed that inguinal hernia surgery does not currently comply with EBM.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The objectives of this study were to compare early predictive marker of the metabolic syndrome with proopiomelanocortin (POMC) methylation status and to determine the association among birth weight, ponderal index, and cord blood methylation status. We collected pregnancy outcome data from pregnant women, cord blood samples at delivery, and blood from children (7-9 years old; n = 90) through a prospective cohort study at Ewha Womans University, MokDong Hospital (Seoul, Korea), from 2003-2005. POMC methylation was assessed by pyrosequencing. We divided subjects into three groups according to cord blood POMC methylation: the low methylation (<10th percentile), mid-methylation, and high methylation (>90th percentile) groups. We analyzed the association of POMC methylation status at birth with adiposity and metabolic components using ANCOVA and multiple linear regression analysis. Birth weights (P = 0.01) and ponderal indices (P = 0.01) in the high POMC methylation group were significantly lower than in the mid-POMC methylation group. In terms of metabolic components of childhood, blood triglycerides (57.97, 67.29 vs. 113.89 mg/dL; P = 0.03, 0.01) and insulin (7.10, 7.64 vs. 10.13 \u03bcIU/mL; P = 0.05, 0.02) at childhood were significantly higher in the high POMC methylation group than in the low and mid-POMC methylation group.\nQuestion: Can proopiomelanocortin methylation be used as an early predictor of metabolic syndrome?",
        "gt": "High POMC methylation in cord blood was associated with lower birth weight, and children with high POMC methylation in cord blood showed higher triglycerides and higher insulin concentrations in blood. Thus, POMC methylation status in cord blood may be an early predictive marker of future metabolic syndrome.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Imaging follow-up (FU) after endovascular aneurysm repair (EVAR) is usually performed by periodic contrast-enhanced computed tomography (CT) scans. This study aims to evaluate the effectiveness of CT-FU after EVAR. In this study, 279 of 304 consecutive patients (261 male, aged 74 years (interquartile range (IQR): 70-79 years) with a median abdominal aortic aneurysm (AAA) diameter of 58 mm (IQR: 53-67 mm)) underwent at least one of the yearly CT scans and plain abdominal films after EVAR. All patients received Zenith stent-grafts for non-ruptured AAAs at a single institution. Patients were considered asymptomatic when a re-intervention was done solely due to an imaging FU finding. The data were prospectively entered in a computer database and retrospectively analysed. As a follow-up, 1167 CT scans were performed at a median of 54 months (IQR: 34-74 months) after EVAR. Twenty-seven patients exhibited postoperative AAA expansion (a 5-year expansion-free rate of 88+/-2%), and 57 patients underwent 78 postoperative re-interventions with a 5-year secondary success rate of 91+/-2%. Of the 279 patients, 26 (9.3%) undergoing imaging FU benefitted from the yearly CT scans, since they had re-interventions based on asymptomatic imaging findings: AAA diameter expansion with or without endoleaks (n=18), kink in the stent-graft limbs (n=4), endoleak type III due to stent-graft limb separation without simultaneous AAA expansion (n=2), isolated common iliac artery expansion (n=1) and superior mesenteric artery malperfusion due to partial coverage by the stent-graft fabric (n=1).\nQuestion: Is there a benefit of frequent CT follow-up after EVAR?",
        "gt": "Less than 10% of the patients benefit from the yearly CT-FU after EVAR. Only one re-intervention due to partial coverage of a branch by the stent-graft would have been delayed if routine FU had been based on simple diameter measurements and plain abdominal radiograph. This suggests that less-frequent CT is sufficient in the majority of patients, which may simplify the FU protocol, reduce radiation exposure and the total costs of EVAR. Contrast-enhanced CT scans continue, nevertheless, to be critical when re-interventions are planned.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether the use of peripheral nerve blocks (PNBs) as part of an analgesic protocol for operative repair of tibia and ankle fractures can improve the quality of postoperative pain management and the quality of recovery (QOR). Prospective cohort study. Orthopedic trauma service in an academic tertiary care center. Ninety-three consecutive patients undergoing operative repair of fractures of the ankle and tibia. Administration of popliteal and saphenous nerve blocks, as part of postoperative analgesia regimen in some patients. Patients were labeled as the regional group or the no-regional group based on whether they received PNBs. Patient satisfaction and the quality of pain management were measured 24 hours after surgery using the Revised American Pain Society Patient Outcome Questionnaire. The QOR was measured at 24 and 48 hours after surgery using the short version of the Quality of Recovery Questionnaire (QOR-9). Satisfaction with pain management was significantly higher (P = 0.005) in the regional group when compared with the no-regional group. Average pain scores over 24 hours was similar between the 2 groups (P = 0.07). The regional group reported less time spent in severe pain over 24-hour period (40 vs. 50%, P = 0.04) and higher overall perception of pain relief (80 vs. 65%, P = 0.003). Patients receiving regional anesthesia also demonstrated better QOR measured by the QOR-9 at 24 hours (P = 0.04) but not at 48 hours (p = 0.11).\nQuestion: Does Regional Anesthesia Improve the Quality of Postoperative Pain Management and the Quality of Recovery in Patients Undergoing Operative Repair of Tibia and Ankle Fractures?",
        "gt": "Patient satisfaction and the quality of postoperative pain management for the first 24 hours were better in patients who received PNBs as part of their postoperative analgesic regimen when compared with patients who received only systemic analgesia.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There are no guidelines for the appropriate follow-up of patients after pulmonary resection for lung cancer. Three-hundred fifty-eight consecutive patients who had undergone complete resections of non-small cell lung cancer between 1987 and 1991 were evaluated for tumor recurrence and development of second primary tumors. Recurrences were categorized by site (local or distant), mode of presentation (symptomatic or asymptomatic), treatment given (curative intent or palliative), and duration of overall survival. Recurrences developed in 135 patients (local only, 32; local and distant, 13; and distant only, 90). Of these, 102 were symptomatic and 33 were asymptomatic (most diagnosed by screening chest roentgenogram). Forty patients received treatment with curative intent (operation or radiation therapy>50 Gy) and 95 were treated palliatively. The median survival duration from time of recurrence was 8.0 months for symptomatic patients and 16.6 months for asymptomatic patients (p = 0.008). Multivariate analysis shows that disease-free interval (greater than 12 months or less than or equal to 12 months) was the most important variable in predicting survival after recurrence and that mode of presentation, site of recurrence, initial stage, and histologic type did not significantly affect survival. New primary tumors developed in 35 patients.\nQuestion: Is follow-up of lung cancer patients after resection medically indicated and cost-effective?",
        "gt": "Although detection of asymptomatic recurrences gives a lead time bias of 8 to 10 months, mode of treatment and overall survival duration are not greatly affected by this earlier detection. Disease-free interval appears to be the most important determinant of survival. Screening for asymptomatic recurrences in patients who have had lung cancer is unlikely to be cost-effective. Frequent follow-up and extensive radiologic evaluation of patients after operation for lung cancer are probably unnecessary.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The learning curve for endoscopic ultrasonography (EUS) is known to be difficult, especially in the field of pancreatic and biliary diseases. The aim of this study was to assess the impact of a live pig model developed for EUS credentialing in France. A total of 17 trainees obtained hands-on EUS experience using a live pig model. Trainees were asked to visualize anatomical structures, to carry out fine-needle aspiration (FNA) on lymph nodes in the liver hilum, and to perform celiac neurolysis. Assessment of the FNA procedure or celiac neurolysis included measurement of time (seconds), evaluation of the precision of the puncture (mm), and existence of technical errors. A significant improvement between a pre-test and post-test was observed for diagnostic procedures in the following anatomical areas: splenic mesenteric vein, vena cava, splenic mesenteric artery, celiac tree, pancreatic gland, and bile duct. For lymph node FNA, a significant improvement was observed in the duration of the procedure (84 seconds vs. 60 seconds; P = 0.01), and precision (4.2 mm vs. 1.8 mm; P = 0.009), but not for the rate of technical error (29% vs. 6%; not significant [n. s.]). For celiac neurolysis, a significant improvement was observed in procedure time (150 seconds vs. 84 seconds; P = 0.003), but not in the rate of technical error (6% vs. 6%; n. s.) or precision (4.2 mm vs. 2.8 mm; n. s.).\nQuestion: EUS training in a live pig model: does it improve echo endoscope hands-on and trainee competence?",
        "gt": "Teaching EUS with a live pig model significantly increased competence in diagnostic procedures with regard to visualizing anatomical structures, performance of FNA and, to a lesser extent, EUS-guided celiac neurolysis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A number of studies have shown that both mortality and hospital admissions due to severe asthma have decreased in recent years in many parts of the world. However, the situation is Spain has not yet been analyzed. The aim of this study was to determine the incidence of very severe, near-fatal asthma in recent years in various Spanish hospitals. A retrospective review of hospital records from 6 hospitals in 5 Spanish autonomous communities was conducted for the period 1997 to 2004 to determine the annual number of patients who required orotracheal intubation and mechanical ventilation due to an asthma attack. Of the 130 patients included in the study, 81 (62%) were women and 61 (47%) were aged between 51 and 75 years. The number of cases observed for the periods 2001-2002 and 2003-2004 (32 and 18, respectively) was significantly lower than that observed for the 1997-1998 and 1999-2000 periods (40 in both cases; P=.019). A significant increase in the incidence was observed in autumn and winter (n=81 [62%]; P=.018). Seventeen patients (13%) died and 8 (6%) developed serious sequelae.\nQuestion: Is the incidence of near-fatal asthma decreasing in Spain?",
        "gt": "Although our sample of 6 hospitals is not widely representative of the entire population of hospitals in Spain, our findings strongly suggest a decrease in the incidence of near-fatal asthma in Spain in recent years.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: AIM OF THE STUDY was the appreciation of the body mass index (BMI) of adolescents with diabetes type 1 treated with different methods of insulin therapy as well as the correlation of the BMI with the age of the patients, duration of the diabetes therapy and with the metabolic control. The examinations included 205 patients aged 14 to 18 years (X 16.8). The examined group consisted of 112 girls (54.5%) and 93 boys (45.5%). In all the patients the body mass index (BMI) was calculated HbA1c, total cholesterol, HDL, LDL, triglyceride the duration and method of therapy of diabetes were determined. The patients were divided in 4 groups. Group 1 and 3 included patients treated with insulin in multiple daily doses (4-5 doses). Group 1 included 49 girls, group 3-36 boys. In group 2 and 4 there were patients treated with intensive therapy with insulin analogs (Humalog, NOVO Rapid) and NPH insulin. In group 2 there were 63 girls, in group 4 -57 boys. In the groups of boys higher statistically significant levels of HbA1c were observed in those treated with multiple daily doses (gr. 3), the body mass index was higher in boys treated with insulin analogs (gr. 4) [p<0.05, vs p<0.05].\nQuestion: Is overweight in patients with type 1 diabetes in the puberty a problem?",
        "gt": "1. The therapy of diabetes type 1 in the puberty with multiple daily doses as well as with the intensive method is not a risk factor for obesity. 2. Normal weight evidenced a proper diabetic metabolic control and a good education about the rational diet and optimal insulin dose. 3. In patients in whom BMI is over normal range it is urgently necessary to verify of the therapeutical management. 4. In patients with diabetes type 1 a strict control of body mass index and the growth velocity during each visit in the out patients is necessary.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study aims to explore the relationship between virtues and self-disclosure via a cross-sectional study and an intervention study among Chinese. In study one, 144 healthy individuals completed the Chinese Virtues Questionnaire (CVQ) and the short version of Jourard Self-Disclosure Questionnaire. In study two, 41 undergraduates voluntarily attended a nine-week intervention. Satisfaction with Life Scale (SWLS) was adopted as the well-being indicator. They were asked to complete the vitality sub-scale of CVQ and SWLS at week one for obtaining the virtue scores and baseline scores of well-being. After an eight-week intervention, SWLS was completed again to examine the intervention efficacy. Among the three virtues, only vitality had the significant and positive relation with self-disclosure. After eight weeks, the high-vitality group obtained the significant growth of satisfaction with life. The change degree of satisfaction among high vitality individuals was significantly higher than the low vitality group.\nQuestion: Can virtues enhance the benefits of expressive writing among healthy Chinese?",
        "gt": "Prescreening of individual vitality may be helpful for identifying the sensitive targets of expressive writing intervention. However, considering that this is a preliminary study, more rigorous randomized controlled trials will be helpful to test this conclusion in future.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Low level of physical activity is an independent risk factor of civilization disorders. Intervention for increasing physical activity has been for generations mentioned in health care. Because of low adherence of the population to those general appeals it is necessary to improve radically the knowledge of health professionals about individual exercise prescription. The aim of this study was to analyze approach of medical doctors in this particular dilemma. A questionnaire was distributed at postgraduate courses for medical doctors. Data from doctors of different specializations were summarized (N=657, from which 458 were females, i.e. 69,7 %, mean age=38,8+/-9,74). 96,4 % of doctors stated that they recommend exercise to their patients though only up to 23,4 % of them are regularly asked by their patients about the exercise. Concrete (type, intensity, duration and frequency) or individually tailored recommendation give 66,2 %, or 62,6 % of doctors respectively. Most respondents (56,0 %) also recommend a consultation of another specialist (mostly rehabilitation doctor and physiotherapist). Majority of addressed professionals shows that current medical education structure does not enable adequate prescription of physical activity without the help of specialist.\nQuestion: Is prescription of physical activity a part of health care in civilization disorders?",
        "gt": "Study showed a positive attitude of medical doctors to exercise prescription. However, information about the need of individualized prescription and knowledge about possibilities of exercise therapy in particular regions should be increased.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We investigated whether routine elective irradiation of a clinically negative inguinal node (IGN) is necessary for patients with locally advanced distal rectal cancer and anal canal invasion (ACI). We reviewed retrospectively 1,246 patients with locally advanced rectal adenocarcinoma managed using preoperative or postoperative chemoradiotherapy and radical surgery between 2001 and 2011. The patients' IGN was clinically negative at presentation and IGN irradiation was not performed. ACI was defined as the lower edge of the tumor being within 3 cm of the anal verge. Patients were divided into two groups, those with ACI (n\u2009=\u2009189, 15.2%) and without ACI (n\u2009=\u20091,057, 84.8%). The follow-up period was a median of 66 months (range, 3-142 months). Among the 1,246 patients, 10 developed IGN recurrence; 7 with ACI and 3 without ACI. The actuarial IGN recurrence rate at 5 years was 0.7%; 3.5% and 0.2% in patients with and without ACI, respectively (p\u2009<\u20090.001). Isolated IGN recurrence occurred in three patients, all of whom had ACI tumors. These three patients received curative intent local treatments, and one was alive with no evidence of disease 10 years after IGN recurrence. Salvage treatments in the other two patients controlled successfully the IGN recurrence for>5 years, but they developed second malignancy or pelvic and distant recurrences. Seven patients with non-isolated IGN recurrence died of disease at 5-22 months after IGN recurrence.\nQuestion: Is elective inguinal radiotherapy necessary for locally advanced rectal adenocarcinoma invading anal canal?",
        "gt": "The low IGN recurrence rate even with ACI and the feasibility of salvage of isolated IGN recurrence indicated that routine elective IGN irradiation is not necessary for rectal cancer with ACI.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the long-term oncological outcome of patients with primary transitional cell carcinoma (TCC) of the distal ureter electively treated with either kidney-sparing surgery (KSS) or radical nephroureterectomy (RNU) in a retrospective, non-randomized, single-centre study. Of 43 consecutive patients with a primary solitary distal ureter TCC, 19 had KSS, consisting of distal ureter resection with bladder cuff excision and ureter reimplantation, and 24 had RNU with bladder cuff excision. The median (range) age at surgery was 69 (31-86) years for the KSS group and 73 (59-87) years for the RNU group, patients in the latter having worse hydronephrotic kidneys. The median (range) follow-up was 58 (3-260) months. A recurrent bladder tumour was diagnosed after a median of 15 months in five of the 19 patients treated by KSS and after a median of 5.5 months in eight of the 24 treated by RNU. Five of the 19 patients treated by KSS and six of the 24 treated by RNU died from metastatic disease despite chemotherapy. Recurrence-free, cancer-specific and overall survival were comparable in the two groups. In two patients (11%) treated by KSS an ipsilateral upper urinary tract TCC recurred after 42 and 105 months, respectively.\nQuestion: Elective management of transitional cell carcinoma of the distal ureter: can kidney-sparing surgery be advised?",
        "gt": "Treatment by distal ureteric resection is feasible in patients with primary TCC of the distal ureter. The long-term oncological outcome seems to be comparable with that of patients treated by RNU. Furthermore, kidney preservation is advantageous if adjuvant or salvage chemotherapy is required.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the rates of Staphylococcus aureus carriage on the hands and in the noses of healthcare workers (HCWs) and the relatedness of S. aureus isolates found in the two sites. Point-prevalence study. Department for Thoracic and Cardiovascular Surgery at the University Hospital of Uppsala, Uppsala, Sweden. Samples were obtained from 133 individuals, 18 men and 115 women, using imprints of each hand on blood agar and a swab from the nose. S. aureus isolates were identified by standard methods and typed by pulsed-field gel electrophoresis. S. aureus was found on the hands of 16.7% of the men and 9.6% of the women, and in the noses of 33.3% of the men and 17.4% of the women. The risk ratio for S. aureus carriage on the hands with nasal carriage was 7.4 (95% confidence interval, 2.7 to 20.2; P<.001). Among the 14 HCWs carrying S. aureus on their hands, strain likeness to the nasal isolate was documented for 7 (50%).\nQuestion: Nasal and hand carriage of Staphylococcus aureus in staff at a Department for Thoracic and Cardiovascular Surgery: endogenous or exogenous source?",
        "gt": "Half of the HCWs acquired S. aureus on the hands from patients or the environment and half did so by apparent self-inoculation from the nose. Regardless of the source of contamination, good compliance with hand hygiene is needed from all HCWs to protect patients from nosocomial infections. The moderate rate of S. aureus carriage on hands in this setting could be the result of the routine use of alcoholic hand antisepsis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A pharmacoinvasive (PI) strategy for early presenting ST-segment elevation myocardial infarction nominally reduced 30-day cardiogenic shock and congestive heart failure compared with primary percutaneous coronary intervention (PPCI). We evaluated whether infarct size (IS) was related to this finding. Using the peak cardiac biomarker in patients randomized to PI versus PPCI within the Strategic Reperfusion Early After Myocardial Infarction (STREAM) trial, IS was divided into 3 groups: small (\u22642 times the upper limit normal [ULN]), medium (>2 to \u22645 times the upper limit normal) and large (>5 times the upper limit normal). The association between IS and 30-day shock and congestive heart failure was subsequently examined. Data on 1701 of 1892 (89.9%) patients randomized to PI (n=853, 50.1%) versus PPCI (n=848, 49.9%) within STREAM were evaluated. A higher proportion of PPCI patients had a large IS (PI versus PPCI: small, 49.8% versus 50.2%; medium, 56.9% versus 43.1%; large, 48.4% versus 51.6%; P=0.035), despite comparable intergroup ischemic times for each reperfusion strategy. As IS increased, a parallel increment in shock and congestive heart failure occurred in both treatment arms, except for the small IS group. The difference in shock and congestive heart failure in the small IS group (4.4% versus 11.6%, P=0.026) in favor of PI likely relates to higher rates of aborted myocardial infarction with the PI strategy (72.7% versus 54.3%, P=0.005). After adjustment, a trend favoring PI persisted in this subgroup (relative risk 0.40, 95% CI 0.15 to 1.06, P=0.064); no difference in treatment-related outcomes was evident in the other 2 groups.\nQuestion: Infarct Size, Shock, and Heart Failure: Does Reperfusion Strategy Matter in Early Presenting Patients With ST-Segment Elevation Myocardial Infarction?",
        "gt": "A PI strategy appears to alter the pattern of IS after ST-segment elevation myocardial infarction, resulting in more medium and fewer large infarcts compared with PPCI. Despite a comparable number of small infarcts, PI patients in this group had more aborted myocardial infarctions and less 30-day shock and congestive heart failure.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Whole-brain radiation therapy (WBRT), open resection, and stereotactic radiosurgery (SRS) are widely used for treatment of metastatic brain lesions, and many physicians recommend WBRT for multiple brain metastases. However, WBRT can be performed only once per patient, with rare exceptions. Some patients may require SRS for multiple metastatic brain lesions, particularly those patients harboring more than 10 lesions. In this paper, treatment results of SRS for brain metastasis were analyzed, and an attempt was made to determine whether SRS is effective, even in cases involving multiple metastatic brain lesions. The authors evaluated the cases of 323 patients who underwent SRS between October 2005 and October 2008 for the treatment of metastatic brain lesions. Treatment was performed using the Gamma Knife model C or Perfexion. The patients were divided into 4 groups according to the number of lesions visible on MR images: Group 1, 1-5 lesions; Group 2, 6-10 lesions: Group 3, 11-15 lesions; and Group 4,>15 lesions. Patient survival and progression-free survival times, taking into account both local and distant tumor recurrences, were analyzed. The patients consisted of 172 men and 151 women with a mean age at SRS of 59 years (range 30-89 years). The overall median survival time after SRS was 10 months (range 8.7-11.4 months). The median survival time of each group was as follows: Group 1, 10 months; Group 2, 10 months; Group 3, 13 months; and Group 4, 8 months. There was no statistical difference between survival times after SRS (log-rank test, p = 0.554), although the probability of development of new lesions in the brain was greater in Group 4 (p = 0.014). Local tumor control rates were not statistically different among the groups (log-rank test, p = 0.989); however, remote disease progression was more frequent in Group 4 (log-rank test, p = 0.014).\nQuestion: Analysis of radiosurgical results in patients with brain metastases according to the number of brain lesions: is stereotactic radiosurgery effective for multiple brain metastases?",
        "gt": "In this study, patients harboring more than 15 metastatic brain lesions were found to have faster development of new lesions in the brain. This may be due to the biological properties of the patients' primary lesions, for example, having a greater tendency to disseminate hematogenously, especially to the brain, or a higher probability of missed or invisible lesions (microscopic metastases) to treat on stereotactic MR images at the time of radiosurgery. However, the mean survival times after SRS were not statistically different between groups. According to the aforementioned results, SRS may be a good treatment option for local control of metastatic lesions and for improved survival in patients with multiple metastatic brain lesions, even those patients who harbor more than 15 metastatic brain lesions, who, after SRS, may have early and easily detectable new metastatic lesions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Physicians tend to over or underestimate symptoms reported by patients. Therefore standardized symptom scoring systems have been proposed to overcome this drawback.AIM: To estimate the prevalence and the diagnostic accuracy of physical and psychological symptoms and delirium in patients admitted to an internal medicine service at a university hospital. We studied 58 patients, 45 with metastasic cancer and 13 with other advanced chronic diseases. The following scales were used: the Confusion Assessment Method for the diagnosis of delirium; the Edmonton Symptom Assessment Scale (ESAS) for pain and other physical symptoms; the Hospital Anxiety and Depression Scale to assess anxiety and depression. The ESAS was simultaneously applied to patients without delirium and their doctors to assess the level of diagnostic concordance. Twenty two percent of patients had delirium. Among the 45 patients without delirium, 11 (25%) had at least eight symptoms and 39 (88.6%) had four symptoms. The prevalence of symptoms was very high, ranging from 22 to 78%. Pain, restlessness, anorexia and sleep disorders were the most common. The concordance between symptoms reported by patients and those recorded by doctor was very low, with a Kappa index between 0.001 and 0.334.\nQuestion: Frequency and assessment of symptoms in hospitalized patient with advanced chronic diseases: is there concordance among patients and doctors?",
        "gt": "In our sample of chronic patients, there is a very high frequency of psychological and physical symptoms that are insufficiently recorded by the medical team.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Millions of dollars are spent each year by individuals seeking to improve their athletic performance. One area of visual training is the use of the tachistoscope, which measures inspection time or visual recognition time. Although the potential of the tachistoscope as a training tool has received some research attention, its use as a means of measurement or predictor of athletic ability in sports has not been explored. The purpose of this pilot study is to assess the potential of the tachistoscope as a measurement instrument by determining if a baseball player's ability to identify a tachistoscopically presented picture of a pitch is correlated with hitting performance as measured by batting average. Using sport-specific slides, 20 subjects-all non-pitching members of the Pacific University Baseball Team-were administered a tachistoscopic test. The test consisted of identifying the type of pitch illustrated in 30 randomly ordered slides depicting a pitcher throwing four different baseball pitches. Each slide was presented for 0.2 sec. The results of the test were compared with the athlete's previous season's batting average. A positive correlation was found between an athlete's ability to correctly identify a picture of a pitch presented tachistoscopically and batting average (r=0.648; P<0.01). These results suggest that a superior ability to recognize pitches presented via tachistoscope may correlate with a higher skill level in batting.\nQuestion: Do scores on a tachistoscope test correlate with baseball batting averages?",
        "gt": "Tachistoscopic test scores correlated positively with batting averages. The tachistoscope may be an acceptable tool to help in assessing batting performance. Additional testing with players from different sports, different levels of ability, and different tachistoscopic times should be performed to determine if the tachistoscope is a valid measure of athletic ability. Implications may also be drawn in other areas such as military and police work.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Chronic total occlusion (CTO) of coronary vessels is still a challenge for percutaneous coronary intervention and recent data show unfavorable long-term results compared with medical therapy. It is unclear whether CTO is also a negative predictor for long-term outcome in minimally invasive bypass grafting. From 1996 to 2007 minimally invasive surgical revascularization of the left internal mammary artery to the left anterior descending artery (LAD) was performed in 1,800 patients. Demographic data, risk factors, perioperative outcome, and annual follow-up were obtained from all patients. Estimated survival and freedom from major adverse cardiac and cerebrovascular events or recurrence of angina with log-rank tests and Cox regression analysis for identification of independent risk factors were calculated for patients with (420 patients) and without (1,380 patients) CTO of the LAD. Revascularization of the LAD could be completed in all but one patient (99.8% success rate with CTO). At 5 years estimated overall survival was 90.5% (95% confidence interval [CI] 85.8 to 95.5) with CTO and 90.4% (95% CI 85.8 to 95.1) without CTO (p = 0.91). Freedom from major adverse cardiac and cerebrovascular events and angina with or without CTO at 5 years was 83.2% (95% CI 77.6 to 88.8) and 85.5% (95% CI 82.6 to 88.1), respectively (p = 0.64). Chronic occlusion of the target vessel and other preoperative factors were not identified as risk factors for major adverse cardiac and cerebrovascular events during follow-up.\nQuestion: Is chronic total coronary occlusion a risk factor for long-term outcome after minimally invasive bypass grafting of the left anterior descending artery?",
        "gt": "As opposed to percutaneous coronary intervention, minimally invasive bypass grafting of a totally occluded LAD is almost always possible and chronic occlusion is not a negative predictor for short and long-term outcome. Minimally invasive bypass grafting of the LAD should be considered the treatment of choice for chronically occluded left anterior descending arteries.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Concerns have been voiced that the use of sexually explicit materials (SEMs) may adversely affect sexual behaviors, particularly in young people. Previous studies have generally found significant associations between SEM consumption and the sexual behaviors investigated. However, most of these studies have focused on sexual behaviors related to sexually transmitted infections or sexual aggression and/or failed to adequately control for relevant covariates. Thus, research more thoroughly investigating the association between SEM consumption and a broader range of sexual behaviors is needed. The study aims to investigate SEM consumption patterns of young people, and to assess the strength of the association between SEM consumption and a range of sexual behaviors, controlling for a comprehensive array of variables previously shown to affect these relationships. Online cross-sectional survey study of 4,600 young people, 15-25 years of age, in The Netherlands was performed. The main outcome measures were self-reported SEM consumption and sexual practices. The study found that 88% of men and 45% of women had consumed SEM in the past 12 months. Using hierarchical multiple regression analyses to control for other factors, the association between SEM consumption and a variety of sexual behaviors was found to be significant, accounting for between 0.3% and 4% of the total explained variance in investigated sexual behaviors.\nQuestion: Does viewing explain doing?",
        "gt": "This study suggests that, when controlling for important other factors, SEM consumption influences sexual behaviors. The small to moderate associations that emerged between SEM consumption and sexual behavior after controlling for other variables suggest that SEM is just one factor among many that may influence youth sexual behaviors. These findings contribute novel information to the ongoing debates on the role of SEM consumption in sexual behaviors and risk, and provide appropriate guidance to policy makers and program developers concerned with sexual education and sexual health promotion for young people.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Exercise referral schemes are widespread across England. National guidance emphasises the need to engage groups that are disadvantaged.AIM: To examine the influence of socioeconomic deprivation on referral to, and use of, exercise referral schemes. Cross-sectional analysis of patients referred by general practices to exercise referral schemes between 2004 and 2006. Six primary care trusts (PCTs) in Greater London. Routine data about patients who had been referred to exercise referral schemes were used to estimate risk ratios for referral by general practice deprivation quintile, odds ratios (ORs) for uptake, and ORs for completion of exercise referral schemes by patients' deprivation status quintile. All 317 general practices in the six PCTs were included in the referral analysis. Referrals were less likely from general practices serving advantaged socioeconomic areas (adjusted risk ratio for trend across deprivation quintiles 0.84; 95% confidence interval [CI] = 0.76 to 0.93). This study found no association between patients' deprivation status and their likelihood of taking up (adjusted OR, least versus most deprived quintile 1.05; 95% CI = 0.83 to 1.33) or completing the scheme (adjusted OR 1.23; 95% CI = 0.84 to 1.79).\nQuestion: Do general practices provide equitable access to physical activity interventions?",
        "gt": "General practices within areas of deprivation were more likely to refer patients to exercise referral schemes than practices in more advantaged areas. Once referred, it was found that patients living in areas of deprivation were as likely to take up and to complete the scheme as those living in more advantaged locations. Research is needed to identify the organisational and contextual factors that allow this pattern of service delivery, which appears to facilitate access to care among patients who live in areas of deprivation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To qualitatively and quantitatively examine body image ideals and perceived weight-related health among African-American girls and their female caregivers to inform intervention development for Girls Rule!, an obesity prevention pilot program. Formative study using qualitative data from semi-structured interviews and validated quantitative body image silhouette assessment among girls (N=47) and caregivers (N=44). The participants were a convenience sample of African-American church members from North Carolina. Differences were evaluated between perceived: 1) current and ideal body size; 2) current and unhealthy body size; and 3) ideal and unhealthy body size. Thirty-seven percent of the girls and 77% of the caregivers were overweight or obese. Three body image themes emerged from the qualitative interviews: 1) being fat is unhealthy; 2) caregivers are role models (positive and negative) for body image ideals; and 3) smaller body size is important for wearing fashionable clothing. A series of 9 body silhouettes were used to assess perceptions of both girls and caregivers. Overall, both girls (2.9 +/- 1.4) and caregivers (4.4 +/- 1.4) ideal body size was significantly (P<.01) smaller than their current body size (3.7 +/- 1.3 girls; 6.3 +/- 2.2 caregivers). Both girls (3.7 +/- 1.4) and caregivers (6.7 +/- 2.0) indicated that their current body sizes were statistically significantly (P<.05) smaller that what they considered to be unhealthy (7.9 +/- 1.4 girls; 7.9 +/- 1.2 caregivers).\nQuestion: \"Does skinny mean healthy?",
        "gt": "Results suggest that most of these African-American participants were not satisfied with their current body size and desired a smaller body. At the same time, both girls and caregivers failed to recognize the potential health consequences associated with their current body size. Critical issues for designing obesity prevention programs include positive role modeling within the family and addressing the association of body size with health risk.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Equations published in literature for predicting resting metabolic rate (RMR) in older individuals were derived from studies with small samples of this age group or extrapolated from data of younger adults. The aim of the present investigation was therefore to validate various predictive equations by comparing calculated RMR with measured RMR in a large group of elderly subjects. RMR was measured by indirect calorimetry after an overnight fast in 225 female (age 67.7 +/- 5.7 y, BMI 26.7 +/- 3.9 kg/m2) and 130 male (age 67.4 +/- 5.4 y, BMI 26.7 +/- 3.2 kg/m2) participants of the longitudinal study on nutrition and health status in an aging population of Giessen, Germany, who were at least 60 years old. In females and males RMR was on average underestimated by 3.3% and 7.5% with the Schofield equation based on body weight, by 2.4% and 4.5% with the Schofield equation based on both weight and height, by 0.7% and 5.0% with the WHO equation based on body weight, and by 2.6% and 4.6% with the Harris-Benedict equation, respectively. RMR calculated with the WHO equation based on body weight and height was 1.8% higher in females and 3.9% lower in males compared to measured RMR. Regarding all predictive equations the difference between predicted and measured RMR were negatively correlated with measured RMR and were partly more pronounced in smokers and obese subjects than in non-smokers and subjects with a BMI<30 kg/m2.\nQuestion: Are the equations published in literature for predicting resting metabolic rate accurate for use in the elderly?",
        "gt": "At the group level all predictive equations used provide a valid estimation of RMR. However, on an individual basis estimation errors may be high. Thus in individuals RMR should be measured instead of being estimated. If measurements cannot be taken, population specific equations should be used for predicting RMR.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the impact of the introduction of graphic health warning labels on cigarette packets on adolescents at different smoking uptake stages. School-based surveys conducted in the year prior to (2005) and approximately 6 months after (2006) the introduction of the graphic health warnings. The 2006 survey was conducted after a TV advertising campaign promoting two new health warnings. Secondary schools in greater metropolitan Melbourne, Australia. Students in year levels 8-12: 2432 students in 2005, and 2050 in 2006, participated. Smoking uptake stage, intention to smoke, reported exposure to cigarette packs, knowledge of health effects of smoking, cognitive processing of warning labels and perceptions of cigarette pack image. At baseline, 72% of students had seen cigarette packs in the previous 6 months, while at follow-up 77% had seen packs and 88% of these had seen the new warning labels. Cognitive processing of warning labels increased, with students more frequently reading, attending to, thinking and talking about warning labels at follow-up. Experimental and established smokers thought about quitting and forgoing cigarettes more at follow-up. At follow-up intention to smoke was lower among those students who had talked about the warning labels and had forgone cigarettes.\nQuestion: Do graphic health warning labels have an impact on adolescents' smoking-related beliefs and behaviours?",
        "gt": "Graphic warning labels on cigarette packs are noticed by the majority of adolescents, increase adolescents' cognitive processing of these messages and have the potential to lower smoking intentions. Our findings suggest that the introduction of graphic warning labels may help to reduce smoking among adolescents.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: New therapies for metastatic non-small cell lung cancer (NSCLC) have improved survival in clinical trials. However, only a minority of patients receive systemic therapy. This article reports treatment patterns and outcomes for a population of Canadian patients with metastatic NSCLC (Ontario). Patients diagnosed with stage IV NSCLC from 2005 to 2009 were identified through multiple linked provincial databases. Patient demographics, systemic treatment, and survival were examined over time. Metastatic NSCLC patients (n\u2009=\u20098113) were identified. The median age was 68 years; 39% had adenocarcinoma, 14% had squamous carcinoma, and a higher than expected proportion (43%) had NSCLC not otherwise specified. Only 24% the patients received first-line chemotherapy; only 31% of these received second-line chemotherapy. More patients received systemic therapy over time (from 19% in 2005 to 26% in 2009, P\u2009<\u2009.0001). Patients who were less than 70 years old or had adenocarcinoma were more likely to receive systemic therapy (P\u2009<\u2009.0001 for both). The median survival, regardless of age, for those selected to receive first-line cisplatin-gemcitabine chemotherapy was longer than that for those receiving other nonpemetrexed platinum doublets at 11.6 months (P\u2009=\u2009.0002). Patients with nonsquamous histology who were treated with second-line pemetrexed had longer median survival than those treated with docetaxel (19.8 vs 14.1 months, P\u2009<\u2009.0001).\nQuestion: Real-world chemotherapy treatment patterns in metastatic non-small cell lung cancer: Are patients undertreated?",
        "gt": "Most patients with metastatic NSCLC in the general population still do not receive systemic therapy. Those selected for first- and second-line systemic treatment, including older patients, have survival outcomes comparable to clinical trial results. Older patients and patients with squamous histology are less likely to receive chemotherapy. The low levels of treatment utilization in this study warrant further investigation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The authors use data from the AIDS Costs and Service Utilization Survey (ACSUS) to investigate the extent to which use of ambulatory medical care is associated with inpatient and emergency department use among HIV-infected persons. Parameter estimates were derived from simultaneous, multiequation models. Higher use of ambulatory medical services is not significantly associated with lower probability of inpatient admissions or emergency department (ED) visits. For the subgroup of patients who received an AIDS diagnosis during the study period, however, the number of ambulatory visits had significant negative effects on hospitalizations and ED use.\nQuestion: Is outpatient care associated with lower use of inpatient and emergency care?",
        "gt": "Outpatient care may offset inpatient and ED services at particular points in the disease course.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this study was to investigate the potential therapeutic roles of honey, prednisolone and disulfiram in an experimental model of inflammatory bowel disease. Another aspect of the study was to find out whether these substances have any effect on nitric oxide (NO) and free radical production. After the induction of colitis with trinitrobenzene sulfonic acid in 64 male rats, physiological saline, honey, prednisolone and disulfiram enemas were applied to the rats once daily for 3 days (acute treatment groups) or 7 days (chronic treatment groups). Control groups received only saline enemas. Rats were killed on the 4th or 8th days and their colonic mucosal damage was quantitated using a scoring system. Acute and chronic inflammatory responses were determined by a mucosal injury score, histological examination and measurement of the myeloperoxidase (MPO) activity of tissues. The content of malonylaldehyde (MDA) and NO metabolites in colon homogenates was also measured to assess the effects of these substances on NO and free oxygen radical production. Estimation of colonic damage by mucosal injury scoring was found to be strongly correlated with the histologic evaluation of colon specimens. On the other hand, mucosal injury scores were not correlated with MPO, MDA or NO values. There were significant differences between the MPO results of chronic-control and chronic-honey groups, as well as chronic-control and chronic-prednisolone groups (p = 0.03 and p = 0.0007). The acute honey, prednisolone, and disulfiram groups had significantly lower MDA results compared to the acute control group (p = 0.04, p = 0.02, and p = 0.04). In terms of NO, there was no significant difference between the treatment and control groups. NO was found to have a strong relationship with MDA (p = 0.03) and MPO values (p = 0.001). On the other hand, MPO results were not found to be correlated with MDA values (p>0.05).\nQuestion: Could honey have a place in colitis therapy?",
        "gt": "MPO activity is not directly proportional to the severity of the inflammation, but it may only determine the amount of neutrophil in the tissues. Inflammatory cells are not the sole intensifying factor in colitis. Therefore, mucosal injury scores may not correlate well with MPO activities. In an inflammatory state NO and MPO levels have a strong relationship, since NO is released from the neutrophils. In an inflammatory model of colitis, intrarectal honey administration is as effective as prednisolone treatment. Honey may have some features in the treatment of colitis, but this issue requires further investigation. Honey, prednisolone and even disulfiram also have some value in preventing the formation of free radicals released from the inflamed tissues. Prednisolone may also have some possible benefits in the inhibition of NO production in colitis therapy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: While damage control (DC) techniques such as the rapid control of exsanguinating haemorrhage and gastrointestinal contamination have improved survival in severely injured patients, the optimal pancreatic injury management strategy in these critically injured patients requiring DC is uncertain. We sought to characterise pancreatic injury patterns and outcomes to better determine optimal initial operative management in the DC population. A two-centre, retrospective review of all patients who sustained pancreatic injury requiring DC in two urban trauma centres during 1997-2004 revealed 42 patients. Demographics and clinical characteristics were analysed. Study groups based on operative management (pack+/-drain vs. resection) were compared with respect to clinical characteristics and hospital outcomes. The 42 patients analysed were primarily young (32.8+/-16.2 years) males (38/42, 90.5%) who suffered penetrating (30/42, 71.5%) injuries of the pancreas and other abdominal organs (41/42, 97.6%). Of the 12 patients who underwent an initial pancreatic resection (11 distal pancreatectomies, 1 pancreaticoduodenectomy), all distal pancreatectomies were performed in entirety during the initial laparotomy while pancreaticoduodenectomy reconstruction was delayed until subsequent laparotomy. Comparing the pack+/-drain and resection groups, no difference in mechanism, vascular injury, shock, ISS, or complications was revealed. Mortality was substantial (packing only, 70%; packing with drainage, 25%, distal pancreatectomy, 55%, pancreaticoduodenectomy, 0%) in the study population.\nQuestion: Pancreatic injury in damage control laparotomies: Is pancreatic resection safe during the initial laparotomy?",
        "gt": "The presence of shock or major vascular injury dictates the extent of pancreatic operative intervention. While pancreatic resection may be required in selected damage control patients, packing with pancreatic drainage effectively controls both haemorrhage and abdominal contamination in patients with life-threatening physiological parameters and may lead to improved survival. Increased mortality rates in patients who were packed without drainage suggest that packing without drainage is ineffective and should be abandoned.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We investigated the clinicopathological features in patients with recurrent renal cell carcinoma (RCC) within 5 years or more than 5 years after nephrectomy and determined predictors of overall survival (OS) and progression-free survival (PFS) after disease recurrence in the administration of first-line sunitinib in the treatment of metastatic RCC (mRCC). In this study we enrolled 86 Turkish patients with mRCC who received sunitinib. Univariate analyses were performed using the log rank test. Fifty-six patients (65%) were diagnosed with disease recurrence within 5 years after radical nephrectomy (early recurrence) and 30 patients (35%) were diagnosed with recurrence more than 5 years after radical nephrectomy (late recurrence). Fuhrman grade was statistically significantly different between the 2 groups (P = .013). The late recurrence patients were significantly associated with the Memorial Sloan Kettering Cancer Center favorable risk group compared with patients with early recurrence (P = .001). There was a statistically significant correlation between recurrence time and the rate of objective remission (ORR) (the late recurrence group vs. the early recurrence group: 43.3% vs. 14.3%, respectively; P = .004). From the time of disease recurrence, the median OS was 42.0 (95% confidence interval [CI], 24.4-59.5) months in the late recurrence group, and 16 (95% CI, 11.5-20.4) months in the early recurrence group (P = .001). Median PFS was 8 (95% CI, 4.05-11.9) months in the early recurrence group, and 20 (95% CI, 14.8-25.1) months in the late recurrence group (P \u2264 .001).\nQuestion: Is Late Recurrence a Predictive Clinical Marker for Better Sunitinib Response in Metastatic Renal Cell Carcinoma Patients?",
        "gt": "The study demonstrated a potential prognostic value of late recurrence in terms of PFS, OS, and ORR.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Mortality and morbidity rates, traditionally used indicators for child injury, are limited in their ability to explain differences in child injury between countries, are inadequate in capturing actions to address the problem of child injury and do not adequately identify progress made within countries. There is a need for a broader set of indicators to help better understand the success of countries with low rates of child injury, provide guidance and benchmarks for policy makers looking to make investments to reduce their rates of fatal and non-fatal child injury and allow monitoring of progress towards achieving these goals. This article describes an assessment of national leadership, infrastructure and capacity in the context of child injury prevention in 18 countries in Europe and explores the potential of these to be used as additional indicators to support child injury prevention practice. Partners in 18 countries coordinated data collection on 21 items relating to leadership, infrastructure and capacity. Responses were coded into an overall score and scores for each of the three areas and were compared with child injury mortality rankings using Spearman's rank correlation. Overall score and scores for leadership and capacity were significantly negatively correlated to child injury mortality ranking.\nQuestion: Leadership, infrastructure and capacity to support child injury prevention: can these concepts help explain differences in injury mortality rankings between 18 countries in Europe?",
        "gt": "Findings of this preliminary work suggest that these three policy areas may provide important guidance for the types of commitments that are needed in the policy arena to support advances in child safety and their assessment a way to measure progress.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess whether TNODS is an independent prognostic factor after adjusting for the lymph node ratio (LNR). The medical literature has suggested that the TNODS is associated with better survival in stage II and III colon cancer. Thus TNODS was endorsed as a quality measure for patient care by American College of Surgeons, National Quality Forum. There is, however, little biologic rationale to support this linkage. : A total of 24,477 stage III colon cancer patients were identified from Surveillance, Epidemiology, and End Results cancer registry and categorized into 4 groups, LNR1 to LNR4, according to LNR interval:<0.07, 0.07 to 0.25, 0.25 to 0.50, and>0.50. Patients were also stratified according to TNODS into high TNODS (>or = 12) and low TNODS (<12) groups. The method of Kaplan-Meier was used to estimate the 5-year survival and the log-rank test was used to test the survival difference among the different groups. Patients with high TNODS have better survival compared with those with low TNODS (5-year survival 51.0% vs. 45.0%, P<0.0001). However, after stratifying by LNR status, there was no significant survival difference between patients with high TNODS and those with low TNODS within strata LNR2 (5-year survival 56.3% vs. 56.0%, P = 0.26). Ironically, patients with high TNODS had significantly worse survival than those with low TNODS within strata LNR3 (5-year survival 41.2% vs. 47.4%, P = 0.0009) and LNR 4 (5-year survival 22.0% vs. 32.1%, P<0.0001).\nQuestion: Should total number of lymph nodes be used as a quality of care measure for stage III colon cancer?",
        "gt": "The previously reported prognostic effect of TNODS on node-positive colon cancer was confounded by LNR. This observation calls into question the use of TNODS as a quality measure for colon cancer patients' care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To discover if any adverse clinical effects have been reported to the UK haemovigilance scheme, Serious Hazards of Transfusion (SHOT) relating to delays in set up of transfusion or extended transfusion time for red cell units. Current guidance for duration of transfusion is based on outdated studies that do not reflect current UK Blood Service practices. Recent evidence suggests that the '30-min rule' could be extended without adverse effects. Aggregated data from reports to SHOT covering a 5-year period (2010-2014) were reviewed in order to identify adverse clinical outcomes related to delay in set up of a red cell transfusion of more than 30 min after removal from cold storage, or total transfusion time of longer than 5 h. Five years of data from SHOT shows that there were no adverse clinical events related to delays in setting up transfusion or extended transfusion time between 2010 and 2014. There were a total of 382 reports which included 143 delays in set-up, and 239 episodes where transfusion took longer than 5 h.\nQuestion: Are the 'rules' for times in set up and duration of red cell transfusion too strict?",
        "gt": "Delays in set up of transfusion and extended transfusion time did not result in any adverse clinical outcomes. Current guidance may be too stringent and lead to increased wastage.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Clinical trial evidence shows minimal survival gains and higher complication rates from radical prostatectomy (RP) versus watchful waiting (WW) for elderly men with localized prostate cancer (PCa). It is believed that these patients are overtreated. The current analyses aim to explore patient-level heterogeneity in survival effects, examine matching of patients to treatments in practice, and identify patient characteristics driving heterogenous effects, in order to present more comprehensive evidence about the concerns of overtreatment. Eleven-year all-cause and PCa-specific survival among SEER-Medicare patients diagnosed during 1996-2002 were analyzed using local instrumental variable approaches. A total of 8462 (77%) of 11,036 patients received RP. The average effects of RP over WW on 11-year overall and cancer-specific survival were 1.1 months (95%CI, -25, 28; P=0.94) and 1.7 months (95%CI, -25, 29; P=0.90) respectively; effects did not differ significantly according to age, race, grade, and stage. Fewer than 1% of patients had significant cancer-specific survival benefit from RP at the 10% level; 6% were expected to gain over 15 months from RP. However, patients with larger expected survival gains from RP were much more likely to receive RP in practice. Such positive self-selection was driven by PCa-specific survival than overall survival. Several comorbidities may play a critical role in predicting who could benefit from RP.\nQuestion: Are Elderly Patients With Clinically Localized Prostate Cancer Overtreated?",
        "gt": "Our analyses corroborate concerns about PCa overtreatment. A small fraction of screen-detected PCa patients derive survival benefits from RP. Prediction tools should account for patient comorbidities to accurately predict survival benefits of RP over WW.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In this retrospective study, we aimed to analyze the frequency of thyroid cancer in patients who underwent thyroidectomy for hyperthyroidism. A total number of 177 patients, who underwent surgery for hyperthyroidism between August 2005 and March 2010, were included in this study. Demographic, clinical, radiologic, and laboratory data were collected retrospectively.Results. Postoperative histopathological examinations revealed thyroid malignancy in 13 (7.3%) patients. Among these 13 patients presenting thyroid malignancy, 53.9% were diagnosed with multinodular toxic goiter (MTG), 38.5% with uninodular toxic goiter (UTG) and 7.6% with Graves' disease.\nQuestion: Thyroid cancer in hyperthyroid patients: is it different clinical entity?",
        "gt": "Thyroid carcinoma is common in hyperthyroidism and thyroid fine-needle aspiration biopsy (TFNAB) is a reliable method in the diagnosis of the thyroid malignancy in these patients. We suggest that it is reasonable to evaluate nodules with TFNAB in hyperthyroid patients prior to surgical intervention.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Coronary endothelial dysfunction after heart transplantation is predictive of cardiac allograft vasculopathy. Immunosuppressive drugs, particularly cyclosporine may contribute to this dysfunction by a direct effect. Tetrahydrobiopterin (BH(4)) is a potent antioxidant and an essential cofactor of nitric oxide biosynthesis. The purpose of this study was to investigate whether BH(4) could reverse the endothelial dysfunction induced by cyclosporine. A previously described in vitro model of drug incubation in Krebs-bicarbonate solution (4 degrees C, 48 hours) of porcine epicardial coronary arteries was used. Coronary endothelial function studies were performed in organ chamber experiments after incubation with cyclosporine (10(-4) mol/L) in the presence or absence of 6-methyltetrahydropterin (MH(4) [0.1 mol/L], a BH(4) analog) to assess its effect on the cyclosporine-induced endothelial dysfunction. The average doses of PGF2(alpha) required to attain 50% of the maximal contraction to KCl was significantly lower (P<.001) in the cyclosporine group (8.6 +/- 1.94 x 10(-6) mol/L) compared to the control group (24.8 +/- 5.2 x 10(-6) mol/L). Exposure to cyclosporine induced a significant decrease in endothelium-dependent relaxations to serotonin (5HT) (% E(max) [5HT]: 77% +/- 4%; P<.05). Addition of MH(4) significantly reversed this impaired response (% E(max) [5HT]: 62% +/- 4%; P<.05). No alterations of relaxation were observed with bradykinin in both groups. Endothelium-independent relaxations to sodium nitroprussiate were fully preserved.\nQuestion: Cyclosporine-induced coronary endothelial dysfunction: is tetrahydrobiopterin the solution?",
        "gt": "These results suggest a significant protective role of BH(4) on coronary endothelial function following exposure to cyclosporine, which could reduce the incidence of endothelial dysfunction and cardiac allograft vasculopathy following cardiac transplantation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the effect(s) of transient events which are perceived as stressful on the inseption of preterm delivery. A case-control study, with immature infants as cases and borderline term babies as controls. A teaching maternity hospital in Athens. All infants born at less than 37 weeks of gestation, during a twelve-month period. Information was collected about maternal socio-demographic and lifestyle characteristics, clinical variables and stressful events occurring within two weeks prior to delivery. Factors affecting the risk of preterm delivery. Extreme prematurity (<33 weeks) is more common among younger (<25 years of age) and older (>29 years of age) women and is positively associated with parity, body mass index and smoking, whereas it is inversely associated with educational level, regular physical exercise and serious nausea/vomiting. After controlling for these factors, however, only coitus during the last weeks of pregnancy had a significant triggering effect on prematurity (P = 0.004, odds ratio 3.21, 95% CI 1.45 to 7.09 for very immature babies, and P = 0.04, OR = 2.20, 95% CI 1.03 to 4.70 for immature babies). On the contrary, several events perceived as stressful, such as illness of relatives or friends, husband's departure, loss of employment, were unrelated to the onset of premature labour.\nQuestion: Are there common triggers of preterm deliveries?",
        "gt": "Coitus during the last few weeks of pregnancy appears to increase the risk of preterm delivery, while a possible detrimental effect of physical exertion seems more limited. Stressful events should not receive undue attention as possible causes of preterm delivery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study aimed to reassess whether the Forrest classification is still useful for the prediction of rebleeding and mortality in peptic ulcer bleedings and, based on this, whether the classification could be simplified. Prospective registry data on peptic ulcer bleedings were collected and categorized according to the Forrest classification. The primary outcomes were 30-day rebleeding and all-cause mortality rates. Receiver operating characteristic curves were used to test whether simplification of the Forrest classification into high risk (Forrest Ia), increased risk (Forrest Ib-IIc), and low risk (Forrest III) classes could be an alternative to the original classification. In total, 397 patients were included, with 18 bleedings (4.5%) being classified as Forrest Ia, 73 (18.4%) as Forrest Ib, 86 (21.7%) as Forrest IIa, 32 (8.1%) as Forrest IIb, 59 (14.9%) as Forrest IIc, and 129 (32.5%) as Forrest III. Rebleeding occurred in 74 patients (18.6%). Rebleeding rates were highest in Forrest Ia peptic ulcers (59%). The odds ratios for rebleeding among Forrest Ib-IIc ulcers were similar. In subgroup analysis, predicting rebleeding using the Forrest classification was more reliable for gastric ulcers than for duodenal ulcers. The simplified Forrest classification had similar test characteristics to the original Forrest classification.\nQuestion: Reassessment of the predictive value of the Forrest classification for peptic ulcer rebleeding and mortality: can classification be simplified?",
        "gt": "The Forrest classification still has predictive value for rebleeding of peptic ulcers, especially for gastric ulcers; however, it does not predict mortality. Based on these results, a simplified Forrest classification is proposed. However, further studies are needed to validate these findings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Methylation of O(6)-methylguanine-DNA methyltransferase (MGMT) has been reported to be a good prognostic factor for patients with glioblastoma multiforme (GBM). To determine whether the absolute value of MGMT messenger RNA (mRNA) might be a prognostic factor and useful for predicting the therapeutic effectiveness of temozolomide, especially with regard to GBMs, the authors measured the absolute value of MGMT mRNA in gliomas by using real-time reverse-transcription polymerase chain reaction (RT-PCR). MGMT mRNA was measured in 140 newly diagnosed gliomas by real-time RT-PCR using the Taq-Man probe. Among 73 GBMs, 45 had been initially treated with temozolomide and radiation. The mean MGMT mRNA value was significantly lower in oligodendroglial tumors than in other tumors. In the 73 GBMs, a significant prognostic factor for progression-free survival was fewer than 1000 copies/ \u03bcgRNA of MGMT mRNA (p = 0.0150). Of 45 patients with GBMs that had been treated with temozolomide and radiation, progression-free survival was significantly longer for those whose GMB had fewer than 1000 copies/\u03bcgRNA of MGMT mRNA than for those whose GBM had more than 1000 copies/\u03bcgRNA (p = 0.0090). In 32 patients with GBMs treated by temozolomide and radiation whose age was younger than 75 years and whose Karnofsky Performance Scale score was more than 70, progression-free and overall survival times were longer for those with GBMs of fewer than 5000 copies/\u03bcgRNA of MGMT mRNA than for those with GBMs of more than 5000 copies/\u03bcgRNA (p = 0.0365 and p = 0.0312).\nQuestion: Is the absolute value of O(6)-methylguanine-DNA methyltransferase gene messenger RNA a prognostic factor, and does it predict the results of treatment of glioblastoma with temozolomide?",
        "gt": "MGMT mRNA might be useful as a prognostic factor and for predicting the results of therapy for GBMs treated by temozolomide. New individual adjuvant therapy based on the results of MGMT mRNA quantitation has been proposed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the tobacco-related education provided by post-secondary respiratory therapy training programs in the United States. A cross-sectional research design was used to survey the entire population of program directors of post-secondary, respiratory therapy training programs in the United States. A valid and reliable questionnaire was developed and mailed using a 2-wave mailing technique (73% return rate). Internal reliability coefficients (Cronbach alpha) for the various components of the questionnaire ranged from 0.78 to 0.91. More than half of programs (56%) offered no teaching on the 5R's. Nearly half (47%) offered no teaching on the 5A's. Of the 13 tobacco-related topics listed in the basic science and clinical science sections of the questionnaire, only one topic (i.e., diseases linked to tobacco use) received 3h or more of instruction by approximately a third of programs (35.8%). The majority of programs (>90%) spent no time teaching students about the socio-political aspects of tobacco use cessation. Moreover, 41% of programs did not formally evaluate students' competence in providing smoking cessation counseling to patients.\nQuestion: Do respiratory therapists receive training and education in smoking cessation?",
        "gt": "Tobacco-related education is a very minor component of the education and training received by respiratory therapy students in the United States.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The objective of the study was to describe trends in hysterectomy route at a large tertiary center. We reviewed all hysterectomies performed at Magee-Womens Hospital from 2000 to 2010. This database was chosen over larger national surveys because it has been tracking laparoscopic procedures since 2000, well before laparoscopic hysterectomy International Classification of Diseases, ninth revision (ICD-9) procedure codes were developed. There were 13,973 patients included who underwent hysterectomy at Magee-Womens Hospital. In 2000, 3.3% were laparoscopic (LH), 74.5% abdominal (AH), and 22.2% vaginal hysterectomy (VH). By 2010, LH represented 43.5%, AH 36.3%, VH 17.2%, and 3.0% laparoscopic converted to open (LH\u2192AH). Hysterectomies performed for gynecological malignancy represented 24.4% of cases. The average length of stay for benign LH and VH, 1.0 \u00b1 1.0 and 1.6 \u00b1 1.0 days respectively, was significantly shorter than the average 3.1 \u00b1 2.3 day stay associated with AH (P<.001). The average patient age was 46.9 \u00b1 10.9 years for LH, 51.5 \u00b1 12.1 years for AH, and 51.7 \u00b1 14.1 years for VH, and over the study period there was a significant trend of increasing patient age (b1 = 0.517, 0.583, and 0.513, respectively [P<.001 for all]).\nQuestion: Hysterectomy surgery trends: a more accurate depiction of the last decade?",
        "gt": "The percentage of LH increased over the last decade and by 2010 had surpassed AH. The 43.4% LH rate in 2010 is much higher than previously reported in national surveys. This likely is due to an increase in the number of laparoscopic procedures being performed over the last few years as well as the ability of our study to capture LH prior to development of appropriate ICD-9 procedure codes. Our unique ability to determine hysterectomy route, which predates appropriate coding, may provide a more accurate characterization of hysterectomy trends.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Computed tomography angiography (CTA) has been increasingly used in traumatic brain injury (TBI) patients to uncover vascular lesions that might have preceded the trauma and caused the bleed. This study aims to evaluate the usefulness of head CTA in the initial care of blunt TBI patients. We conducted a retrospective case-control analysis of adult TBI patients, admitted to our Level I trauma center from January 1, 2012 to December 31, 2012. The patients were grouped as those with and without a CTA of the head. The primary outcomes included a change in management after the findings of head CTA and secondary outcomes included rate of admission to the ICU, ICU length of stay, hospital length of stay, discharge disposition, and mortality. Six hundred adult patients had blunt TBI and underwent head CT as a part of their evaluation. Of these 600 patients, 132 (22%) underwent head CTA in addition to CT. Only one patient had altered management after the CTA results; the patient had a diagnostic angiogram that was negative. Ninety-eight patients did not have any additional findings on CTA. Of the remaining 33 patients with additional CTA findings, 12 had incidental vascular malformations, which showed no acute pathology and were not related to the injury. In the matched comparisons, patients with CTA had a longer hospital stay, higher rate of ICU admission, and longer ICU stay. There was no significant difference in mortality and discharge disposition between the 2 groups.\nQuestion: Is CT Angiography of the Head Useful in the Management of Traumatic Brain Injury?",
        "gt": "Head CTA is commonly used after blunt TBI but does not alter management and should be abandoned in the absence of clear indications.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Previous studies have suggested that statins may prevent development of osteoarthritis and have antiinflammatory effects. Our aim was to examine the associations between statin use and patient-reported joint symptoms in 2 large cohorts of middle-aged and older women. Data were from 6,966 middle-aged (born 1946-1951) and 4,806 older (born 1921-1926) participants in the Australian Longitudinal Study on Women's Health who completed surveys from 2001 to 2011, including questions about joint pain/stiffness, physical functioning, and self-rated health (SRH). Administrative pharmaceutical data were used to classify participants according to statin use, cumulative volume of statin use, and type of drug. Associations between statin use and newly reported symptoms were analyzed using logistic regression with generalized estimating equations to account for repeated measures. A total of 2,096 (31.3%) of the middle-aged women and 2,473 (51.5%) of the older women were classified as statin users. After adjustment for confounders, statin use in middle-aged women was weakly associated with poor physical functioning (odds ratio [OR] 1.29, 99% confidence interval [99% CI]1.07-1.55) and poor SRH (OR 1.35, 99% CI 1.13-1.61), but not with new joint pain/stiffness (OR 1.09, 99% CI 0.88-1.34). No dose-response relationships were found. Pravastatin and atorvastatin were associated with poor physical functioning, while atorvastatin was also associated with poor SRH. Associations found in older women were mostly explained by confounders.\nQuestion: Is statin use associated with new joint-related symptoms, physical function, and quality of life?",
        "gt": "This large study did not demonstrate an association between statin use and reduced onset of joint pain/stiffness. Associations between statin use and poor physical functioning and poor SRH may be explained by factors other than joint pain/stiffness, e.g., muscle pain.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The American College of Surgeons Oncology Group (ACOSOG) Z0050 trial demonstrated that positron emission tomography (PET) prevents nontherapeutic thoracotomies in a substantial fraction of patients with known or suspected non-small cell lung cancer (NSCLC). However, the benefit of PET in clinical stage IA patients has been questioned due to the lower prevalence of metastases and poor ability to discriminate benign from malignant lung lesions. This study evaluates whether PET prevents nontherapeutic pulmonary resections in clinical stage IA patients by finding advanced disease or by declaring a nodule as benign. We reanalyzed all patients with clinical stage IA NSCLC from ACOSOG Z0050. The clinical, PET, and pathologic stages were compared for this prospective cohort. One hundred twenty-two clinical stage IA patients were evaluated and 78.7% (96 of 122; 95% confidence interval [CI], 70.4 to 85.6) were eventually shown to have cancer. PET correctly showed 7.4% (9 of 122; 95% CI, 3.4 to 13.5) of patients to have advanced disease (stages IIIA to IV). However, due to a high false positive rate, the positive predictive value for advanced disease was only 33.3% (9 of 27; 95% CI, 16.5 to 54.0). The negative predictive value of PET to predict benign lesions was only 57% (16 of 28; 95% CI, 37.2 to 75.5). Thus, 43% (12 of 28; 95% CI, 24.5 to 62.8) of patients with a PET negative primary lesion actually had cancer, and all of these had resectable disease (stages IA to IIB).\nQuestion: Does positron emission tomography prevent nontherapeutic pulmonary resections for clinical stage IA lung cancer?",
        "gt": "In clinical stage IA lung cancer patients, PET prevents nontherapeutic pulmonary resections less than 10% of the time. If a strategy of no surgery and serial computed tomographic scans is chosen for PET negative lesions, over 40% of patients with NSCLC will have surgery delayed. A prospective trial comparing PET versus resection for clinical stage IA lesions would clarify the value of PET for these patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The study aimed to evaluate the usability of DVD simulations, the impact on student learning, clinical placement orientation, and the potential for using DVD simulations to reduce the clinical placement burden on the health care system with nursing students. A total of 11 DVD simulations were developed by Monash University academics. Second year students (N=191) from the Bachelor of Nursing course at Monash University, viewed a range of DVDs. Students' perceptions and attitudes about the clinical relevance of the simulations were assessed by having them complete a 7-point Likert self-report scale. Qualitative data was also collected from two focus groups (N=7). Overall, nursing students perceived the DVD simulations positively in relation to learning attention (M=4.93, SD=1.02, CI 4.25-4.54), learning potential (M=4.45, SD= 1.30, CI 5.13-5.50), clinical relevance to practice (M=5.32, SD=0.65, CI 4.36-4.55), and information processing quality (M=5.62, SD= 1.02, CI 5.47-5.76). The following themes emerged from the focus groups: provided familiarisation for clinical placements, learning wastage occurs in varying amounts, simulations could replace some clinical placement rotations, supportive of multidisciplinary approach and integration, and simulations should have pedagogical integration into weekly clinical cases.\nQuestion: Can interprofessional education DVD simulations provide an alternative method for clinical placements in nursing?",
        "gt": "Nursing students reported that the simulations were educationally, professionally, and clinically relevant. The cost benefit of using DVD simulations as an alternative and potential replacement to elements of nursing clinical placements should be investigated further.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patient-reported cognitive function can be measured using negatively worded items (concerns) and positively worded (abilities) items. It is possible that reporting abilities is less subject to the influence of emotional states. This study evaluated the relationship between cognitive concerns and cognitive abilities. Cancer patients (N\u2009=\u2009509; mean age\u2009=\u200961 years; 50% men; 86% White) completed concerns and abilities items developed by the National Institutes of Health Patient-Reported Outcomes Information System (PROMIS). Confirmatory factor analysis was used to evaluate the extent to which items were loaded on one single factor (unidimensionality). Multidimensionality was evaluated using bi-factor analysis (local factors: concerns and abilities). Slope parameters from multidimensional item response theory (IRT) and unidimensional IRT were compared to evaluate which factor solution fits best. Acceptable fit indices were found in both one-factor confirmatory factor analysis (comparative fit index (CFI)\u2009=\u20090.96; root mean squared error of approximation (RMSEA)\u2009=\u20090.062) and bi-factor analysis (CFI\u2009=\u20090.98; RMSEA\u2009=\u20090.043). Thus, abilities and concerns could be considered as a single dimension. Yet, high loadings on the local factor in bi-factor analysis and slope discrepancies between unidimensional IRT and multidimensional IRT indicate that abilities should be considered as a separate factor from concerns.\nQuestion: Self-reported cognitive concerns and abilities: two sides of one coin?",
        "gt": "Concerns and abilities could be measured using one-unidimensional item bank. Results also support measuring each construct separately. We recommend a conservative approach by measuring and reporting concerns and abilities separately. We therefore recommend two separate but co-calibrated item banks in the PROMIS network: cognitive function item bank-concerns and cognitive function item bank-abilities. Both item banks showed good psychometric properties and are available for research and clinical purposes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study aims to verify the effect of hypercholeresterolaemia on implant and bone augmentation failures. A retrospective cohort study was conducted on 268 sequential patients scheduled for implant and bone augmentation surgery under conscious sedation in a private practice. Total serum cholesterol (TC) levels were assessed via blood tests before surgery. Patients were divided into two groups: TC<200 mg/dl and TC>200 mg/dl. A 6-month post-loading follow-up was scheduled both for implants and grafts. The outcomes considered were implant failure (removal) and graft infection/failure. The effect of cholesterol on early implant and grafting failure was investigated according to a logistic regression model. Two hundred and twenty-seven patients fulfilled inclusion criteria; 139 had hypercholesterolemia. The 6-month post-loading overall implant failure rate was 6.25% at patient level (2.00% at implant level). Partial or total graft infection rate was 10.2%. High TC increased by 7.48 times the odds of the grafting failure (P = 0.047; 95% CI: -0.94 to 59.23), whilst it did not modify the odds of implant failure (P = 0.749; 95% CI: 0.28 to 2.49).\nQuestion: Is a high level of total cholesterol a risk factor for dental implants or bone grafting failure?",
        "gt": "High total serum cholesterol levels tend to increase graft failure rates whilst it did not influence implant failures.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It is known that the outcome of percutaneous coronary intervention is worse in diabetics than in non-diabetics. The aim of our study was to determine whether abciximab therapy could improve clinical outcome in an unselected diabetic population that underwent percutaneous coronary interventions. We analyzed retrospectively 198 diabetic patients who underwent PTCA from January 1997 to January 2000. Seventy-three patients (36.7%) were treated with abciximab and the remaining 125 patients (63.3%) did not receive abciximab. The mean follow-up was 12.6 months. The events considered were death, non-fatal myocardial infarction, any revascularization procedure (including the target vessel), and hospital admission for unstable angina. Patients who received abciximab had more frequent previous myocardial infarction (67.1 vs. 52.8%; p = 0.04), worse left ventricular function (0.53 vs. 0.59%; p = 0.02), more frequent angiographic thrombus (67.1 vs. 36.8%; p<0.001), more complex lesions (B2/C) (76.4 vs. 55.8%; p = 0.004), and less frequent location in left anterior descending artery (34.2 vs. 60.8%; p = 0.002). The indication for PTCA in patients who received abciximab was most often related to myocardial infarction. There were no differences between the groups in sex, age and distribution of diabetes treatment. Events were more frequent in diabetics not treated with abciximab than in those who were treated with abciximab (38 vs. 22%; p<0.037). The patients not treated with abciximab suffered more frequently target vessel revascularization (22.7 vs. 7.2%; p<0.007). There were no significant differences in the frequency of death or non-fatal myocardial infarction, but hospital readmissions for unstable angina were significantly more frequent in diabetics not treated with abciximab (29.1 vs. 15.9%; p = 0.045). Multivariate analysis identified abciximab as a predictor of the absence of complications during follow-up (OR: 0.45; p = 0.03).\nQuestion: Does abciximab improve the prognosis of diabetics after percutaneous coronary intervention?",
        "gt": "Abciximab treatment seems to reduce events in unselected diabetic patients undergoing percutaneous coronary intervention, particularly target vessel revascularization.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Prospective evaluation of short (dyspnoea) and mid-term outcomes in 47 consecutive patients admitted in the intensive care unit for acute pulmonary edema treated on a liberal basis. Patients were elderly (83 year-old) and 60% had preserved left ventricular ejection fraction (>50%). Dyspnoea assessed by visual analogue score was weakly associated with treatment posology. Despite low use of inotropes (6%) and intubation (9%), hospital and D90 mortality was high (19% and 32% respectively). Higher mortality was noticed in patients receiving no isosorbide dinitrate (p = 0.04). In the multivariate analysis, only age and delta brain natriuretic peptide (difference between BNP on D1 and D0) remained significantly associated with mortality on D90 (OR 1.13; p = 0.03 and OR 1.004; p = 0.04 respectively).\nQuestion: Shall we Follow the Guidelines for Isosorbide Dinitrate in Acute Pulmonary Edema?",
        "gt": "Acute pulmonary edema carried a dramatic in-hospital and mid-term mortality in our elderly patients. Isosorbide dinitrate was associated with decreased D90 mortality but not in the multivariate analysis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The primary aim of this study was to examine the needs of older people in relation to cardiac rehabilitation and to determine if these were currently being met. A secondary aim was to compare illness representations, quality of life and anxiety and depression in groups with different levels of attendance at a cardiac rehabilitation programme. Coronary heart disease accounted for over seven million cardiovascular deaths globally in 2001. Associated deaths increase with age and are highest in those older than 65. Effective cardiac rehabilitation can assist independent function and maintain health but programme uptake rates are low. We have, therefore, focussed specifically on the older patient to determine reasons for the low uptake. Mixed methods. A purposive sample of 31 older men and women (>or =65 years) completed three questionnaires to determine illness representations, quality of life and anxiety and depression. They then underwent a brief clinical assessment and participated in a face-to-face audio-taped interview. Quantitative: Older adults, who did not attend a cardiac rehabilitation programme, had significantly poorer personal control and depression scores (p<0.01) and lower quality of life scores than those who had attended. Few achieved recommended risk factor reduction targets. Qualitative: The three main themes identified as reflecting the views and experiences of and attendance at the cardiac rehabilitation programme were: 'The sensible thing to do', 'Assessing the impact' and 'Nothing to gain'.\nQuestion: Are older patients' cardiac rehabilitation needs being met?",
        "gt": "Irrespective of level of attendance, cardiac rehabilitation programmes are not meeting the needs of many older people either in terms of risk factor reduction or programme uptake. More appropriate programmes are needed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Bladder decompensation is well described following artificial urinary sphincter implantation in neurogenic bladders. We evaluated the long-term results of various bladder outlet procedures in a subset of patients with neurogenic bladder and isolated outlet deficiency. We retrospectively reviewed the charts of 15 consecutive patients who underwent bladder outlet procedures during a 10-year period for urinary incontinence associated with neuropathic bladder dysfunction. Postoperative success was defined as a dry interval of at least 4 hours. Preoperative evaluation showed a smooth bladder in 11 patients with vesicoureteral reflux and hydronephrosis in 2. Using the minimal acceptable capacity for age, mean percent expected bladder capacity for age was 89% +/- 25%, capacity below 20 cm H(2)O was 81% and capacity below 30 cm H(2)O was 89%. Mean preoperative expected capacity for age was 60% +/- 18%. Mean postoperative followup was 11.2 years. Postoperatively, 11 patients achieved initial dryness but 9 subsequently presented with recurrent incontinence and 2 presented with upper tract deterioration. Four cases failed the initial bladder outlet procedure. Salvage procedures included augmentation cystoplasty in all 15 patients, combined with repeat bladder outlet procedure in 4 and bladder neck closure in 2. Mean time to augmentation cystoplasty was 39.6 +/- 28 months.\nQuestion: Is long-term bladder deterioration inevitable following successful isolated bladder outlet procedures in children with neuropathic bladder dysfunction?",
        "gt": "Isolated bladder outlet procedures for neurogenic incontinence portend a poor long-term outcome, requiring augmentation cystoplasty despite the use of anticholinergic medications and strict followup. Preoperative urodynamic evaluation does not predict the need or timing from the initial bladder outlet procedure for future augmentation cystoplasty.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The MC1R (melanocortin-1 receptor) locus underlies intraspecific variation in melanin-based dark plumage coloration in several unrelated birds with plumage polymorphisms. There is far less evidence for functional variants of MC1R being involved in interspecific variation, in which spurious genotype-phenotype associations arising through population history are a far greater problem than in intraspecific studies. We investigated the relationship between MC1R variation and plumage coloration in swans (Cygnus), which show extreme variation in melanic plumage phenotypes among species (white to black). The two species with melanic plumage, C. atratus and C. melanocoryphus (black and black-necked swans respectively), both have amino acid changes at important functional sites in MC1R that are consistent with increased MC1R activity and melanism. Reconstruction of MC1R evolution over a newly generated independent molecular phylogeny of Cygnus and related genera shows that these putative melanizing mutations were independently derived in the two melanic lineages. However, interpretation is complicated by the fact that one of the outgroup genera, Coscoroba, also has a putative melanizing mutation at MC1R that has arisen independently but has nearly pure white plumage. Epistasis at other loci seems the most likely explanation for this discrepancy. Unexpectedly, the phylogeny shows that the genus Cygnus may not be monophyletic, with C. melanocoryphus placed as a sister group to true geese (Anser), but further data will be needed to confirm this.\nQuestion: Testing whether macroevolution follows microevolution: are colour differences among swans (Cygnus) attributable to variation at the MCIR locus?",
        "gt": "Our study highlights the difficulty of extrapolating from intraspecific studies to understand the genetic basis of interspecific adaptive phenotypic evolution, even with a gene whose structure-function relationships are as well understood as MC1R as confounding variation make clear genotype/phenotype associations difficult at the macroevolutionary scale. However, the identification of substitutions in the black and black-necked swan that are known to be associated with melanic phenotypes, suggests Cygnus may be another example where there appears to be convergent evolution at MC1R. This study therefore provides a novel example where previously described intraspecific genotype/phenotype associations occur at the macroevolutionary level.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We measured biomarkers of tumour growth and vascularity in interval and screen-detected colorectal cancers (CRCs) in the English Bowel Cancer Screening Programme in order to determine whether rapid tumour growth might contribute to interval CRC (a CRC diagnosed between a negative guaiac stool test and the next scheduled screening episode). Formalin-fixed, paraffin-embedded sections from 71 CRCs (screen-detected 43, interval 28) underwent immunohistochemistry for CD31 and Ki-67, in order to measure the microvessel density (MVD) and proliferation index (PI), respectively, as well as microsatellite instability (MSI) testing. Interval CRCs were larger (P=0.02) and were more likely to exhibit venous invasion (P=0.005) than screen-detected tumours. There was no significant difference in MVD or PI between interval and screen-detected CRCs. More interval CRCs displayed MSI-high (14%) compared with screen-detected tumours (5%). A significantly (P=0.005) higher proportion (51%) of screen-detected CRC resection specimens contained at least one polyp compared with interval CRC (18%) resections.\nQuestion: Are there biological differences between screen-detected and interval colorectal cancers in the English Bowel Cancer Screening Programme?",
        "gt": "We found no evidence of biological differences between interval and screen-detected CRCs, consistent with the low sensitivity of guaiac stool testing as the main driver of interval CRC. The contribution of synchronous adenomas to occult blood loss for screening requires further investigation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Women living in deprived neighborhoods are a risk group for overweight and obesity, particularly during the childbearing years. Several socio-demographic characteristics may compound this risk, but little is known about why this might be the case. Sedentary behaviors are emerging as a socio-demographically patterned risk factor for obesity. The purpose of the present study was to assess socio-demographic differences in sedentary behaviors, and to examine whether these behaviors could explain the relation between socio-demographic variables and BMI (BMI) in this risk group. Women aged 18-46 years were recruited from 40 urban and 40 rural deprived neighborhoods in Victoria, Australia. In total, 3879 women reported socio-demographic variables (age, educational level, employment status, marital status, number of children, residential location and country of birth), sedentary behaviors (television time, computer time, total screen time and total sedentary time), physical activity, and height and weight, which were used to calculate BMI. For each socio-demographic variable, four single mediation models were conducted using two-level mixed-models regression analyses. Mediating effects were examined using the MacKinnon product-of-coefficients procedure and the Sobel test. All socio-demographic variables were significantly associated with sedentary behaviors. Single mediation analyses revealed that television time (\u03b1\u03b2\u2009=\u20090.017, 95% CI\u2009=\u20090.000, 0.030) and total screen time (\u03b1\u03b2\u2009=\u20090.006, 95% CI\u2009=\u20090.000, 0.012) mediated 14.1% and 4.9% of the relationship between educational level and BMI, respectively. Total screen time mediated 45.1% of the relationship between employment status and BMI (\u03b1\u03b2\u2009=\u2009-0.020, 95% CI\u2009=\u2009-0.033, -0.006), and television time mediated 8.2% of the relationship between country of birth and BMI (\u03b1\u03b2\u2009=\u2009-0.008, 95% CI\u2009=\u2009-0.016, -0.001).\nQuestion: Do sedentary behaviors mediate associations between socio-demographic characteristics and BMI in women living in socio-economically disadvantaged neighborhoods?",
        "gt": "Sedentary behaviors differed depending on socio-demographic characteristics, and partly explained the relationship between socio-demographic factors and BMI in this sample of women. Both television time and total screen time are potential behaviors to target in future programs aimed at reducing socio-demographic disparities in overweight and obesity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This research aims to register predictive tests of reading by way of a first intention test usually proposed in children with school difficulties: the WISC-R. Thirty-one children aged from 3.9 to 8.3 years, consulting in a psychiatry service for school difficulties, were tested twice. Twenty-one children aged less than 5.9 years (age for beginning to read), consulting for anticipated schooling, were also included in the study. These fifty-two children passed twice WISC-R for the elder and WPPSI for those who were younger. Three subtests, similitude test, understanding test and test of Kohs 'blocks seemed to be good predictive markers of ability to read. Predictive score for fiability with these three tests was 87%.\nQuestion: Can successful reading acquirements be predicted?",
        "gt": "These tests that bring the ability of generalizing into question, as reality and space adjustment, show well the necessary qualities for a child who must begin to read.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Closed-suction drains, implants, and acellular dermal matrix (ADM) are routinely used in tissue expander-based immediate breast reconstruction (TE-IBR). Each of these factors is thought to increase the potential for surgical site infection (SSI). Although CDC guidelines recommend only 24 hours of antibiotic prophylaxis after TE-IBR, current clinical practices vary significantly. This study evaluated the difference in SSI between 2 different prophylactic antibiotic durations. A noninferiority randomized controlled trial was designed in which TE-IBR patients received antibiotics either 24 hours postoperatively or until drain removal. The primary outcome was SSI, as defined by CDC criteria. Operative and postoperative protocols were standardized. Secondary endpoints included clinical outcomes up to 1 year and all implant loss, or reoperation. There were 112 TE-IBR patients (180 breasts) using ADM who were randomized into 2 study arms, with 62 patients in the 24-hour group and 50 in the extended group. Surgical site infection was diagnosed in 12 patients in the 24-hour group and 11 in the extended group (19.4% vs 22.0%, p\u00a0= 0.82). The extended group had 7 patients who required IV antibiotics and an overall implant loss in 7 patients (14.0%). The 24-hour group had 4 patients who required IV antibiotics, with 3 requiring removal (4.8%). Patients with diabetes, postoperative seroma, or wound dehiscence were all more likely to develop SSI (p<0.02).\nQuestion: Are Prophylactic Postoperative Antibiotics Necessary for Immediate Breast Reconstruction?",
        "gt": "In a randomized controlled noninferiority trial, 24 hours of antibiotics is equivalent to extended oral antibiotics for SSI in TE-IBR patients. Additional multicenter trials will further assess this important aspect of TE-IBR postoperative care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We have described an alternative technique for orthotopic heart transplantation (bicaval Wythenshawe technique) which maintains the right and left atrial anatomy and contractility. Fifty patients were randomized into two groups: group A (n = 25) who had orthotopic heart transplantation using the bicaval Wythenshawe technique and group B (n = 25) who had conventional (Lower and Shumway) technique of orthotopic heart transplantation. We compared the cardiac output (measured by thermodilution technique) with atrial activation (AAI pacing) to cardiac output without atrial activity (VVI pacing) in both groups to identify any beneficial hemodynamic effects. All patients were studied the first and second weeks after transplantation. The inaccuracies of comparing cardiac output measurements caused by different loading conditions, inotropic state, and systemic vascular resistance were eliminated by using the patient as his or her own control. The difference between the measured cardiac output with atrial pacing and ventricular pacing was 1.42 +/- 0.44 L/min in group A in comparison with 0.32 +/- 0.4 L/min in group B (p = 0.001 Wilcoxon signed rank). The percentage of atrial contribution to the cardiac output in group A was 30% +/- 12% (standard deviation), 95% confidence interval in comparison with 7% +/- 9%, 95% confidence interval in group B. The mean stroke volume in group A was higher in sinus rhythm (65 +/- 19.2 ml) and atrial pacing (62 +/- 17.7 ml) compared with ventricular pacing (49.17 +/- 16.43 ml) p = 0.001. In group B no statistical difference was found between stroke volume measured with atrial (47.71 +/- 6.23 ml) or ventricular pacing (46.9 +/- 6.35 ml).\nQuestion: Orthotopic heart transplantation hemodynamics: does atrial preservation improve cardiac output after transplantation?",
        "gt": "We conclude that the bicaval technique of orthotopic heart transplantation preserve the atrial kick and its contribution to cardiac output early after transplantation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although echocardiography has been incorporated into the diagnostic algorithm of patients with suspected infective endocarditis, systematic usage in clinical practice remains ill defined. To test whether the rigid application of a predefined standardized clinical assessment using the Duke criteria by the research team would provide improved diagnostic accuracy of endocarditis when compared with usual clinical care provided by the attending team. Between April 1, 2000 and March 31, 2001, 101 consecutive inpatients with suspected endocarditis were examined prospectively and independently by both teams. The clinical likelihood of endocarditis was graded as low, moderate or high. All patients underwent transthoracic echocardiography and appropriate transesophageal echocardiography if deemed necessary. All diagnostic and therapeutic outcomes were evaluated prospectively. Of 101 consecutive inpatients (age 50+/-16 years; 62 males) enrolled, 22% subsequently were found to have endocarditis. The pre-echocardiographic likelihood categories as graded by the clinical and research teams were low in nine and 37 patients, respectively, moderate in 83 and 40 patients, respectively, and high in nine and 24 patients, respectively, with only a marginal agreement in classification (kappa=0.33). Of the 37 patients in the low likelihood group and 40 in the intermediate group, no endocarditis was diagnosed. In 22 of 24 patients classified in the high likelihood group, there was echocardiographic evidence of vegetations suggestive of endocarditis. Discriminating factors that increased the likelihood of endocarditis were a prior history of valvular disease, the presence of an indwelling catheter, positive blood cultures, and the presence of a new murmur and a vascular event. General internists, rheumatologists and intensive care physicians were more likely to order echocardiography in patients with low clinical probability of endocarditis, of which pneumonia was the most common alternative diagnosis.\nQuestion: Can structured clinical assessment using modified Duke's criteria improve appropriate use of echocardiography in patients with suspected infective endocarditis?",
        "gt": "Although prediction of clinical likelihood varies between observers, endocarditis is generally found only in those individuals with a moderate to high pre-echocardiographic clinical likelihood. Strict adherence to indications for transthoracic echocardiography and transesophageal echocardiography may help to facilitate more accurate diagnosis within the moderate likelihood category. Patients with low likelihood do not derive additional diagnostic benefit with echocardiography although other factors such as physician reassurance may continue to drive diagnostic demand.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this study was to analyze whether, and by whom sexuality is discussed in amputation departments. The focus was on whether professionals received questions about sexuality from their patients with a lower limb amputation and whether they addressed sexuality themselves, as well as on the knowledge and comfort level, approach and attitudes toward sexuality of these professionals. An online questionnaire, including questions on self-perceived sexological competence and the Knowledge, Comfort, Approach and Attitudes towards Sexuality Scale. Seventy-eight percent of the professionals had not received questions about sexuality from their patients and 67% had not addressed sexuality. Self-perceived knowledge about sexuality and self-perceived ability to recognize sexual problems increased the odds of receiving a question about sexuality and the odds of addressing this issue.\nQuestion: Sexuality in people with a lower limb amputation: a topic too hot to handle?",
        "gt": "Sexuality is rarely discussed by professionals in the amputation department. It is, however, the responsibility of the professional to do so. By addressing sexuality in a systematic way and discussing this as a common topic professionals \"give permission\" to patients and other team members to discuss eventual sexual problems or concerns. Therefore, the professionals' self-perceived sexological competence and feeling of comfort with the topic of sexuality need to be increased. Implications for Rehabilitation Sexuality is rarely discussed by professionals in the amputation department, even though sexual problems do occur in patients with a lower limb amputation (LLA). By addressing sexuality in a systematic way and discussing this as a common topic professionals \"give permission\" to patients and other team members to discuss eventual sexual problems or concerns. Our study shows that self-perceived knowledge about sexuality and self-perceived ability to recognize sexual problems increases the odds of receiving a question about sexuality and the odds of addressing this issue. Investing in courses that focus on increasing the knowledge and feeling of comfort concerning sexuality of professionals working with people with a LLA is therefore of important value.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In the endovascular era, elderly patients are offered repair of their aortoiliac aneurysms (AAA) more frequently than in the past. Our objective is to compare age groups and draw inferences for AAA repair outcomes. We identified 20,095 patients who underwent AAA repair between 2005 and 2010 using the American College of Surgeons NSQIP national database. Preoperative characteristics and outcomes were compared among age groups (group A: 0 to 64 years; B: 65 to 79 years; C: 80 to 89 years; and D: 90 years and older). The age distribution of the cohort was A: 17.1%, B: 57.2%, C: 24%, and D: 1.7%. Nonagenarians presented significantly more often as emergencies in comparison with groups A to C (A: 13.8%, B: 10.8%, C: 12.9%, D: 22.1%; p<0.001). Endovascular aneurysm repair was performed more frequently in older patients (A: 55.2%, B: 63.7%, C: 74.6%, D: 77.9%; p<0.001). Risk of any complication was significantly different among groups, becoming more prevalent with advanced age (A: 22.8%, B: 23.4%, C: 24.7%, D: 27.8%; p = 0.041). Nonsurgical complications (A: 14.7%, B: 16.4%, C: 18%, D: 19.8%; p<0.001) and cardiovascular complications (A: 3.9%, B: 4.5%, C: 5.5%, D: 5.2%; p = 0.003) were also higher with advanced age. Overall mortality was 3.1%, 4.9%,7.2%, and 13.2% for groups A to D, respectively (p<0.001). Mortality after elective AAA repair was significantly higher for open surgery compared with endovascular aneurysm repair in all age groups (open surgery vs endovascular aneurysm repair, A:1.9% vs 0.5%; p = 0.001; B: 3.9% vs 1.2%; p<0.001; C: 7.4% vs 2%; p<0.001; D: 18.8% vs 3.8%; p = 0.004). After adjusting for confounders in the entire cohort, advanced age persisted as an independent factor for postoperative mortality with a higher risk of death of 1.8 (95% CI, 1.3-2.5), 2.7 (95% CI, 1.9-3.8), and 3.3 (95% CI, 1.8-6.1) times for groups B, C, and D, respectively (group A reference).\nQuestion: Age-stratified results from 20,095 aortoiliac aneurysm repairs: should we approach octogenarians and nonagenarians differently?",
        "gt": "Advanced age is independently associated with higher risk of death after AAA repair and indication for surgery should be adjusted for different age groups accordingly. Endovascular aneurysm repair should be preferred for octogenarians and nonagenarians with indication to undergo repair of their AAA.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: An increased prevalence of metabolic syndrome including nonalcoholic fatty liver disease (NAFLD) was reported in psoriasis. NAFLD can progress to nonalcoholic steatohepatitis and fibrosis. Transient elastography (TE) is a noninvasive liver fibrosis assessment. We evaluated the prevalence of significant liver fibrosis or high liver stiffness measurement (LSM) using the LSM cutoff over 7\u2009kPa and its associated factors in psoriatic patients. Subjects underwent TE and ultrasonography. Univariate and multivariate analysis were performed for the associated factors. One hundred and sixty-eight patients were recruited. Three patients were excluded due to TE failure. Mean BMI was 24.8 \u00b1 4.7\u2009kg/m(2). NAFLD, metabolic syndrome, and diabetes were seen in 105 (63.6%), 83 (50.3%), and 31 (18.8%) patients. The total cumulative dose of methotrexate over 1.5\u2009g was seen in 39 (23.6%) patients. Mean LSM was 5.3 \u00b1 2.9\u2009kPa. High LSM was found in 18 (11.0%) patients. Waist circumference (OR: 1.24; 95% CI: 1.11-1.38; P = 0.0002), diabetes (OR: 12.70; 95% CI: 1.84-87.70; P = 0.010), and AST (OR: 1.08; 95% CI: 1.02-1.16; P = 0.017) were associated with high LSM.\nQuestion: Liver Stiffness Measurement in Psoriasis: Do Metabolic or Disease Factors Play the Important Role?",
        "gt": "11% of psoriatic patients had significant liver fibrosis by high LSM. Waist circumference, diabetes, and AST level were the independent predictors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To discover whether family physicians who go through residency training and The College of Family Physicians of Canada's (CFPC) certification process are more responsive than other physicians to woman abuse, whether they perceive and approach such abuse more appropriately, and whether they seek out more education on the subject. A national survey using a pretested 43-item mailed questionnaire to examine perceptions of and approaches to detection and management of woman abuse. Canadian family and general practice. A cross-sectional sample of 1574 family physicians and general practitioners, of whom 963 (61%) volunteers responded. Demographic variables, perceptions of abuse, methods of diagnosing and managing woman abuse. Most respondents agreed they could not diagnose and treat woman abuse effectively, regardless of certification status. They indicated they were detecting only 33% of cases. Certificants of CFPC, in particular residency-trained certificants, were more likely to think that they should be diagnosing woman abuse than noncertificants; they were also more likely to help victims by referring them to specialists and other agencies. Certificants were also more likely to think they should be treating these patients themselves, and that they were not adequately trained to do so. Although most respondents thought they needed more education, certificants were more likely to know of relevant courses, to have attended such courses, and to have read books or articles on the topic.\nQuestion: Physicians' perceptions of and approaches to woman abuse. Does certification in family medicine make a difference?",
        "gt": "Being a certificant is not associated with perceived skills in diagnosing and treating woman abuse, but is associated with an increased awareness of the problem. Certificants know that education on woman abuse is available.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Previous reports suggest that earlier hospital discharges and reduced postoperative complications occur when a retroperitoneal approach is used for aortic surgery. Other publications refute this concept. In an effort to determine the most cost efficient method for aortic surgery in our institution, while maintaining high standards of care and outcome, we compared the retroperitoneal approach to the conventional transperitoneal aortic operation. Between December 1995 and April 1998, 120 patients underwent aortic surgery by either the transperitoneal (n=60) or retroperitoneal approach (n=60). All patients were enrolled prospectively in a vascular registry and retrospectively reviewed. Patients were randomly assigned to one of three vascular surgeons. A clinical pathway for elective aortic surgery was developed and applied to both groups. Patients were evaluated with respect to demographics, comorbidities, preoperative risk stratification, conduct of the operative procedure, length of stay, complications, cost, clinical outcomes and patient satisfaction. The indications for aortic surgery were similar in both groups - 64% for aneurysm disease and 36% for occlusive disease. Both symptomatic and asymptomatic aneurysms were included and size ranged from 4.4 to 14cm. All aortic reconstructions were done in the standard manner using knitted Dacron velour prostheses in either the aortic tube, bi-iliac or bi-femoral configuration. Statistical analysis of means and medians was accomplished using the Wilcoxin Rank-sum test and percentages were compared using Fisher's Exact test. P values less than 0.05 indicate statistical significance. There were no statistically significant differences in patient demographics. The incidence of atherosclerotic coronary artery disease, obstructive pulmonary disease, diabetes, hyperlipidemia, tobacco abuse, distal lower extremity occlusive disease and the results of chemical myocardial stress evaluations were similar in both groups. Comorbidities of pre-existing renal insufficiency/failure and morbid obesity were increased in the retroperitoneal group. Five patients in the retroperitoneal group represented redo aortic surgery and there were no redo procedures in the transperitoneal group. Length of operative procedures and blood replacement requirements for both groups were similar. The transperitoneal group required 2-3l more intraoperative intravenous (IV) crystalloid than the retroperitoneal group (P<0.0001). Statistically significant reductions in ICU days, postoperative ileus and total lengths of stay were observed in the retroperitoneal group (P<0.0001). This resulted in substantial reductions in hospital costs for the retroperitoneal group (P<0.01). Postoperative complications were similar for both groups except for statistically significant increases in pulmonary edema (P<0.01) and pneumonia (P<0.001) in the transperitoneal group. Cardiac arrhythmias, primarily atrial dysrhythmias, were more frequent in the transperitoneal group but this failed to reach statistical significance (P<0.16). Combined thirty day mortality was 0.9%. Time of recovery to full activity and patient satisfaction substantially favored the retroperitoneal group.\nQuestion: Retroperitoneal approach for aortic surgery: is it worth it?",
        "gt": "Our clinical pathway and algorithm for aortic surgery was easily followed by those patients in the retroperitoneal approach group and resulted in decreases in ICU time, postoperative ileus, volume of intraoperative crystalloid and total length of stay. The patients in the transperitoneal group often failed to progress appropriately on the pathway. Reduced hospital costs associated with aortic surgery using the retroperitoneal approach has increased the profitability for this surgery in our institution by an average of $4000 per case and has increased the value (quality/cost) of this surgery to our patients and our institution.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We observed in our practice several cases of impaction with meat boluses without bony edges, in patients with patent esophageal lumen. The aim of this study was to search for eventual underlying motor disorders which could be responsible for this impaction. We included 19 patients who attended the endoscopy service for meat bolus impaction without organic esophageal stenosis. This group was compared with 18 control volunteers. Both groups underwent UGI series, UGI endoscopy and low-compliance perfusion standard esophageal manometry. Compared with the control group, the impacted subjects presented marked reduction in amplitude and duration of esophageal contraction in the proximal esophagus.\nQuestion: Foreign body impaction in the esophagus: are there underlying motor disorders?",
        "gt": "These motor disorders could be responsible for the foreign body impaction in the esophagus. However, we believe this patient group should be further studied by 24-hour esophageal manometry to reach a more accurate diagnosis by studying each patient's entire circadian cycle.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The risk of hypo- and hyperglycemia has been assessed for years by computing the well-known low blood glucose index (LBGI) and high blood glucose index (HBGI) on sparse self-monitoring blood glucose (SMBG) readings. These metrics have been shown to be predictive of future glycemic events and clinically relevant cutoff values to classify the state of a patient have been defined, but their application to continuous glucose monitoring (CGM) profiles has not been validated yet. The aim of this article is to explore the relationship between CGM-based and SMBG-based LBGI/HBGI, and provide a guideline to follow when these indices are computed on CGM time series. Twenty-eight subjects with type 1 diabetes mellitus (T1DM) were monitored in daily-life conditions for up to 4 weeks with both SMBG and CGM systems. Linear and nonlinear models were considered to describe the relationship between risk indices evaluated on SMBG and CGM data. LBGI values obtained from CGM did not match closely SMBG-based values, with clear underestimation especially in the low risk range, and a linear transformation performed best to match CGM-based LBGI to SMBG-based LBGI. For HBGI, a linear model with unitary slope and no intercept was reliable, suggesting that no correction is needed to compute this index from CGM time series.\nQuestion: Are Risk Indices Derived From CGM Interchangeable With SMBG-Based Indices?",
        "gt": "Alternate versions of LBGI and HBGI adapted to the characteristics of CGM signals have been proposed that enable extending results obtained for SMBG data and using clinically relevant cutoff values previously defined to promptly classify the glycemic condition of a patient.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Pregnancy may provide a 'teachable moment' for positive health behaviour change, as a time when women are both motivated towards health and in regular contact with health care professionals. This study aimed to investigate whether women's experiences of pregnancy indicate that they would be receptive to behaviour change during this period. Qualitative interview study. Using interpretative phenomenological analysis, this study details how seven women made decisions about their physical activity and dietary behaviour during their first pregnancy. Two women had required fertility treatment to conceive. Their behaviour was driven by anxiety and a drive to minimize potential risks to the pregnancy. This included detailed information seeking and strict adherence to diet and physical activity recommendations. However, the majority of women described behaviour change as 'automatic', adopting a new lifestyle immediately upon discovering their pregnancy. Diet and physical activity were influenced by what these women perceived to be normal or acceptable during pregnancy (largely based on observations of others) and internal drivers, including bodily signals and a desire to retain some of their pre-pregnancy self-identity. More reasoned assessments regarding benefits for them and their baby were less prevalent and influential.\nQuestion: Is pregnancy a teachable moment for diet and physical activity behaviour change?",
        "gt": "Findings suggest that for women who conceived relatively easily, diet and physical activity behaviour during pregnancy is primarily based upon a combination of automatic judgements, physical sensations, and perceptions of what pregnant women are supposed to do. Health professionals and other credible sources appear to exert less influence. As such, pregnancy alone may not create a 'teachable moment'. Statement of contribution What is already known on this subject? Significant life events can be cues to action with relation to health behaviour change. However, much of the empirical research in this area has focused on negative health experiences such as receiving a false-positive screening result and hospitalization, and in relation to unequivocally negative behaviours such as smoking. It is often suggested that pregnancy, as a major life event, is a 'teachable moment' (TM) for lifestyle behaviour change due to an increase in motivation towards health and regular contact with health professionals. However, there is limited evidence for the utility of the TM model in predicting or promoting behaviour change. What does this study add? Two groups of women emerged from our study: the women who had experienced difficulties in conceiving and had received fertility treatment, and those who had conceived without intervention. The former group's experience of pregnancy was characterized by a sense of vulnerability and anxiety over sustaining the pregnancy which influenced every choice they made about their diet and physical activity. For the latter group, decisions about diet and physical activity were made immediately upon discovering their pregnancy, based upon a combination of automatic judgements, physical sensations, and perceptions of what is normal or 'good' for pregnancy. Among women with relatively trouble-free conception and pregnancy experiences, the necessary conditions may not be present to create a 'teachable moment'. This is due to a combination of a reliance on non-reflective decision-making, perception of low risk, and little change in affective response or self-concept.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Cross-sectional study. College of Medicine and King Khalid University Hospital, Riyadh, Saudi Arabia. The surgical and histological data of 852 patients who underwent appendicectomy were reviewed. All incidental or interval appendicectomies were excluded. Only patients who were admitted and whose appendices were removed and subjected to histology were included (585 patients). The data on patients who had a normal appendix on histology further analyzed to include demographics, specific investigations, operative findings of the appendix and additional operative findings that need other surgical procedures. A normal appendix was removed in 54 (9.2%) of the patients. Only 5.5% of those patients had a computed tomography (CT) scan preoperatively and 3.7% had diagnostic laparoscopy. In 21 patients, additional operative and histological findings were obtained that might have caused the right lower abdominal pain.\nQuestion: Acute appendicitis: is removal of a normal appendix still existing and can we reduce its rate?",
        "gt": "In spite of the advances in the diagnostic and imaging techniques, the rates of negative findings on appendicectomy have not decreased much. Clinical judgment is still the most important factor in the management of patients with suspected acute appendicitis. The routine use of CT scan or diagnostic laparoscopy for all patients who are suspected to have appendicitis is neither cost-effective nor safe.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Fecal leukocyte test (FLT) is widely used to screen for invasive diarrheas including C. difficile associated diarrhea (CDAD), which account for more than 25 % of all antibiotic associated diarrhea. 263 stool samples from patients with suspected CDAD were studied simultaneously for fecal leukocyte test (FLT) and Clostridium difficile toxin assay (CDTA). FLT was performed by the Giemsa technique and CDTA was performed by enzyme immuno assay (EIA). Sensitivity, specificity, positive predictive value and negative predictive value of FLT as compared to CDTA were 30%, 74.9%, 13.2% and 89.3% respectively.\nQuestion: Is Fecal Leukocyte Test a good predictor of Clostridium difficile associated diarrhea?",
        "gt": "Considering the poor sensitivity of FLT, and the comparable cost and time of obtaining a CDTA at our institution, we conclude that FLT is not a good screening test for CDAD. Possible reasons for FLT being a poor predictor of CDTA are discussed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A recent British Association of Endocrine and Thyroid Surgeons consensus document suggested that day-case thyroidectomy is feasible in a small proportion of patients but has to be balanced against risks. Currently, there is no large reported series of same-day discharge in thyroid and parathyroid surgery from the UK. The aim of this study was to assess the outcomes of day-case thyroid and parathyroid surgery. We conducted a retrospective study of patients who underwent thyroid or parathyroid surgery between January 2000 and December 2011 at Oxford University Hospitals. The end points analysed were complications in the form of bleeding, hypocalcaemia, wound infection, and seroma. A total of 2,102 patients (495 males and 1,607 females, age range = 13-90 years) underwent surgery for parathyroid (n = 776) or thyroid (n = 1,326) conditions. The operations included minimally invasive parathyroidectomy (MIP) (n = 331), open parathyroidectomy (n = 445), lobectomy (n = 687), isthmusectomy (n = 23), total thyroidectomy (n = 580) and thyroglossal cyst excision (n = 36). Routine arrangements were in place for consideration of same-day discharge for lobectomies, thyroglossal cyst surgery, and MIPs; lobectomies accounted for 63 % of same-day cases, followed by parathyroidectomy (35 %). Over the decade, day-case surgery increased from 4 to 17 % for thyroid surgery and from 20 to 40 % for parathyroid surgery. None of the 435 patients who had same-day discharge was readmitted for bleeding [confidence interval (CI) 0-0.6 %]. There was no 30-day mortality for the whole cohort. Complications in patients who underwent surgery in the whole cohort versus those who were discharged the same day were temporary hypocalcaemia (4 vs. 0.2 %), permanent hypocalcaemia (1 vs. 0.4 %), bleeding (0.4 vs. 0 %), seroma (0.3 vs. 0 %), and wound infection (0.3 vs. 0 %).\nQuestion: Changing trends in thyroid and parathyroid surgery over the decade: is same-day discharge feasible in the United Kingdom?",
        "gt": "Current protocols for thyroid or parathyroid surgery make same-day discharge feasible and safe in carefully selected patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the effectiveness and direct of two protective devices-a shielded 3 ml safety syringe (Safety-Lok; Becton Dickinson and Co., Becton Dickinson Division, Franklin Lakes, N.J.) and the components of a needleless IV system (InterLink; Baxter Healthcare Corp., Deerfield, Ill.)--in preventing needlestick injuries to health care workers. Twelve-month prospective, controlled, before-and-after trial with a standardized questionnaire to monitor needlestick injury rates. Six hospital inpatient units, consisting of three medical units, two surgical units (all of which were similar in patient census, acuity, and frequency of needlesticks), and a surgical-trauma intensive care unit, at a 900-bed urban university medical center. All nursing personnel, including registered nurses, licensed practical nurses, nursing aides, and students, as well as medical teams consisting of an attending physician, resident physician, interns, and medical students on the study units. After a 6-month prospective surveillance period, the protective devices were randomly introduced to four of the chosen study units and to the surgical-trauma intensive care unit. Forty-seven needlesticks were reported throughout the entire study period, 33 in the 6 months before and 14 in the 6 months after the introduction of the protective devices. Nursing staff members who were using hollow-bore needles and manipulating intravenous lines accounted for the greatest number of needlestick injuries in the pre-intervention period. The overall rate of needlestick injury was reduced by 61%, from 0.785 to 0.303 needlestick injuries per 1000 health care worker-days after the introduction of the protective devices (relative risk = 1.958; 95% confidence interval, 1.012 to 3.790; p = 0.046). Needlestick injury rates associated with intravenous line manipulation, procedures with 3 ml syringes, and sharps disposal were reduced by 50%; however, reductions in these subcategories were not statistically significant. No seroconversions to HIV-1 or hepatitis B virus seropositivity occurred among those with needlestick injuries. The direct cost for each needlestick prevented was $789.\nQuestion: Do protective devices prevent needlestick injuries among health care workers?",
        "gt": "Despite an overall reduction in needlestick injury rates, no statistically significant reductions could be directly attributed to the protective devices. These devices are associated with a significant increase in cost compared with conventional devices. Further studies must be concurrently controlled to establish the effectiveness of these devices.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The patient-centered medical home has gained much traction. Little is known about the relationship between the model and specific health care processes for chronic diseases such as diabetes. This study assesses the impact of features of a medical home on diabetes care. A cross-sectional survey of 540 patients with Medicaid (Medi-Cal) health insurance and type 2 diabetes in Los Angeles County was performed. The Primary Care Assessment Tools was used to measure seven features of medical-home performance. The response rate of the patient survey was 68.9%. Patient-reported medical-home performance averaged a score of 2.85 \u00b1 0.29 (on a 1-4 scale, with 4 equaling the best care). Patients who received more timely and thorough diabetes care reported higher medical-home performance in every feature except for the comprehensiveness-services available. For example, the first-contact access feature score was higher among patients who had an HbA1c test in the past 6 months versus those who did not (2.38 vs. 2.25; P<0.05). Before and after adjusting for sociodemographics and health status, total medical-home performance was positively associated with each diabetes care measure. A 1-point increase in total medical-home score was associated with 4.53 higher odds of an HbA1c test in the past 6 months and 1.88 higher odds of an eye exam in the past year.\nQuestion: Do experiences consistent with a medical-home model improve diabetes care measures reported by adult Medicaid patients?",
        "gt": "Features consistent with higher medical-home performance are associated with improvements in patient-reported diabetes care process measures, even in this low socioeconomic status setting. The patient-centered medical-home model may help in caring for people with type 2 diabetes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The Brazilian Government created Participatory Health Councils (PHCs) to allow citizen participation in the public health policy process. PHCs are advisory bodies that operate at all levels of government and that bring together different societal groups to monitor Brazil's health system. Today they are present in 98% of Brazilian cities, demonstrating their popularity and thus their potential to help ensure that health policies are in line with citizen preferences. Despite their expansive reach, their real impact on health policies and health outcomes for citizens is uncertain. We thus ask the following question: Do PHCs offer meaningful opportunities for open participation and influence in the public health policy process? Thirty-eight semi-structured interviews with health council members were conducted. Data from these interviews were analyzed using a qualitative interpretive content analysis approach. A quantitative analysis of PHC data from the Sistema de Acompanhamento dos Conselhos de Saude (SIACS) database was also conducted to corroborate findings from the interviews. We learned that PHCs fall short in many of the categories of good governance. Government manipulation of the agenda and leadership of the PHCs, delays in the implementation of PHC decision making, a lack of training of council members on relevant technical issues, the largely narrow interests of council members, the lack of transparency and monitoring guidelines, a lack of government support, and a lack of inclusiveness are a few examples that highlight why PHCs are not as effective as they could be.\nQuestion: Participatory health councils and good governance: healthy democracy in Brazil?",
        "gt": "Although PHCs are intended to be inclusive and participatory, in practice they seem to have little impact on the health policymaking process in Brazil. PHCs will only be able to fulfil their mandate when we see good governance largely present. This will require a rethinking of their governance structures, processes, membership, and oversight. If change is resisted, the PHCs will remain largely limited to a good idea in theory that is disappointing in practice.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Over two-thirds of UK medical schools are augmenting their selection procedures for medical students by using the United Kingdom Clinical Aptitude Test (UKCAT), which employs tests of cognitive and non-cognitive personal qualities, but clear evidence of the tests' predictive validity is lacking. This study explores whether academic performance and professional behaviours that are important in a health professional context can be predicted by these measures, when taken before or very early in the medical course. This prospective cohort study follows the progress of the entire student cohort who entered Hull York Medical School in September 2007, having taken the UKCAT cognitive tests in 2006 and the non-cognitive tests a year later. This paper reports on the students' first and second academic years of study. The main outcome measures were regular, repeated tutor assessment of individual students' interpersonal skills and professional behaviour, and annual examination performance in the three domains of recall and application of knowledge, evaluation of data, and communication and practical clinical skills. The relationships between non-cognitive test scores, cognitive test scores, tutor assessments and examination results were explored using the Pearson product-moment correlations for each group of data; the data for students obtaining the top and bottom 20% of the summative examination results were compared using Analysis of Variance. Personal qualities measured by non-cognitive tests showed a number of statistically significant relationships with ratings of behaviour made by tutors, with performance in each year's objective structured clinical examinations (OSCEs), and with themed written summative examination marks in each year. Cognitive ability scores were also significantly related to each year's examination results, but seldom to professional behaviours. The top 20% of examination achievers could be differentiated from the bottom 20% on both non-cognitive and cognitive measures.\nQuestion: Can personal qualities of medical students predict in-course examination success and professional behaviour?",
        "gt": "This study shows numerous significant relationships between both cognitive and non-cognitive test scores, academic examination scores and indicators of professional behaviours in medical students. This suggests that measurement of non-cognitive personal qualities in applicants to medical school could make a useful contribution to selection and admission decisions. Further research is required in larger representative groups, and with more refined predictor measures and behavioural assessment methods, to establish beyond doubt the incremental validity of such measures over conventional cognitive assessments.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients who sustain traumatic vertebral fractures often have multiple other associated injuries. Because of the mechanisms of injury, many of these patients routinely undergo chest computed tomographic (CCT) and/or abdominal/pelvic computed tomographic (APCT) scans to diagnose intrathoracic or intra-abdominal injuries. These scans are routinely reformatted to provide more detailed imaging of the spine. Although the patient does not incur more radiation, the charges associated with this are significant. This study compared the sensitivity of these CT modalities in detecting thoracolumbar spine fractures. A retrospective chart review identified blunt trauma victims, admitted through the emergency department, with a discharge diagnosis of thoracic or lumbar spine fracture that received (1) a chest and T-spine CT, (2) an abdominal/pelvic and lumbar spine CT, or both. Final radiologic readings of these patients' CT scans were obtained, and the sensitivities of the different imaging methods were compared. Discharge diagnosis of spine fracture was considered the gold standard. One hundred seventy-six APCT scans with reformatting and 175 CCT scans with reformatting were available for comparison. There were 9 of 176 false-negative APCT scans vs 3/176 false-negative lumbar spine CT scans. There were 14/175 false-negative CCT scans vs 2/175 false-negative thoracic spine CT scans. The differences in sensitivity were significant (P<.001) for both comparisons.\nQuestion: Computed tomographic screening for thoracic and lumbar fractures: is spine reformatting necessary?",
        "gt": "Reformatting of CCT and APCT scans gives improved sensitivity in the detection of thoracic and lumbar spine fractures in trauma patients. Future study looking at clinically significant fractures or those that change clinical management decisions may find that the reformatted images are not routinely needed as a screening tool.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this study was to determine whether there is a difference in biopsying bone (endplate), disk, or paravertebral soft tissue to culture the pathogenic organism causing diskitis-osteomyelitis. A retrospective review was conducted of 111 spinal biopsies performed between 2002 and 2011. Pathologic examination was used as the reference standard for detecting diskitis-osteomyelitis. Microbiologic yield, sensitivity, and specificity were calculated. The yields for different groups were compared by use of Fisher exact test. The analysis was repeated with biopsy samples from patients not being treated with antibiotics at the time of biopsy. A total of 122 biopsy specimens were obtained from 111 spinal biopsy procedures on 102 patients. Overall, 27 (22%) biopsies were performed on the endplate-disk, 61 (50%) on the disk only, and 34 (28%) on paravertebral soft tissue only. The microbiologic yield was 36% for all biopsies, 19% for endplate-disk biopsies, 39% for disk-only biopsies, and 44% for soft-tissue biopsies. The sensitivity and specificity of the microbiologic results for all specimens were 57% and 89%; endplate-disk, 38% and 86%; disk only, 57% and 89%; and paravertebral soft tissue, 68% and 92%. There was no statistically significant difference between the yields of the endplate-disk, disk-only, and paravertebral soft-tissue biopsies.\nQuestion: Is Biopsying the Paravertebral Soft Tissue as Effective as Biopsying the Disk or Vertebral Endplate?",
        "gt": "Paravertebral soft-tissue changes, when present, may be considered a viable target for biopsy in cases of diskitis-osteomyelitis, even in the absence of a paravertebral abscess.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Falls have become increasingly focussed in the current discussion about patient safety and quality indicators because falls are one of the most frequently documented problems during geriatric treatment in hospital. We compared 811 \"fallers\" (total number of falls: 1177) and 5229 \"non-fallers\" in a geriatric hospital. The research question was: Are falls associated with an outcome of lower mobility (Barthel Index) at discharge? A significant difference between the two groups was found in the following items: female (fallers 63.4% vs. non-fallers 69.8%), hospital stay (fallers 27.1 days vs. non-fallers 19.3 days), Barthel Index at admission (fallers 39.3 pts vs. non-fallers 48.3 pts). No linear relationship was found between the rate of falls and the mobility (Barthel Index at discharge). The lowest fall rates were found in the BI groups 80-100 pts (6.4%) and 0-20 pts (13.1%). A higher rate of falls was associated with a better outcome in two of the three mobility-related items of the Barthel Index (transfer, walk/wheelchair). 44% of the falls resulted in injuries or pain.\nQuestion: In-hospital falls: a quality indicator?",
        "gt": "The comparison of fall rates requires risk adjustment. Falls are not a suitable quality indicator.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine whether serum concentrations of S100beta protein and neuron-specific enolase (NSE) are predictors of cerebral damage in cardiovascular surgery. Prospective clinical study. University hospital. Eighteen patients with conventional cardiopulmonary bypass (CPB), 7 with selective cerebral perfusion (SCP), and 3 volunteers (blood samples). None. S100beta and NSE were measured in the blood obtained at 7 time points during and after operation. The concentrations of these markers in the blood from the surgical field and the cell-saver device, and the influence of graded hemolysis (in vitro) on the concentrations of these proteins were also examined. The mean values of S100beta in the CPB group (2.08 +/- 2.00 ng/mL) and the SCP group (1.46 +/-0.77 ng/mL) were highest after aortic declamping and after termination of SCP, respectively. The mean values of NSE in the CPB group (29.1 +/- 14.0 ng/mL) and the SCP group (31.2 +/- 13.6 ng/mL) were highest after termination of CPB and at the end of the operation, respectively. Three patients suffered from cerebral complications, but the elevation of these markers during operation was indistinguishable from those in the other patients. Peak concentrations of S100beta protein in the CPB group and NSE in the SCP group were correlated with the duration of aortic cross-clamping and CPB, respectively. S100beta protein and NSE concentrations in the blood from the surgical field were significantly larger than those in arterial blood, whereas the concentrations in the blood in the cell-saving device were not elevated. The concentration of S100beta protein was not influenced by the extent of hemolysis, whereas NSE concentration was markedly elevated by hemolysis.\nQuestion: Are serum S100beta proteins and neuron-specific enolase predictors of cerebral damage in cardiovascular surgery?",
        "gt": "A large part of the increases in S100beta protein and NSE during CPB and SCP is not attributed to neuronal damage, but to contamination with the blood from the surgical field. To determine whether these markers are useful to predict neurologic complications, it will be necessary to exclude contamination from the surgical field as observed in the present study.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the association between self-rated health, obesity, and self-reported health behaviors of Latino immigrants Two hundred two Latino immigrants (mean age=31.63, SD=8.30, 54% female) participated in a 15-minute interview and height and weight measurements. Participants reporting good to excellent health reported engaging in physical activity during the past month (P<.05), eating more fruits and vegetables (P<.001 and P<.01 respectively), and watching less television (P<.01) than did those who reported fair to poor health. Self-rated health was not associated with BMI.\nQuestion: Do Latino immigrants link self-rated health with BMI and health behaviors?",
        "gt": "Greater attention to Latinos' self-perception of health in relation to weight is needed to develop interventions to improve health status.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Minimally invasive surgery to stage early ovarian cancer is still regarded as pioneering among gynecologic oncologists. Previous retrospective experiences demonstrated the safety and feasibility of laparoscopy in this field. To review the laparoscopic staging procedure in a series of patients with early ovarian cancer and compare results with the literature. From January 2004 to September 2011, 19 patients with apparent early stage ovarian/fallopian tube cancer Stage IA to IC underwent either primary treatment or completion staging by laparoscopy. Surgical, pathologic, and oncologic outcomes were analyzed. The mean operative time was 212 +/- 69 minutes. Three patients (16%) underwent fertility sparing surgery. The mean estimated blood loss was two +/- two g/dl. The mean number of pelvic and para-aortic lymph nodes collected was 17 (range 7-27) and 14 (range 8-21), respectively. The mean volume of ovarian/tubal tumor was 119 cm3 (range 1.5-500). The disease was reclassified to a higher stage in ten women (52%). One major intraoperative complication (five percent) occurred which required the conversion to laparotomy. The mean follow up period was 30 +/- 16 months (range 10-74). Overall survival and disease-free survival were 100% and 84%, respectively.\nQuestion: Laparoscopic management of early stage ovarian cancer: is it feasible, safe, and adequate?",
        "gt": "Laparoscopic staging of early ovarian cancer appears to be feasible and comprehensive when performed by gynecologic oncologists experienced with advanced laparoscopy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The analysis by Denaturing Gradient Gel Electrophoresis (DGGE) of the PCR-amplified V3 region of 16S rRNA gene was previously shown to detect and differentiate a large number of human and animal mycoplasmas. In this study, we further assessed the suitability of the technique for epidemiological surveillance of mycoplasmas belonging to the 'Mycoplasma mycoides' cluster, a phylogenetic group that includes major ruminant pathogens. The V3 region of 16S rRNA genes from approx. 50 field strains was amplified and analysed by DGGE. Detection and identification results were compared with the ones obtained by antigenic testing and sequence analysis.\nQuestion: Epidemiological surveillance of mycoplasmas belonging to the 'Mycoplasma mycoides' cluster: is DGGE fingerprinting of 16S rRNA genes suitable?",
        "gt": "The DGGE technique is robust and valuable as a first-line test, but the patterns obtained for strains belonging to the 'M. mycoides' cluster were too variable within a taxon and in contrast too conserved between taxa to allow an unequivocal identification of isolates without further analysis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Modified Response Evaluation Criteria In Solid Tumors (mRECIST), developed by the American Association for the Study of Liver Diseases (AASLD) criteria measure changes in arterialized hepatocellular carcinoma (HCC) and aim at providing a common framework for the design of clinical trials. It still isn't determined whether mRECIST can be applied in routine clinical practice and whether mRECIST could estimate viable tumor correctly. We retrospectively analyzed data from patients subjected to transcatheter arterial chemoembolization (TACE) as initial treatment for advanced HCC in our institution. Not suitable for using mRECIST standard cases and the agreement in response between RECIST and mRECIST were assessed. Then we selected HCC patients who achieved complete response (CR) according to mRECIST, following PET-CT examinations. We also compared arterial enhanced computed tomography (CT) or magnetic resonance imaging (MRI) with positron emission tomography (PET)-CT examination and analyzed their correlation. Out of 143 HCC patients, mRECIST evaluation appeared to be applicable for 128 (89.51%) assessable patients. In these 128 assessable patients, the objective response (OR) rates (complete/CR+partial response/PR) according to RECIST and mRECIST were 64.06% (82 of 128 patients) and 78.13% (100 of 128; p<0.001), respectively. Discordance in the response evaluations between the two methods was observed in 46 patients (35.94%) and was statistically significant (Kappa=0.491; p<0.001). The overall survival (OS) of patients who achieved an OR as assessed by mRECIST or by RECIST was significantly better than the survival of non-responding patients (stable disease/SD, or progressive disease/PD).\nQuestion: The true role of mRECIST guideline: does it really estimate viable tumor or merely improve accuracy in hepatocellular carcinoma response evaluation?",
        "gt": "Although mRECIST criteria show a good correlation with prognosis, they demand strict requirements for patient selection and couldn't be useful as a tool for routine clinical practice. Furthermore, merely by means of contrast-enhanced CT or MRI, mRECIST couldn't estimate viable tumor sufficiently.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The prevalence of human papillomavirus (HPV) rises with increasing histological severity of neoplasia, more cigarettes smoked per day and higher lifetime number of sexual partners in women with cervical dyskaryosis. Recently, the highly sensitive SPF10 primers and Inno-LiPA (line probe assay) HPV prototype research assay became available for the detection and typing of HPV. using this system, we challenged the previously reported findings. the study group comprised 304 women referred because of abnormal pap smears in whom a histological diagnosis was made. Data on the lifetime number of sexual partners and smoking behaviour were obtained by questionnaire. HPV analysis was performed on cervical scrapes obtained at the enrollment visit. oncogenic HPV was found in 288 (95%) women. A total of 86 (30%) out of these 288 women disclosed multiple types. HPV 16 occurred significantly less often in multiple infections than was expected on the basis of chance alone. The grade of neoplasia was significantly associated with the presence of oncogenic HPV, and this association depended on the presence of HPV type 16. No association was found between grade of neoplasia and the presence of multiple HPV types. Neither the lifetime number of sexual partners nor smoking were associated with oncogenic HPV, the five most frequent HPV types separately or the presence of multiple types.\nQuestion: Using a new HPV detection system in epidemiological research: change of views on cervical dyskaryosis?",
        "gt": "we conclude that the association between the detection of HPV and the epidemiological risk factors, as found with the GP5/6 PCR in the past, could not be confirmed when using SPF10 PCR primers and LiPA HPV genotyping. We suggest that the number of sexual partners and smoking may be determinants of high HPV viral load rather than determinants of the presence of HPV per se.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We aimed to investigate the epidemiology of self-reported chronic respiratory disease throughout Scotland, and to explore the relationship between quality of life and geographic location in those reporting disease. A cross-sectional study. Self-reported data on age, gender, socioeconomic factors, smoking habits, selected illnesses (major respiratory and atopic diseases, and other major conditions), respiratory symptoms, use of medicines and health services, and quality of life were collected using a postal questionnaire. A total of 4,560 adults registered with 1 of 57 family practices (22 rural and 35 urban) throughout Scotland. The response rate was 60%. Following adjustment for potential confounders, participants from rural areas reported a significantly lower prevalence of any chest illness (adjusted odds ratio [OR], 0.72; 95% confidence interval [CI], 0.58 to 0.91), asthma (adjusted OR, 0.59; 95% CI, 0.46 to 0.76), and eczema/dermatitis (adjusted OR, 0.67; 95% CI, 0.52 to 0.87). Rural location was less likely than urban location to be associated with the reporting of persistent cough and phlegm and different symptoms (types of breathlessness and wheeze) indicative of asthma. No difference in prevalence was found for other respiratory problems. Participants from rural areas reporting COPD or emphysema, or cough or phlegm symptoms had significantly better quality of life scores than their urban counterparts.\nQuestion: Is living in a rural area good for your respiratory health?",
        "gt": "In this study, living in a rural area was associated with a lower prevalence of asthma but not other chronic respiratory disorders, and a lower prevalence of some respiratory symptoms (including wheeze). Although the prevalence of COPD or emphysema did not differ between rural and urban areas, rural residency appeared to be associated with better health status among subjects with these conditions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the outcome of the port-access approach for patent foramen ovale (PFO) closure and to identify the long-term risk of recurrent thromboembolic events in the paradoxical embolus subgroup after closure. Between 1997 and 2001, 31 patients underwent PFO closure using the port-access approach. Twelve of the 31 patients underwent PFO closure secondary to at least one paradoxical embolic event leading to either transient ischemic attack or cerebral infarction. All patients were followed longitudinally with office visits and telephone interviews. The mean age was 47 years (range 18 to 85 years). All procedures were completed successfully without conversion to median sternotomy. The mean duration of aortic occlusion and cardiopulmonary bypass for all patients (n = 31) was 32 minutes (range 17 to 55 minutes) and 72 minutes (range 40 to 124 minutes), respectively. Postoperative complications included pneumonia/pulmonary embolus (n = 1), transient atrial fibrillation (n = 3, 9.7%), and exploration for bleeding (n = 3, 9.7%). No deaths were recorded. All patients were assessed using transesophageal echocardiography, and the closure of the PFO was documented. The average length of hospital stay was 3.8 days (range 2 to 10 days) for patients with paradoxical emboli. The mean follow-up period for the paradoxical embolus subgroup was 23 months (range 4 to 45 months). One patient was lost to follow-up. Neither transient ischemic attack nor cerebral infarction recurred during follow-up.\nQuestion: Minimal access closure of patent foramen ovale: is it also recommended for patients with paradoxical emboli?",
        "gt": "The port-access approach to PFO closure is a safe and effective procedure, with acceptable initial experience outcome and excellent low-risk rate of recurrent thromboembolic events.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The objective of this study was to determine whether the duration and progress of the first stage of labor are different in black compared with white women. Retrospective cohort study of labor progress among consecutive black (n\u2009=\u20093,924) and white (n\u2009=\u2009921) women with singleton term pregnancies (\u2265 37 weeks) who completed the first stage of labor. Duration of labor and progression from 1 cm to the next was estimated using interval-censored regression. Labor duration and progress among black and white women in the entire cohort, and stratified by parity, were compared in multivariable interval-censored regression models. Repeated-measures analysis with 9th-degree polynomial modeling was used to construct average labor curves. There were no significant differences in duration of the first stage of labor in black compared with white women (median, 4-10 cm: 5.1 vs. 4.9 hours [p\u2009=\u20090.43] for nulliparous and 3.5 vs. 3.9 hours [p\u2009=\u20090.84]for multiparous women). Similarly, there were no significant differences in progression in increments of 1 cm. Average labor curves were also not significantly different.\nQuestion: Are there differences in the first stage of labor between Black and White women?",
        "gt": "Duration and progress of the first stage of labor are identical in black and white women. This suggests similar standards may be applied in the first stage of labor.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Healthcare institutions spend enormous time and effort to train their workforce. Web-based training can potentially streamline this process. However the deployment of web-based training in a large-scale setting with a diverse healthcare workforce has not been evaluated. The aim of this study was to evaluate the satisfaction of healthcare professionals with web-based training and to determine the predictors of such satisfaction including age, education status and computer proficiency. Observational, cross-sectional survey of healthcare professionals from six hospital systems in an integrated delivery network. We measured overall satisfaction to web-based training and response to survey items measuring Website Usability, Course Usefulness, Instructional Design Effectiveness, Computer Proficiency and Self-learning Attitude. A total of 17,891 healthcare professionals completed the web-based training on HIPAA Privacy Rule; and of these, 13,537 completed the survey (response rate 75.6%). Overall course satisfaction was good (median, 4; scale, 1 to 5) with more than 75% of the respondents satisfied with the training (rating 4 or 5) and 65% preferring web-based training over traditional instructor-led training (rating 4 or 5). Multivariable ordinal regression revealed 3 key predictors of satisfaction with web-based training: Instructional Design Effectiveness, Website Usability and Course Usefulness. Demographic predictors such as gender, age and education did not have an effect on satisfaction.\nQuestion: Satisfaction with web-based training in an integrated healthcare delivery network: do age, education, computer skills and attitudes matter?",
        "gt": "The study shows that web-based training when tailored to learners' background, is perceived as a satisfactory mode of learning by an interdisciplinary group of healthcare professionals, irrespective of age, education level or prior computer experience. Future studies should aim to measure the long-term outcomes of web-based training.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To describe the association between labour market status and death by suicide with focus on admission with a psychiatric disorder. Nested case-control study. Data from routine registers. Entire Danish population. 9011 people aged 25-60 years who committed suicide during 1982-1997 and 180 220 matched controls. In the general population, not being fully employed is associated with a twofold to threefold increased relative risk of death by suicide, compared with being fully employed. In contrast, fully employed people who have been first admitted to a psychiatric hospital within the past year are at increased suicide risk. Patients who are unemployed, social benefits recipients, disability pensioners, or otherwise marginalised on the labour market have a suicide risk of 0.60 (95% CI: 0.46 to 0.78), 0.41 (0.23 to 0.74), 0.70 (0.45 to 1.08), and 0.86 (0.53 to 1.41), respectively. Although a similar risk decrease is found in women, men, people younger than 30 years, people older than 45 years, and in people who become unemployed, the reversed effect attenuates with time since admission, and little association is seen when a marginal structural model is applied.\nQuestion: Effect of psychiatric illness and labour market status on suicide: a healthy worker effect?",
        "gt": "Although the results show an increased suicide mortality associated with unemployment and labour market marginalisation in the general population, the results suggest little or an inverse association between unemployment and suicide in people with psychiatric illness. The associations seen suggest the need to consider healthy worker selection effects when studying the causal pathway from unemployment and psychiatric illness to suicide.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study sought to determine whether there is a positive correlation between gallbladder emptying, biliary pain, and in vitro contractility. Ultrasound measurements were carried out on 25 gallstone patients. The response of gallbladder strips to 1.75*10(-11) to 5.25*10(-7) M cholecystokinin-8 was recorded. In a second study 23 patients filled in pain questionnaires, and in vitro studies were again carried out. Of five patients with no gallbladder emptying, four had in vitro contraction. Overall, a significant, positive linear correlation was found (P<0.0001). In the second study in vitro contractility showed a positive linear correlation with pain.\nQuestion: The relationship between in vivo emptying of the gallbladder, biliary pain, and in vitro contractility of the gallbladder in patients with gallstones: is biliary colic muscular in origin?",
        "gt": "Gallbladder emptying correlates with contractility. However, since most 'non-contractors' can contract, we suggest the term 'non-emptying' or 'emptying' to describe gallbladder dynamics. The positive correlation between pain and contractility suggests that biliary pain has a muscular component.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Long-term psychiatric consequences of World War II are currently a main medical and political topic in Germany. This retrospective study examined 33 psychogeriatric cases. PTSD-criteria following ICD-10 were fulfilled in every case. All patients had a delayed subtype of PTSD with a latency of 14-60 years between trauma and onset of disorder. No case of chronic PTSD was found. In 26 cases a depression was diagnosed.\nQuestion: Do German World War II victims fulfill PTSD-criteria?",
        "gt": "Long latencies for PTSD are a typical feature in psychogeriatrics, possibly due to the situation in post-war-Germany probably even more in the Soviet occupied zone, the later German Democratic Republic (GDR). In the GDR it was not at all a public topic to speak about Russian violence (political taboo). The depressive and psychotic comorbidity of psychogeriatric PTSD-patients should be examined more specifically in future studies.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The cross-cultural applicability of the concept of posttraumatic stress was investigated by assessing symptom frequency and levels of comorbid psychopathology in adolescents from the United States and Russia. A self-report survey was conducted in representative samples of 2,157 adolescents 14 to 17 years old from urban communities of the United States (N=1,212) and Russia (N=945). In both countries, the levels of all three major clusters of posttraumatic symptoms (reexperiencing, avoidance, and arousal), as well as of internalizing psychopathology, increased along with the level of posttraumatic stress. Expectations about the future had a tendency to decrease with increasing posttraumatic stress. No differences between countries in significant interaction effects for symptom levels were found.\nQuestion: Is posttraumatic stress in youth a culture-bound phenomenon?",
        "gt": "The current findings suggest that posttraumatic symptoms and their associations with other adolescent mental health problems are not culture bound and that the psychological consequences of trauma follow similar dynamics cross-culturally.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the growth and neurodevelopment outcomes of very low-birth-weight (VLBW) preterm infants supplemented with oral probiotics for the prevention of necrotizing enterocolitis (NEC). This prospective follow-up study was conducted in a cohort of VLBW preterm infants enrolled in a randomized controlled clinical trial to evaluate the efficacy of oral probiotics for the prevention of NEC. Growth outcomes included weight, length, and head circumference. Cognitive and neuromotor development were assessed by using the Bayley Scales of Infant Development II. Sensory and neurological performance was evaluated by standard techniques. The primary outcome was neurodevelopmental impairment at 18 to 22 months' corrected age. A total of 221 infants completed the trial protocol. Of the 208 infants eligible for follow-up, 174 infants (86 in the probiotics group and 88 in the control group) were evaluated. There was no significant difference in growth and neurodevelopmental outcomes between the two groups.\nQuestion: Do oral probiotics affect growth and neurodevelopmental outcomes in very low-birth-weight preterm infants?",
        "gt": "Oral probiotic administered to VLBW infants to reduce the incidence and severity of NEC started with the first feed did not affect growth, neuromotor, neurosensory, and cognitive outcomes at 18 to 22 months' corrected age.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Recent meta-analyses assessing the efficacy of perioperative beta-blockade trials have failed to show a reduction in postoperative morbidity and mortality. Tight control of heart rate (HR) has been suggested to improve these outcomes. Meta-analyses have not considered the influence of tight HR control on the efficacy of perioperative beta-blockade. Using previously published search strategies, we identified all randomized trials evaluating perioperative beta-blockers after noncardiac surgery. This search yielded 10 trials with 2176 patients. We used the data from these studies to correlate measures of HR control with major postoperative outcomes, primarily in-hospital myocardial infarction (MI). Odds ratio (OR) and 95% confidence intervals (CI) were calculated, and metaregression was performed correlating measures of HR control with MI. The combined results of all studies did not show a significant cardioprotective effect of beta-blockers, with considerable heterogeneity among the studies (OR = 0.76; 95% CI = 0.4-1.4; P = 0.38 heterogeneity: I(2) = 34%). However, grouping the trials on the basis of maximal HR showed that trials where the estimated maximal HR was<100 bpm were associated with cardioprotection (OR = 0.23; 95% CI = 0.08-0.65; P = 0.005) whereas trials where the estimated maximal HR was>100 bpm did not demonstrate cardioprotection (OR = 1.17; 95% CI = 0.79-1.80; P = 0.43) with no heterogeneity. Moreover, metaregression of the HR response to beta-blockade against the log OR of postoperative MI demonstrated a linear association between the effect of beta-blockade on the mean, maximal, and variation in HR and the OR of an MI (r(2) = 0.63; P<0.001) where a larger effect of beta-blockers on HR was associated with a decreased incidence of postoperative MI. Across all studies, beta-blockade resulted in a reduction in postoperative HR (weighted mean difference: 8.6 bpm; 95% CI = -9.6 to -7.6; I(2) = 85.3%) with considerable heterogeneity. This large heterogeneity in HR response to beta-blockade was found to be related, in part, to the type of beta-blocker, specifically, metoprolol, and the concomitant use of calcium channel blockers. Calcium channel blocker use and beta-blockers other than metoprolol resulted in more effective control of HR. There was wide variability in the HR response to beta-blockade. Twenty-five percent of patients receiving beta-blockers had episodes when the HRs were more than 100 bpm, although 15% of placebo patients also had bradycardia, which would have required a dose reduction had they been administered beta-blockers. Finally, this analysis found that perioperative beta-blockade was associated with an increased incidence of bradycardia (OR = 3.49; 95% CI = 2.4-5.9) and congestive heart failure (OR = 1.68; 95% CI = 1.00-2.8).\nQuestion: Does tight heart rate control improve beta-blocker efficacy?",
        "gt": "The trials that achieve the most effective control of HR are associated with a reduced incidence of postoperative MI, suggesting that effective control of HR is important for achieving cardioprotection. Second, this analysis demonstrates that administration of beta-blockers does not reliably decrease HRs in all patients, and may be associated with increased side effects. Judicious use of combination therapy with other drugs may be necessary to achieve effective postoperative control of HR.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Congenital lobar emphysema (CLE) is characterized by unilobar alveolar distension secondary to bronchomalacia or absent cartilage. In contrast, congenital pulmonary lymphangiectasis (CPL) is defined as distended lymphatics in the bronchovascular bundle, in the interlobular septa, and in the subpleural space. Little information is available regarding the radiologic presentation of CLE as it correlates with histological diagnosis. In a retrospective chart review from 1995 to 2002, 8 patients (5 boys and 3 girls) with clinical and radiologic diagnosis of CLE were reviewed. The mean age at diagnosis was 26 months (range, 11 days to 10 years). All but one had classic respiratory symptoms of CLE. Six of 7 chest computed tomography (CT), scans were suggestive of CLE. Of 8 patients, 3 were treated without pulmonary resection with resolution of symptoms. Five patients underwent lobectomies, and histology results showed CPL in 3. CT failed to identify CPL in all cases.\nQuestion: Unilobar congenital pulmonary lymphangiectasis mimicking congenital lobar emphysema: an underestimated presentation?",
        "gt": "Diagnosis of CLE is not as straightforward as the literature suggests. Even retrospectively, radiologic distinction between CLE and CPL could not be achieved by an experienced pediatric radiologist. CPL, thus, mimics CLE clinically and radiologically and, therefore, should be considered in the differential radiologic diagnosis of CLE.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: No prospective data exist regarding the bleeding risk attributable to endoscopic biopsy in patients taking antiplatelet agents. A majority of Western endoscopists withdraw antiplatelet agents before upper endoscopy, despite expert guidelines to the contrary.STUDY: We performed a prospective, single-blind, randomized study in healthy volunteers participating in a larger study regarding the effect of antiplatelet agents on gastroduodenal mucosal healing. Multiple gastroduodenal biopsies were performed during 2 esophagogastroduodenoscopy in subjects dosed with aspirin enteric-coated 81 mg once daily or clopidogrel 75 mg once daily. Data for endoscopic bleeding, clinical bleeding, blood vessel size, and depth of biopsy in histology specimens were collected. Four hundred and five antral biopsies and 225 duodenal biopsies were performed during 90 esophagogastroduodenoscopy in 45 subjects receiving aspirin or clopidogrel. Median maximum blood vessel diameter per biopsy was 31.9 \u03bc (range: 9.2 to 133.8). About 50.8% of biopsy specimens breached the muscularis mucosa. In the clopidogrel group, no bleeding events were noted after 350 biopsies [upper confidence limit (UCL) for probability of bleeding=0.0085]. In the aspirin group, there were no clinical events (UCL=0.0106) and one minor endoscopic bleeding event (UCL=0.0169).\nQuestion: Is gastroduodenal biopsy safe in patients receiving aspirin and clopidogrel?",
        "gt": "Consistent with expert guidelines, the absolute risk attributable to gastroduodenal biopsy in adults taking antiplatelet agents seems to be low. Half of routine biopsies enter submucosa. The largest blood vessels avulsed during biopsy correspond to midsized and large arterioles and venules.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A prospective and retrospective review of patients 10 years and younger with idiopathic scoliosis evaluated with a total spine magnetic resonance imaging (MRI) scan. To determine the incidence of neural axis abnormalities in infantile and juvenile patients with idiopathic scoliosis without neurologic findings on history and examination, to determine the need for a screening MRI in this age group. In previous studies, a 19.2% and 26% incidence of neural axis abnormalities were found in infantile and juvenile patients with \"idiopathic\" scoliosis, respectively, raising the question of routine MRI screening of the spinal canal in these patients. A prospective study included 34 consecutive patients newborn to 10 years of age treated between 1992 and 1996 at a spinal deformity clinic with idiopathic scoliosis>20 degrees without neurologic findings. In addition, a retrospective review of 64 patients age newborn to 10 years of age with idiopathic scoliosis was performed. All patients were evaluated by a total spine MRI protocol for examination of neural axis abnormalities. The incidence of neural axis abnormalities in the prospective group of 34 patients was 17.6% (6 of 34); the incidence of neural axis abnormalities was 20.3% (13 of 64) in the retrospective group. Of 6 patients in the infantile age range, 3 (50%) had neural axis abnormalities.\nQuestion: Incidence of neural axis abnormalities in infantile and juvenile patients with spinal deformity. Is a magnetic resonance image screening necessary?",
        "gt": "A total spine MRI is recommended at presentation in patients with juvenile onset idiopathic scoliosis (>20 degrees) because of the high incidence of neural axis abnormalities. Further study appears warranted to establish the incidence of neural axis abnormalities in infantile idiopathic scoliosis to determine the need for total spine MRI screening in this age group.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Motor vehicle crashes are highly elevated among newly licensed teenage drivers. Limits on high-risk driving conditions by driver licensing policies and parents can protect novice teens from negative driving outcomes, while they experience and driving proficiency. The purpose of this research was to evaluate the effects of strict parent-imposed driving limits on driving outcomes during the first year of licensure. A sample of 3,743 Connecticut teens was recruited and randomized to the Checkpoints Program or comparison condition. Assessments conducted at baseline, licensure, 3-, 6-, and 12-months postlicensure included parent-imposed driving limits, traffic violations, and crashes. Bivariate and multivariate analyses were conducted to assess the effects of strict parent limits on traffic violations and crashes during the first year of licensure. Thirty percent of teens reported at least one traffic violation and 40% reported at least one crash. More strict parent-imposed limits at licensure, 3-, 6-, and 12-months postlicensure, were associated with fewer violations and crashes in multivariate analyses. Notably, adherence to recommended night curfew was consistently associated with fewer violations and crashes.\nQuestion: Do recommended driving limits affect teen-reported traffic violations and crashes during the first 12 months of independent driving?",
        "gt": "The findings indicate that strict parent-imposed limits may protect novice teen drivers from negative driving outcomes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the association between cigarette smoking and prostatism in a community-based setting using standardized urinary symptom scores, peak urinary flow rates, and prostatic volume as indicators of disease. A population-based cohort of 2,115 Caucasian men aged forty to seventy-nine years from Olmsted County, Minnesota, was administered a previously validated questionnaire that elicited information on frequency of urinary symptoms (approximating the American Urological Association's symptom index), and a detailed history on cigarette smoking, including both amount and pack-years of smoking. Peak urinary flow rates were measured by a standard uroflowmeter (Dantec 1000). The prostatic volume was measured for a subsample of 471 men by transrectal ultrasound. Compared to never-smokers, smokers were less likely to have moderate to severe urinary symptoms (age-adjusted odds ratio 0.82; 95% confidence interval [CI] 0.61 to 1.08). This varied by smoking intensity, however; in men who smoked less than 1 pack a day the age-adjusted odds ratio was 0.53 (95% CI 0.33 to 0.83) and among men smoking 1 to 1.4 packs a day, the odds ratio was 0.87 (95% CI 0.56 to 1.36). For men who smoked 1.5 packs or more a day, the odds ratio was elevated at 1.32 (95% CI 0.84 to 2.07). Smokers were less likely to have peak flow rates less than 15 mL/sec compared with never-smokers (age- and voided volume-adjusted odds ratio 0.48; 95% CI 0.35 to 0.66), or prostatic volume greater than 40 mL (odds ratio 0.54; 95% CI 0.19 to 1.55).\nQuestion: Cigarette smoking and prostatism: a biphasic association?",
        "gt": "These data from a community-based sample suggest that light or moderate smokers are less likely to have moderate to severe prostatism, whereas heavy smokers are at least as likely to have moderate to severe prostatism compared with never-smokers.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Increasing the rate of watertight tendon healing has been suggested as an important criterion for optimizing clinical results in rotator cuff arthroscopic repair. A double-row anchorage technique for rotator cuff repair will produce better clinical results and a better rate of tendon healing than a single-row technique. Cohort study; Level of evidence, 2. We compared 31 patients undergoing surgery with a double-row anchorage technique using Panalok anchors and Cuff Tack anchors and 35 patients with rotator cuff tear undergoing surgery with a single-row anchorage arthroscopic technique using Panalok anchors. We compared pre- and postoperative Constant score and tendon healing, as evaluated by computed tomographic arthrography 6 months after surgery, in these 2 groups. The Constant score increased significantly in both groups, with no difference between the 2 groups (P = .4). Rotator cuff healing was judged anatomic in 19 patients with double-row anchorage and in 14 patients with single-row anchorage; this difference between the groups was significant (P = .03).\nQuestion: Can a double-row anchorage technique improve tendon healing in arthroscopic rotator cuff repair?",
        "gt": "In this first study comparing double- and single-row anchorage techniques, we found no significant difference in clinical results, but tendon healing rates were better with the double-row anchorage. Improvements in the double-row technique might lead to better clinical and tendon healing results.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Tobacco-induced pulmonary vascular disease is partly driven by endothelial dysfunction. The bioavailability of the potent vasodilator nitric oxide (NO) depends on competition between NO synthase-3 (NOS3) and arginases for their common substrate (L-arginine). We tested the hypothesis whereby tobacco smoking impairs pulmonary endothelial function via upregulation of the arginase pathway. Endothelium-dependent vasodilation in response to acetylcholine (Ach) was compared ex vivo for pulmonary vascular rings from 29 smokers and 10 never-smokers. The results were expressed as a percentage of the contraction with phenylephrine. We tested the effects of L-arginine supplementation, arginase inhibition (by N(omega)-hydroxy-nor-l-arginine, NorNOHA) and NOS3 induction (by genistein) on vasodilation. Protein levels of NOS3 and arginases I and II in the pulmonary arteries were quantified by Western blotting. Overall, vasodilation was impaired in smokers (relative to controls; p<0.01). Eleven of the 29 smokers (the ED(+) subgroup) displayed endothelial dysfunction (defined as the absence of a relaxant response to Ach), whereas 18 (the ED(-) subgroup) had normal vasodilation. The mean responses to 10(-4) M Ach were -23 \u00b1 10% and 31 \u00b1 4% in the ED(+) and ED(-) subgroups, respectively (p<0.01). Supplementation with L- arginine improved endothelial function in the ED(+) subgroup (-4 \u00b1 10% vs. -32 \u00b1 10% in the presence and absence of L- arginine, respectively; p = 0.006), as did arginase inhibition (18 \u00b1 9% vs. -1 \u00b1 9%, respectively; p = 0.0002). Arginase I protein was overexpressed in ED(+) samples, whereas ED(+) and ED(-) samples did not differ significantly in terms of NOS3 expression. Treatment with genistein did not significantly improve endothelial function in ED(+) samples.\nQuestion: Is arginase a potential drug target in tobacco-induced pulmonary endothelial dysfunction?",
        "gt": "Overexpression and elevated activity of arginase I are involved in tobacco-induced pulmonary endothelial dysfunction.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Despite advances in asthma treatment, severe asthma (SA) still results in high morbidity and use of health resources. Our hypothesis was that SA patients would achieve adequate control with a systematic protocol, including oral corticosteroids, budesonide/formoterol maintenance and reliever therapy and a multidisciplinary approach to improve adherence. Non-controlled (NC) SA patients were enrolled to receive 2\u00a0weeks of oral corticosteroids and 12\u00a0weeks of formoterol\u2009+\u2009budesonide. Assessments included asthma control questionnaire (ACQ), asthma control test (ACT), daily symptom diary, lung function and health-related quality of life (HRQoL) questionnaires. Of 51 patients, 13 (25.5%) achieved control. NC patients had higher utilization of health resources and higher exacerbation rates. Both controlled (C) and NC patients had significantly reduced ACQ scores after oral corticosteroid treatment. After 12\u00a0weeks, C patients continued improving. NC patients did not have significant changes. A similar pattern was found regarding lung function, use of rescue medication, and days free of symptoms. After 2\u00a0weeks of oral corticosteroids, an increase occurred in those who achieved the ACQ cut off; however, 53.8% of C patients had an ACQ\u2009<\u20091.57 versus 21.1% of NC patients (p\u2009=\u20090.03). Both groups had low HRQoL at baseline with improvement after intervention.\nQuestion: Can severe asthmatic patients achieve asthma control?",
        "gt": "Despite rigorous, optimized follow-up treatment, 75% of SA patients did not achieve adequate symptom control and presented with impaired quality of life. Conversely, application of a low-cost, easy to implement systematic protocol can prevent up to 25% of SA patients from up-titrating to new and complex therapies, thus reducing costs and morbidity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The effectiveness of the step II of the World Health Organization analgesic ladder including tramadol has been questioned recently. Retrospective study of patients treated with tramadol admitted as inpatients to one palliative care unit between November 1, 2009, and October 30, 2012. In the study period, 730 patients were admitted and 66 (9%) of them met the criteria for inclusion; 45 (68%) continued medication with tramadol until discharge from the unit, while 21 (32%) had to switch to an opioid for moderate to severe pain. The reason for switching was uncontrolled pain in 16 (76%) patients, and for 5 (24%) patients, the switch was made for other reasons.\nQuestion: Does Tramadol Have a Role in Pain Control in Palliative Care?",
        "gt": "The data suggest that tramadol may have a role to play in the treatment of pain in palliative care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To develop a preliminary characterization of the urological personality. Thirty-four urology residents (29 male) from all eleven Canadian training programs anonymously completed the Revised NEO personality inventory (NEO-PI-R(c)), a commercially available validated personality assessment tool in which participants agree or disagree with a compilation of 240 statements. A score is generated in each of five character traits according to the five factor theory of personality: extraversion (E), openness (O), conscientiousness (C), agreeableness (A) and neuroticism (N). The group mean on each scale was compared to the normative mean for the general adult population using one-sample, two-tailed t tests. Urology residents scored significantly higher than the general population on three of the five personality factors: extraversion (E) (p<.001), openness (O) (p<.02) and conscientiousness (C) (p<.05). There was no significant difference from norms in agreeableness (A) or neuroticism (N).\nQuestion: The urological personality: is it unique?",
        "gt": "The high scores in 'extraversion' reflect the social, warm, active and talkative nature of urology residents. As well, urology residents tend to be willing to entertain new ideas and are purposeful and determined based on their high scores on 'openness' and 'conscientiousness' respectively. Canadian urology residents possess a distinct personality in comparison to the general population. These provocative findings should be interpreted with caution. If confirmed on a wider basis, the data may be helpful in career counseling and resident selection. Future studies examining differences between the urological personality and other surgical subspecialties may further refine applications of the data.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Silent intrauterine infection is a frequent cause of preterm labour. Maternal C-reactive protein (CRP) and leukocyte count are important predictors of such infections. Treatment with corticosteroids is known to elevate leukocyte count and in this manner can possibly interfere with its accuracy as a predictor of infection. Therefore, we investigated the impact of antenatal administration of 16-methylene-prednisolone (Decortilen solubile) on the maternal serum level of CRP and leukocyte count. Furthermore, we determined the haptoglobin, the platelet count as well as the percentage of stab cells and lymphocytes. 20 patients with preterm labour between 25 + 6 and 34 + 2 weeks of gestation were enrolled in a prospective study. Premature rupture of the membranes, uterine bleeding, infection and treatment with antibiotics were criteria for exclusion. Three doses (60 mg) of Decortilen solubile were given intravenously 24 h apart. Blood samples were obtained before, twice a day (8.00 a.m. and p.m.) during treatment and until the day 4 after termination of corticosteroid treatment. For statistical analysis the Wilcoxon rank sum test was used. Before corticosteroid treatment the medians (range) were: CRP: 5.2 (<5.0-28.0) mg/l, haptoglobin: 1.4 (0.7-2.0) g/l, leukocytes: 10.5 (5.2-16.0) G/l, platelets: 246 (128-424) G/l, stabs: 9.5 (3.0-14.0)% and lymphocytes: 28.5 (16.0-50.0)%. During the after termination of corticosteroid administration no significant changes in the CRP and haptoglobin levels were seen. The leukocyte count was unchanged during treatment and decreased on day 1-2 after termination of treatment. The platelet count remained unchanged during corticosteroid treatment and increased significantly thereafter. The stab cell percentage increased slightly from day 1-2 to day 3-4 after termination of treatment. The lymphocyte percentage increased during treatment and decreased significantly from day 1-2 to day 3-4 after treatment.\nQuestion: Does lung maturation therapy with 16-methylene-prednisolone modify maternal infection parameters in threatened premature labor?",
        "gt": "Decortilen solubile treatment is not associated with an increase in maternal CRP-level and leukocyte count. We emphasise that the accuracy especially of the CRP for early prediction of silent infection in preterm labour does not seem to be impaired by this corticosteroid in a dosage usually administered for prevention of respiratory distress syndrome.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The finding that the relative safety disadvantage of small compared with large cars is less for post-1980 cars than for pre-1980 cars has stimulated speculation that increasing fuel economy standards would increase fatalities less than previously expected. Fatal crashes between two cars of similar model year were examined to see whether this would be the case. Driver fatality risk in relation to car mass was examined with Fatal Accident Reporting System data for crashes between two cars of a specific model year. The relative risk for driver fatality in the lighter car compared with the other driver's risk in a car 50% heavier was as follows: for 1966 through 1979 cars, the risk was between 3.7 and 5.1; for 1984 cars, 2.6; and for 1990 cars, 4.1.\nQuestion: Car mass and fatality risk: has the relationship changed?",
        "gt": "The results suggest that the lesser mass effect observed for mid-1980s cars occurred because improved crashworthiness features appeared in small cars earlier than in large cars. As all cars are redesigned, the relationship between risk and mass can be expected to approach that observed earlier in pre-1980 cars. If so, future fatality increases from fuel economy increases will be greater than estimated on the basis of mid-1980 data.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether there is an association between the 'clinic-home blood pressure difference' (CHBPD) and psychological distress in a sample not selected without regard to blood pressure and hypertension status. A cross-sectional study. An academic family medicine department in Toronto, Canada. Consecutive attenders (n = 214) of the primary care facility. Subjects aged less than 16 years and those being administered psychotropic or blood pressure-lowering agents were excluded. The CHBPD was calculated from clinic blood pressure readings and self-measurements by subjects at home; psychological distress was measured by the 30-item version of the General Health Questionnaire (GHQ). No significant association between the CHBPD and psychological distress could be shown for systolic and diastolic blood pressures. The same applied to GHQ subdomains and the CHBPD modelled on several independent variables by multiple linear regression analyses.\nQuestion: Is the 'clinic-home blood pressure difference' associated with psychological distress?",
        "gt": "The results from this study, using a large sample drawn from a community, support the view that the CHBPD is not related to anxiety, depression and other forms of psychological distress, but rather is a reaction specific to the clinic setting itself.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The role of left ventricular (LV) diastolic dysfunction in recurrent atrial fibrillation (AF) after catheter ablation remains unknown. We investigated LV diastolic function using the ratio of early transmitral flow velocity (E) to early diastolic mitral annular velocity (e') and evaluated its predictive value for AF recurrence. One hundred three AF patients underwent transthoracic echocardiography before ablation and during 3 months of follow-up. Clinical and echocardiographic parameters of patients with maintained sinus rhythm were compared with those with recurrent AF. Of 103 patients, 26 had recurrent AF during follow-up. The E/e' index was the best independent predictor of AF recurrence in a multivariate logistic regression model. A cutoff value of 11.2 for the E/e' measured before ablation was associated with a sensitivity of 80.8% and specificity of 81.8% (area under ROC curve, 0.840; 95% CI, 0.754-0.926) for AF recurrence. E/e' measured in sinus rhythm after ablation had an even better predictive power (area under ROC curve, 0.917; 95% CI, 0.850-0.983).\nQuestion: Does the E/e' index predict the maintenance of sinus rhythm after catheter ablation of atrial fibrillation?",
        "gt": "LV diastolic function was closely associated with AF recurrence after catheter ablation. The E/e' index can be used as an incremental predictor for AF recurrence after catheter ablation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The relationship between giant cell lesions (GCLs) of the maxillofacial (MF) skeleton and those of the axial/appendicular (AA) skeleton has been long debated. The present study compared the clinical and radiographic characteristics of subjects with MF and AA GCLs. This was a retrospective cohort study of patients treated for GCLs at Massachusetts General Hospital from 1993 to 2008. The predictor variables included tumor location (MF or AA) and clinical behavior (aggressive or nonaggressive). The outcome variables included demographic, clinical, and radiographic parameters, treatments, and outcomes. Descriptive and bivariate statistics were computed, and P<or= .05 was considered significant. The sample included 93 subjects: 45 with MF (38 with aggressive and 7 with nonaggressive) and 48 with AA (30 with aggressive and 18 with nonaggressive). Comparing the patients with MF and AA GCLs, those with MF lesions presented younger (P<.001), and the lesions were more commonly asymptomatic (P<.001), smaller (P<.001), and managed differently (P<.001) than AA lesions. When stratified by clinical behavior, aggressive tumors were diagnosed earlier than nonaggressive tumors (P<.001). Controlling for location and clinical behavior, patients with MF aggressive lesions were younger (P<.001) than those with AA aggressive lesions. MF nonaggressive lesions were more commonly asymptomatic (P = .04), smaller (P = .05), and less commonly locally destructive (P = .05) than AA nonaggressive lesions.\nQuestion: Maxillofacial and axial/appendicular giant cell lesions: unique tumors or variants of the same disease?",
        "gt": "These results suggest that MF and AA GCLs represent a similar, if not the same, disease. Comparing the aggressive and nonaggressive subgroups, more similarities were found than when evaluating without stratification by clinical behavior. The remaining differences could be explained by the likelihood that MF tumors are diagnosed earlier than AA tumors because of facial exposure and dental screening examinations and radiographs.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: From 15 to 30% of all ischemic strokes are cardioembolic. Transthoracic echocardiography plays a key role in the evaluation, diagnosis and management of the embolic source. The absence of official recommendations for the use of echocardiography in patients with ischemic stroke leads to a universal application showing low diagnostic efficiency.AIM: To analyze the diagnostic accuracy of echocardiograpm in patients with ischemic stroke in two situations: with universal indication and after the application of risk clinical criteria. Analysis of the echocardiograms performed on patients with acute ischemic stroke from the stroke unit during the years 2009-2011. We study the diagnostic and etiological contribution to the etiological study. Apply a selection criteria: 'high risk patient with need of test performance during admission' (age<60 years, abnormal baseline electrocardiogram, cardiomegaly on chest radiograph or baseline history of heart disease, suspected endocarditis and/or active neoplasia) and analyzed their validity. From 930 inpatients, 201 (21.6%), underwent echocardiogram. Cardioembolic source was detected in 9.95%. After application of selection criteria, only 97 patients (10.4%) should have undergone it. The proposed criteria have a sensitivity 95%, specificity 56.9%, positive predictive value 19.6% and negative predictive value of 99%.\nQuestion: Is necessary to perform a transthoracic echocardiogram in all the patients with cryptogenic stroke during hospitalization?",
        "gt": "The application of our criteria in undetermined stroke patients help us to identify with high efficiency cardioembolic sources postponing the test to an ambulatory scenario in the rest of the patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Scabies, or mange as it is called in animals, is an ectoparasitic contagious infestation caused by the mite Sarcoptes scabiei. Sarcoptic mange is an important veterinary disease leading to significant morbidity and mortality in wild and domestic animals. A widely accepted hypothesis, though never substantiated by factual data, suggests that humans were the initial source of the animal contamination. In this study we performed phylogenetic analyses of populations of S. scabiei from humans and from canids to validate or not the hypothesis of a human origin of the mites infecting domestic dogs. Mites from dogs and foxes were obtained from three French sites and from other countries. A part of cytochrome c oxidase subunit 1 (cox1) gene was amplified and directly sequenced. Other sequences corresponding to mites from humans, raccoon dogs, foxes, jackal and dogs from various geographical areas were retrieved from GenBank. Phylogenetic analyses were performed using the Otodectes cynotis cox1 sequence as outgroup. Maximum Likelihood and Bayesian Inference analysis approaches were used. To visualize the relationship between the haplotypes, a median joining haplotype network was constructed using Network v4.6 according to host. Twenty-one haplotypes were observed among mites collected from five different host species, including humans and canids from nine geographical areas. The phylogenetic trees based on Maximum Likelihood and Bayesian Inference analyses showed similar topologies with few differences in node support values. The results were not consistent with a human origin of S. scabiei mites in dogs and, on the contrary, did not exclude the opposite hypothesis of a host switch from dogs to humans.\nQuestion: Are humans the initial source of canine mange?",
        "gt": "Phylogenetic relatedness may have an impact in terms of epidemiological control strategy. Our results and other recent studies suggest to re-evaluate the level of transmission between domestic dogs and humans.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Pleural effusion (PE) is commonly encountered in mechanically ventilated, critically ill patients and is generally addressed with evacuation or by fluid displacement using increased airway pressure (P(AW)). However, except when massive or infected, clear evidence is lacking to guide its management. The aim of this study was to investigate the effect of recruitment maneuvers and drainage of unilateral PE on respiratory mechanics, gas exchange, and lung volume. Fifteen critically ill and mechanically ventilated patients with unilateral PE were enrolled. A 3-step protocol (baseline, recruitment, and effusion drainage) was applied to patients with more than 400 mL of PE, as estimated by chest ultrasound. Predefined subgroup analysis compared patients with normal vs reduced chest wall compliance (C(CW)). Esophageal and P(AW)s, respiratory system, lung and C(CW)s, arterial blood gases, and end-expiratory lung volumes were recorded. In the whole case mix, neither recruitment nor drainage improved gas exchange, lung volume, or tidal mechanics. When C(CW) was normal, recruitment improved lung compliance (81.9 [64.8-104.1] vs 103.7 [91.5-111.7]mL/cm H2O, P<.05), whereas drainage had no significant effect on total respiratory system mechanics or gas exchange, although it measurably increased lung volume (1717 vs 2150 mL, P<.05). In the setting of reduced C(CW), however, recruitment had no significant effect on total respiratory system mechanics or gas exchange, whereas pleural drainage improved respiratory system and C(CW)s as well as lung volume (42.7 [38.9-50.0] vs 47.0 [43.8-63.3], P<.05 and 97.4 [89.3-97.9] vs 126.7 [92.3-153.8]mL/cm H2O, P<.05 and 1580 vs 1750 mL, P<.05, respectively).\nQuestion: Drainage of pleural effusion in mechanically ventilated patients: time to measure chest wall compliance?",
        "gt": "Drainage of a moderate-sized effusion should not be routinely performed in unselected population of critically ill patients. We suggest that measurement of C(CW) may help in the decision-making process.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A retrospective cohort. To report the incidence rates of shoulder injuries diagnosed with magnetic resonance imaging (MRI) in tetraplegic athletes and sedentary tetraplegic individuals. To evaluate whether sport practice increases the risk of shoulder injuries in tetraplegic individuals. Campinas, Sao Paulo, Brazil. Ten tetraplegic athletes with traumatic spinal cord injury were selected among quad rugby athletes and had both the shoulders evaluated by MRI. They were compared with 10 sedentary tetraplegic individuals who were submitted to the same radiological protocol. All athletes were male with a mean age of 32.1 years (range 25-44 years, s.d.=6.44). Time since injury ranged from 6 to 17 years, with a mean value of 9.7 years and s.d. of 3.1 years. All sedentary individuals were male with a mean age of 35.9 years (range 22-47 years, s.d.=8.36). Statistical analysis showed a protective effect of sport in the development of shoulder injuries, with a weak correlation for infraspinatus and subscapularis tendinopathy (P=0.09 and P=0.08, respectively) and muscle atrophy (P=0.08). There was a strong correlation for acromioclavicular joint (ACJ) and labrum injuries (P=0.04), with sedentary individuals at a higher risk for these injuries.\nQuestion: Is sport practice a risk factor for shoulder injuries in tetraplegic individuals?",
        "gt": "Tetraplegic athletes and sedentary individuals have a high incidence of supraspinatus tendinosis, bursitis and ACJ degeneration. Statistical analysis showed that there is a possible protective effect of sport in the development of shoulder injuries. Weak evidence was encountered for infraspinatus and subscapularis tendinopathy and muscle atrophy (P=0.09, P=0.08 and P=0.08, respectively). Strong evidence with P=0.04 suggests that sedentary tetraplegic individuals are at a greater risk for ACJ and labrum injuries.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the relationship between case volume and outcome for major trauma patients. Prospective follow-up study of all major trauma patients (with injury severity score>15) arriving alive, with no invariably fatal injury, at 14 English emergency departments between 1990 and 1993. Using the stratified W statistic, an age and severity adjusted measure of outcome, the relationship between volume of cases and outcome was initially examined using the Spearman correlation coefficient. Multiple regression analysis was used to explore further the relationship, after adjustment for hospital-level characteristics. The smallest department saw five major trauma cases each year, the largest saw 96. The results of the initial correlation analyses indicated that there was little evidence that outcome improved with increasing volumes for all major trauma (rho(s) = 0.12, 95% confidence interval [CI]: -0.36 to 0.55) nor for the cases presenting out-of-hours (rho(s) = 0.30, 95% CI: -0.19 to 0.67). However, there was evidence that patients with multiple injury (rho(s) = 0.65, 95% CI: 0.27 to 0.86) and those with severe head injuries (rho(s) = 0.52, 95% CI: 0.08 to 0.79) did better in high volume departments. This pattern, of a positive relationship for more complex cases was also in evidence from the results of the multiple regression analyses and, in particular, for patients with multiple injuries, was stable over time.\nQuestion: Does size matter?",
        "gt": "While there was little evidence that all patients with major trauma do better in higher volume departments, there was evidence that patients with complex needs, such as the multiple injured or those with head injuries, had better outcomes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To reconfirm the association of KPNB3 with schizophrenia in Chinese population. Two single nucleotide polymorphisms (SNPs), rs2588014 and rs626716 at the KPNB3 locus, were genotyped in 304 Chinese Han family trios consisting of fathers, mothers, and affected offsprings with schizophrenia. These 2 SNPs were detected by PCR-based restriction fragment length polymorphism (RFLP) analysis. The Hardy-Weinberg equilibrium for genotypic distributions was estimated by the goodness-of-fit test. The UNPHASED program was used to perform transmission disequilibrium test (TDT), haplotype analysis, and pair-wise measure of linkage disequilibrium (LD) between these 2 SNPs. The genotypic distributions of both rs2588014 and rs626716 were in the Hardy-Weinberg equilibrium (P>0.05). The TDT revealed allelic association with rs626716 (chi2 = 9.31, P = 0.0023) but not with rs2588014 (chi2 = 3.44, P = 0.064). The global P-value was 0.0099 for 100 permutations. The haplotype analysis also showed a disease association (chi2 = 25.97, df = 3, P = 0.0000097).\nQuestion: Is KPNB3 locus associated with schizophrenia?",
        "gt": "The present study provides further evidence in support of the KPNB3 association with schizophrenia in Chinese population.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adolescents with Anorexia Nervosa (AN), treated with family-based treatment (FBT) who fail to gain 2.3 kg by the fourth week of treatment have a 40-50% lower chance of recovery than those who do. Because of the high risk of developing enduring AN, improving outcomes in this group of poor responders is essential. This study examines the feasibility and effects of a novel adaptive treatment (i.e., Intensive Parental Coaching-IPC) aimed at enhancing parental self-efficacy related to re-feeding skills in poor early responders to FBT. 45 adolescents (12-18 years of age) meeting DSM TR IV criteria for AN were randomized in an unbalanced design (10 to standard FBT; 35 to the adaptive arm). Attrition, suitability, expectancy rates, weight change, and psychopathology were compared between groups. There were no differences in rates of attrition, suitability, expectancy ratings, or most clinical outcomes between randomized groups. However, the group of poor early responders that received IPC achieved full weight restoration (>95% of expected mean BMI) by EOT at similar rates as those who had responded early.\nQuestion: Can adaptive treatment improve outcomes in family-based therapy for adolescents with anorexia nervosa?",
        "gt": "The results of this study suggest that it is feasible to use an adaptive design to study the treatment effect of IPC for those who do not gain adequate weight by session 4 of FBT. The results also suggest that using IPC for poor early responders significantly improves weight recovery rates to levels comparable to those who respond early. A sufficiently powered study is needed to confirm these promising findings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: School mental health services are important contact points for children and adolescents with mental disorders, but their ability to provide comprehensive treatment is limited. The main objective was to estimate in mentally disordered adolescents of a nationally representative United States cohort the role of school mental health services as guide to mental health care in different out-of-school service sectors. Analyses are based on weighted data (N\u200a=\u200a6483) from the United States National Comorbidity Survey Replication Adolescent Supplement (participants' age: 13-18 years). Lifetime DSM-IV mental disorders were assessed using the fully structured WHO CIDI interview, complemented by parent report. Adolescents and parents provided information on mental health service use across multiple sectors, based on the Service Assessment for Children and Adolescents. School mental health service use predicted subsequent out-of-school service utilization for mental disorders i) in the medical specialty sector, in adolescents with affective (hazard ratio (HR)\u200a=\u200a3.01, confidence interval (CI)\u200a=\u200a1.77-5.12), anxiety (HR\u200a=\u200a3.87, CI\u200a=\u200a1.97-7.64), behavior (HR\u200a=\u200a2.49, CI\u200a=\u200a1.62-3.82), substance use (HR\u200a=\u200a4.12, CI\u200a=\u200a1.87-9.04), and eating (HR\u200a=\u200a10.72, CI\u200a=\u200a2.31-49.70) disorders, and any mental disorder (HR\u200a=\u200a2.97, CI\u200a=\u200a1.94-4.54), and ii) in other service sectors, in adolescents with anxiety (HR\u200a=\u200a3.15, CI\u200a=\u200a2.17-4.56), behavior (HR\u200a=\u200a1.99, CI\u200a=\u200a1.29-3.06), and substance use (HR\u200a=\u200a2.48, CI\u200a=\u200a1.57-3.94) disorders, and any mental disorder (HR\u200a=\u200a2.33, CI\u200a=\u200a1.54-3.53), but iii) not in the mental health specialty sector.\nQuestion: School mental health services: signpost for out-of-school service utilization in adolescents with mental disorders?",
        "gt": "Our findings indicate that in the United States, school mental health services may serve as guide to out-of-school service utilization for mental disorders especially in the medical specialty sector across various mental disorders, thereby highlighting the relevance of school mental health services in the trajectory of mental care. In light of the missing link between school mental health services and mental health specialty services, the promotion of a stronger collaboration between these sectors should be considered regarding the potential to improve and guarantee adequate mental care at early life stages.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Intraductal papillary mucinous neoplasms (IPMNs) are well-established pancreatic precancerous lesions. Indications for resection are outlined in the 2012 International Consensus Guidelines (ICG). Because of the low specificity of the ICG, many patients will undergo potentially unnecessary surgery for nonmalignant IPMNs. Several retrospective studies have reported that positron emission tomography (PET) with CT (PET/CT) is highly sensitive and specific in detecting malignant IPMNs. We hypothesized that PET/CT complements the ICG in identification of malignant IPMNs. From 2009 to 2013, patients with a suspected clinical or cytopathologic diagnosis of IPMN were prospectively enrolled in a clinical trial at a single center. Results of preoperative PET/CT on determination of IPMN malignancy (ie, high-grade dysplastic and invasive) was compared with surgical pathology. PET/CT uptake was considered increased if the standardized uptake value was \u22653. Of the 67 patients enrolled, 50 patients met all inclusion criteria. Increased PET/CT uptake was associated with significantly more malignant and invasive IPMNs (80% vs 13%; p<0.0001 and 40% vs 3%; p = 0.004). When patients were divided into branch duct and main duct IPMNs, increased PET/CT uptake was also associated with more malignancy (60% vs 0%; p = 0.006 for branch duct IPMN and 100% vs 23%; p = 0.003 for main duct IPMN). Patients with ICG criteria (eg, worrisome features and high-risk stigmata) and increased PET/CT uptake had more malignant and invasive IPMNs than patients with ICG criteria, but no increased uptake (78% vs 17%; p = 0.001 and 33% vs 3%; p = 0.03). The sensitivity and specificity of the ICG criteria for detecting malignancy were 92% and 27%, respectively, and PET/CT was less sensitive (62%) but more specific (95%). When PET/CT was added to ICG criteria, the association resulted in 78% sensitivity and 100% specificity.\nQuestion: Does PET with CT Have Clinical Utility in the Management of Patients with Intraductal Papillary Mucinous Neoplasm?",
        "gt": "The addition of PET/CT to preoperative workup improves the performance of the ICG for predicting malignant risk in patients with IPMN.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To verify whether bladder dysfunction detected by urodynamic studies prior to radical prostatectomy can predict postoperative continence status. Twenty patients diagnosed with prostate cancer had multichannel subtracted filling and voiding videocystometry before undergoing radical retropubic prostatectomy. Postoperatively, all patients had periodic clinical assessment of continence status. On preoperative filling cystometry, detrusor instability with a maximal detrusor pressure greater than 15 cm H2O was demonstrated in 12/20 patients (60%). Postoperatively, 11/20 patients (55%) were continent, 4 (20%) had mild stress incontinence and 5 (25%) complained of episodic urge incontinence. However, only 5 of the 12 patients with preoperatively diagnosed detrusor instability manifested clinical urge incontinence after surgery (positive predictive value = 41.6%).\nQuestion: Can preoperative urodynamic examination allow us to predict the risk of incontinence after radical prostatectomy?",
        "gt": "The incidence of preoperative detrusor instability in our series was high, but little correlation was found between this finding and postoperative incontinence.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The present study was conducted to assess the efficacy of contrast-enhanced ultrasound with low mechanical index in evaluating the response of percutaneous radiofrequency ablation treatment of hepatocellular carcinoma by comparing it with 4-row spiral computed tomography. 100 consecutive patients (65 men and 35 women; age range: 62 - 76 years) with solitary hepatocellular carcinomas (mean lesion diameter: 3.7 cm +/- 1.1 cm SD) underwent internally cooled radiofrequency ablation. Therapeutic response was evaluated at one month after the treatment with triple-phasic contrast-enhanced spiral CT and low-mechanical index contrast-enhanced ultrasound following bolus injection of 2.4 ml of Sonovue (Bracco, Milan). 60 out of 100 patients were followed up for another 3 months. Contrast-enhanced sonographic studies were reviewed by two blinded radiologists in consensus. Sensitivity, specificity, NPV and PPV of contrast-enhanced ultrasound examination were determined. After treatment, contrast-enhanced ultrasound identified persistent signal enhancement in 24 patients (24 %), whereas no intratumoral enhancement was detected in the remaining 76 patients (76 %). Using CT imaging as gold standard, the sensitivity, specificity, NPV, and PPV of contrast enhanced ultrasound were 92.3 % (95 % CI = 75.9 - 97.9 %), 100 % (95 % CI = 95.2 - 100 %), 97.4 % (95 % CI = 91.1 - 99.3 %), and 100 % (95 % CI = 86.2 - 100 %).\nQuestion: Is contrast-enhanced US alternative to spiral CT in the assessment of treatment outcome of radiofrequency ablation in hepatocellular carcinoma?",
        "gt": "Contrast-enhanced ultrasound with low mechanical index using Sonovue is a feasible tool in evaluating the response of hepatocellular carcinoma to radiofrequency ablation. Accuracy is comparable to 4-row spiral CT.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Gait and cognitive disturbances are common in Parkinson's disease (PD). These deficits exacerbate fall risk and difficulties with mobility, especially during complex or dual-task walking. Traditional gait training generally fails to fully address these complex gait activities. Virtual reality (VR) incorporates principles of motor learning while delivering engaging and challenging training in complex environments. We hypothesized that VR may be applied to address the multifaceted deficits associated with fall risk in PD. Twenty patients received 18 sessions (3 per week) of progressive intensive treadmill training with virtual obstacles (TT + VR). Outcome measures included gait under usual-walking and dual-task conditions and while negotiating physical obstacles. Cognitive function and functional performance were also assessed. Patients were 67.1 \u00b1 6.5 years and had a mean disease duration of 9.8 \u00b1 5.6 years. Posttraining, gait speed significantly improved during usual walking, during dual task, and while negotiating overground obstacles. Dual-task gait variability decreased (ie, improved) and Trail Making Test times (parts A and B) improved. Gains in functional performance measures and retention effects, 1 month later, were also observed.\nQuestion: Virtual reality for gait training: can it induce motor learning to enhance complex walking and reduce fall risk in patients with Parkinson's disease?",
        "gt": "To our knowledge, this is the first time that TT + VR has been used for gait training in PD. The results indicate that TT + VR is viable in PD and may significantly improve physical performance, gait during complex challenging conditions, and even certain aspects of cognitive function. These findings have important implications for understanding motor learning in the presence of PD and for treating fall risk in PD, aging, and others who share a heightened risk of falls.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This was a two phase study. In Phase 1, rates of IVC filter retrieval were collected retrospectively from June 2010 to June 2012. During Phase 2 an IVC filter pathway was developed and prospective data was collected from July 2012 to June 2014. Univariate analysis and Kaplan-Meier estimates were performed to determine the rate of IVC filter retrieval and to analyse factors contributing to retrieval rates. 95 patients (39 Phase 1; 56 Phase 2) had an IVC filter inserted over a 4 year period. In Phase 1, of those eligible to have their filter removed, the 12-month retrieval rate was 63%, this improved to 100% in Phase 2. Following implementation of the IVC filter pathway (Phase 2) no patients were lost to follow-up.\nQuestion: Retrieval rates of inferior vena cava (IVC) filters: are we retrieving enough?",
        "gt": "We have improved the rate of IVC filter retrieval in our institution by development of an IVC filter pathway. Rates of optional IVC filter retrieval in our experience are now higher than previously published figures.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Current literature suggests that novices reach a plateau after two to seven trials when training on the MIST VR laparoscopic virtual reality system. We hypothesize that significant benefit may be gained through additional training. Second-year medical students (n = 12) voluntarily enrolled under an IRB-approved protocol for MIST VR training. All subjects completed pre- and posttraining questionnaires and performed 30 repetitions of 12 tasks. Performance data were automatically recorded for each trial. Learning curves for each task were generated by fitting spline curves to the mean overall scores for each repetition. Scores were assessed for plateaus by repeated measures, slope, and best score. On average, subjects completed training in 7.1 h. (range, 5.9-9.2). Two to seven performance plateaus were identified for each of the 12 MIST VR tasks. Initial plateaus were found for all tasks by the 8th repetition; however, ultimate plateaus were not reached until 21-29 repetitions. Overall best score was reached between 20 and 30 repetitions and occurred beyond the ultimate plateau for 9 tasks.\nQuestion: Laparoscopic virtual reality training: are 30 repetitions enough?",
        "gt": "These data indicate that a lengthy learning curve exists for novices and may be seen throughout 30 repetitions and possibly beyond. Performance plateaus may not reliably determine training endpoints. We conclude that a significant and variable amount of training may be required to achieve maximal benefit. Neither a predetermined training duration nor an arbitrary number of repetitions may be adequate to ensure laparoscopic proficiency following simulator training. Standards which define performance-based endpoints should be established.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We sought to evaluate the long-term performance of a consecutive cohort of patients implanted with a 17-mm bileaflet mechanical prosthesis. Between January 1995 and December 2005, 78 patients (74 women, mean age=71\u00b112 years) underwent aortic valve replacement with a 17-mm mechanical bileaflet prosthesis (Sorin Bicarbon-Slim and St. Jude Medical-HP). Preoperative mean body surface area and New York Heart Association class were 1.6\u00b10.2 m2 and 2.6\u00b10.8, respectively. Preoperative mean aortic annulus, indexed aortic valve area, and peak and mean gradients were 18\u00b11.6 mm, 0.42 cm2/m2, 89\u00b132 mm Hg, and 56\u00b121 mm Hg, respectively. Patients were divided into two groups, according to the presence (group A, 29 patients) or absence of patient-prosthesis mismatch (group B, 49 patients). Patient-prosthesis mismatch was defined by an indexed effective orifice area less than 0.85 cm2/m2. Overall hospital mortality was 8.8%. Follow-up time averaged 86\u00b144 months. Actuarial 5-year and 10-year survival rates were 83.7% and 65.3%, respectively. The mean postoperative New York Heart Association class was 1.3\u00b10.6 (p<0.001). Overall indexed left ventricular mass decreased from 163\u00b148 to 120\u00b142 g/m2 (p<0.001), whereas average peak and mean prosthesis gradients were 28\u00b19 mm Hg and 15\u00b16 mm Hg, respectively (p<0.001). Early and long-term mortality were similar between the two groups as well as long-term hemodynamic performance (mean peak gradient was 28 mm Hg and 27 mm Hg in group A and B, respectively, not significant); left ventricular mass regression occurred similarly in both groups (indexed left ventricular mass at follow-up was 136\u00b148 and 113\u00b140 in group A and B, respectively; not significant).\nQuestion: Aortic valve replacement with 17-mm mechanical prostheses: is patient-prosthesis mismatch a relevant phenomenon?",
        "gt": "Selected patients with aortic stenosis experience satisfactory clinical improvement after aortic valve replacement with modern small-diameter bileaflet prostheses.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A reverse J-shaped association between serum 25-hydroxyvitamin D (25[OH]D) concentration and all-cause mortality was suggested in a 9-year follow-up (1991-2000) analysis of the Third National Health and Nutrition Examination Survey (NHANES III, 1988-1994). Our objective was to repeat the analyses with 6 years additional follow-up to evaluate whether the association persists through 15 years of follow-up. The study included 15 099 participants aged \u2265 20 years with 3784 deaths. Relative risk (RR) of death from all causes was adjusted for age, sex, race/ethnicity, and season using 2 Poisson regression approaches: traditional categorical and cubic splines. Results were given for 9 25(OH)D levels:<20, 20 to 29, 30 to 39, 40 to 49, 50 to 59, 60 to 74, 75 to 99 (reference), 100 to 119, and \u2265 120 nmol/L. The reverse J-shaped association became stronger with longer follow-up and was not affected by excluding deaths within the first 3 years of follow-up. Similar results were found from both statistical approaches for levels<20 through 119 nmol/L. Adjusted RR (95% confidence interval [CI]) estimates for all levels<60 nmol/L were significantly>1 compared with the reference group. The nadir of risk was 81 nmol/L (95% CI, 73-90 nmol/L). For 25(OH)D \u2265 120 nmol/L, results (RR, 95% CI) were slightly different using traditional categorical (1.5, 1.02-2.3) and cubic splines approaches (1.2, 0.9-1.4). The association appeared in men, women, adults ages 20 to 64 years, and non-Hispanic whites but was weaker in older adults. The study was too small to evaluate the association in non-Hispanic black and Mexican-American adults.\nQuestion: Is there a reverse J-shaped association between 25-hydroxyvitamin D and all-cause mortality?",
        "gt": "A reverse J-shaped association between serum 25(OH)D and all-cause mortality appears to be real. It is uncertain whether the association is causal.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Estimation of small bowel length is of interest following the recent development of device-assisted enteroscopy. This new technology allows access to the deep small bowel, but rates of examination of the entire small bowel (total enteroscopy) differ between study populations. Variation in small bowel length could factor into this observed irregularity in total enteroscopy rates. Medical literature contains limited information regarding small bowel length in living patients and conflicting data regarding small bowel length and its relationship to height and weight. We carried out small bowel measurements on surgical patients to further define the total length of the small bowel and its relationship to height, weight and body mass index (BMI). Measurement of ileojejunal length on 91 surgical patients undergoing laparotomy for routine indications. Demographic data were collected for each subject, including height, weight and BMI. Small bowel length was found to vary widely between individuals (average 998.52\u2009cm, range 630-1510\u2009cm). Linear regression analysis demonstrated a statistically significant relationship between small bowel length and height (regression coefficient\u2009=\u20090.0561, P-value\u2009=\u20090.0238). A linear relationship between small bowel length and weight or BMI was not observed.\nQuestion: Variation in small bowel length: factor in achieving total enteroscopy?",
        "gt": "Length of the small bowel in humans is pertinent to advances in deep enteroscopy and existing surgical applications such as intestinal bypass and prevention of short gut syndrome. If average small bowel length varies with height, total enteroscopy may be easier to achieve in patients who are short in stature.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The last decade there has been an increased awareness of the problem of anastomotic leakage after low anterior resection for rectal cancer, which may have led to more defunctioning stomas. In this study, current use of defunctioning stomas was assessed and compared to the use of defunctioning stomas at the time of the TME-trial together with associated outcomes. Eligible patients with rectal cancer undergoing low anterior resection were selected from the Dutch Surgical Colorectal Audit (DSCA, n = 988). Similar patients were selected from the TME-trial (n = 891). The percentages of patients with a defunctioning stoma, anastomotic leakage and postoperative mortality rates were studied. Multivariable models were used to study possible confounding on the outcomes. At the time of the TME-trial, 57% of patients received a defunctioning stoma. At the time of the DSCA, 70% of all patients received a defunctioning stoma (p<0.001). Anastomotic leakage rates were similar (11.4% and 12.1%; p = 0.640). The postoperative mortality rate differed (3.9% in the TME-trial vs. 1.1% in the DSCA; p<0.001), but was not associated with a more frequent use of a stoma (OR 1.80, 95% CI 0.91-3.58).\nQuestion: An increasing use of defunctioning stomas after low anterior resection for rectal cancer. Is this the way to go?",
        "gt": "In current surgical practice, 70% of patients undergoing LAR for rectal cancer receives a defunctioning stomas. This percentage seems increased when compared to data from the TME-trial. Clinically relevant anastomotic leakage rates remained similar. Therefore, current routine use of defunctioning stomas should be questioned.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Nearly 50 % of subjects with continuing symptoms of attention-deficit hyperactivity disorder (ADHD) in adulthood show a comorbid substance use disorder. Both, ADHD and alcohol dependence have a high genetic load and might even share overlapping sources of genetic liability. We investigated phenotype and 5-HTT/5-HT2c allelic characteristics in 314 alcoholics of German descent. 21 % of the alcoholics fulfilled DSM-IV-criteria of ADHD with ongoing symptoms in adulthood. There was no significant difference in 5-HTT- or 5-HT2c-allele distribution between alcoholics and matched controls or between alcoholics with or without ADHD.\nQuestion: ADHD and alcohol dependence: a common genetic predisposition?",
        "gt": "In our sample the functional relevant 5-HTT-promoter and the 5-HT2c-receptor Cys23Ser polymorphism do not contribute to the supposed common genetic predisposition of ADHD and alcohol dependence.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this study was to evaluate the effect of Burch colposuspension for stress urinary incontinence on concomitant coital incontinence. The urogynecology database was searched for sexually active women, who experienced coital incontinence on vaginal penetration, orgasm, or both and who had subsequently undergone Burch colposuspension for urodynamic stress incontinence. The women were interviewed or sent a questionnaire on postoperative bladder and sexual function after a minimum follow-up time of 6 months. Thirty of 43 women answered the questionnaire. Preoperatively, 22 women (73%) experienced urinary leakage during penetration, 3 (10%) during orgasm and 5 (17%) at both. Stress incontinence symptoms were successfully treated in 23 (77%). Coital incontinence was cured in 21 of 30 (70%) and improved in 2.\nQuestion: Does Burch colposuspension cure coital incontinence?",
        "gt": "The results of this small series suggest that coital incontinence is likely to be cured or improved when stress incontinence has been successfully treated by Burch colposuspension.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Permanent visual impairment has been reported to occur in up to 19% of GCA patients. The aim of this study was to examine whether implementation of a fast-track approach could reduce the rate of permanent visual impairment and inpatient days of care in GCA patients. A fast-track outpatient GCA clinic (FTC) was implemented in the Department of Rheumatology, Hospital of Southern Norway Trust Kristiansand, Norway in 2012. The patients included in this study were subsequently recruited between March 2010 and October 2014. Routine clinical and laboratory data and number of inpatient days of care were collected. During the observation period, 75 patients were diagnosed with GCA. Among the 75 GCA patients, 32 were evaluated conventionally and 43 in the FTC. In the conventionally approached group, six patients suffered from permanent visual impairment, while in the FTC group only one patient suffered from permanent visual impairment. The relative risk of permanent visual impairment in the GCA patients examined in the FTC was 88% lower compared with the conventionally evaluated group (relative risk 0.12, 95% CI: 0.01, 0.97, P = 0.01). The mean difference in inpatient days of care between patients evaluated conventionally and patients evaluated in the FTC was 3 days (3.6 vs 0.6 days, P<0.0005).\nQuestion: The fast-track ultrasound clinic for early diagnosis of giant cell arteritis significantly reduces permanent visual impairment: towards a more effective strategy to improve clinical outcome in giant cell arteritis?",
        "gt": "The implementation of the FTC in GCA care appears to significantly reduce the risk of permanent visual impairment and is more cost effective by reducing the need for inpatient care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Physical activity may lower the risk for coronary heart disease by mitigating inflammation, which plays a key role in the pathophysiology of atherosclerosis. The purpose of this study was to examine the association between physical activity and C-reactive protein concentration in a national sample of the U.S. population. The analytic sample included 13,748 participants>or=20 years of age in the National Health and Nutrition Examination Survey III (1988-1994) with complete data for the main study variables. After adjusting for age, sex, ethnicity, education, work status, smoking status, cotinine concentration, hypertension, body mass index, waist-to-hip ratio, high-density lipoprotein cholesterol concentration, and aspirin use, the odds ratios for elevated C-reactive protein concentration (dichotomized at the>or=85th percentile of the sex-specific distribution) were 0.98 (95% confidence interval = 0.78-1.23), 0.85 (0.70-1.02), and 0.53 (0.40-0.71) for participants who engaged in light, moderate, and vigorous physical activity, respectively, during the previous month compared with participants who did not engage in any leisure-time physical activity. In addition, leisure-time physical activity was positively associated with serum albumin concentration and inversely associated with both log-transformed plasma fibrinogen concentration and log-transformed white blood cell count.\nQuestion: Does exercise reduce inflammation?",
        "gt": "These results add to mounting evidence that physical activity may reduce inflammation, which is a critical process in the pathogenesis of cardiovascular disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Stereotactic biopsies are procedures with a high diagnostic yield and a low but serious risk of hemorrhage. Postoperative management remains controversial. To evaluate the predictive value of intraoperative bleeding and its implication on postoperative management. Cases of intraoperative bleeding were prospectively documented in a consecutive series comprising 303 patients. Categories were as follows: no bleeding, single drop, \u226410 drops and>10 drops. Incidence, size of hemorrhage and neurological deterioration were noted. Hemorrhage on routine postoperative CT scans was correlated with intraoperative findings, sample size, location and pathology. A total of 93 patients (30.7%) showed intraoperative bleeding and 68 (22.4%) showed blood on postoperative CT. In 13 patients (4.3%) the diameter was>1 cm; 19 patients (6.3%) experienced neurological worsening, 9 (3.0%) having postoperative hemorrhage and 3 (1.0%) permanent neurological deficits. Bleeding was associated with postoperative hemorrhage (p<0.0001). The negative predictive values to rule out any postoperative hemorrhage or hemorrhages>1 cm were 92 and 100%, respectively. Number of samples, location and pathology had no significant influence on postoperative hemorrhage.\nQuestion: Intraoperative bleeding in stereotactic biopsies and its implication on postoperative management: can we predict CT findings?",
        "gt": "Stereotactic biopsies have a low risk of symptomatic hemorrhages. Intraoperative bleeding is a surveillance parameter of hemorrhage on CT. Therefore, routine postoperative CT may be restricted to patients who show intraoperative bleeding.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate if mental fatigue is a symptom that appears independently from other clinical features in patients with Parkinson disease (PD), and to study if fatigue is persistent over time in these patients. In 1993, 233 patients with PD were included in a community-based study of fatigue and followed prospectively over 8 years. Fatigue was measured by a combination of a seven-point scale and parts of the Nottingham Health Profile (NHP) at baseline and after 4 and 8 years. In addition, the Fatigue Severity Scale (FSS) was used to evaluate fatigue in 2001. Population-averaged logistic regression models for correlated data were performed to study the relationship between fatigue and various demographic and clinical variables. In patients who were followed throughout the 8-year study period, fatigue increased from 35.7% in 1993 to 42.9% in 1997 and 55.7% in 2001. Fatigue was related to disease progression, depression, and excessive daytime sleepiness (EDS). However, the prevalence of fatigue in patients without depression and EDS remained high and increased from 32.1% to 38.9% during the study period. For about 44% of the patients with fatigue the presence of this symptom varied during the study period, as it was persistent in 56% of the patients with fatigue.\nQuestion: Is fatigue an independent and persistent symptom in patients with Parkinson disease?",
        "gt": "The authors confirmed the high prevalence of mental fatigue in patients with Parkinson disease (PD). Fatigue is related to other non-motor features such as depression and excessive daytime sleepiness, but cannot be explained by this comorbidity alone. In more than half of the patients mental fatigue is persistent and seems to be an independent symptom that develops parallel to the progressive neurodegenerative disorder of PD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the influence of the periodontal disease (PD), a chronic infection, in patients with chronic craniofacial pain complaints. Twenty patients with chronic craniofacial pain and PD (CFP group) and 20 patients with PD (PD group) were assessed before and after periodontal treatment (baseline, 30 and 180 days after treatment). The parameters evaluated were: plaque index, bleeding index, clinical probe insertion, Visual Analogic Scale (VAS) for pain intensity and Numerical Rating Scale (NRS) and Verbal Rating Scale (VRS) for the 'chief complaint'. After 180 days PD was controlled in both groups (p<0.001); the VAS decreased in CFP group (p<0.001); 'chief complaint' improved (p=0.005 and p=0.027, respectively in CFP and PD group). VRS showed improvement between the groups in 30 (p=0.004) and 180 days (p=0.001).\nQuestion: Refractory craniofacial pain: is there a role of periodontal disease as a comorbidity?",
        "gt": "These results suggest a possible influence of periodontal disease, as a comorbidity, in refractory craniofacial pain patients and in their pain levels.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Measurement of blood lead (BPb) is the usual method for biomonitoring of persons exposed to inorganic lead.AIM: To explore the use of salivary lead (SPb) as an alternative. BPb and SPb levels were measured in a group of 82 lead exposed adults. The mean BPb of the workers was 26.6 microg/dl (SD 8.6, range 10-48) and the mean SPb level 0.77 microg/dl, or 3% of the BPb level. As the SPb distribution was skewed, logarithmic transformation was performed to normalise the distribution. A bivariate scattergram of BPb and logSPb (r = 0.41, p = 0.00) had a line of best fit expressed as BPb = 29.7 + 8.95logSPb. The relation of logSPb and BPb was stronger among non-smokers (r = 0.42) compared to smokers (r = 0.3); and among those without a medical condition (r = 0.44). Multiple linear regression analysis (fitting smoking and medical condition into the model) yielded an R of 0.54, and an adjusted R(2) of 0.26.\nQuestion: Can salivary lead be used for biological monitoring of lead exposed individuals?",
        "gt": "The study findings do not support the use of SPb for biomonitoring at BPb levels ranging from 10 to 50 microg/dl.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Storage of embryos for fertility preservation before chemotherapy is widely practiced. For multiple oocyte collection, the ovaries are hyperstimulated with gonadotrophins that significantly alter ovarian physiology. The effects of ovarian stimulation prior to chemotherapy on future ovarian reserve were investigated in an animal model. Cyclophosphamide (Cy) in doses of 0, 50 or 100 mg/kg was administered to 38 adult mice (control, unstimulated). A second group of 12 mice were superovulated with equine chorionic gonadotrophin (eCG, 10 IU on Day 0) before Cy administration; hCG (10 IU) was administered (Day 2) followed by 0, 50 or 100 mg/kg Cy (Day 4). In both groups ovaries were removed, serially sectioned (7-day post-Cy), primordial follicles were counted and differences between groups evaluated. Follicle number dropped from 469 +/- 24 (mean +/- SE) to 307 +/- 27 and 234 +/- 19 with 50 or 100 mg/kg Cy, respectively (P<0.0001). In the eCG pretreated group, follicle count dropped from 480 +/- 31 to 345 +/- 16 and 211 +/- 26 when 50 or 100 mg/kg Cy were administered (P<0.0001). There were no significant differences in follicle count between the pretreated eCG group and controls for each chemotherapy dose.\nQuestion: Does controlled ovarian stimulation prior to chemotherapy increase primordial follicle loss and diminish ovarian reserve?",
        "gt": "This animal study indicates that ovarian stimulation before administration of Cy does not adversely affect ovarian reserve post-treatment. These results provide support for the safety of fertility preservation using ovarian stimulation and IVF-embryo cryopreservation procedures prior to chemotherapy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study compared three different methods of determining a reading addition and the possible improvement on reading performance in children and young adults with low vision. Twenty-eight participants with low vision, aged 8 to 32 years, took part in the study. Reading additions were determined with (a) a modified Nott dynamic retinoscopy, (b) a subjective method, and (c) an age-based formula. Reading performance was assessed with MNREAD-style reading charts at 12.5 cm, with and without each reading addition in random order. Outcome measures were reading speed, critical print size, MNREAD threshold, and the area under the reading speed curve. For the whole group, there was no significant improvement in reading performance with any of the additions. When participants with normal accommodation at 12.5 cm were excluded, the area under the reading speed curve was significantly greater with all reading additions compared with no addition (p = 0.031, 0.028, and 0.028, respectively). Also, the reading acuity threshold was significantly better with all reading additions compared with no addition (p = 0.014, 0.030, and 0.036, respectively). Distance and near visual acuity, age, and contrast sensitivity did not predict improvement with a reading addition. All, but one, of the participants who showed a significant improvement in reading with an addition had reduced accommodation.\nQuestion: Do reading additions improve reading in pre-presbyopes with low vision?",
        "gt": "A reading addition may improve reading performance for young people with low vision and should be considered as part of a low vision assessment, particularly when accommodation is reduced.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There continues to be controversy about the necessity of interval appendectomy for delayed presentation of acute appendicitis. While recent studies suggest that the risk of recurrent disease is small, the risk of interval appendectomy is also small and does provide histologic identification and usually definitive treatment of the right lower quadrant inflammatory process. A retrospective analysis of medical records gathered from 2002 to 2007 at a major teaching hospital of 986 adult patients over the age of 13 with appendicitis were analyzed. Forty-six patients (5%) were found to have right lower quadrant abscess or phlegmon, and were managed with intravenous antibiotics. Some patients also underwent percutaneous drainage. These patients were then readmitted 6 to 26 wk later for an elective laparoscopic interval appendectomy. There were 19 males and 27 females with an average age of 43 y. Ninety-four percent of the appendectomies were completed laparoscopically; 16% of patients were found to have a normal or obliterated appendix on pathologic evaluation and likely did not benefit from interval appendectomy. On the other hand, 84% of patients had persistent acute appendicitis, chronic appendicitis, evidence of inflammatory bowel disease, or neoplasm identified, and likely benefited from surgical appendectomy.\nQuestion: Can interval appendectomy be justified following conservative treatment of perforated acute appendicitis?",
        "gt": "Interval appendectomy provides diagnostic and therapeutic benefit to patients who present with a right lower quadrant abdominal inflammatory focus, and should be carefully considered in all adult patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this paper is to investigate the potential of using primary care optometry data to support ophthalmic public health, research and policy making. Suppliers of optometric electronic patient record systems (EPRs) were interviewed to gather information about the data present in commercial software programmes and the feasibility of data extraction. Researchers were presented with a list of metrics that might be included in an optometric practice dataset via a survey circulated by email to 102 researchers known to have an interest in eye health. Respondents rated the importance of each metric for research. A further survey presented the list of metrics to 2000 randomly selected members of the College of Optometrists. The optometrists were asked to specify how likely they were to enter information about each metric in a routine sight test consultation. They were also asked if data were entered as free text, menus or a combination of these. Current EPRs allowed the input of data relating to the metrics of interest. Most data entry was free text. There was a good match between high priority metrics for research and those commonly recorded in optometric practice.\nQuestion: Can data in optometric practice be used to provide an evidence base for ophthalmic public health?",
        "gt": "Although there were plenty of electronic data in optometric practice, this was highly variable and often not in an easily analysed format. To facilitate analysis of the evidence for public health purposes a UK based minimum dataset containing standardised clinical information is recommended. Further research would be required to develop suitable coding for the individual metrics included. The dataset would need to capture information from all sectors of the population to ensure effective planning of any future interventions.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this study was to discuss, in the light of the results of a survey, the calcium ration of a sample of French youth and to determine whether various sports activities can be related to dietary calcium intake. Physical activity was evaluated using Baecke's questionnaire. Calcium intake was evaluated using a food frequency oriented questionnaire. The survey was performed on a population of 10,373 subjects (6,966 males and 3,407 females) including three different groups of subjects: school children and college students, military personnel, and athletes registered in sports federations. The mean age of this population was 19 +/- 9 yr, ages ranging between 7 and 50 yr. The mean amount of declared calcium intake (DCI) for the total population was 1242 +/- 843 mg per 24 hr (mg x d(-1)). Fifty percent of this population consumed less than 1000 mg x d(-1) and 13% less than 500 mg x d(-1). There was no significant relationship between the index of activity and declared calcium intake. Calcium intake decreased with age and was lower in females compared to males.\nQuestion: Is there a relationship between physical activity and dietary calcium intake?",
        "gt": "The subjects trained in individual endurance sports such as triathlon, biking, and road running have a lower DCI than subjects trained in team sports such as volley ball, handball, or basketball. This survey, performed on a large population, does indicate that for half of them daily calcium intake is below the threshold of 1,000 mg x d(-1) considered the daily requirement covering the needs of a population without age or gender distinction and that calcium intake is not related to the level of physical activity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: A recent hypothesis has implicated superfertility as a cause of recurrent pregnancy loss. Clinical support for the concept comes from one report that 40% of women experiencing recurrent miscarriages had monthly fecundity rates of 60% or greater and thus were designated as superfertile. To confirm or refute this finding, clinical histories of 201 women with a history of recurrent pregnancy loss were reviewed and months to desired pregnancy, karyotypes of their products of conception as well as results of laboratory tests including antiphospholipid antibodies and circulating natural killer cells were recorded. The prevalence of superfertility was 32% (64/201) among recurrently aborting women compared with 3% of the general population according to the model of Tietze (P\u00a0<\u00a00.0001). Fifty-nine of the 201 (30%) study patients displayed presence of APA,LA, increased CD56(+) cells, or increased NK cytotoxicity and were designated as having an immunologic risk factor. Of the 192 karyotypes of products of conception from women with a history of recurrent miscarriage, 153 (80%) had a normal chromosome complement and 38 (20%) were abnormal. Among the normal karyotypes, 86 (56%) were 46XX and 67 (44%) were 46XY.\nQuestion: Is superfertility associated with recurrent pregnancy loss?",
        "gt": "Recurrent pregnancy loss is associated with superfertility in 32%, immunologic risk factors in 30% and a 20% frequency of chromosomally abnormal pregnancy losses. Thus, implantation failure can result from too much or too little implantation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess whether a true knowledge of crowding alters treatment decisions compared with estimates of crowding. Thirty-six orthodontists were asked to estimate crowding using visualization on eight mandibular arch study models and to indicate possible extraction choices. For each model, the intermolar widths, intercanine widths, and clinical scenarios were identical, but the true crowding varied from 0.2 to 8.4mm as to a lesser extent did the curve of Spee. Eleven orthodontists repeated the visualization exercise after 2 weeks to assess reliability. All 36 of the orthodontists were asked to repeat the treatment planning exercise on the same models, but this time was provided with the true amount of crowding in each case. When the 36 orthodontists used direct visualization of the models to assess crowding, the range of their estimates of crowding increased as the crowding increased. As might be expected, they also tended to move towards extraction treatments as the crowding increased (P = 0.013, odds ratio = 3). Although the reliability of the repeat estimates of crowding were moderate, the mean estimates were greater than the true crowding for each model. When orthodontists were presented with the true amount of crowding, rather than their estimate of crowding, it had a significant effect on the decision to extract, with fewer orthodontists recommending extractions. The principal limitation of this study is that it was a laboratory-based study and utilized just the mandibular arch model for estimation and treatment planning.\nQuestion: Does a true knowledge of dental crowding affect orthodontic treatment decisions?",
        "gt": "Direct visualization may overestimate the amount of crowding present. When the true amount of crowding is known, it can lead to more consistent treatment planning, with the decision to extract fewer teeth in the borderline cases. A formal space analysis is likely to assist with treatment planning.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We performed a retrospective study to determine the usefulness of contrast enema examinations in patients with small-bowel obstruction and known intraabdominal malignancy. Thirty-two patients with known or suspected intraabdominal malignancy and small-bowel obstruction who underwent both CT and subsequent contrast enema were identified. CT and contrast enema reports were reviewed for patients with tumor involvement of the colon to determine whether the contrast enema findings had provided additional information to the data that had been acquired with CT. In cases in which the contrast enema had provided additional information, the patients' medical records were reviewed to determine whether treatment had been modified as a result of the additional information. In 14 (44%) of 32 patients, the contrast enema provided evidence of synchronous colonic disease not previously detected. The colonic involvement could be classified into two categories: implants (n = 1) and narrowing or complete obstruction (n = 13). Findings of the contrast enema resulted in a change in treatment in 10 (32%) of 32 of our patient population.\nQuestion: Contrast enema before bypass surgery for small-bowel obstruction in the oncologic patient: is it necessary?",
        "gt": "Patients with known intraabdominal malignancy who present with small-bowel obstruction may have synchronous large-bowel disease that is undetectable on standard CT scans. In these patients, the additional information provided by the contrast enema altered subsequent treatment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate preparedness for rural practice and to ascertain where graduates of a community-based rural training program practise. Mailed cross-sectional survey. Rural communities in British Columbia. Graduates of the University of British Columbia's (UBC) rural training program from 1982 to 1991 and a random sample of non-program-trained rural BC physicians. Self-reported preparedness for rural practice in various areas of family medicine and in aspects of professional and personal life in rural settings. Locations of practice. Rural program graduates reported themselves better prepared in family medicine, community medicine, practice management, and behavioural science. Non-program-trained rural physicians thought themselves better prepared in medical subspecialties. Responses in pediatrics, obstetrics and gynecology, and surgical preparation showed no important differences. Rural program residents were located in rural areas (51%), regional settings (20.5%), and metropolitan areas (17.9%).\nQuestion: Training for rural practice. Are graduates of a UBC program well prepared?",
        "gt": "Graduates of the UBC rural training program consider themselves better prepared for rural family practice than non-program-trained rural physicians in several areas of family practice. Most graduates of the program were practising in rural and regional settings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: An everyday clinical practice dilemma in the 20-30% of metastatic colorectal cancer (CRC) patients that have not been operated on their primary tumour, is, under which specific histopathology and molecular circumstances, an endoscopic biopsy could be considered adequate to provide a representative RAS/BRAF molecular status to guide treatment. A consecutive series of 193 paired biopsy and primary CRC tumour samples between August 2008 and 2010 available in the Department of Pathology archives, University Hospitals, KU Leuven were retrieved. For a pair to be included, in the endoscopic biopsy, 20% of invasive adenocarcinoma cells should be present and enough slides to yield an extracted DNA concentration of \u2a7e5\u2009ng\u2009\u03bcl(-1), and no<2\u2009ng\u2009\u03bcl(-1) should be available for cutting. Exons 2-4 KRAS/NRAS, BRAF, PIK3CA molecular evaluation was performed with RT-PCR and Sequenom. From 165 deemed adequate by the pathologist pairs, 85 (51.5%) were concordantly mutated in at least one of the tested genes, 70 (42.5%) were wt and 10 (6%) were discordant, harbouring a mutation in the primary and not in the endoscopic biopsy. In the re-evaluation, when more slides were cut per discordant pair, mutational status changed in two of the six discordantly KRAS-mutated pairs. A strong strength of agreement for both runs was observed (Cohen's kappa, k=0.877, P<0.001 and k=0.901, P<0.001, respectively) between the surgically acquired and the endoscopic biopsy specimens' evaluation.\nQuestion: KRAS, NRAS, BRAF mutation comparison of endoscopic and surgically removed primary CRC paired samples: is endoscopy biopsy material adequate for molecular evaluation?",
        "gt": "Based on our results, an endoscopic biopsy could provide an accurate mutational profile and become a justified alternative to a surgically removed primary tumour specimen, as long as specific histopathology criteria are met.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The A1470T polymorphism (rs1049434) in the monocarboxylate (lactate/pyruvate) transporter 1 gene (MCT1) has been suggested to influence athletic performance in the general population. We compared genotype distributions and allele frequencies of the MCT1 gene A1470T polymorphism between endurance athletes, sprint/power athletes and matched controls. We also examined the association between the MCT1 A1470T and the athletes' competition level ('elite' and 'national' level). The study involved endurance athletes (n=112), sprint/power athletes (n=100), and unrelated sedentary controls (n=621), all Caucasians. Genomic DNA was extracted from buccal epithelium using a standard protocol. We conducted Fisher's exact tests and multinomial logistic regression analyses to assess the association between MCT1 genotype and athletic status/competition level. Sprint/power athletes were more likely than controls to possess the minor T allele (TT genotype compared to the AA [p<0.001]; TT or AT compared to the AA [p=0.007]; TT compared to both AA and AT genotypes [p<0.001]). Likewise, sprint/power athletes were more likely than endurance athletes to have the TT genotype compared to the AA (p=0.029) and the TT compared to both AA and AT genotypes (p=0.027). Furthermore, elite sprint/power athletes were more likely than national-level athletes to have the TT genotype compared to the AA (p=0.044), and more likely to have the TT genotype compared to both AA and AT genotypes (recessive model) (p=0.045).\nQuestion: MCT1 A1470T: a novel polymorphism for sprint performance?",
        "gt": "The MCT1 TT genotype is associated with elite sprint/power athletic status. Future studies are encouraged to replicate these findings in other elite athlete cohorts.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The incidence of Staphylococcus aureus (S. aureus) colonization on the skin of patients with atopic eczema/dermatitis syndrome (AEDS) is approximately 90% and a variety of evidence implicates epidermal staphylococcal infection as a pathogenic factor in atopic dermatitis. However, the mechanism(s) underlying the effects of this organism in the disease process are unclear. The cellular responses of AEDS suffers and asymptomatic atopic individuals to bacterial superantigens (SAg) were investigated in an attempt to elucidate the role of staphylococcal enterotoxin B (SEB) in atopic disease. Peripheral blood mononuclear cells (PBMC) were isolated from normal nonatopic adults, asymptomatic atopic individuals, patients with active AEDS and patients with active allergic asthma. The cells were cultured for 24 or 96 h with house dust mite (HDM), SEB and phytohaemagluttinin (PHA), and the supernatants were assayed for cytokine levels. Staphylococcal enterotoxin B selectively stimulates the production of interleukin (IL)-5 in AEDS sufferers but not in asymptomatic atopics or nonatopics. Additionally, we observed comparable susceptibility to the IL-5-stimulatory effects of SEB in allergic asthmatics.\nQuestion: Staphylococcal enterotoxin induced IL-5 stimulation as a cofactor in the pathogenesis of atopic disease: the hygiene hypothesis in reverse?",
        "gt": "Given the central role of IL-5-driven eosinophilia in progression from mild atopy to severe disease, these findings provide a plausible mechanism for the AEDS-promoting effects of staphylococcal SAg. Staphylococcal enterotoxin B may also have a similar role in atopic respiratory disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study was performed to evaluate the trauma triage system currently used by the general hospital of Viborg County, Denmark. According to the trauma triage system, an isolated high-energy trauma leads to a trauma team call. The aim of the study was to determine whether a high-energy trauma patient with no symptoms of injury is a sufficient indication to lead to a trauma team call. The study was based on prospective registration of traumatised patients admitted to the hospital during the period from 1 March 2000 to 28 February 2003. A ROC curve analysis was used to validate the ability of the trauma points to predict severe injury by isolated high-energy traumas. The study included 514 trauma patients, 304 of whom had suffered high-energy traumas. The positive predictive value of a trauma team call was 45% of severe injury. Among the subgroup of patients with no immediate symptoms, the positive predictive value was 15%. The ROC curve analysis found the optimum cut point to be a high-energy trauma with at least one symptom of injury. The sensitivity was 70% and the specificity 52%.\nQuestion: Should high-energy traumas always result in a trauma team call?",
        "gt": "The study suggests that a high-energy trauma patient showing no symptoms of injury is not a sufficient indication to lead to a trauma team call. This has caused a change in the scoring system. A trauma team call based on a high-energy trauma now implies that the patient shows signs of at least one symptom of injury.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Our objective was to assess the educational benefits of a formal pathology rotation during an obstetrics and gynecology residency program and to determine the utility of this information in clinical practice. In this descriptive study, the benefits of a 2-month rotation in pathology for obstetrics and gynecology residents were analyzed. A computerized listing of surgical cases processed by each resident was sent to the obstetrics and gynecology program director. Our resident accessioned 5.4% of the total pathology cases processed each month. Reports from previous residents (over a 17-year period) and from program directors at the annual educational retreat indicate that such information was not relevant to our graduates in their clinical practice.\nQuestion: Formal pathology rotation during obstetrics and gynecology residency: is it beneficial?",
        "gt": "A formal pathology rotation for obstetric residents can improve knowledge base, but the usefulness of this knowledge in clinical practice is dubious.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Tumor necrosis factors, TNF and lymphotoxin-\u03b1 (LT), are cytokines that bind to two receptors, TNFR1 and TNFR2 (TNF-receptor 1 and 2) to trigger their signaling cascades. The exact mechanism of ligand-induced receptor activation is still unclear. It is generally assumed that three receptors bind to the homotrimeric ligand to trigger a signaling event. Recent evidence, though, has raised doubts if the ligand:receptor stoichiometry should indeed be 3:3 for ligand-induced cellular response. We used molecular dynamics simulations, elastic network models, as well as MM/PBSA to analyze this question. Applying MM/PBSA methodology to different stoichiometric complexes of human LT-(TNFR1)n=1,2,3 the free energy of binding in these complexes has been estimated by single-trajectory and separate-trajectory methods. Simulation studies rationalized the favorable binding energy in the LT-(TNFR1)1 complex, as evaluated from single-trajectory analysis to be an outcome of the interaction of cysteine-rich domain 4 (CRD4) and the ligand. Elastic network models (ENMs) help to associate the difference in the global fluctuation of the receptors in these complexes. Functionally relevant transformation associated with these complexes reveal the difference in the dynamics of the receptor when free and in complex with LT.\nQuestion: Are different stoichiometries feasible for complexes between lymphotoxin-alpha and tumor necrosis factor receptor 1?",
        "gt": "MM/PBSA predicts complexes with a ligand-receptor molar ratio of 3:1 and 3:2 to be energetically favorable. The high affinity associated with LT-(TNFR1)1 is due to the interaction between the CRD4 domain with LT. The global dynamics ascertained from ENMs have highlighted the differential dynamics of the receptor in different states.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to evaluate the relative frequencies of sensitisation to four common inhalant allergens in two atopic populations suffering from asthma and/or rhinitis. One had been studied in the period of 1975 till 1979, and a second population was evaluated between 1992 and 1995. At both time periods patients with inhalant allergy and visiting our outpatient clinic were included. Quantification of IgE to Dermatophagoides pteronyssinus, birch, timothy grass, and mugwort was performed via the Phadebas RAST technique (Pharmacia, Brussels, Belgium). In patients suffering from respiratory allergy the frequency of birch pollen sensitisation significantly increased from 13% in the period 1975-1979 to 34% in the period 1992-1995. In contrast, the frequency of house dust mite, timothy grass pollen, and mugwort pollen sensitisation remained almost unchanged. The increase was not associated with an increase in the birch pollen count.\nQuestion: Is the prevalence of specific IgE to classical inhalant aeroallergens among patients with respiratory allergy changing?",
        "gt": "Birch pollen hypersensitivity has almost tripled among atopic subjects during the last 2 decades. The exact mechanisms for this increase remain to be evaluated.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Stepwise segmental pulmonary vein isolation (SPVI) and circumferential pulmonary vein isolation (CPVI) have been developed to treat patients with atrial fibrillation (AF), but the preferable approach for paroxysmal AF (PAF) has not been established. One hundred and ten patients with symptomatic PAF were randomized into a stepwise SPVI group (n=55) or CPVI group (n=55). Systemic SPVI combined with left atrial linear ablation tailored by inducibility of AF was performed in the stepwise SPVI group. Circumferential linear ablation around the left and right-sided pulmonary veins (PVs) guided by 3-dimensional electroanatomic mapping was performed in the CPVI group. The endpoints of ablation are non-induciblity of AF in the stepwise SPVI group and continuity of circular lesions combined with PV isolation in the CPVI group. After the initial procedures, atrial tachyarrhythmis (ATa) recurred within the first 3 months in 23 of the 55 patients (41.8%) who underwent stepwise SPVI and in 20 of the 55 patients (36.4%) who had CPVI (p=0.69). Repeat procedures were performed in 7 patients from the stepwise SPVI group and 5 from the CPVI group (p=0.76). During the 3-9 months after the last procedure, 46 patients (83.6%) from the CPVI group and 43 (78.2%) from the stepwise SPVI group did not have symptomatic ATa while not taking anti-arrhythmic drugs (p=0.63). Severe subcutaneous hematoma or PV stenosis occurred in 3 patients.\nQuestion: Is circumferential pulmonary vein isolation preferable to stepwise segmental pulmonary vein isolation for patients with paroxysmal atrial fibrillation?",
        "gt": "The efficacy of stepwise SPVI is comparable to that of CPVI for patients with PAF.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of the study was to assess long-term state and trait anxiety in cardiac surgical risk patients. Thirty two patients with serum S100B>0.3 microg/l 48 hours after cardiac surgery with cardiopulmonary bypass were matched according to age, gender, type, date and length of surgery with 35 operated patients without elevated S100B. They completed Spielberger's Anxiety Inventory (STAI). Patients with elevated S100B reported more state anxiety and trait anxiety. S100B was an independent predictor of both state and trait anxiety when controlling for perioperative variables.\nQuestion: Protein S100B after cardiac surgery: an indicator of long-term anxiety?",
        "gt": "Patients with elevated S100B reported more anxiety 3-6 years after cardiac surgery. A postoperative blood sample can identify risk patients and facilitate appropriate follow-up.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine long-term survival after pancreatoduodenectomy for pancreatic ductal adenocarcinoma and to identify clinical factors associated with long-term survival. The prognosis for long-term survival even after potentially curative resection for pancreatic adenocarcinoma is thought to be poor. Clinical factors determining short-term survival after pancreatic resection are well studied, but prognostic factors predicting long-term survival with a potential for cure are poorly understood. A case-control study was conducted of 357 patients who underwent pancreatoduodenectomy for pancreatic ductal adenocarcinoma between 1981 and 2001. Histologic specimens were reanalyzed to confirm diagnosis. Follow-up was at least 5 years or until death. There was an improved survival throughout the observation period (P = 0.004). We found 62 actual 5-year survivors of whom 21 patients survived greater than 10 years, for a 5- and 10-year survival rate of 18% and 13%, respectively. Cohort analysis comparing patients with short-term (<5 years, n = 295) and long-term (>or =5 years, n = 62) survival showed that more advanced disease (greatest tumor diameter, lymph node metastasis) and decreased serum albumin concentration were unfavorable for long-term survival (all P<0.05). In contrast, the extent of resection and more aggressive histologic features did not correlate with long-term survival (all P>0.05). En-bloc resection (P = 0.005) but not resection margin status (P>0.05) was associated with long-term survival. Adjuvant chemoradiation therapy did not significantly influence long-term survival. Multivariate analysis identified lymph node status (OR 0.36, 95% CI 0.14-0.89, P = 0.03) as a prognostic factor for long-term survival. Five-year survival was no guarantee of cure because 16% of this subset died of pancreatic cancer up to 7.8 years after operation.\nQuestion: Long-term survival after pancreatoduodenectomy for pancreatic adenocarcinoma: is cure possible?",
        "gt": "Pancreatoduodenectomy for adenocarcinoma in the head of pancreas can provide long-term survival in a subset of patients, particularly in the absence of lymph node metastasis. One of 8 patients can achieve 10-year survival with a potential for cure.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Use of nucleic acid amplification tests (NAATs), such as strand displacement assay (SDA, BD ProbeTec C trachomatis/N gonorrhoeae Amplified DNA Assay), for the detection of gonococcal infection in the community is controversial because of the possibility of false-positive results in low prevalence populations.AIM: To evaluate if culture confirmation of gonococcal infection can be improved for subjects found to be positive by BD ProbeTec in community clinics. Two cervical swabs were collected for culture to confirm NAAT positive results in women aged over 16 years-a majority of whom were<25 years and asymptomatic. One swab was urgently transported (UTP) and processed in the laboratory within 2 hours whereas the other swab (RTP) was stored at 4 degrees C, transported at room temperature and processed 4-72 hours after collection depending on the time and day of collection. Altogether, 56 subjects with NAAT positive results were recruited into the study. Nine (16.1%) subjects who were culture negative were excluded from final analysis due to prior antibiotic treatment (4/9) or the culture having been taken more than 1 month after the NAAT was positive (4/9) or an incorrect specimen being received (1/9). Overall, 41/47 (87.2%) NAAT positive subjects were confirmed by culture. In total, 40/47 (85.1%) UTP swabs and 27/47 (57.4%) RTP swabs were positive (p<0.05).\nQuestion: Can culture confirmation of gonococcal infection be improved in female subjects found to be positive by nucleic acid amplification tests in community clinics?",
        "gt": "This study shows that culture confirmation in NAAT positive subjects in a community gonococcus screening programme can be significantly improved by urgent transportation to and processing of specimens in the laboratory.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To confirm the hypothesis that isolated cardiac echogenic foci at the second-trimester anomaly scan do not influence our current calculation of risk of trisomy 21 in individual pregnancies, which is based on maternal age and nuchal translucency thickness at 11-14 weeks. Observational study in a fetal medicine unit. In a general pregnant population undergoing first-trimester nuchal translucency screening, data from 239 singleton pregnancies with isolated cardiac echogenic foci at the second-trimester anomaly scan were compared with those of a control group of 7449 pregnancies with normal anomaly scans. Prevalence of trisomy 21 was determined in both groups. Following the anomaly scan, the individual risks of trisomy 21 were calculated by adjusting the previous risk based on maternal age and first-trimester nuchal translucency. We assumed that echogenic foci did not alter each individual risk calculation. The expected number of cases of Down syndrome in both groups was then calculated from the sum of probabilities of each individual affected fetus. The observed number of cases was compared with the expected number in both study and control populations. There was no statistically significant difference between the prevalence of trisomy 21 in the study group (no cases) and in the control population (three cases). From individual risk calculations, observing no cases of trisomy 21 in the study group was the most likely event if echogenic foci did not increase the risk of this chromosomal abnormality (P = 0.62).\nQuestion: Isolated echogenic foci in the fetal heart: do they increase the risk of trisomy 21 in a population previously screened by nuchal translucency?",
        "gt": "The finding of isolated echogenic foci at the time of the 20 week-scan does not significantly change the risks of trisomy 21 if background risk and previous nuchal translucency measurements are taken into account in the individual risk calculation. We suggest that no further adjustments to risk should be used.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although increased prevalence of transfusion transmissible infections (TTI) among \"men who have sex with men\" (MSM) has been well documented, the exclusion of MSM as blood donors is contested. The aim of this systematic review is to find studies that describe the risk of TTI in MSM blood donors. We searched MEDLINE, Embase, The Cochrane Central Register of Controlled Trials, Cinahl, and Web of Science, and used GRADE for determining evidence quality. We included studies comparing MSM and non-MSM blood donors (or people eligible to give blood), living in areas most relevant for our Blood Service. Out of 18 987 articles, 14 observational studies were included. Two studies directly compared MSM with non-MSM donors showing that MSM donors have a statistically significant higher risk of HIV-1 infections. In one of these studies it was shown that this was related to recent (<12 months) MSM contact. In two additional studies no evidence was shown in favour of a certain deferral period for MSM. Ten studies, applying permanent deferral for MSM, compared infected versus non-infected donors. One study found that MSM is a statistically significant risk factor for HIV-1 infection in blood donors. For other TTI such as HBV or HCV, an increased risk of infection could not be demonstrated, because the precision of the results was affected by the low numbers of donors with MSM as risk factor, or because of risk of bias in the included studies. All studies included low level evidence, because of risk of bias and imprecision of the results.\nQuestion: Is having sex with other men a risk factor for transfusion-transmissible infections in male blood donors in Western countries?",
        "gt": "High-quality studies investigating the risk of TTI in MSM who donate blood are scarce. The available evidence suggests a link between MSM blood donors and HIV-1 infection, but is too limited to be able to unambiguously/clearly recommend a certain deferral policy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim was to evaluate the psychological impact on women undergoing invasive procedures of prenatal diagnosis. Department of Gynecology and Obstetrics, 1st Medical Faculty, Charles University, Prague. A questionnaire was given to 200 pregnant women and to 160 midwives and students. The acquired data were statistically evaluated using the non-parametric chi 2 test for a 5% confidence interval and the Kruskal-Wallis test (analysis of non-normal distribution of random variables). We found that 85% of pregnant patients were satisfied with the information given by their obstetrician prior to the procedure, 53% of the patients were distressed about the procedure. The largest percentage of patients feared complications of the procedure, while fear of the results of the procedure took second place.\nQuestion: Is the information we give women prior to invasive prenatal procedures adequate?",
        "gt": "We found that only some of the patients and midwives had complete information about the actual method of performing these procedures, about the risk, and about the time it takes to obtain results. Most patients receive their information from a doctor-geneticist, which is in agreement with our system. The patient's distress regarding the procedure is not dependent on the level of education. From the acquired data, it follows that greater significance should be placed on the informing patients as well as midwives about all aspects of performing invasive procedure of prenatal diagnosis. According to our study, neither the patient nor the midwife have an adequate perception of the benefits and risk of prenatal diagnostic examinations.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The objective of this study was to compare the performance of pulmonary autografts with mechanical aortic valves, in the treatment of aortic valve stenosis. Forty patients with aortic valve stenoses, and below the age of 55 years, were randomly assigned to receive either pulmonary autografts (n = 20) or mechanical valve (Edwards MIRA; Edwards Lifesciences, Irvine, CA) prostheses (n = 20). Clinical outcomes, left ventricular mass regression, effective orifice area, ejection fraction, and mean gradients were evaluated at discharge, 6 months, and one year after surgery. Follow-up was complete for all patients. Hemodynamic performance was significantly better in the Ross group (mean gradient 2.6 mm Hg vs 10.9 mm Hg, p = 0.0005). Overall, a significant decrease in left ventricular mass was found one year postoperatively. However, there was no significant difference in the rate and extent of regression between the groups. There was one stroke in the Ross group and one major bleeding complication in the mechanical valve group. Both patients recovered fully.\nQuestion: Do pulmonary autografts provide better outcomes than mechanical valves?",
        "gt": "In our randomized cohort of young patients with aortic valve stenoses, the Ross procedure was superior to the mechanical prostheses with regard to hemodynamic performance. However, this did not result in an accelerated left ventricular mass regression. Clinical advantages like reduced valve-related complications and lesser myocardial strain will have to be proven in the long term.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Perceived discrimination poses risks for psychological distress among Asian Americans, but the differential impact of general unfair treatment and racial discrimination has not been examined. Although social support from distal sources reduces discrimination-related distress either directly or as a buffer, the unique roles of spousal support have remained understudied. Nativity status was examined as another moderator of these relationships to resolve previous inconsistent findings regarding its relationship to the discrimination-distress link. Data were from 1,626 U.S.- and foreign-born Asian American adults (Mage = 42.17 years; n = 1,142 married/cohabiting) in the nationally representative National Latino and Asian American Study, who reported on experiences of unfair treatment, racial discrimination, social supports from spouses, family, friends, and neighborhood, and psychological distress. Hierarchical multiple regressions showed that both unfair treatment and racial discrimination predicted psychological distress, and spousal support predicted distress above and beyond distal forms of social support in the context of perceived discrimination. Moderation analyses revealed that spousal support buffered against negative psychological consequences of unfair treatment, but not racial discrimination. Spousal support was not differentially protective as a function of nativity; however, U.S.-born respondents reacted with greater distress to unfair treatment than their foreign-born counterparts.\nQuestion: Do spouses matter?",
        "gt": "Psychological effects of both general and race-based discrimination, and the unique contributions of distinct sources of social support, are important to understanding adjustment and cultural transition among Asian Americans. Nativity differentially influences effects of unfair treatment. Implications for future research are discussed.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Anastomotic leaks represent the most common severe postoperative complications after esophagectomy. In this study standard inflammatory laboratory parameters [leukocytes, C-reactive protein (CRP)] were evaluated as indicators for anastomotic leakage after esophagectomy. Between 1 / 1997 and 12 / 2006 a total of 558 patients with esophageal cancer underwent an Ivor-Lewis esophagectomy. Among these patients, all those (n = 50, 8.9 %) suffering from an anastomotic leak were matched to 50 patients without anastomotic leakage. Leukocytes, CRP level and clinical parameters (body temperature, cardiac / respiratory problems, wound secretion) were retrospectively analysed at short-term intervals in both groups. Patients with anastomotic leaks showed significant continuously increased CRP levels and leukocyte counts from the second or, respectively, 5 (th) postoperative day onwards compared to patients without anastomotic leaks. Using a stepwise regression, an 80 % sensitivity for leakage detection has been calculated by a cut-off value for CRP set at 13.5 mg / dL from day 2 onwards or, respectively, for leukocytes at 10.5 Gpt / L from day 8 onwards. Concomitantly, patients with anastomotic leaks suffered significantly more from respiratory problems and abdominal pain.\nQuestion: Are leukocytes and CRP early indicators for anastomotic leakage after esophageal resection?",
        "gt": "CRP appears to be a reliable and predictable indicator for anastomotic leakage after esophagectomy and should, therefore, be routinely used as a screening marker to provide a reason for extended diagnosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: to examine the effect of the adoption of endovascular aneurysm repair (EVAR) on the outcome of open repair (OR). between May 1998 and December 2001, EVAR (Zenith) was performed in 117 patients, and OR was performed because of anatomic restrictions in 40 (group A), and because of young age in 11 patients (group B). EVAR patients had higher ASA classifications (p<0.0001). EVAR was associated with a 98.3% (115 patients) technical success rate, one conversion to OR and one fatal cardiac arrest. Thirty-day mortality was 2.6% (3 patients) in EVAR, 15% (6 patients) in group A and none in group B. There was no difference in late survival between the three groups. Late reinterventions, mainly endovascular, were more frequent in EVAR. At a median follow-up of 17 months one stent-graft had migrated 5 mm distally and five stents had fractured, but without clinical consequence.\nQuestion: Does the wide application of endovascular AAA repair affect the results of open surgery?",
        "gt": "EVAR provides good results even with inclusion of high-risk patients. The adoption of EVAR may adversely affect the results of OR offered to patients because of anatomic considerations. However, OR continues to be the first option for low-risk young patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To test whether an ultramolecular dilution of homeopathic Thyroidinum has an effect over placebo on weight reduction of fasting patients in so-called 'fasting crisis'. Randomised, placebo-controlled, double-blind, parallel group, monocentre study.SETTING/ Hospital for internal and complementary medicine in Munich, Germany. Two hundred and eight fasting patients encountering a stagnation or increase of weight after a weight reduction of at least 100 g/day in the preceding 3 days. One oral dose of Thyroidinum 30cH (preparation of thyroid gland) or placebo. Main outcome measure was reduction of body weight 2 days after treatment. Secondary outcome measures were weight reduction on days 1 and 3, 15 complaints on days 1-3, and 34 laboratory findings on days 1-2 after treatment. Weight reduction on the second day after medication in the Thyroidinum group was less than in the placebo group (mean difference 92 g, 95% confidence interval 7-176 g, P=0.034). Adjustment for baseline differences in body weight and rate of weight reduction before medication, however, weakened the result to a non-significant level (P=0.094). There were no differences between groups in the secondary outcome measures.\nQuestion: Does a homeopathic ultramolecular dilution of Thyroidinum 30cH affect the rate of body weight reduction in fasting patients?",
        "gt": "Patients receiving Thyroidinum had less weight reduction on day 2 after treatment than those receiving placebo. Yet, since no significant differences were found in other outcomes and since adjustment for baseline differences rendered the difference for the main outcome measure non-significant, this result must be interpreted with caution. Post hoc evaluation of the data, however, suggests that by predefining the primary outcome measure in a different way, an augmented reduction of weight on day 1 after treatment with Thyroidinum may be demonstrated. Both results would be compatible with homeopathic doctrine (primary and secondary effect) as well as with findings from animal research.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Diverse results exist regarding myocardial release of endothelin after coronary artery bypass grafting. Because endothelin may be involved in regulation of coronary blood flow, postoperative endothelin-blockade could influence the surgical outcome. In this study, we have evaluated the cardiac outflow of endothelin and effects on coronary flow by endothelin-blockade immediately after completion of the coronary bypass grafting. Thirty patients were subjected to infusions of endothelinA blocker (BQ-123, 260 nmoL/min for up to 30 minutes) or endothelinA blocker and endothelinB blocker (BQ-123 and BQ-788, 260 and 250 nmol/min, respectively, for up to 30 minutes) into a veingraft anastomosed to a coronary vessel, and the coronary blood flow was measured. Plasma levels of endothelin from the coronary sinus and the periphery were determined. There were no significant changes in flow caused by endothelinA blockade alone or in combination with endothelinB blockade. There were no immediately increased levels of endothelin after surgery or after infusions of the endothelin blockers.\nQuestion: Is there a role for endothelin-blockade early after coronary artery bypass grafting?",
        "gt": "Endothelin blockade does not influence the immediate perioperative myocardial blood flow after coronary bypass grafting. There is no significantly increased myocardial outflow of endothelin, and endothelin does not have any influence on the basal tone of the coronary vessels in the early phase after coronary bypass grafting.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To describe the new drugs marketed in Brazil during the period 2000-2004, compare the description to the country's burden of disease, and suggest initiatives capable of addressing the situation from the perspective of a developing country. Records of new drugs were surveyed in an official drug registration database. The new drugs were categorized by Anatomical Therapeutic Chemical classification, indication, and innovation, and compared with the needs of the country's burden of disease. Data on the morbidity and mortality rates of selected diseases (diabetes, Hansen's disease, hypertension, tuberculosis) were retrieved from official documents and the literature. During the period investigated, 109 new drugs were launched. Most were general anti-infectives for systemic use (19), followed by antineoplastic and immunomodulating agents (16). The number of new drugs launched in 2004 was roughly one-third that of 2000. Of 65 new drugs, only one-third can be classified as innovative. Most new drugs were intended to treat noninfectious diseases that typically affect developed countries, diseases that constitute only a fraction of the country's challenges.\nQuestion: New drugs in Brazil: do they meet Brazilian public health needs?",
        "gt": "A mismatch occurs between public health needs and the new drugs launched on the Brazilian market. Not only did the number of new drugs decrease in the study period, but only a few were actually new in therapeutic terms. Developing countries must acquire expertise in research and development to strengthen their capacity to innovate and produce the drugs they need.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To better establish the clinical features, natural history, clinical management, and rehabilitation implications of dysautonomia after traumatic brain injury, and to highlight difficulties with previous nomenclature. Retrospective file review on 35 patients with dysautonomia and 35 sex and Glasgow coma scale score matched controls. Groups were compared on injury details, CT findings, physiological indices, and evidence of infections over the first 28 days after injury, clinical progress, and rehabilitation outcome. the dysautonomia group were significantly worse than the control group on all variables studied except duration of stay in intensive care, the rate of clinically significant infections found, and changes in functional independence measure (FIM) scores.\nQuestion: Dysautonomia after traumatic brain injury: a forgotten syndrome?",
        "gt": "Dysautonomia is a distinct clinical syndrome, associated with severe diffuse axonal injury and preadmission hypoxia. It is associated with a poorer functional outcome; however, both the controls and patients with dysautonomia show a similar magnitude of improvement as measured by changes in FIM scores. It is argued that delayed recognition and treatment of dysautonomia results in a preventable increase in morbidity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study examined whether the AR-CAG repeat length might affect clinical characteristics (testis volume) seminal parameters (sperm count and its mobility) along with hormonal serum profile [FSH, LH, Testosterone (T) and Inhibin B (InhB)] both in idiopathic male infertility (IM) and in infertility due to a previous condition of cryptorchidism (CryM) or to Y chromosome long arm microdeletions (YM). Observational study without intervention(s). One hundred and ten IM patients [90 idiopathic olizoospermic males (IOM) and 20 idiopathic azoospermic males (IAM)], 19 CryM male and 10 YM patients were included. Sixty-one age-matched healthy men who had fathered within 3 years were involved representing the control group (FM). AR-CAG repeats stretch was significantly longer in IOM (p<0.05), CryM (p<0.05) and YM (p<0.001) than FM. When the AR-CAG repeat tracts were subdivided in three subgroups according to the length of CAG repeats tract assessed in fertile subjects (the one with the middle (n 19-21) belonging to the 25 and 75 % inter-quartile, the ends belonging to the<25 % inter-quartile and>75 % inter-quartile, respectively), there was a statistically significant difference of distribution of AR-CAG tract length among fertile and different groups of infertile men (p=<0.0005; chi-square test). Moreover, the subgroup of AR-CAG repeat stretch with 22-28 triplets was associated with lower levels of InhB both in idiopathic oligozoospermic (Scheffe, Bonferroni and Dunett tests p=<0.01) and azoospermic men (Scheffe, Bonferroni and Dunett test p=<0.05), while, when FM and men with idiopathic infertility were gathered in a single group, both the subgroup of AR- CAG tract with 15-18 repeats and the one with 22-28 repeats are associated with lower testis volume, reduced sperm count and serum InhB levels.\nQuestion: Could androgen receptor gene CAG tract polymorphism affect spermatogenesis in men with idiopathic infertility?",
        "gt": "Our study showed that the outliers of AR-CAG repeat length seem to influence the function of AR, affecting testis volume and Sertoli cell function and consequently sperm production in both fertile and idiopathic infertile men.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In reference textbooks describing axillary block, the ulnar, radial, and median nerves are located in a common sheath surrounding the axillary artery. In contrast, the musculocutaneous nerve is described as lying outside this sheath in the coracobrachialis muscle. In a recent case report of ultrasound-guided axillary block, the musculocutaneous nerve was joined to the median nerve outside this muscle. Our study evaluated the prevalence of atypical musculocutaneous nerve localizations during axillary block. All patients undergoing ultrasound-guided axillary block were included from December 2006 to December 2008. Before needle insertion, musculocutaneous, median, ulnar, and radial nerves were localized using ultrasound. Nerve stimulation confirmed atypical nerve localization. After injection of local anesthetics, musculocutaneous and median nerve anatomical relationships were observed. The musculocutaneous nerve was outside the coracobrachialis muscle in 83 of the 387 analyzed blocks (22%). It was near the axillary artery in 22 cases (6%). The musculocutaneous and median nerves appeared as a common neural structure in 61 cases (16%). After local anesthetic injection, a common trunk persisted in 16 of 61 cases (26%), musculocutaneous and median nerves separated in 37 cases (61%), and 2 roots of the median nerve appeared (with or without a separated musculocutaneous nerve) in 6 cases (10%). Two cases (3%) remained undefined. Ulnar nerve location of the 83 patients with atypical musculocutaneous nerve position differed from the ones with a classical musculocutaneous nerve localization.\nQuestion: Is the musculocutaneous nerve really in the coracobrachialis muscle when performing an axillary block?",
        "gt": "During axillary block, the musculocutaneous nerve is outside the coracobrachialis muscle in 1 of 5 patients. This atypical location should be considered during performance of axillary blockade to avoid repeated IM puncture.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The risk of virologic failure and selection of resistant strains remains a challenge in HIV-1 perinatally infected children. HIV-1 coreceptor usage was determined in HAART-failing children followed in Necker Hospital (Paris, France) in order to estimate the proportion of these patients who may benefit from CCR5-antagonists therapy. HIV-1 coreceptor usage was determined with the SVM(Geno2pheno10%) algorithm in 51 children with virologic failure after a median treatment exposure of 7.8 years. CXCR4-tropic strains were found in 31.4% of the patients. CXCR4 usage was associated with high HIV-1 DNA (P=0.01), old age (P=0.02), long ART cumulative exposure (P=0.006), and previous exposure to high number of different drugs (P=0.03) and ART combinations (P=0.03) in univariate analysis. Selection of resistant viruses and current exposure to a darunavir-based HAART tended to be more frequent in the CXCR4 group compared with the children infected with CCR5-tropic strains (P=0.06). In multivariate analysis, CXCR4 usage was exclusively correlated with HIV-1 DNA (P=0.03), which accurately reflects the cumulative exposure to viral replication over the whole duration of HIV infection.\nQuestion: CCR5 antagonists:  a therapeutic option in HIV-1 perinatally infected children experiencing virologic failure?",
        "gt": "Two-thirds of HAART-failing children could benefit from CCR5 antagonists-based strategies, even in case of triple-class virologic failure. Such therapy should be discussed more appropriately at early stages of infection, when CCR5-tropic strains are most frequently isolated. However, before considering such strategies, further studies are needed to evaluate the efficacy and the tolerability of CCR5 antagonists in this pediatric population.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To summarize the social, economic, emotional, and psychological consequences incurred by women with obstetric fistula; present the results of a meta-analysis for 2 major consequences, divorce/separation and perinatal loss; and report on improvements in health and self-esteem and on the possibility of social reintegration following successful fistula repair. We conducted a review of the literature published between 1985 and 2005 on fistula in developing countries. We then performed a meta-analysis for 2 of the major consequences of having a fistula, divorce/separation and perinatal child loss. Studies suggest that surgical treatment usually closes the fistula and improves the physical and mental health of affected women.\nQuestion: Social and economic consequences of obstetric fistula: life changed forever?",
        "gt": "With additional social support and counseling, women may be able to successfully reintegrate socially following fistula repair.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To address the question whether general practitioners (GPs) should receive practical training in shoulder problems and to test whether cortisone injections are better than anaesthetic injections for rotator cuff problems. A pragmatic split-plot, randomized trial with a cluster factorial design, conducted in general practices across five centres across the United Kingdom. Ninety-one practices were randomized to receive additional training in diagnosing and injecting rotator cuff problems or no additional training. Two hundred patients consulting their general practices with shoulder pain were then randomized to receive either a corticosteroid or lignocaine injection. The main outcome was score on the British Shoulder Disability Questionnaire (BSDQ). The Short-Form 36-item Health Survey and EuroQol at 12 months from entry to the trial were also scored. Over the course of the trial there was a mean difference of 0.94 (s.e. = 1.01) on the BSDQ score between the groups, with patients treated by the untrained group having a mean of 9.46 (s.e. = 0.82) and those by the trained group having a mean of 8.51 (s.e. = 0.60). There were no statistically significant differences between the groups. Analysing by substance injected, there was a mean difference of 0.15 (s.e. = 0.48) throughout the trial between the groups, with patients given the cortisone having a mean BSDQ of 9.67 (s.e. = 0.39) and those given lignocaine, 9.82 (s.e. = 0.39). This was not statistically significantly different.\nQuestion: Shoulder acute pain in primary healthcare: is retraining effective for GP principals?",
        "gt": "Training GPs in the diagnosis and treatment of shoulder disorders does not make any difference to the outcome, in terms of pain and disability, 1 yr later. Further, there is no advantage to injecting steroid in a group with predominant rotator cuff disorder. Trial registration. International Standard Randomized Controlled Trial Number 58537244. Trial steering committee comprised Prof. Paul Dieppe, Prof. Elaine Hay, Dr Brian Hazleman and Dr Kerenza Hood.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Few healthcare economic evaluations, and none in cardiac rehabilitation, report results based on both community and patient preferences for health outcomes. We published the results of a randomized trial of cardiac rehabilitation after myocardial infarction in 1994 in which preferences were measured using both perspectives but only patient preferences were reported. This secondary analysis uses both types of preference measurements. We collected community Quality of Well-Being (QWB) and patient Time Trade-off (TTO) preference scores from 188 patients (rehabilitation, n=93; usual care, n=95) on entry into the trial, at 2 months (end of the intervention) and again at 4, 8, and 12 months. Mean preference scores over the 12-month follow-up study period, estimates of quality-adjusted life years (QALYs) gained per patient, incremental cost-effectiveness ratios [costs inflated to 2006 US dollars] and probabilities of the cost-effectiveness of rehabilitation for costs per QALY up to USD100,000 are reported. Mean QWB preference scores were lower (P<0.01) than the corresponding mean TTO preference scores at each assessment point. The 12-month changes in mean QWB and TTO preference scores were large and positive (P<0.001) with rehabilitation patients gaining a mean of 0.011 (95% confidence interval, -0.030 to +0.052) more QWB-derived QALYs, and 0.040 (-0.026, 0.107) more TTO-derived QALYs, per patient than usual care patients. The incremental cost-effectiveness ratio for QWB-derived QALYs was estimated at $60 270/QALY (about euro50 600/QALY) and at $16 580/QALY (about euro13 900/QALY) with TTO-derived QALYs. With a willingness to spend $100 000/QALY, the probability of rehabilitation being cost-effective is 0.58 for QWB-derived QALYs and 0.83 for TTO-derived QALYs.\nQuestion: Community or patient preferences for cost-effectiveness of cardiac rehabilitation: does it matter?",
        "gt": "This secondary analysis of data from a randomized trial indicates that cardiac rehabilitation is cost-effective from a community perspective and highly cost-effective from the perspective of patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Dogma suggests optimal myocardial protection in cardiac surgery after prior coronary artery bypass graft surgery (CABG) with patent left internal thoracic artery (LITA) pedicle graft requires clamping the graft. However, we hypothesized that leaving a patent LITA-left anterior descending (LAD) graft unclamped would not affect mortality from reoperative cardiac surgery. Data were collected on reoperative cardiac surgery patients with prior LITA-LAD grafts from July 1995 through June 2006 at our institution. With the LITA unclamped, myocardial protection was obtained initially with antegrade cardioplegia followed by regular, retrograde cardioplegia boluses and systemic hypothermia. The Society of Thoracic Surgeons National Database definitions were employed. The primary outcome was perioperative mortality. Variables were evaluated for association with mortality by bivariate and multivariate analyses. In all, 206 reoperations were identified involving patients with a patent LITA-LAD graft. Of these, 118 (57%) did not have their LITA pedicle clamped compared with 88 (43%) who did. There were 15 nonsurvivors (7%): 8 of 188 (6.8%) in the unclamped group and 7 of 88 (8.0%) in the clamped group (p = 0.750). Nonsurvivors had more renal failure (p = 0.007), congestive heart failure (p = 0.017), and longer perfusion times (p = 0.010). When controlling for independently associated variables for mortality, namely, perfusion time (odds ratio 1.014 per minute; 95% confidence interval: 1.004 to 1.023; p = 0.004) and renal failure (odds ratio 4.146; 95% confidence interval: 1.280 to 13.427; p = 0.018), an unclamped LITA did not result in any increased mortality (odds ratio 1.370; 95% confidence interval: 0.448 to 4.191). Importantly, the process of dissecting out the LITA resulted in 7 graft injuries, 2 of which significantly altered the operation.\nQuestion: Do you need to clamp a patent left internal thoracic artery-left anterior descending graft in reoperative cardiac surgery?",
        "gt": "In cardiac surgery after CABG, leaving the LITA graft unclamped did not change mortality but may reduce the risk of patent graft injury, which may alter an operation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine patient understanding of how to properly gain access to urgent and emergency medical care under TennCare, a government-mandated managed health care initiative designed to replace Medicaid in Tennessee. We prospectively surveyed a convenience sample of ED patients at university hospital ED with an annual census of 50,000 during two periods (summer 1994 and summer 1995). In 1994, 250 TennCare patients were enrolled (part 1). In 1995, 199 were enrolled (part 2). Patients from seven different TennCare managed care organizations (MCOs) were interviewed. Thirty-eight percent of part 1 patients and 37% of part 2 patients did not have or did not know the names of their primary care physicians (PCPs). Fifty-eight percent of the part 1 patients who knew their PCPs' names had never visited them. This figure had decreased to 25% by the time part 2 patients were surveyed. Seventy-three percent of part 1 patients interviewed did not call their PCPs before coming to the ED. This figure had decreased to 48% by the time part 2 patients were interviewed. Thirty-two percent of part 1 patients were aware that they were supposed to contact the PCP before visiting the ED, whereas 94% of part 2 patients were aware of this requirement. Thirty-one percent of part 1 patients and 40% of part 2 patients who tried to contact their PCPs were unsuccessful, most often because of a delay on the part of PCPs in returning calls. Fifty-six percent of part 1 patients and 69% of part 2 patients did not know that they might be held responsible for the bill if an ED visit was not considered a true emergency and was not approved by the MCO.\nQuestion: Access to emergency care under TennCare: do patients understand the system?",
        "gt": "Improvements in communication of pertinent information must be implemented in managed care systems such as TennCare to better inform participants of the proper use of the system. MCOs will not reduce inappropriate use of the ED if patients are not aware of their responsibilities and do not know their PCPs or how to gain access to them. PCP responsiveness to patients must also be improved.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Approximately 14% of hemodialysis patients have atrial fibrillation. Hemodialysis patients with atrial fibrillation appear to be at increased risk of both thromboembolic complications and bleeding. Furthermore, there is uncertainty regarding the efficacy of warfarin or acetylsalicylic acid (ASA) therapy for preventing strokes in this subgroup because they were excluded from relevant trials. We performed a cost-utility analysis. Probabilistic sensitivity analysis was used to incorporate parameter uncertainty into the model. Expected value of perfect information and scenario analyses were performed to identify the important drivers of the decision and focus future research.SETTING & Base case was a 60-year-old male hemodialysis patient in the United States.MODEL, PERSPECTIVE, & A Markov Monte Carlo microsimulation model was constructed from the perspective of the health care payer, and patients were followed up during their lifetime. We compared 3 alternative treatment strategies for permanent atrial fibrillation in hemodialysis patients: warfarin, ASA, or no treatment. Quality-adjusted survival and cost. ASA and warfarin both prolonged survival compared with no treatment (0.06 and 0.15 quality-adjusted life-years [QALYs], respectively). ASA was associated with an incremental cost-effectiveness ratio of $82,100/QALY. Warfarin provided additional benefits at a cost of $88,400 for each QALY gained relative to ASA. At a threshold of $100,000/QALY, the probabilities that no treatment, warfarin, and ASA were the most efficient therapy were 20%, 58%, and 23%, respectively. Parameterization data and costs were taken from US studies and may not be generalizable to other countries. Peritoneal dialysis patients were not included in the analysis.\nQuestion: Should hemodialysis patients with atrial fibrillation undergo systemic anticoagulation?",
        "gt": "The high future cost of hemodialysis constrains incremental cost-effectiveness ratios to values greater than commonly cited thresholds ($50,000/QALY). Based on available evidence, warfarin appears to be the optimal therapy to prevent thromboembolic stroke in hemodialysis patients with atrial fibrillation. Additional study is required to determine the efficacy of warfarin and risk of bleeding complications in this population so that patients can make a more informed choice.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To measure the extent to which health-related quality of life (HRQoL) in people living with HIV is associated with duration of antiretroviral therapy (ART) after controlling for sociodemographic, clinical, and other therapy-related factors. Cross-sectional analysis. A gender-stratified random sample of 421 participants aged 18-64 years was selected from the patients on ART at a health facility in Kenya. Three hundred and ninety two patients participated in the study, representing a 93% response rate. Data on general physical and mental health functioning status were collected using the SF-36 health survey questionnaire. Hierarchical logistic regression analysis was used to predict the SF-36 summary scores. In regression analyses, the duration of ART was negatively associated with HRQoL (odds ratio (OR): 0.6, 95% confidence interval (CI): 0.45-0.92) after controlling for sociodemographic, clinical, and other therapy-related factors. Patients with chronic diseases or clinical symptoms of acute illness had significantly worse HRQoL (OR: 0.5, 95% CI: 0.30-0.79 and OR: 0.3, 95% CI: 0.16-0.59, respectively). Therapy interruptions, adverse drug reactions, and World Health Organization stage at initiation of therapy were not associated with HRQoL.\nQuestion: Does duration on antiretroviral therapy determine health-related quality of life in people living with HIV?",
        "gt": "Patients on ART for a relatively longer duration reported poorer HRQoL at the study facility independent of the effect of other therapy-related, clinical, and sociodemographic factors. Program managers and clinicians in the Kenyan health system may need to refocus attention on this subgroup to avert 'loss to treatment' that may have negative repercussions on the substantial gains made against the HIV scourge.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the association between inflammatory bowel disease (IBD) and gallstone disease (GD) by performing a meta-analysis. PubMed, Medline, Embase, Web of Science and the Cochrane Library were searched for relevant articles published between January 1980 and February 2015. All statistical analyses were performed using STATA 12.0. A fixed-effects model was adopted; heterogeneity was evaluated by \u03c7(2) test and I(2) statistic; publication bias was assessed by Begg's and Egger's tests. Five studies qualified for inclusion in the meta-analysis. Patients with IBD had a significantly higher prevalence of GD than those in the control group [odds ratio (OR) 1.72, 95% confidence interval (CI) 1.40-2.12, P<0.0001]. Subgroup analyses showed a significantly higher prevalence of GD in patients with Crohn's disease (CD) (OR 2.05, 95% CI 1.61-2.63, P<0.0001). However, no significant difference in the prevalence of GD was observed between patients with ulcerative colitis (UC) and controls (OR 1.12, 95% CI 0.75-1.68, P = 0.585). Studies from Italy, Sweden and the UK revealed a higher prevalence of GD in patients with IBD. No heterogeneity (I(2) = 25.2%, P = 0.228) or publication bias was observed in our meta-analysis (Begg's test, P = 0.711; Egger's test, P = 0.805).\nQuestion: Is gallstone disease associated with inflammatory bowel diseases?",
        "gt": "Our meta-analysis suggests there is a trend towards higher prevalence of GD in IBD patients, and especially in patients with CD. More rigorous, large-scale multi-center studies are required to investigate the association between GD and IBD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To investigate the efficacy and safety of the Trevo ProVue (TPV) stent retriever in stroke patients with large artery occlusions, with particular attention to the full structural radiopacity of the TPV. Case files and images of TPV treatments were reviewed for clinical and technical outcome data, including revascularization rates, device and procedure related complications, and outcome at discharge and after 90\u2005days. 76 patients were treated with TPV. Mean National Institutes of Health Stroke Scale (NIHSS) score was 18 and 68% had additional intravenous thrombolysis. 63 occlusions were in the anterior circulation: 44 M1 (58%), 8 M2 (11%), 8 internal carotid artery-terminus (11%), 2 internal carotid artery- left (3%), 1 A2 (1%), and 13 vertebrobasilar (17%). 58 of 76 (76%) were solely treated with TPV; the remainder were treated with additional stent retrievers. Mean number of passes in TPV only cases was 2.2 (SD 1.2). In rescue cases, 3.2 (SD 2.2) passes were attempted with the TPV followed by 2.6 rescue device passes (SD 2). TPV related adverse events occurred in 4/76 cases (5%) and procedural events in 6/76 cases (8%). Mean procedural duration was 64\u2005min (SD 42). Thrombolysis in Cerebral Infarction (TICI) 2b/3 recanalization was achieved in 69/76 patients (91%), including 50% TICI 3. Of 56 survivors (74%), 37 (49%) showed a favorable outcome at 90\u2005days (Solitaire With the Intention for Thrombectomy trial criteria), statistically associated with age, baseline NIHSS, onset to revascularization time, and TICI 2b-3 reperfusion. TPV radiopacity allowed for visual feedback, changing the methodology of stent retriever use in 44/76 cases (58%).\nQuestion: Mechanical thrombectomy with the Trevo ProVue device in ischemic stroke patients: does improved visibility translate into a clinical benefit?",
        "gt": "Neurothrombectomy with TPV is feasible, effective, and safe. The recanalization rate compares favorably with reported data in the literature. Improved structural radiopacity may facilitate neurothrombectomy or influence the course of action during retrieval.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Common bile duct stenting is widely performed for bridging benign and malignant obstructions. A major limitation is early stent occlusion making regular stent exchange necessary. Covalent binding of glycosaminoglycanes to polyethylene stents proved to reduce encrustation in urological implants. Since development of urological and biliary stent occlusion shows parallels, the aim of the study was to evaluate the efficacy of heparin coating of biliary endoprostheses in preventing encrustation. In a prospective randomized trial, heparin-coated and native stents were endoscopically placed for almost 90 days on average. After removal, all stents were dried (50\u00b0C, 24 h), weighed and after longitudinal incision visible encrustation and discoloration recorded. Fifty-three patients (21 females/32 males, 70 \u00b1 12 (42-87) years) were included; 13 patients (4 females/9 males, 58-79 years) completed the study according to the protocol. After removal, mean weight of encrustation in native stents was more than double as high as of covered stents (native: 37.9 \u00b1 19.8 (16-93) mg; covered: 17.6 \u00b1 6.7 (9-33) mg). In 12 of 13 cases, the encrustation weight of the native stent was higher than that of the corresponding covered stent in the same patient. Premature stent explantation became necessary in 3 of 13 native stents, because of recurrent jaundice or cholangitis but only in 1 of 13 covered stents. After longitudinal incision, the three uncovered stents showed excessive encrustation whereas no significant encrustation was found in the covered prosthesis. Altogether, covered stents showed less visible accumulation of clogging material and discoloration than native stents.\nQuestion: Does heparin coating reduce encrustation of biliary plastic endoprostheses?",
        "gt": "Covalent bound heparin is highly effective in preventing encrustation of biliary polyethylene endoprostheses.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Currently, surgery- and catheter-mediated ablation is applied when drug refractoriness of atrial fibrillation is evident, although little is known about the long-term incidence of new atrial arrhythmia and the preservation of sinus node function. To address this issue, 30 patients with successful corridor surgery for lone paroxysmal atrial fibrillation and normal preoperative sinus node function were followed in a single outpatient department. Five years after surgery, the actuarial proportion of patients with recurrence of atrial fibrillation arising in the corridor was 8% +/- 5%, with new atrial arrhythmias consisting of atrial flutter and atrial tachycardia in the corridor 27% +/- 8%, and with incompetent sinus node requiring pacing therapy 13% +/- 6%. Right atrial transport was preserved in 69% of the patients without recurrence of atrial fibrillation and normal sinus node function. Stroke was documented in two patients.\nQuestion: Long-term follow-up of corridor operation for lone atrial fibrillation: evidence for progression of disease?",
        "gt": "Corridor surgery for atrial fibrillation is a transient or palliative treatment instead of a definitive therapy for drug refractory atrial fibrillation. This observation strongly affects patient selection for this intervention and constitutes a word of caution for other, nonpharmacologic interventions for drug refractory atrial fibrillation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Plain radiographic measures of the acetabulum may fail to accurately define coverage or pathomorphology such as impingement or dysplasia. CT scans might provide more precise measurements for overcoverage and undercoverage. However, a well-defined method for such CT-based measurements and normative data regarding CT-based acetabular coverage is lacking.QUESTIONS/ The purposes of the study were (1) to develop a method for evaluation of percent coverage of the femoral head by the acetabulum; and (2) to define normative data using a cohort of asymptomatic patient hip and pelvic CT scans and evaluate the variability in acetabular version for asymptomatic patients with normal lateral coverage (lateral center-edge angle [LCEA] 20\u00b0-40\u00b0) that has previously been defined as abnormal based on radiographic parameters. Two-hundred thirty-seven patients (474 hips) with hip CT scans obtained for reasons other than hip-related pain were evaluated. The scans were obtained from a hospital database of patients who underwent CT evaluation of abdominal trauma or pain. In addition, hips with obvious dysplasia (LCEA<20\u00b0) or profunda (LCE>40\u00b0) were excluded resulting in a final cohort of 222 patients (409 hips [115 men, 107 women]) with CT scans and a mean age of 25 \u00b1 3 years. CT scan alignment was corrected along the horizontal and vertical axis and percent acetabular coverage around the clockface (3 o'clock = anterior), and regional (anterior, superior, posterior) and global surface area coverage was determined. Percent coverage laterally was correlated with the LCEA and the presence and prevalence of cranial retroversion (crossover sign) and a positive posterior wall sign were determined. The mean regional percent femoral head surface area coverage for the asymptomatic cohort was 40% \u00b1 2% anteriorly, 61% \u00b1 3% superiorly, and 48% \u00b1 3% posteriorly. Mean global coverage of the femoral head was 40% \u00b1 2%. The local coverage anteriorly (3 o'clock) was 38% \u00b1 3%, laterally (12 o'clock) was 67% \u00b1 2%, and posteriorly (9 o'clock) was 52% \u00b1 3%. The mean lateral coverage represented a mean LCEA of 31\u00b0 (\u00b1 1 SD). Fifteen percent of hips demonstrated cranial retroversion that would correlate with a crossover sign, and 30% had<50% posterior coverage that would correlate with a positive posterior wall sign on an anteroposterior pelvis radiograph. In addition, male hips had a higher prevalence of a crossover sign (19%; 95% confidence interval [CI], 14%-25% versus 11%; 95% CI, 7%-16%; p = 0.03) and posterior wall sign (46%; 95% CI. 39%-53% versus 13%; 95% CI, 9%-19%; p<0.001) compared with women. A positive crossover sign or posterior wall sign was present for 113 male hips (53%; 95% CI, 46%-60%) compared with 39 female hips (20%; 95% CI, 15%-26%; p<0.001).\nQuestion: Are normal hips being labeled as pathologic?",
        "gt": "This study provides normative coverage data and a reproducible method for evaluating acetabular coverage. Cranial acetabular retroversion (crossover sign) and a positive posterior wall sign were frequent findings in a young asymptomatic cohort and might be a normal variant rather than pathologic in a significant number of cases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To analyze anatomical risk factors and surgical technique dependent variables, which determine the risk for femoral notch impingement in anatomically correct placed tibial tunnels for anterior cruciate ligament (ACL) surgery. Twenty fresh frozen adult human knee specimens under the age of 65 years were used. Digital templates mimicking a tibial tunnel aperture at the tibia plateau were designed for different tibial tunnel diameters and different drill-guide angles. The centres of these templates were placed over the geometric centre of the native tibial ACL footprint. The distances between the anterior borders of the templates and the anterior borders of the footprints (graft free zone) were measured and compared. Furthermore, anatomic risk factors for femoral notch impingement were determined. The graft free zone was statistically significantly longer for larger drill-guide angles compared to smaller drill-guide angles (p<0.00001). Furthermore, 8 mm diameter tibial tunnels had a statistically significant larger graft free zone compared to 10-mm-diameter tibial tunnels (p<0.00001). For the 10 mm diameter tibial tunnels with drill-guide angle of 45\u00b0, 9 out of 20 knees (45 %) were \"at risk\" for notching and 4 out of 20 knees (20 %) had \"definite\" notching. For 10-mm tunnels with drill-guide angle of 45\u00b0, a risk for notching was associated with smaller tibial ACL footprint (p<0.05).\nQuestion: Can a tibial tunnel in ACL surgery be placed anatomically without impinging on the femoral notch?",
        "gt": "If a perfect centrally positioned tibial tunnel is drilled, a real risk for femoral notch impingement exists depending on the size of the tibial ACL footprint and surgery-related factors. Therefore, in anatomical tibial tunnel placement in single bundle ACL reconstruction surgery, particular attention should be paid to size of the tunnel and drill-guide angle to minimize the risk of femoral notch impingement.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Accidental injuries are frequent and their socioeconomic consequences enormous. The present study aimed to identify predictors of the number of days of leave taken in a consecutively selected group of accident victims who sustained severe, mostly life-threatening physical trauma. One hundred patients with severe accidental injuries who were referred to a trauma surgeons' intensive care unit were followed up for 12 months. The main outcome measure was the number of days of leave taken that were attributable to the accident 1 year after the trauma. Multiple regression analysis explained 30% of the variance in the number of days of leave taken that were attributable to the accident. Factors contributing to the predictive model were injury severity, type of accident and, most significantly, the patients' subjective self-assessment of accident severity and of their abilities to cope with the accident and its job-related consequences. Patients who perceived the severity of their accident as relatively low and judged their coping abilities as high took a mean 121 days of leave compared to 287 days of leave taken by those who perceived the trauma as relatively severe and were less optimistic regarding their coping abilities. A two-factor analysis of variance showed that patient perceptions of accident severity and their appraisal of their coping abilities made independent contributions to the predicted amount of leave taken.\nQuestion: Does patient cognition predict time off from work after life-threatening accidents?",
        "gt": "In severely injured accident victims, leave taken because of the accident depended to a considerable degree on the patients' accident-related self-assessment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The evidence is now compelling that colorectal cancer incidence and mortality can be reduced by screening, and medical organizations recommend regular screening among persons of average risk aged 50 years or older. We sought to determine whether appropriate screening has become more widespread now that consensus over its value has been achieved. We analyzed data from the 1992 and 1998 National Health Interview Survey, an in-person survey of a nationally representative sample of the U.S. population. Persons aged>or =50 years (4428 in 1992, 12,629 in 1998) were questioned about their use of colorectal cancer screening. Self-reported use of fecal occult blood testing and proctoscopy increased slightly from 1992 to 1998. In 1998, however, only an estimated 22.9% of Americans aged>or =50 years had been screened with either the home-administered fecal occult blood testing in the past year or proctoscopy within 5 years. Nearly half of fecal occult blood testings were performed with a sample taken during an in-office physical examination rather than with the recommended home kit.\nQuestion: Are people being screened for colorectal cancer as recommended?",
        "gt": "Most eligible persons are still not meeting the screening recommendations for colorectal cancer. Education is needed for both the public and health care providers to increase their compliance with current guidelines.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To test the hypothesis that the presence of national mental health policies, programs and legislation would be associated with lower national suicide rates. Suicide rates from 100 countries were regressed on mental health policy, program and legislation indicators. Contrary to the hypothesized relationship, the study found that after introducing mental health initiatives (with the exception of substance abuse policies), countries' suicide rates rose.\nQuestion: Do nations' mental health policies, programs and legislation influence their suicide rates?",
        "gt": "It is of concern that most mental health initiatives are associated with an increase in suicide rates. However, there may be acceptable reasons for the observed findings, for example initiatives may have been introduced in areas of increasing need, or a case-finding effect may be operating. Data limitations must also be considered.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether weight problems in children (overweight, obesity and overweight or obesity) were related to deprivation indices when attributed only according to electoral ward of the school attended. To determine whether children with weight problems were more likely to be found in some wards rather than others, and to compare the distribution for boys and girls. Retrospective, cross-sectional, observational study. One hundred and six primary schools from all parts of Liverpool city. Five cohorts of 9-10-year-old children between 1998 and 2003. Body mass index (BMI) for each child to estimate proportions overweight, obese and overweight or obese according to international criteria. Between January 1998 and March 2003, the heights and weights of 7902 boys and 7514 girls were measured and BMI calculated. The prevalence of boys and girls categorised as overweight or obese was very high (1620, 20.6% and 1909, 25.7%, respectively). Prevalence was not related to deprivation and varied between wards only for the girls; some wards had very different prevalence rates for boys and girls (Picton: 59 boys, 23.4%; 106 girls, 36.6%). The most deprived ward did not have a remarkable prevalence of overweight or obesity (Speke: 32 boys, 15.3%; 40 girls, 19.8%).\nQuestion: Is overweight and obesity in 9-10-year-old children in Liverpool related to deprivation and/or electoral ward when based on school attended?",
        "gt": "Obesity is a major problem and requires urgent action but targeting intervention on the basis of administrative areas may be very wasteful. Different factors seem to lead to obesity in boys and girls, and attention should be paid to the role of the physical environment.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To date, the majority of the vestibular schwannoma (VS) literature has focused on tumor control rates, facial nerve function and hearing preservation. Other factors that have been shown to significantly affect quality-of-life (QOL), such as dizziness, remain understudied. The primary objective of the current study is to investigate the association between radiation dose to the vestibule and post-treatment changes in vestibular function and patient reported dizziness handicap. This is a prospective observational pilot study at a tertiary academic referral center including all subjects that underwent linear accelerator-based stereotactic radiotherapy (SRS) for sporadic VS and completed pre-treatment and post-treatment vestibular testing and Dizziness Handicap Inventory (DHI) questionnaires. Associations between objective vestibular test results, patient-reported DHI scores and radiation dose parameters were investigated. Ten patients met inclusion criteria. Tumor control was achieved in all individuals. There were no statistically significant associations or identifiable trends between radiation dose and change in vestibular function or DHI scores. Notably, the four ears receiving the highest vestibular dose had minimal changes in vestibular function tests and DHI scores.\nQuestion: Does radiation dose to the vestibule predict change in balance function and patient perceived dizziness following stereotactic radiotherapy for vestibular schwannoma?",
        "gt": "To the best of our knowledge, no previous reports have described the association between radiation dose to the vestibule and post-treatment changes in vestibular function and patient reported DHI. Based on these preliminary data, radiation dose to the vestibule does not reliably predict change in objective or subjective vestibular outcome measures.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: C sign is used to alert the physician of the possible presence of talocalcaneal coalition (TCC), so that advanced imaging can be ordered. The purpose of this study was to know the prevalence of the C sign among patients with TCC and its relationship to the presence of a TCC or to hindfoot alignment. Retrospective reviews of the presence of C sign in radiographs of 88 feet with TCC (proved by computed tomography scan or surgical findings) and 260 flexible flatfeet were conducted. C sign was classified as complete and interrupted (types A, B, and C). The interobserver variability of the C sign was studied. Seven radiographic parameters were measured to analyze the relationship of these measurements with the presence or absence of the C sign. C sign was present in 68 feet (77%) with TCC: 14.5% complete and 62.5% interrupted (26% type A, 19.5% type B, and 17% type C). C sign was present in 116 flatfeet (45%), all of them interrupted (0.4% type A, 5.5% type B, and 39% type C). The talo-first metatarsal angle, the talohorizontal angle, the calcaneal pitch, the calcaneo-fifth metatarsal angle, and the naviculocuboid overlap presented a more pathologic value when a C sign was present. The \u03ba-value for the presence of a C sign was 0.663.\nQuestion: C sign: talocalcaneal coalition or flatfoot deformity?",
        "gt": "The so-called true C sign (complete or interrupted type A) indicates the presence of a TCC and it is not related to flatfoot deformity. However, it is only present in 41% of the cases. The interrupted C sign is much more likely to be related to flatfoot deformity than to the presence of a TCC, specifically when a type C is found.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Gastroenterologists are often hampered by the lack of a reliable, non-invasive index of bowel inflammation when establishing a differential diagnosis for patients presenting with chronic diarrhoea. Investigations aim to distinguish between inflammatory bowel disease (IBD) (e.g. Crohn's disease, ulcerative colitis) and irritable bowel syndrome (IBS). As an acute phase protein, faecal calprotectin measurement may be useful in this context. A new ELISA-based assay for calprotectin was evaluated. The ability of calprotectin to distinguish between patients with IBS and Crohn's disease was studied. The assay showed adequate inter- and intra-batch imprecision and was suitable for routine use in the laboratory. Calprotectin concentration was significantly greater in patients with Crohn's disease compared with controls (n = 25, P<0.001) and patients with IBS (n = 25, P<0.001).\nQuestion: Faecal calprotectin: a new marker for Crohn's disease?",
        "gt": "A single calprotectin measurement may aid gastroenterologists in the differential diagnosis of Crohn's disease and IBS. Its use could decrease the number of invasive or radiological investigations undertaken in the latter group of patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In the early stages, clinical and chest radiographic findings of acute interstitial pneumonia (AIP) are often similar to those of bronchiolitis obliterans organizing pneumonia (BOOP). However, patients with AIP have a poor prognosis, while those with BOOP can achieve a complete recovery after corticosteroid therapy. The objective of this study was to identify differences in high-resolution CT (HRCT) findings between the two diseases. The study included 27 patients with AIP and 14 with BOOP who were histologically diagnosed [open-lung biopsy (n=7), autopsy (n=17), transbronchial lung biopsy (n=17)]. The frequency and distribution of various HRCT findings for each disease were retrospectively evaluated. Traction bronchiectasis, interlobular septal thickening, and intralobular reticular opacities were significantly more prevalent in AIP (92.6%, 85.2%, and 59.3%, respectively) than in BOOP (42.9%, 35.7%, and 14.3%, respectively) (p<0.01). Parenchymal nodules and peripheral distribution were more prevalent in BOOP (28.6% and 57.1%, respectively) than in AIP (7.4% and 14.8%, respectively) (p<0.01). Areas with ground-glass attenuation, air-space consolidation, and architectural distortion were common in both AIP and BOOP.\nQuestion: Can acute interstitial pneumonia be differentiated from bronchiolitis obliterans organizing pneumonia by high-resolution CT?",
        "gt": "For a differential diagnosis of AIP and BOOP, special attention should be given to the following HRCT findings: traction bronchiectasis, interlobular septal thickening, intralobular reticular opacities, parenchymal nodules, pleural effusion, and peripheral zone predominance.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Vacuum-assisted venous drainage enables adequate drainage through small-diameter cannulas but concerns are that it results in more gaseous microemboli delivered to the patient. Five identical embolus detectors monitored the propagation of entrained air through a cardiopulmonary bypass (CPB) model. The ability of the CPB circuit to remove gaseous microemboli was studied with vacuum-assisted venous drainage and gravity siphon venous drainage using different pump speeds and rates of gaseous microemboli delivery. Under all conditions entrained venous air resulted in the detection of gaseous microemboli in the perfusate after the arterial filter. In blood-primed circuits, increased flow rates and higher levels of vacuum-assisted venous drainage were independently associated with increased gaseous microemboli counts in the arterial line. Vacuum-assisted venous drainage at -40 mm Hg did not significantly increase gaseous microemboli activity when compared with gravity siphon venous drainage at 4 L/min flow rate.\nQuestion: Does vacuum-assisted venous drainage increase gaseous microemboli during cardiopulmonary bypass?",
        "gt": "Vacuum-assisted venous drainage at -40 mm Hg does not statistically reduce the ability of the CPB circuit to remove gaseous microemboli at lower pump rates. High levels of vacuum and increased pump flow rates should be avoided. Air should not be introduced into the venous line.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There has been a rapid growth in the use of patient-assessed outcomes (PAOs) that are measured in the assessment of health technologies. The process of collection of such measures can be costly, and there may be problems associated with the ability of the patient to complete them. The use of electronically stored routine data may reduce costs and overcome the problems associated with patient completion. The feasibility of using routine data surrogates for the UK Inflammatory Bowel Disease Questionnaire (UKIBDQ) and the Short Form 36 (SF-36) was examined. Clinical terms and codes for the UKIBDQ and SF-36 questions were identified, and data from electronic routine sources were sought on patients participating in a randomized controlled trial. The presence or absence of relevant symptoms was used to generate surrogate scores, which were compared with the original scores. Most questions in the UKIBDQ and SF-36 were codable but only one third of the terms were recorded routinely in electronic form. The surrogate total IBDQ score had reasonable reliability (Kuder-Richardson coefficient = 0.51), but this reliability could not be determined for the SF-36. Intraclass correlations between routine and designed data were poor to weak.\nQuestion: Can electronic routine data act as a surrogate for patient-assessed outcome measures?",
        "gt": "Although electronic routine data sources had the capacity to develop surrogate measures for patient assessed outcomes, there was evidence of wide underutilization of coding systems leading to an underreporting of symptoms. This finding is consistent with previous literature where only poor correlations were illustrated between patient assessed outcomes and surrogate scoring of symptoms.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adjunctive use of glycoprotein IIb/IIIa inhibitors (GPI) is associated with favorable outcomes following percutaneous coronary intervention (PCI). Guidelines for use of GPI have been published by various national societies including National Institute of Clinical Excellence (NICE), United Kingdom. The latter has not been updated since publication. The impact of contemporary trials such as ISAR-REACT (which showed no benefit of abciximab and 600 mg of clopidogrel compared with 600 mg of clopidogrel alone, in elective patients) on adherence to NICE guidelines is unknown. We audited use of GPI against NICE guidelines following publication in May 2002. Data were collected from 1,685 patients between September and November in years 2002, 2003, 2004, and 2007. In 2002 and 2003, only 10.2% and 11.8%, respectively, of patients were noncompliant to NICE guidelines. Over time, there was an increase in patients not given GPI despite meeting NICE criteria. After publication of ISAR-REACT, the comparative figures for noncompliance in 2004 and 2007 were 40.0% and 44.5%. A similar pattern was seen in patients with diabetes; in 2002 and 2003 noncompliance was 16.7% and 11.1%, respectively, and in 2004 and 2007 noncompliance was 38.0% and 44.7%, respectively. Qualitatively, similar findings were recorded in patients with NSTE-ACS. The overall noncompliance to NICE guidelines increased from 11.0% to 42.1% (P<0.0001) after the ISAR-REACT study.\nQuestion: Guidelines to practice gap in the use of glycoprotein IIb/IIIa inhibitors: from ISAR-REACT to overreact?",
        "gt": "We found a decline in compliance to NICE guidelines on GPI usage during PCI. This was likely influenced by contemporary trials demonstrating little or no benefit of GPI in patients undergoing elective PCI who are adequately pretreated with clopidogrel. Our findings suggest the need for a mechanism whereby regular updates to guidelines can be disseminated following new trial evidence.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Hip fracture is associated with high mortality among the elderly. Most patients require surgery, but the timing of the operation remains controversial. Surgery within twenty-four hours after admission has been recommended, but evidence supporting this approach is lacking. The objective of this study was to determine whether a delay in surgery for hip fractures affects postoperative mortality among elderly patients. We conducted a prospective, observational study of 2660 patients who underwent surgical treatment of a hip fracture at one university hospital. We measured mortality rates following the surgery in relation to the delay in the surgery and the acute medical comorbidities on admission. The mortality following the hip fracture surgery was 9% (246 of 2660) at thirty days, 19% at ninety days, and 30% at twelve months. Of the patients who had been declared fit for surgery, those operated on without delay had a thirty-day mortality of 8.7% and those for whom the surgery had been delayed between one and four days had a thirty-day mortality of 7.3%. This difference was not significant (p = 0.51). The thirty-day mortality for patients for whom the surgery had been delayed for more than four days was 10.7%, and this small group had significantly increased mortality at ninety days (hazard ratio = 2.25; p = 0.001) and one year (hazard ratio = 2.4; p = 0.001). Patients who had been admitted with an acute medical comorbidity that required treatment prior to the surgery had a thirty-day mortality of 17%, which was nearly 2.5 times greater than that for patients who had been initially considered fit for surgery (hazard ratio = 2.3, 95% confidence interval = 1.6 to 3.3; p<0.001).\nQuestion: Early mortality after hip fracture: is delay before surgery important?",
        "gt": "The thirty-day mortality following surgery for a hip fracture was 9%. Patients with medical comorbidities that delayed surgery had 2.5 times the risk of death within thirty days after the surgery compared with patients without comorbidities that delayed surgery. Mortality was not increased when the surgery was delayed up to four days for patients who were otherwise fit for hip fracture surgery. However, a delay of more than four days significantly increased mortality.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this paper was to assess whether the Health of the Nation Outcome Scales (HoNOS) is a valid outcome measure in the consultation liaison psychiatry (CL) setting. Statistical analysis was performed on 6 months of HoNOS data from a busy metropolitan CL service. There were statistical differences between the HoNOS scores of groups referred for different types of mental health follow up, but also wide ranges within, and substantial overlap between, each of these groups. HoNOS item analysis demonstrated significant contributions to changes in HoNOS scores across multiple items.\nQuestion: HoNOS in the consultation liaison psychiatry setting: is it valid?",
        "gt": "Although the HoNOS appears to have validity as a measure of severity of mental illness in the CL setting at a population level, concerns can be raised about its usefulness as a measure of change in the severity of mental illness in this setting.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Post-term pregnancy is frequently associated with higher fetal and maternal morbidity and mortality. Its management essentially depends on clinical cervical characteristics as evaluated by the Bishop score (BS). However, BS is poorly predictive of the delivery outcome. We sought to demonstrate that ultrasound measurement of cervical length and evaluation of fetal height could predict the outcome in post-term pregnancies. A prospective single center study was undertaken between the 21st of January and the 1st of June 2013. Fetal height was measured using a transperineal technique and cervical length was evaluated by a vaginal ultrasound on patients consulting and their term date. C-section rates were considered to be the primary judgment criteria. A total of 136 patients were included. C-section rates in this population was 19%. Fetal height and cervical length were not different between the C-section group and the vaginal delivery group.\nQuestion: Are ultrasound measurements of the cervical length and fetal head-perineum distance predictive of delivery outcome in post-term pregnancies?",
        "gt": "Our study demonstrates that ultrasound measurement of cervical length and fetal height do not show better results than BS in predicting the outcome of post-term pregnancy. Combining these ultrasound measurements has already been suggested in other studies and promising results have been shown. More studies are necessary to further these results.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The prevention of major duct injury at cholecystectomy relies on the accurate dissection of the cystic duct and artery, and avoidance of major adjacent biliary and vascular structures. Innumerable variations in the anatomy of the extrahepatic biliary tree and associated vasculature have been reported from radiographical and anatomical studies, and are cited as a potential cause of bile duct injury at cholecystectomy. A photographic study of the dissected anatomy of 186 consecutive cholecystectomies was undertaken and each photo analysed to assess the position of the cystic duct and artery, the common bile duct and any anomalous structures. The anatomy in the region of the gallbladder neck was relatively constant. Anatomical variations were uncommon and anomalous ducts were not seen. Vascular variations were the only significant abnormalities found in the present series.\nQuestion: Extrahepatic biliary anatomy at laparoscopic cholecystectomy: is aberrant anatomy important?",
        "gt": "Anatomy in the region of the gallbladder neck varies mostly in vascular patterns. Aberrant ducts or duct abnormalities are rarely seen during cholecystectomy hightlighting the principle that careful dissection and identification is the key to safe cholecystectomy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Radial head alignment is the key to determine elbow reduction after treatment of subluxations or Monteggia fractures. The radiocapitellar ratio (RCR) quantifies the degree of subluxation, by evaluating radial head alignment with the capitellum of the humerus; this ratio is reproducible when measured on true lateral radiographs of nonsubluxated elbows. However, the impact of beam angulation on RCR measurement is unknown.QUESTIONS/ Our hypotheses were that the RCR of the nonsubluxated elbow would remain in the normal range as the beam angle changed and that the RCR variability would increase for the subluxated elbow with small deviations in the beam angle. Radiographs were taken of six healthy cadaveric extremities using beam angles ranging from -20\u00b0 to 20\u00b0 along the inferosuperior axis and from -20\u00b0 to 20\u00b0 along the dorsoventral axis. The same views then were taken of the six arms with anterior radiocapitellum subluxation followed by posterior radiocapitellum subluxation. RCRs were measured by one observer. As a reference value, the RCR was measured in the 0\u00b0 to 0\u00b0 position and the difference between each RCR in a nonreference position was subtracted from each RCR reference to obtain the delta-RCR. An ANOVA was performed to assess the main and interactive effects on the RCR measured in each C-arm position compared with the RCR measured on a true lateral radiograph. The RCR remained in the normal range even as the beam angle of the C-arm varied between -20\u00b0 and 20\u00b0. The position of the beam did not affect the RCR in anteriorly subluxated elbows (p = 0.777), whereas RCR variation increased especially in the presence of posterior radial head subluxation when the C-arm position was 10\u00b0 or more out of plane (p = 0.006). The inferosuperior malposition of the C-arm had a greater impact on quantification of radial head alignment measurement. Despite that, the RCR measurement is reliable in reduced and subluxated elbows on lateral radiographs with a C-arm position deviation of as much as 20\u00b0.\nQuestion: Does radiographic beam angle affect the radiocapitellar ratio measurement of subluxation in the elbow?",
        "gt": "Identification of a subluxated elbow could be made on any lateral radiograph with a beam angulation deviation of as much as 20\u00b0. This suggests that the RCR is a useful diagnostic tool for clinical and research purposes, although for subluxated elbows, it is important to pay careful attention to the inferosuperior position of the C-arm.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Aneuploidy screening is widely practised in the field of obstetrics in current times. This study thus aims to gain an insight on pregnant women's knowledge and risk perception of Down syndrome and first trimester screening (FTS), as well as their views on various potential pregnancy outcomes and how these may affect their decision-making processes. A cross-sectional questionnaire-based qualitative study of consecutive 50 women choosing to undergo FTS at KK Women's and Children's Hospital (KKH), Singapore was conducted. The women completed a questionnaire after their FTS pretest counselling session. Basic knowledge of Down syndrome and FTS as well as participants' risk perception with regards to various cut-off values used in FTS were examined. Patients' views of various potential pregnancy outcomes were also studied. Most patients had good retention and comprehension of what FTS entailed after a FTS counselling session at the KKH Antenatal Monitoring Clinic. However, knowledge of the risks of invasive diagnostic testing was poor. Patients also did not possess an adequate understanding of FTS risk values. With regards to risk perception, patients had very different views on acceptable pregnancy outcomes and what constituted a high-risk FTS value to them personally. A significant number of women were concerned even at medically low-risk values of 1:500 and 1:1000 in FTS. The majority of patients viewed highest detection rate followed by a lowest false positive rate as the more important factors impacting their choice of a Down syndrome screening test.\nQuestion: Are pregnant women adequately equipped for autonomy in pregnancy screening?",
        "gt": "This study demonstrates the diversity of pregnant women's risk perception, risk aversion and participation in decision processes when there are 2 different values in competition. The study also highlights our patients' gaps in knowledge and lack of understanding of risk values used in FTS.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Six genotypes of the hepatitis C virus (HCV) have been identified thus far, and their distribution is well defined. Genotype 1, which is the most prevalent worldwide, is always compared to genotypes 2 and 3, particularly in terms of treatment response. However, little is known about the differences between genotypes 2 and 3 because these genotypes are analyzed together in most studies. Therefore, the aim of this study was to evaluate differences in the clinical, epidemiological, laboratory, and histological parameters between HCV-2 and HCV-3. Patients with chronic hepatitis C infected with genotypes 2 and 3 were studied retrospectively and compared according to clinical, laboratory, and histological aspects. Hepatitis C virus-ribonucleic acid (HCV-RNA) was analyzed quantitatively by TaqMan\u00ae real-time PCR, and the HCV genotype was determined by sequencing the 5'-untranslated region. A total of 306 patients with chronic HCV-2 (n=50) and HCV-3 (n = 256) were studied. Subtype 2b (n=17/50) and subtype 3a (n=244/256) were the most prevalent among patients infected with HCV-2 and HCV-3, respectively. The mean age was 47 \u00b1 10 years, and there was a predominance of men in the group studied (61%). Comparative analysis between HCV-2 and HCV-3 showed a younger age (p=0.002), less prevalence of arterial hypertension (p=0.03), higher serum albumin levels (p=0.01), more advanced stage of liver fibrosis (p=0.03), and higher frequency of steatosis in patients with HCV-3 (p=0.001). After multivariate regression analysis, all the variables, except serum albumin, remained as variables associated with HCV-3 in the final model.\nQuestion: Do differences exist between chronic hepatitis C genotypes 2 and 3?",
        "gt": "Clinical and histological differences exist between HCV-2 and HVC-3, which suggests the need for separate analyses of these genotypes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Stigma and discrimination toward mentally disabled persons might exist within the medical environment and may form a barrier for patients to receive appropriate care. The aim of this study is to determine the attitudes of medical students toward mentally disabled people and to understand the impact of schooling on attitude difference by evaluating second and sixth year medical students. The study was carried out among 452 students from the all the three public medical schools located in Istanbul, Turkey. Attitudes were assessed through a Likert scale by presenting vignettes for depression and schizophrenia. In both men and women, the scores of last year students for depression and schizophrenia scales were better compared with those of the second graders, and the differences were statistically significant (p<0.05). However, the proportion of students who did not perceive schizophrenia as \"temporary\" and \"curable\" and the perceived likelihood of dangerousness for schizophrenia were higher among the last year students compared with the second graders.\nQuestion: Does stigma concerning mental disorders differ through medical education?",
        "gt": "As a result of this study, it was determined that last year students had improved attitudes toward the mentally ill; however, they still had striking stigmatizing opinions and judgments. The improvement in the attitude score between the second and the sixth graders is considered a result of the students' contact and interaction with persons having mental disorders throughout their medical education. The challenge is to maintain a social environment that aims to reduce the distance between the patient and the medical staff through introducing a holistic approach in medical schools.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Silver-Russell syndrome (SRS) is a genetically heterogeneous syndrome characterized by low birth weight, severe short stature, and variable dysmorphic features. GH treatment is a registered growth-promoting therapy for short children born small for gestational age, including SRS, but there are limited data on the GH response in SRS children and on differences in response among the (epi)genetic SRS subtypes (11p15 aberrations, maternal uniparental disomy of chromosome 7 [mUPD7], and idiopathic SRS). To compare growth and adult height between GH-treated small for gestational age children with and without SRS (non-SRS), and to analyze the difference in GH response among SRS genotypes. A longitudinal study. Sixty-two SRS and 227 non-SRS subjects. All subjects received GH treatment (1 mg/m(2)/d). Adult height and total height gain. The SRS group consisted of 31 children with 11p15 aberrations, 11 children with mUPD7, and 20 children with idiopathic SRS. At the start of GH treatment, mean (SD) height standard deviation score [SDS] was significantly lower in SRS (-3.67 [1.0]) than in non-SRS (-2.92 [0.6]; P<.001). Adult height SDS was lower in SRS (-2.17 [0.8]) than in non-SRS (-1.65 [0.8]; P = .002), but the total height gain SDS was similar. There was a trend toward a greater height gain in mUPD7 than in 11p15 (P = .12).\nQuestion: Long-Term Results of GH Treatment in Silver-Russell Syndrome (SRS): Do They Benefit the Same as Non-SRS Short-SGA?",
        "gt": "Children with SRS have a similar height gain during GH treatment as non-SRS subjects. All (epi)genetic SRS subtypes benefit from GH treatment, with a trend toward mUPD7 and idiopathic SRS having the greatest height gain.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Adrenocortical carcinoma (ACC) is a rare neoplasm with poor prognosis. Discerning ACCs from benign adenomas histologically may be difficult if invasion into surrounding tissues or metastases are missing. In order to establish molecular markers for malignancy, we analyzed seven normal adrenals, three massive macronodular ACTH-independent adrenocortical hyperplasias (MMAHs), 30 adrenocortical adenomas (ACAs) and ten ACCs. All tissues were studied for the presence of alterations in the p53 tumor suppressor gene using the PAb 1801 antibody, which detects mutant p53 protein and the pYNZ22 microsatellite marker to show loss of heterozygosity (LOH) at 17p, for expression of the proliferation-associated antigen Ki67 using the MIB1 antibody, for the rate of apoptotic tumor cells with the TdT-mediated dUTP biotin nick end labeling (TUNEL) method, and for LOH of 11q13 (menin gene locus) with the D11S956 microsatellite marker. 0/3 MMAH, 1/28 ACA and 3/10 ACC revealed immunopositive staining for p53. LOH for pYNZ22 was observed in 1/3 MMAH, 1/23 informative ACA and 6/6 informative ACC. The rate of apoptotic cells was significantly higher in ACC (P<0.0001 by ANOVA) than in ACA but there was some overlap between groups. The Ki67 index (% immunopositive cells) was 1.9+/-1.30% (mean+/-s.d.) in normal adrenals, 3.47+/-1.37% in MMAH, and 2.11+/-1.01% in ACA. ACC had the highest Ki67 index of 11.94+/-7.58% distinguishing all ACC from the ACA and MMAH studied with a cut-off level of 5%. LOH for 11q13 was detected in 2/3 MMAH, 5/26 ACA and 6/8 ACC.\nQuestion: Discerning malignancy in adrenocortical tumors: are molecular markers useful?",
        "gt": "We conclude that a Ki67 index above 5% is a sensitive and specific indicator of ACC and may be useful in the differentiation of adenomas from carcinomas.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Circulating concentrations of proteins associated with coagulation and fibrinolysis may differ between individuals with coronary artery disease (CAD) who develop an acute myocardial infarction (AMI) rather than stable exertional angina. We compared plasma concentrations of fibrinogen, d-dimer, tissue-type plasminogen activator, and plasminogen activator inhibitor-1 (PAI-1) between patients whose first clinical manifestation of CAD was an AMI (n = 198) rather than stable exertional angina (n = 199). We also compared plasma concentrations of these proteins between patients with symptomatic CAD (either AMI or stable angina; n = 397) and healthy, control subjects (n = 197) to confirm the sensitivity of these assays to detect epidemiologic associations. At a median of 15 weeks after presentation, patients with AMI had slightly higher d-dimer concentrations than patients with stable angina (P = .057), but were not significantly different in other markers. By contrast, fibrinogen, d-dimer, and tissue-type plasminogen activator were significantly higher (P<.001) and PAI-1 lower in patients with CAD than in healthy control subjects. After statistical adjustment for clinical covariates, cardiac risk factors, medications, and other confounders, fibrinogen, d-dimer, and PAI-1 remained significantly associated with CAD.\nQuestion: Do plasma biomarkers of coagulation and fibrinolysis differ between patients who have experienced an acute myocardial infarction versus stable exertional angina?",
        "gt": "Selected plasma markers of coagulation and fibrinolysis did not distinguish patients presenting with AMI from those with stable exertional angina.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Components of metabolic syndrome (MS) have been individually linked to colorectal cancer risk and prognosis; however, an understanding of the dominant mechanisms is lacking. Twenty-one patients (10 MS; 11 non-MS) with resectable colorectal cancer were prospectively enrolled. Patients were classified for MS by the World Health Organization criteria and tested for circulating vascular endothelial growth factor (VEGF), interleukin-6 (IL-6), insulin-like growth factor-1 (IGF-1), fasting insulin, and tumor expression of IGF-1 receptor (IGF-1R), insulin-receptor (IR) and receptor for advanced glycation end-products (RAGE). Circulating markers were re-tested 6 months after surgery. The MS group had significantly higher baseline and post-operative fasting insulin levels (p<0.001 and 0.003). No differences were observed in circulating IL-6, VEGF, IGF-1 and free IGF-1. By immunohistochemistry (IHC), IGF-1R expression was significantly higher in tumor vs. normal tissues (p<0.001) while IR expression showed no difference. Interestingly, 64% of tumors demonstrated high IR positivity in the vessels within or surrounding the tumor stroma, but not in the vessels away from the tumor. By reverse transcription polymerase chain reaction (RT-PCR), tumor IGF-1R over-expression (80%) was confirmed, but there was no difference between MS and non-MS patients. Tumor RAGE over-expression was found in 67% of patients and was equally distributed between the two groups.\nQuestion: Metabolic syndrome and colorectal cancer: is hyperinsulinemia/insulin receptor-mediated angiogenesis a critical process?",
        "gt": "Hyperinsulinemia was the only significant factor distinguishing patients with colorectal cancer who have MS. The preferential over-expression of IR in the peri-tumoral microvessels suggests that hyperinsulinemia might contribute to colorectal cancer growth by enhancing angiogenesis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In this study, we compare variant Creutzfeldt-Jakob disease (vCJD) cases definitely linked to blood transfusion, those with a history of blood transfusion in which no donor has developed vCJD and primary cases with no history of blood transfusion. The aim is to determine whether there are any differences in the demographics or clinical phenotype in these groups that might suggest additional cases of transfusion transmission of vCJD. All cases of vCJD who are old enough to donate blood (i.e.>17\u00a0years old) are notified to the UKBTS at diagnosis, regardless of whether they are known to have a blood donation history. A search is then made for donor records and, if found, all components produced and issued to hospitals are identified and their fate determined. Recipient details are then checked against the NCJDRSU register to establish whether there is a match between these individuals and patients who have been diagnosed with vCJD. In the reverse study, attempts are made to trace the donors to all cases reported to have received a blood transfusion and donors' details are checked against the register to determine if any have developed vCJD. Of the 177 cases of vCJD diagnosed in the UK as of 1 February 2014, the TMER study identified 15 cases reported to have received a blood transfusion. Transfusion records were unavailable for 4 of these cases, all pre-1980, and in one other case there was no transfusion recorded in the medical notes. Transfusion records were found for 10 cases. One case transfused at symptom onset was excluded from this analysis. The mean age at onset of symptoms of the remaining nine transfusion recipients (four female and five male) was 42\u00b79\u00a0years; 57\u00b76\u00a0years in the three known transfusion-transmitted cases and 35\u00b75\u00a0years in the six not linked cases. In one of these cases, details of components transfused were unavailable, and the remaining five cases received a total of 116 donor exposures with 112 donors identified, none of whom is known to have developed clinical vCJD. To date, five of the 112 identified donors have died and none was certified as dying of vCJD or any other neurological disorder. Two of the transfusion-transmitted cases did not fulfil diagnostic criteria for probable vCJD during life but were confirmed at post-mortem. Both cases were in the older age range (68 and 74\u00a0years, respectively), and neither had a positive MRI brain scan. The remaining cases all fulfilled the criteria for the diagnosis of vCJD in life, but two of these had atypical features and were older than the expected age at onset for vCJD.\nQuestion: Variant CJD and blood transfusion: are there additional cases?",
        "gt": "In conclusion, it is possible that one or more of the vCJD cases that received a blood transfusion derived from an individual not known to have vCJD were infected by the blood transfusion. However, the evidence for this is weak, and the absence of a past history of transfusion in most cases of vCJD excludes a large number of unrecognised transfusion-transmitted cases.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: An epidemic of human papillomavirus (HPV)-related oropharyngeal squamous cell cancer (OPSCC) has been reported worldwide largely due to oral infection with HPV type-16, which is responsible for approximately 90% of HPV-positive cases. The purpose of this study was to determine the rate of HPV-positive oropharyngeal cancer in Southwestern Ontario, Canada. A retrospective search identified ninety-five patients diagnosed with OPSCC. Pre-treatment biopsy specimens were tested for p16 expression using immunohistochemistry and for HPV-16, HPV-18 and other high-risk subtypes, including 31,33,35,39,45,51,52,56,58,59,67,68, by real-time qPCR. Fifty-nine tumours (62%) were positive for p16 expression and fifty (53%) were positive for known high-risk HPV types. Of the latter, 45 tumors (90%) were identified as HPV-16 positive, and five tumors (10%) were positive for other high-risk HPV types (HPV-18 (2), HPV-67 (2), HPV-33 (1)). HPV status by qPCR and p16 expression were extremely tightly correlated (p<0.001, Fishers exact test). Patients with HPV-positive tumors had improved 3-year overall (OS) and disease-free survival (DFS) compared to patients with HPV-negative tumors (90% vs 65%, p = 0.001; and 85% vs 49%, p = 0.005; respectively). HPV-16 related OPSCC presented with cervical metastases more frequently than other high-risk HPV types (p = 0.005) and poorer disease-free survival was observed, although this was not statistically significant.\nQuestion: Does HPV type affect outcome in oropharyngeal cancer?",
        "gt": "HPV-16 infection is responsible for a significant proportion of OPSCC in Southwestern Ontario. Other high-risk subtypes are responsible for a smaller subset of OPSCC that present less frequently with cervical metastases and may have a different prognosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients with advanced cancer and an abdominal surgical emergency pose a dilemma, because rescue surgery may be futile. This study defines morbidity and mortality rates and identifies preoperative risk factors that may predict outcome. The National Surgical Quality Improvement Program database was queried for patients with disseminated cancer undergoing emergent abdominal surgery (2005-2012). Preoperative variables were used for prediction models for 30-day major morbidity and mortality. A tree model and logistic regression were used to find factors associated with outcomes. A training dataset was analyzed and then model performance was evaluated on a validation dataset. Study patients had an overall 30-day major morbidity and mortality rate of 48.8% and 26%, respectively. The classification tree model for prediction for a morbidity involved the following variables: sepsis, albumin, functional status, and transfusion (misclassification rate, 36%). The tree model for mortality showed that an American Society of Anesthesiologists (ASA) score of 4 or 5 with a dependent functional status to be predictive of mortality (misclassification rate, 24%). There was agreement between models for predictive variables.\nQuestion: Should we operate for an intra-abdominal emergency in the setting of disseminated cancer?",
        "gt": "The decision to operate for an abdominal emergency in the setting of disseminated cancer is difficult. Our study confirms the high risk for morbidity and mortality in this population. Preoperative factors including sepsis, increased ASA class, low serum albumin level, and patient functional dependence all predict poor outcomes.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Disseminated intravascular coagulation (DIC) is usually diagnosed in sick infants who have prolonged clotting times, depletion of platelets and coagulation factors, and elevated levels of fibrin derivatives. However, the diagnostic accuracy of abnormal coagulation profiles in neonates at risk of DIC has been uncertain. Since DIC is characterized by activation of both the coagulation and fibrinolytic systems, the objective of this study was to determine whether coagulation screening tests correctly identify infants with biochemical evidence of increased thrombin and plasmin generation. Non-surgical patients in a tertiary care nursery who were sick enough to require an indwelling arterial catheter for monitoring purposes, were enrolled in a prospective cohort study. Blood samples for thrombin/antithrombin III (TAT) complexes and the plasmin-derived fibrinopeptide B beta 1-42 were drawn 36 to 72 h after birth from a free-flowing arterial line. Platelet counts, D-Dimer levels, plasma fibrinogen concentrations and prothrombin times, expressed as International Normalized Ratios or INR, were measured at the same time. One hundred patients were studied. Fifty-seven infants had elevated levels of TAT (>or = 4 micrograms/l) and B beta 1-42 (>or = 4 nmol/l). The sensitivities of platelets<150 x 10(9)/l, D-Dimer>500 ng/ml, fibrinogen<1.5 g/l, and INR>1.5 were 39%, 30%, 12%, and 11%, respectively. Corresponding specificities were 88%, 91%, 98%, and 95%.\nQuestion: Do coagulation screening tests detect increased generation of thrombin and plasmin in sick newborn infants?",
        "gt": "Abnormal coagulation screens in sick newborn infants strongly support a diagnosis of DIC. However, normal screens do not exclude activation of the coagulation and fibrinolytic systems.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Lack of response to anti-epileptic drugs (AEDS) is considered a \"red flag\" pointing to a diagnosis of Psychogenic Nonepileptic Seizures (PNES). On the other hand, placebo effects are relevant in any medical condition with a complex psychosocial component. We aimed to evaluate the presence and frequency of a placebo response in patients with sole PNES and explore its impact on diagnostic delay. We reviewed the medical records of 102 patients referred for video EEG monitoring and diagnosed with PNES. Patients with PNES and epilepsy were excluded. The response to AEDs was analyzed according to patients' reports and medical records. Patients were classified, according to the response to AEDs, in two groups: responders (patients achieving remission) and non-responders. Then, we compared the diagnostic delay from the first event to the final diagnosis between these groups. Forty-seven patients (79.7%) with sole PNES who were using AEDs were identified. Twenty-two patients (46.8%) had reported complete or partial remission of PNES with mean response duration of 7.2 months (SD+9.6 months). The time delay of the diagnosis in the AED responder group was 10.6 years; the delay in non-responders was 5.6 years (p=0.035).\nQuestion: Psychogenic nonepileptic seizures: should we use response to AEDS as a red flag for the diagnosis?",
        "gt": "Patients with sole PNES receiving AEDs can go into PNES remission. A favorable response to AEDs is likely to be interpreted as supporting a diagnosis of epilepsy and is associated with diagnostic delay. Physicians should bear in mind that patients with PNES may be particularly vulnerable to placebo effects.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The aim of this study was to investigate the possibility of a relationship between corneal biomechanical properties and different grades of dermatochalasis. Patients were assigned to four groups according to the severity of their dermatochalasis: normal (Group 1), mild (Group 2), moderate (Group 3), and severe (Group 4). An Ocular Response Analyzer device was used to measure corneal hysteresis (CH), corneal resistance factor (CRF), and corneal-compensated intraocular pressure (IOPcc). We found no significant differences in the mean values of the CH, CRF, and IOPcc of all groups (P=0.75, P=0.93, and P=0.11, respectively). However, CH and IOPcc were negatively correlated in Group 1, Group 2, and Group 3 patients (P=0.013, r=-0.49; P=0.015, r=-0.52; and P=0.011, r=-0.47, respectively), but this correlation was not apparent in the Group 4 patients (P=0.57, r=0.12). CRF and IOPcc were correlated, but only in Group 4 (P=0.001, r=0.66).\nQuestion: Does severity of dermatochalasis in aging affect corneal biomechanical properties?",
        "gt": "Severe dermatochalasis was associated with altered corneal biomechanical properties. Some of the important visual consequences of dermatochalasis and related diseases (such as floppy eyelid syndrome) can be understood by considering corneal biomechanical alterations.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate whether physicians are prescribing antihypertensive drugs appropriately and according to the recommendations of the Canadian Hypertension Society. Retrospective cohort study. Family medicine teaching clinic in Montreal. A cohort of 183 patients followed between 1993 and 1995. Of 350 patients registered at the clinic, 167 were excluded because diagnosis of hypertension was not supported by chart review, their charts contained insufficient information, they were pregnant or younger than 18 years, or they had secondary hypertension and complex medical conditions. The dependent variable was the antihypertensive medication. Independent variables were age and sex of patients, duration of hypertension, total number of visits and number of visits for hypertension, number of physicians consulted at the clinic, associated medical conditions, diagnosis of target organ damage, blood pressure readings, and associated medications. Diuretics were prescribed most frequently (45.9%). Angiotensin-converting enzyme (ACE) inhibitors ranked second (28.4%), followed by calcium channel blockers (26.2%) and beta-blockers (18.0%). Age, sex, duration of hypertension, and blood pressure readings were not associated with medications. Prescription of beta-blockers was strongly associated with previous myocardial infarction, but not with diagnosis of angina pectoris. Patients with contraindications to beta-blockers were less likely to receive them and more likely to receive calcium channel blockers. Only 32% of diabetic patients received ACE inhibitors.\nQuestion: Treating hypertension. Are the right drugs given to the right patients?",
        "gt": "Results suggest that some prescriptions for antihypertensive medications are inappropriate, but that physicians are following some of the Canadian Hypertension Society's recommendations. A better understanding of physicians' prescribing behaviours could help target continuing education interventions to improve prescribing for hypertension.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: As many as 33% of patients suffering from subarachnoid hemorrhage (SAH) present with multiple intracranial aneurysms (MIAs). It is believed that aneurysm surgery has the potential to increase the risk of cerebral vasospasm due to surgical manipulations of the parent vessels and brain tissue. Consequently, 1-stage surgery of MIAs, which usually takes longer and requires more manipulation, could even further increase the risk of vasospasm. The aim of this study is to define the correlation between vasospasm and the operative treatment of single intracranial aneurysms versus MIAs in a 1-stage operation. The authors analyzed a database including 1016 patients with SAH, identified retrospectively between 1989 and 1996 and prospectively collected between 1997 and 2004. Exclusion criteria were endovascular treatment, surgery after SAH Day 3, and, in patients with MIAs, undergoing more than 1 operation. Cerebral vasospasm was diagnosed by transcranial Doppler (TCD) ultrasonography and was defined as a maximum mean blood flow velocity>120 cm/second. The diagnosis of symptomatic vasospasm was made if a new neurological deficit occurred that could not be explained by concomitant complications. A total of 643 patients who experienced 810 aneurysms were included. Four hundred twenty-four patients were female (65.9%) and 219 were male (34.1%) with an average age of 53.1 years. One hundred twenty-one patients (18.8%) were diagnosed with MIAs. Maximum mean flow velocities measured by TCD were 131 cm/second in patients with MIAs and 129.5 cm/second in patients with single intracranial aneurysms. The incidence of TCD vasospasm (p = 0.561) as well as of symptomatic vasospasm (p = 0.241) was not significantly different in the 2 groups.\nQuestion: Early surgery of multiple versus single aneurysms after subarachnoid hemorrhage: an increased risk for cerebral vasospasm?",
        "gt": "Clipping of more than 1 aneurysm in a 1-stage operation within 72 hours after SAH can be performed without increasing the risk of cerebral (TCD) vasospasm and symptomatic vasospasm.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Because anticipation of death is common within the intensive care unit, attention must be paid to the prevention of distressing signs and symptoms, enabling the patient to die peacefully. In the relevant studies on this subject, there has been a lack of focus on measuring determinants of comfort in this population. To evaluate whether dying without distressing signs after the withdrawal of life-sustaining measures is possible using a newly introduced protocol and to analyze the potential influence of opioids and sedatives on time till death. This was a prospective observational study, in two nonacademic Dutch intensive care units after the introduction of a national protocol for end-of-life care. The study lasted two years and included adult patients in whom mechanical ventilation and/or vasoactive medication was withdrawn. Exclusion criteria included all other causes of death. During the study period, 450 patients died; of these, 305 patients were eligible, and 241 were included. Ninety percent of patients were well sedated before and after withdrawal. Severe terminal restlessness, death rattle, or stridor was seen in less than 6%. Dosages of opioids and sedatives increased significantly after withdrawal, but did not contribute to a shorter time till death according the regression analysis.\nQuestion: An Observational Study on a Protocol for Withdrawal of Life-Sustaining Measures on Two Non-Academic Intensive Care Units in The Netherlands: Few Signs of Distress, No Suffering?",
        "gt": "The end-of-life protocol seems effective in realizing adequate patient comfort. Most patients in whom life-sustaining measures are withdrawn are well sedated and show few signs of distress. Dosages of opioids and sedatives increase significantly during treatment withdrawal but do not contribute to time until death. Dying with a minimum of distressing signs is thus practically possible and ethically feasible.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Assessing prescription patterns of asthma medication for children is helpful to optimize prescribing by general practitioners (GPs). The aim was to explore prescription patterns in children with physician-diagnosed asthma and its determinants in general practice. We used the Second Dutch National Survey of General Practice (DNSGP-2) with children aged 0-17 years registered in 87 general practices. All children with at least one asthma prescription were included (n = 2993). Prescription rates and prescription of continuous (\u22653 prescriptions/year) versus intermittent asthma medication were calculated. Data, including several GP characteristics, were analysed using multivariate logistic regression accounting for clustering within practices. During one year, 16% of the children with physician-diagnosed asthma (n = 3562) received no asthma medication. Of the 2993 children with asthma receiving asthma medication (on average 2.9 prescriptions/year), 61% received one or two prescriptions, 39% received three or more. Continuous medication with a bronchodilator and/or a corticosteroid was prescribed in 22% of these children. One out of 5 children receiving continuous medication was prescribed a bronchodilator only. In 7.5% of the prescriptions, asthma medications other than bronchodilators or corticosteroids were prescribed. Prescribing asthma medication varied widely between practices, but none of the children and GP determinants had an independent effect on prescribing continuous versus intermittent medication.\nQuestion: Asthma prescription patterns for children: can GPs do better?",
        "gt": "In general practice, the annual number of asthma prescriptions per child with asthma is relatively low. One in 20 children is prescribed bronchodilators only continuously, indicating room for improvement. Child and GP characteristics cannot be used for targeting educational efforts.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Several international guidelines for the management of women with epilepsy (WWE) have been developed since 1989. We aimed to determine whether guidelines for the management of WWE are followed and whether active implementation of such guidelines makes a difference to clinical practice. The study covered a 2-year period of \"passive dissemination\" of guidelines followed by a 2-year period of \"active implementation.\" Documentation reflecting adherence to the guidelines was abstracted retrospectively from electronic medical records on 215 WWE aged 16-42 years. Data abstracted from case notes included counselling on contraception and pregnancy-related issues; follow-up during pregnancy; advice on supplementation of folic acid, calcium, and vitamin D; and serum folate measurements. A questionnaire assessing the knowledge of WWE issues was completed by 112 (71%) of 157 patients. Documentation that WWE issues had been addressed was found in approximately one third of medical case records with no measurable effect of active implementation. Only the follow-up during pregnancy seemed to have improved. Serum folate measurements in 51 women treated with enzyme-inducing antiepileptic drugs (AEDs) revealed folate deficiency in 11 (22%). Respondents to the questionnaire recalled having received information from their neurologists on the interaction between AEDs and oral contraceptives (46%), need to plan pregnancy (63%), and folic acid requirement (56%).\nQuestion: Management of women with epilepsy: Are guidelines being followed?",
        "gt": "Judged by a review of documentation in case notes, active implementation of guidelines had no measurable effect on clinical practice. However, the follow-up during pregnancy seemed to have improved. Patients' knowledge of WWE issues compared favorably with published studies. Better strategies are needed to secure successful implementation of guidelines.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In this study, we aimed to evaluate the relationship of serum serotonin levels, which are supposed to affect vascular function, to peripheral arterial disease. This prospective study was performed in 70 patients (57 males, 13 females; mean age 67\u2009\u00b1\u200913 years) with peripheral arterial disease scheduled for surgery and 70 controls (52 males, 18 females; mean age 58\u2009\u00b1\u200912 years). The rates of diabetes mellitus and hypertension and the fasting glucose levels were significantly higher in the peripheral arterial disease group (p\u2009=\u20090.001). Total, low-density, and high-density cholesterol, triglycerides, urea, and creatinine levels, and the smoking rate were similar in both groups (p\u2009>\u20090.05). The serotonin levels were significantly higher in patients with peripheral vascular disease scheduled for surgery compared to the control group (p\u2009=\u20090.024).\nQuestion: Is serotonin a valuable parameter in peripheral arterial disease?",
        "gt": "The plasma serotonin level is an important parameter in peripheral arterial disease.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Inadvertent adjustments and malfunctions of programmable valves have been reported in cases in which patients have encountered powerful electromagnetic fields such as those involved in magnetic resonance imaging, but the potential effects of magnetic toys on programmable valves are not well known. The magnetic properties of nine toy magnets were examined. To calculate the effect of a single magnet over a distance, the magnetic flux density was directly measured using a calibrated Hall probe at seven different positions between 0 and 120 mm from the magnet. Strata II small (Medtronic Inc.), Codman Hakim (Codman&Shurtleff), and Polaris (Sophysa) programmable valves were then tested to determine the effects of the toy magnets on each valve type. The maximal flux density of different magnetic toys differed between 17 and 540 mT, inversely proportional to the distance between toy and measurement instrument. Alterations to Strata and Codman valve settings could be effected with all the magnetic toys. The distances that still led to an alteration of the valve settings differed from 10 to 50 mm (Strata), compared with 5 to 30 mm (Codman). Valve settings of Polaris could not be altered by any toy at any distance due to its architecture with two magnets adjusted in opposite directions.\nQuestion: Magnetic toys: forbidden for pediatric patients with certain programmable shunt valves?",
        "gt": "This is the first report describing changes in the pressure setting of some adjustable valves caused by magnetic toys in close contact. Parents, surgeons, neurologists, pediatric oncologists, and paramedics should be informed about the potential dangers of magnetic toys to prevent unwanted changes to pressure settings.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Our aim was to compare the tissue yield of two different prostate biopsy instruments: the newer end-cut versus standard side-notch technique. A total of 87 patients, who underwent transrectal ultrasound guided prostate biopsy were included in the study between February 2003 and July 2003. Twenty-five patients underwent prostate biopsy with the end-cut technique with a stroke length of 33 mm (EC-33), 25 patients were biopsied with a stroke length of 23 mm of the same instrument (EC-23) whereas the remaining 37 patients underwent biopsy with an instrument working with side-notch technique with a 22 mm stroke length (SN). The length, weight and weight/length ratio (WLR) were measured for each biopsy core. The pathologic specimens were evaluated qualitatively. The length, weight and WLR as well as the complication rates, pain, zero biopsy rates, pathologic quality and cancer detection rates were compared between the groups. Three groups were similar according to age, PSA values (free, total, free/total), prostate volumes (TZ, total) and PSA densities. The cancer detection rate was not statistically different between groups and was overall 20,9%. As the groups were compared according to mean core lengths, weights and densities the sequence was found to be EC-33>EC-23>SN. The EC group had higher prostatic glandular capture rates and better pathological quality. However, the zero biopsy rates were 12%, 7% and 1% for EC-33, EC-23 and SN groups, respectively and the difference was statistically significant. The complication rates after biopsy were similar for each group. The mean visual analogous scale scores were not significantly different between the groups. Another interesting finding was that cores containing cancer were heavier and denser than the others regardless of the instrument type.\nQuestion: Can we obtain better specimens with an end-cutting prostatic biopsy device?",
        "gt": "The use of the presented new instrument, enables to obtain longer, heavier and denser cores with a higher pathologic quality and glandular coverage without increasing the number of biopsies and morbidity. However, the relatively high zero biopsy rate is a handicap that needs to be improved.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although the clinical importance of vascular endothelial growth factor (VEGF) overexpression in oral squamous cell carcinoma (OSCC) has been investigated, there are limited data about the overexpression of VEGF receptors (VEGF-Rs) and their clinical importance. VEGF-R isoforms have proven influence on proliferation rates, metastasis, and survival in different neoplasms. This study was conducted to investigate VEGF-R expression levels in OSCC samples and to identify any clinical relevance. A retrospective cohort study design (n = 50) was used. Clinical data were gathered from patient charts. Validated immunohistochemical methods were applied to determine VEGF-R isoform expression by tumor cells. Descriptive and inferential statistics with respect to the variable scale were computed. The significance level was set at a P value less than or equal to .05. This study found overexpression of different VEGF-R isoforms in 88% of examined specimens. Statistically important associations were detected between overexpression of specific VEGF-Rs and tumor size, neck node metastasis, and tumor-associated death. Furthermore, a history of common OSCC risk factors (smoking and alcohol consumption) were found considerably more often in patients whose OSCC specimens displayed VEGF-R overexpression.\nQuestion: Vascular endothelial growth factor receptor isoforms: are they present in oral squamous cell carcinoma?",
        "gt": "These findings show that VEGF-R overexpression occurs frequently in OSCC and could have clinical implications.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context:  Poor adherence to oral maintenance chemotherapy can cause relapse of acute lymphoblastic leukemia (ALL). A multicenter study for the evaluation of adherence to oral 6-mercaptopurine (6-MP) maintenance chemotherapy for childhood ALL in Egypt to identify contributing factors and possible steps to promote adherence. The study included 129 children with ALL in complete remission receiving 6-MP single daily oral dose in the evening. Evaluation was done through specific questionnaires for the patients as well as serum 6-MP measurements. Nonadherence was detected in around 56% by questionnaires and around 50% by serum 6-MP level measurement. There was a highly significant correlation between nonadherence as found by the questionnaire and 6-MP level (P - 0.001). Nonadherence was significantly associated with low socioeconomic standard, noneducation and low educational level and large family size by both methods. High cost to come for follow-up visits was significant by questionnaire but not by 6-MP measurement. Adolescent age, the higher number of siblings, lack of written instructions, long time spent per visit, were all associated with higher rates of nonadherence, although none reached statistical significance.\nQuestion: Acute lymphoblastic leukemia: are Egyptian children adherent to maintenance therapy?",
        "gt": "Nonadherence is a real problem in pediatric patients. Specific questionnaires can be an excellent reliable method for the routine follow-up of these children, and drug level assay can be requested only for confirmation. This protocol is especially effective in developing countries where financial resources may be limited. Every effort should be made to uncover its true incidence, contributing factors, and best methods of intervention.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Interventions that improve HbA1c levels do not necessarily improve health-related quality of life (QoL). This issue may be particularly relevant in asymptomatic diabetes patients detected earlier in the course of the disease. HbA1c , diabetes-specific QoL (ADDQoL) and health status were measured in 510 screen-detected diabetes patients from the ADDITION-Cambridge trial at 1 and 5 years post diagnosis. Multivariable logistic/linear regression was used to quantify the longitudinal association between change in HbA1c from 1 to 5 years and ADDQoL and health status at 5 years, adjusting for age, sex, education and trial group; alcohol consumption, smoking, physical activity, plasma vitamin C, HbA1c , ADDQoL or health status at 1 year, and glucose-lowering medication at 5 years. From 1 to 5 years, median HbA1c interquartile range increased from 6.3% (5.9-6.8) to 6.8% (6.4-7.4); the median ADDQoL score and mean health status physical health summary score decreased from -0.4 (-1 to -0.08) to -0.5 (-1.08 to -0.09) (suggesting an adverse impact of diabetes on QoL) and by -0.79 (8.94) points, respectively. Increases in HbA1c were independently associated with reporting a negative impact of diabetes on QoL (OR\u2009=\u20091.38, 95% CI: 1.03 to 1.85) but not with the health status summary scores.\nQuestion: Are changes in glycaemic control associated with diabetes-specific quality of life and health status in screen-detected type 2 diabetes patients?",
        "gt": "Increases in HbA1c from 1 to 5 years post-diagnosis were independently associated with increased odds of reporting a negative impact of diabetes on QoL. While our results suggest that efforts to reduce HbA1c do not adversely affect health-related QoL, large numbers of participants still report a negative impact of diabetes on their QoL 5 years post-diagnosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The relationship between extracranial venous system abnormalities and central nervous system disorders has been recently theorized. In this paper we delve into this hypothesis by modeling the venous drainage in brain and spinal column areas and simulating the intracranial flow changes due to extracranial morphological stenoses. A lumped parameter model of the cerebro-spinal venous drainage was created based on anatomical knowledge and vessels diameters and lengths taken from literature. Each vein was modeled as a hydraulic resistance, calculated through Poiseuille's law. The inputs of the model were arterial flow rates of the intracranial, vertebral and lumbar districts. The effects of the obstruction of the main venous outflows were simulated. A database comprising 112 Multiple Sclerosis patients (Male/Female = 42/70; median age \u00b1 standard deviation = 43.7 \u00b1 10.5 years) was retrospectively analyzed. The flow rate of the main veins estimated with the model was similar to the measures of 21 healthy controls (Male/Female = 10/11; mean age \u00b1 standard deviation = 31 \u00b1 11 years), obtained with a 1.5 T Magnetic Resonance scanner. The intracranial reflux topography predicted with the model in cases of internal jugular vein diameter reduction was similar to those observed in the patients with internal jugular vein obstacles.\nQuestion: An anatomy-based lumped parameter model of cerebrospinal venous circulation: can an extracranial anatomical change impact intracranial hemodynamics?",
        "gt": "The proposed model can predict physiological and pathological behaviors with good fidelity. Despite the simplifications introduced in cerebrospinal venous circulation modeling, the key anatomical feature of the lumped parameter model allowed for a detailed analysis of the consequences of extracranial venous impairments on intracranial pressure and hemodynamics.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Laparoscopic appendicectomy (LA) has proved to be a safe, effective procedure for appendicitis. However, its application in the current surgical practice is still far less than the laparoscopic cholecystectomy. Therefore, its role as a gold standard operation for acute appendicitis (AA) is less well established. Between September 1999 and January 2007, a series of 200 patients (112 female, 88 male) with AA underwent LA in our surgical unit. A single consultant surgeon performed all the cases. Outcomes, including the length of stay, operative time, and complications, were evaluated. Follow-up assessment of patients was performed by outpatient appointment. The indications for LA were clinical diagnosis of AA for 177 patients (85%) and interval appendicectomy for 23 patients (15%). The mean age of these patients was 18.8 years (range, 8-83). Operative diagnosis of inflamed appendix, including perforated appendicitis in 9 patients (7.5%), was made in 139 patients (69.5%), and the appendix was macroscopically normal in 40 patients (20%). Different pathologies were found in 21 patients (11.5%). Of the 40 (20%) macroscopically normal appendices, 10 (5%) appendices were reported as inflamed by histopathology examination. The operative time ranged from 13 to 62 minutes, with a mean of 18 minutes. Minor morbidity was reported in 11 patients (5.5%)\nQuestion: Laparoscopic appendectomy in a district hospital: does the technique influence the outcome?",
        "gt": "In experienced hands using a meticulous technique, LA provides diagnostic and therapeutic options, decreased operative time, rapid recovery, short hospital stay, fewer postoperative complications, and no intra-abdominal abscesses. Appendicectomy has cured right iliac fossa pain in almost all the patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The optimal learner to simulator ratio for procedural skills training is not known. Research in motor learning suggests observational training in pairs, termed 'dyad training', may be as effective as directed self-regulated learning (DSRL). This study was conducted to compare the relative effectiveness and efficiency of dyad versus DSRL training of simulation-based lumbar puncture (LP). We conducted a two-group randomised equivalence trial. First-year internal medicine residents (n\u00a0=\u00a050) were randomly assigned to learn LP either in dyads or as individual learners on a simulator, using a directed self-regulated approach (i.e. the learning sequence was defined for them, but they defined the pace of learning). Participants were videotaped performing a simulated LP on a pre-test, an immediate post-test, and a 6-week delayed retention test. In duplicate, blinded raters independently evaluated all trainee performances using a previously validated 5-point global rating scale (GRS) and 35-item checklist. Our analyses showed no significant differences (p\u00a0=\u00a00.69) on pre-test, post-test or retention test GRS scores between the dyad (mean\u00a0\u00b1\u00a0standard deviation [SD] scores by test: 2.39\u00a0\u00b1\u00a00.57, 3.48\u00a0\u00b1\u00a00.62, 3.12\u00a0\u00b1\u00a00.85, respectively) and DSRL (mean\u00a0\u00b1\u00a0SD scores by test: 2.67\u00a0\u00b1\u00a00.50, 3.34\u00a0\u00b1\u00a00.77, 3.21\u00a0\u00b1\u00a00.79, respectively) groups. Both groups improved significantly from pre-test to post-test (p\u00a0<\u00a00.001) and retained that performance following the 6-week delay. Dyad participants experienced significantly greater pre-test to post-test gains than DSRL participants (p\u00a0=\u00a00.02). There was no significant difference in total practice time between the groups (20.94\u00a0minutes for individuals and 24.20\u00a0minutes for dyads; p\u00a0=\u00a00.175).\nQuestion: Are two heads better than one?",
        "gt": "Our results indicate that learning in pairs is as effective as independent DSRL. Dyad training permits the more efficient use of simulators as two learners use the same resources as an individual.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the release of nickel from 1- and 2-euro coins and the ability to produce allergic contact dermatitis from the application of coins to the palmar skin of nickel-sensitized individuals. Three experiments were conducted. Experiments 1 and 2 checked the release of nickel from 1- and 2-euro coins by using the dimethylglyoxime test. In experiment 3, the elicitation of positive reactions was checked by applying coins to the palmar skin for 48 h under occlusion in nickel-sensitized and non-sensitized individuals. The dimethylglyoxime test for release of nickel was positive in all cases. Positive patch test reactions to euro coins applied to the palmar skin of nickel-sensitized individuals were observed at 48 and 96 h.\nQuestion: High nickel release from 1- and 2-euro coins: are there practical implications?",
        "gt": "The results show that positive patch test reactions to euro coins can be obtained from nickel-sensitized individuals after 48 h of application to the palmar skin under occlusion. These results do not contradict other experiments in which repeated handling of coins was unable to provoke fingertip allergic contact dermatitis. A dose-response relationship is a credible explanation to support such potential discrepancies.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To examine the later development of language and literacy of children who had delayed language at age 2 but were in the normal range at age 4. Longitudinal data were analyzed from 3,598 pairs of twins participating in the Twins Early Development Study (TEDS). Six hundred thirty-three twins (8.8%) were delayed at age 2 based on parent-reported expressive vocabulary, and of these, 373 (59.0%) were classified as recovered based on 4-year measures. Each recovered 4-year-old was matched on vocabulary, gender, and zygosity to another 4-year-old without a history of early delay. Although the recovered group was below the mean for the total TEDS sample on measures of language at ages 7 and 12, there were no significant differences between the recovered and matched groups. Within the recovered group, it was not possible to predict outcome at better than a chance level.\nQuestion: Illusory recovery: are recovered children with early language delay at continuing elevated risk?",
        "gt": "Children who appear to have recovered by age 4 from early delay are at modest risk for continuing difficulties, but this appears to be no higher than the risk for other 4-year-olds with equivalent scores, reflecting the continuing variability in longitudinal outcome after age 4. All children in the low normal range at age 4 merit continuing monitoring.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To evaluate the effect of guided imagery as an intervention to reduce pain and anxiety in patients undergoing a total joint arthroplasty. A total of 121 patients scheduled for elective total joint arthroplasty. The design for this study was a 2-group quasi-experimental design. The intervention group listened to a guided imagery CD containing a message to develop a sense of relaxation and harmony. The intervention and control groups were compared on self-reported pain and anxiety levels postoperatively on Days 1, 2, and 3. There was no significant difference in pain and anxiety levels between the groups. However, the intervention group had lower levels of anxiety and pain at all time points. Both groups followed a similar anxiety and pain pattern with the highest reported levels at Day 2.\nQuestion: Is guided imagery effective in reducing pain and anxiety in the postoperative total joint arthroplasty patient?",
        "gt": "Conduct further research of guided imagery as an intervention for reducing pain and anxiety utilizing randomized controlled trials with a diverse sample of patients.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In February 2009 the Improving Maternity Services in Australia - The Report of the Maternity Services Review (MSR) was released and recommended improving women's access to and availability of birth centres. It was unclear if this was in response to an overwhelming request for birth centres in the submissions received by the commonwealth or a compromise for excluding homebirth from the maternity service reforms.AIM: The aim of this paper was to examine what was said in the submissions to the MSR about birth centres. Data for this study comprised 832 submissions to the MSR that are publicly available on the Commonwealth of Australia Department of Health and Ageing website. All 832 submissions were downloaded, and read for any mention of the words 'birth centre', 'birth center'. Content analysis was used to categorise and report the data. Of the 832 submissions to the MSR 197 (24%) mentioned birth centres while 470 (60%) of the submissions mentioned homebirth. Only 31 (4%) of the submissions to the Maternity Review mentioned birth centres without mentioning home birth also. Most of the submissions emphasised that 'everything should be on the menu' when it came to place of birth and care provider. Reasons for choosing a birth centre were identified as: 'the best compromise available, 'the right and natural way' and 'the birth centre as safe'. Women had certain requirements of a birth centre that included: 'continuity of carer', 'midwife led', 'a sanctum from medicalised care', 'resources to cope with demand', 'close to home', and 'flexible guidelines and admission criteria'. Women weighed up a series of requirements when deciding whether to give birth in a birth centre. The recommendation by the MSR to expand birth centres and ignore home birth is at odds with the strong view expressed that 'everything should be on the menu'. The requirements women described of birth centre care are also at odds with current trends.\nQuestion: Birth centres and the national maternity services review: response to consumer demand or compromise?",
        "gt": "If there is to be an expansion of birth centres, service providers need to make sure that women's views are central to the design. Women will not cease having homebirths due to expanded birth centre options.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the efficacy of secondary preventive therapy against tuberculosis (TB) among gold miners working in South Africa. An observational study. Health service providing comprehensive care for gold miners. The incidence of recurrent TB was compared between two cohorts of HIV-infected miners: one cohort (n = 338) had received secondary preventive therapy with isoniazid (IPT) and the other had not (n = 221). The overall incidence of recurrent TB was reduced by 55% among men who received IPT compared with those who did not (incidence rates 8.6 and 19.1 per 100 person-years, respectively; incidence rate ratio, 0.45; 95% confidence interval 0.26-0.78). The efficacy of isoniazid preventive therapy was unchanged after controlling for CD4 cell count and age. The number of person-years of IPT required to prevent one case of recurrent TB among individuals with a CD4 cell count<200 x 106 cells/l, and>or = 200 x 106 cells/l was 5 and 19, respectively.\nQuestion: Efficacy of secondary isoniazid preventive therapy among HIV-infected Southern Africans: time to change policy?",
        "gt": "Secondary preventive therapy reduces TB recurrence: the absolute impact appears to be greatest among individuals with low CD4 cell counts. International TB preventive therapy guidelines for HIV-infected individuals need to be expanded to include recommendations for secondary preventive therapy in settings where TB prevalence is high.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Suicide mortality among medical practitioners is in many countries significantly higher compared with other professionals and the general population. Differences between male and female physicians are difficult to estimate reliably because previous comparisons are mainly based on crude mortality rates. Age-specific mortality rates were calculated for physicians, other professionals and the general population, males and females separately, as well as standardized mortality ratios (SMR) comparing physicians with the other groups. Crude mortality rates were calculated for the specialist groups. The SMR for male (female) physicians was 0.9 (2.4) compared with the general male (female) population and 2.4 (3.7) compared with other male (female) professionals. The SMR between male and female physicians was 1.2 (95% CI 0.9-1.7).\nQuestion: Suicide mortality among medical doctors in Finland: are females more prone to suicide than their male colleagues?",
        "gt": "Our results do not support the claim that female physicians have a greater risk of suicide than their male colleagues, but are concordant with previous observations of a higher suicide rate in female physicians compared with the general population and other female professionals.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The field of scar assessment lacks a standard methodology. Previous methods have focused on a wide range of scar types, resulting in poorer sensitivity and diminishing their discriminatory effectiveness. As part of a clinical trial investigating the scar-improving efficacy of transforming growth factor-beta3, the authors investigated the use of a visual analogue scale and scar ranking as scar assessment tools. Scar photographic images were assessed using a newly developed computerized scar assessment system by an external lay panel. A total of 4296 scar images were collected for visual analogue scale assessment and 2148 scar pairs were collected for scar ranking. Intrarater consistency was 100 percent for the ranking data, with differences very close to zero for the visual analogue scale consistency data. Reducing the number of assessors in the external panel significantly improved intraclass correlation coefficients. From month 1 to month 12, the correlation coefficients for the difference in visual analogue scale score showed that the assessors reliably noted the changes in the maturing scars. Combining logistic regression with an area under the curve of 0.72 in a receiver operating characteristic curve analysis, the visual analogue scale score was shown to be a highly statistically significant predictor of a good scar.\nQuestion: Visual analogue scale scoring and ranking: a suitable and sensitive method for assessing scar quality?",
        "gt": "The authors have shown the visual analogue scale scar scoring and scar ranking methods to be consistent, reliable, valid, and feasible. These methods for scar assessment are highly sensitive and capable of reliably measuring differences in scar quality, making them valuable techniques, reaching an unmet clinical need, and enabling investigation of changes in scar quality (e.g., with time or after therapeutic intervention).",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In 2004, a community-based health insurance (CBI) scheme was introduced in Nouna health district, Burkina Faso, with the objective of improving financial access to high quality health services. We investigate the role of CBI enrollment in the quality of care provided at primary-care facilities in Nouna district, and measure differences in objective and perceived quality of care and patient satisfaction between enrolled and non-enrolled populations who visit the facilities. We interviewed a systematic random sample of 398 patients after their visit to one of the thirteen primary-care facilities contracted with the scheme; 34% (n\u2009=\u2009135) of the patients were currently enrolled in the CBI scheme. We assessed objective quality of care as consultation, diagnostic and counselling tasks performed by providers during outpatient visits, perceived quality of care as patient evaluations of the structures and processes of service delivery, and overall patient satisfaction. Two-sample t-tests were performed for group comparison and ordinal logistic regression (OLR) analysis was used to estimate the association between CBI enrollment and overall patient satisfaction. Objective quality of care evaluations show that CBI enrollees received substantially less comprehensive care for outpatient services than non-enrollees. In contrast, CBI enrollment was positively associated with overall patient satisfaction (aOR = 1.51, p = 0.014), controlling for potential confounders such as patient socio-economic status, illness symptoms, history of illness and characteristics of care received.\nQuestion: Does enrollment status in community-based insurance lead to poorer quality of care?",
        "gt": "CBI patients perceived better quality of care, while objectively receiving worse quality of care, compared to patients who were not enrolled in CBI. Systematic differences in quality of care expectations between CBI enrollees and non-enrollees may explain this finding. One factor influencing quality of care may be the type of provider payment used by the CBI scheme, which has been identified as a leading factor in reducing provider motivation to deliver high quality care to CBI enrollees in previous studies. Based on this study, it is unlikely that perceived quality of care and patient satisfaction explain the low CBI enrollment rates in this community.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Eugenol, obtained from clove oil (Eugenia caryophyllata), possess several biological activities. It is anti-inflammatory, analgesic, anaesthesic, antipyretic, antiplatelet, anti-anaphylactic, anticonvulsant, anti-oxidant, antibacterial, antidepressant, antifungal and antiviral. The anti-oxidant activity of eugenol have already been proven. From this perspective testing, a series of planned structural derivatives of eugenol were screened to perform structural optimization and consequent increase of the potency of these biological activities. In an attempt to increase structural variability, 16 compounds were synthesized by acylation and alkylation of the phenolic hydroxyl group. Anti-oxidant activity capacity was based on the capture of DPPH radical (2,2-diphenyl-1-picryl-hydrazyl), ABTS radical 2,2'-azino-bis(3-ethylbenzothiazoline-6-sulphonic acid), measure of TBARS (thiobarbituric acid-reactive species), total sulfhydryl and carbonyl content (eugenol derivatives final concentrations range from 50 to 200\u2009\u03bcm). Four derivatives presented an efficient concentration to decrease 50% of the DPPH radical (EC50 )<\u2009100\u2009\u03bcm, which has a good potential as a free-radical scavenger. Three of these compounds also showed reduction of ABTS radical. Eugenol derivatives presenting alkyl or aryl (alkylic or arylic) groups substituting hydroxyl 1 of eugenol were effective in reducing lipid peroxidation, protein oxidative damage by carbonyl formation and increase total thiol content in cerebral cortex homogenates. In liver, the eugenol derivatives evaluated had no effect.\nQuestion: Eugenol derivatives as potential anti-oxidants: is phenolic hydroxyl necessary to obtain an effect?",
        "gt": "Our results suggest that these molecules are promising anti-oxidants agents.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether body balance is perturbed more in low back pain patients than in healthy subjects, under the concept of posturo-kinetic capacity. Comparison of posturographic and respiratory parameters between low back pain and healthy subjects. It has been demonstrated that respiratory movements constitute a perturbation to posture, compensated by movements of the spine and of the hips, and that low back pain is frequently associated with a loss of back mobility. Ten low back pain patients and ten healthy subjects performed five posturographic tests under three different respiratory rate conditions: quiet breathing (spontaneous), slow breathing (0.1 Hz) and fast breathing (0.5 Hz). Intergroup comparison showed that the mean displacements of the center of pressure were greater for the low back pain group, especially along the antero-posterior axis, where respiratory perturbation is primarily exerted. Inter-condition comparison showed that in slow and fast breathing relatively to quiet breathing, the mean displacement of the center of pressure along the antero-posterior axis was significantly increased only for the low back pain group.\nQuestion: Does respiration perturb body balance more in chronic low back pain subjects than in healthy subjects?",
        "gt": "According to the results, respiration presented a greater disturbing effect on body balance in low back pain subjects.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: There are many studies that evaluate the role of surgery in the treatment of complications of pediatric acute sinusitis; however there are few studies, if any that report the incidence of surgery following recovery from acute complicated sinusitis. The goal of this study was to report the incidence and indications for surgical intervention after recovery from complications of pediatric acute sinusitis. We reviewed the records of all children admitted to a tertiary care children's hospital between January 2005 and September 2010 with a diagnosis of sinusitis and an orbital or intracranial complication. Eighty-six patients met inclusion criteria. Charts were reviewed for type of complication, initial treatment (medical or surgical), type of procedure, secondary procedures, age, and comorbidities. Statistical analysis was completed using independent samples student t-tests and Mann-Whitney tests. A total of 86 patients with a mean age of 6.38 years (2 months to 18 years) were identified. Eighty patients had orbital complications while six presented with intracranial complications. Twenty-seven patients (31%) underwent sinus surgery during the acute phase of their illness whereas 59 patients (69%) were treated medically. After hospitalization and recovery for acute complicated sinusitis, surgery was performed on nine patients (mean age 4.86 years) within 1 month to 2 years post hospitalization. Of the nine patients who required secondary surgery following resolution of the initial complicated sinusitis, four patients were following initial surgical intervention and five patients had initially resolved their complication with medical therapy alone. Indications for subsequent surgery included failure of medical therapy for persistent rhinosinusitis (8 patients) and second complication (1 patient).\nQuestion: Do you need to operate following recovery from complications of pediatric acute sinusitis?",
        "gt": "This study suggests that following resolution of complicated pediatric rhinosinusitis, very few patients may need further surgical intervention. Subsequent intervention is best guided by clinical judgment, symptoms during outpatient clinic visits, and failure of medical therapy.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: It is possible that the traditional method to determine the intraocular pressure after excimer-laser PRK is inaccurate. Measuring the pressure in the temporal part of the cornea might give the true values. Intraocular pressure was measured with a Goldmann Applanation Tonometer and with the Tonopen, before and after PRK for myopia in the central and in the temporal parts of the cornea. The paired student t-test was used for statistical analysis. The results of central and temporal measurements before treatment were identical with both instruments. After PRK, central values were 2 to 3 mm Hg lower than temporal values when measured with a Goldmann Tonometer, and about 2 mm lower when measured with the Tonopen. The differences were highly significant (p<0.0001 and p = 0.004 respectively).\nQuestion: Are we measuring the right intraocular pressure after excimer laser photorefractive laser keratoplasty in myopia?",
        "gt": "The intraocular pressure measured in the usual manner after excimer-laser PRK is lower than the temporally measured pressure. These differences could be caused by absence of the Bowman's membrane, thinning of the cornea and/or change of its topography.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The popularization of problem-based learning (PBL) has drawn attention to the motivational and cognitive skills necessary for medical students in group learning. This study identifies the effect of motivational and cognitive factors on group productivity of PBL tutorial groups. A self-administered questionnaire was completed by 115 students at the end of PBL tutorials for 4 themes. The questionnaire explored student perceptions about effect of motivation, cohesion, sponging, withdrawal, interaction, and elaboration on group productivity. We further analyzed (a) differences in perceptions between male and female students, (b) effect of \"problems,\" and (c) effect of student progress over time on group productivity. There were linear relations between a tutorial group's success and the factors studied. Significant differences were noted between male and female student groups.\nQuestion: Medical student perceptions of factors affecting productivity of problem-based learning tutorial groups: does culture influence the outcome?",
        "gt": "Students and tutors need to recognize symptoms of ineffective PBL groups. Our study emphasizes the need to take into account cultural issues in setting ground rules for PBL tutorials.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine if a change in the pulse oximeter goal range and high alarm limit for oxygen saturation (SpO2) alters the distribution of SpO2 for premature infants in oxygen. This was a prospective, observational analysis. For group 1 (February 2002 to April 2002, n = 23), pulse oximeter alarms were set at 80% (low) and 96% (high), and the goal range was 90-95%. For group 2 (May 2002 to August 2003, n = 49), the high alarm was lowered to 94%, and the goal range was 88 to 94%. The SpO2 values for 24 h were downloaded from Nellcor pulse oximeters during the two periods and the percent time within, above and below the goal range was derived and compared. Groups were similar except for use of post-natal steroids (group 2>1). The percent time within (57.7+/-9.8 vs 59.4+/-12.4%), above (15.4+/-10.6 vs 14+/-9.4%) and below (26.9+/-9.7 vs 26.6+/-10.2%) the goal range was similar for groups 1 and 2, respectively. However, the percent time with SpO2<80% increased significantly for group 2 (4.0+/-2.7 vs 1.9+/-1.4%).\nQuestion: Pulse oximetry in very low birth weight infants: can oxygen saturation be maintained in the desired range?",
        "gt": "Changes in pulse oximeter policy and alarms in labile, sick premature infants need evaluation for their effects on the distribution of SpO2 values before routine use.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Brain derived proteins such as 14-3-3, neuron-specific enolase (NSE), S 100b, tau, phosphorylated tau and Abeta1-42 were found to be altered in the cerebrospinal fluid (CSF) in Creutzfeldt-Jakob disease (CJD) patients. The pathogenic mechanisms leading to these abnormalities are not known, but a relation to rapid neuronal damage is assumed. No systematic analysis on brain-derived proteins in the CSF and neuropathological lesion profiles has been performed. CSF protein levels of brain-derived proteins and the degree of spongiform changes, neuronal loss and gliosis in various brain areas were analyzed in 57 CJD patients. We observed three different patterns of CSF alteration associated with the degree of cortical and subcortical changes. NSE levels increased with lesion severity of subcortical areas. Tau and 14-3-3 levels increased with minor pathological changes, a negative correlation was observed with severity of cortical lesions. Levels of the physiological form of the prion protein (PrPc) and Abeta1-42 levels correlated negatively with cortical pathology, most clearly with temporal and occipital lesions.\nQuestion: Brain-derived proteins in the CSF: do they correlate with brain pathology in CJD?",
        "gt": "Our results indicate that the alteration of levels of brain-derived proteins in the CSF does not only reflect the degree of neuronal damage, but it is also modified by the localization on the brain pathology. Brain specific lesion patterns have to be considered when analyzing CSF neuronal proteins.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: USA300 is a genetic lineage found both in methicillin-resistant (MRSA) and methicillin-sensitive Staphylococcus aureus (MSSA) isolates. In Colombia, hospital and community MRSA infections are caused by a USA300-related community genotype MRSA (CG-MRSA) clone. The genetic origin of this clone is unknown yet. To identify and characterize methicillin-resistant (MRSA) and methicillin-sensitive S. aureus (MSSA) isolates in order to improve the information about the origin of the CG-MRSA isolates in Colombia. USA300-related MSSA isolates were detected and characterized from a study of 184 S. aureus isolates (90 MRSA and 94 MSSA) recovered from infections. The genetic relatedness of the isolates was established by means of pulsed field gel electrophoresis (PFGE), multilocus sequence typing (MLST) and protein A gene typification ( spa typing). Among 184 isolates, 27 (14.7%) showed molecular characteristics and genetic relationship with the USA300 clone, of which 18 were MRSA and nine were MSSA. All USA300-related MRSA harbored Staphylococcal cassette chromosome mec (SCC mec ) IVc (3.1.2). In the MSSA isolates, SCC mec remnants or att B duplicate sites were not detected.\nQuestion: Methicillin-sensitive Staphylococcus aureus isolates related to USA300 clone: Origin of community-genotype MRSA in Colombia?",
        "gt": "In Colombia, the CG-MRSA isolates probably originated in the dissemination of an USA300-related MSSA clone which later acquired SCC mec IVc.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study investigates the relation between changes in pulse oximeter oxygen saturation (SpO2) and changes in arterial oxygen saturation (SaO2) in the critically ill, and the effects of acidosis and anaemia on precision of using pulse oximetry to predict SaO2. Forty-one consecutive patients were recruited from a nine-bed general intensive care unit into a 2-month study. Patients with significant jaundice (bilirubin>40 micromol/l) or inadequate pulse oximetry tracing were excluded. A total of 1085 paired readings demonstrated only moderate correlation (r= 0.606; P<0.01) between changes in SpO2 and those in SaO2, and the pulse oximeter tended to overestimate actual changes in SaO2. Anaemia increased the degree of positive bias whereas acidosis reduced it. However, the magnitude of these changes was small.\nQuestion: Do changes in pulse oximeter oxygen saturation predict equivalent changes in arterial oxygen saturation?",
        "gt": "Changes in SpO2 do not reliably predict equivalent changes in SaO2 in the critically ill. Neither anaemia nor acidosis alters the relation between SpO2 and SaO2 to any clinically important extent.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: This study evaluates the impact of free annual health examinations on survival of elderly (>or =65 years of age) residents in Kaohsiung City, Taiwan. A stratified random sample scheme was used in each of the 11 districts of Kaohsiung City. A total of 1,193 elderly people were selected and interviewed in 1993; deaths and results of health check-ups were recorded through 1998. While over 50% of the subjects received at least one health examination between 1993 and 1998, only 18% received three or more. Most (60%) subjects who received examinations in a given year also received examinations the subsequent year; most (over 70%) who did not receive examinations in a given year did not receive check-ups the following year. Cox proportional hazards model showed that those who utilized the examination service had better survival probability than those who did not, given the same age, sex, education, marital status, living arrangements, and number of chronic diseases at baseline: The relative risk (RR) of mortality for those who ever utilized the health examination service was 0.50 (P<0.0001).\nQuestion: Do the elderly benefit from annual physical examination?",
        "gt": "Elderly subjects who received annual health examinations had lower mortality than those who did not. This finding should be interpreted cautiously, however, as the difference in survival may reflect better general health behaviors among those who participated in the program.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Considering the paucity of data relating erythropoiesis-stimulating agent (ESA) use to ovarian cancer survival, our objective was to evaluate the effect of ESA as used for the treatment of chemotherapy-induced anemia (CIA) on survival in ovarian cancer patients. A multi-institution retrospective chart review was performed on ovarian cancer patients. Data collection included patient demographic, surgicopathologic, chemotherapy, ESA, and survival data. Patients were stratified by ever-use of ESA and were compared using appropriate statistical methods. A total of 581 patients were eligible for analysis with 39% (n = 229) patients with ever-use of ESA (ESA-YES) and 61% (n = 352) never-use ESA (ESA-NO). Mean age was 60.4 years with most patients having stage IIIC (60%) of papillary serous histological diagnosis (64%) with an optimal cytoreduction (67%). Median follow-up for the cohort was 27 months. Both ESA-YES and ESA-NO groups were similar regarding age, body mass index, race, stage, histological diagnosis, and debulking status. Compared with the ESA-NO group, ESA-YES patients were significantly more likely to experience recurrence (56% vs 80%, P<0.001) and death (46% vs 59%, P = 0.002). Kaplan-Meier curves demonstrated a significant reduction in progression-free survival for ESA-YES patients (16 vs 24 months, P<0.001); however, overall survival was statistically similar between the 2 groups (38 vs 46 months, P = 0.10). When stratifying by ever experiencing a CIA, ESA-YES patients demonstrated a significantly worse progression-free survival (17 vs 24 months, P = 0.02) and overall survival (37 vs 146 months, P<0.001).\nQuestion: Treatment of chemotherapy-induced anemia in ovarian cancer patients: does the use of erythropoiesis-stimulating agents worsen survival?",
        "gt": "Our data evaluating the use of ESA as a treatment of CIA in ovarian cancer patients are similar to reports in other tumor sites. Considering that patients who used ESA were more likely to experience recurrence and death and to have decreased survival, the use of ESA in ovarian cancer patients should be limited.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We carried out two studies (a and b) to assess general practitioners' attitudes towards a) regionally developed guidelines and b) guidelines developed by the Danish College of General Practitioners. a) A randomized study among all GPs in Aarhus county comparing their attitudes towards guidelines in general and towards regional multidisciplinary developed guidelines on Pap-testing for cervical cancer, and b) a survey among all Danish GPs on attitudes towards earlier submitted guidelines for diabetes Type 2. GPs in Aarhus county and in all Denmark. a) Questionnaires sent to 370 doctors in Aarhus county, and b) to 3471 GPs in all Denmark. a) Attitudes to the known Pap guidelines compared with general attitudes. Themes in question were acceptance of guidelines, acceptance of multidisciplinary involvement, especially from the administrative staff, perceived effect on the consultation and the quality of care. In study b) remembrance of receiving, having read and used previous guidelines. Wishes with respect to future updates. a) GPs were very positive towards the Pap guidelines they knew, and only few resisted. The number of positive answers was significantly fewer when doctors were asked about guidelines in general. b) There was an overwhelmingly positive attitude towards guidelines from the College on diabetes care and other topics relevant to GP work.\nQuestion: Do general practitioners want guidelines?",
        "gt": "Danish GPs reported a very positive attitude towards the presented well-known guidelines on Pap testing and diabetes Type 2, and a fairly positive attitude towards hypothetical questions on guidelines in general.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The laparoscopic approach must be shown to be cost-effective as well as safe and technically effective before being widely adopted. A review of 54 consecutive patients who underwent open and laparoscopic colposuspension is presented and a cost-analysis is performed comparing the two approaches. This study was a retrospective controlled review of patient records and accounts of in-hospital costs incurred at a private hospital. Theater costs were significantly greater in the laparoscopic group but this was balanced by a shorter length of stay and subsequent reduced accommodation cost. There was no difference in the overall in-hospital costs between the two groups.\nQuestion: Laparoscopic colposuspension. Is it cost-effective?",
        "gt": "The laparoscopic surgical approach is safe and effective and by no means more expensive than the open approach. In the future, the laparoscopic approach can only become more cost efficient; techniques will improve and there will be earlier returns to work and, subsequently, greater productivity.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Portal hypertension has been reported as a negative prognostic factor and a relative contraindication for liver resection. This study considers a possible role of fibrosis evaluation by transient elastography (FibroScan(\u00ae)) and its correlation with portal hypertension in patients with cirrhosis, and discusses the use of this technique in planning therapeutic options in patients with hepatocellular carcinoma (HCC). A total of 77 patients with cirrhosis, 42 (54.5%) of whom had HCC, were enrolled in this study during 2009-2011. The group included 46 (59.7%) men. The mean age of the sample was 65.2 years. The principle aetiology of disease was hepatitis C virus (HCV)-related cirrhosis (66.2%). Liver function was assessed according to Child-Pugh classification. In all patients liver stiffness (LS) was measured using FibroScan(\u00ae). The presence of portal hypertension was indirectly defined as: (i) oesophageal varices detectable on endoscopy; (ii) splenomegaly (increased diameter of the spleen to \u2265 12 cm), or (iii) a platelet count of<100,000 platelets/mm(3). Median LS in all patients was 27.9 kPa. Portal hypertension was recorded as present in 37 patients (48.1%) and absent in 40 patients (51.9%). Median LS values in HCC patients with and without portal hypertension were 29.1 kPa and 19.6 kPa, respectively (r = 0.26, P<0.04). Liver stiffness was used to implement the Barcelona Clinic Liver Cancer algorithm in decisions about treatment.\nQuestion: Does transient elastography (FibroScan\u00ae) have a role in decision making in hepatocellular carcinoma?",
        "gt": "The evaluation of liver fibrosis by transient elastography may be useful in the follow-up of patients with cirrhosis and a direct correlation with portal hypertension may aid in the evaluation of surgical risk in patients with HCC and in the choice of alternative therapies.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Between 1 and 2 per cent of head and neck squamous cell carcinoma patients will reveal no evidence of a primary malignancy. The management of this group poses many problems, including the morbidity associated with wide field irradiation as well as the difficulty in treatment when a primary does emerge. The aim of this study was to assess the use of fluoro-deoxy-glucose positron emission tomography (FDG-PET) imaging in patients presenting with an unknown head and neck primary and to consider its routine use in such patients. We enrolled 25 patients into our study over a four year period. They all presented with a histologically proven, metastatic, squamous cell carcinoma of the neck for which no primary could be found despite full clinical, endoscopic and radiological evaluation with computed tomography (CT) and/or magnetic resonance imaging (MRI). Additionally, all the patients underwent imaging using FDG-PET. The images were interpreted by two radiologists experienced in PET imaging. A primary was identified in nine of the 25 patients (42 per cent); however, of these patients, six had false positive results and only three patients were true positives with supportive histology. In the remaining 16 patients, no abnormality was identified on CT, MRI or PET. Of these 16 patients, two eventually displayed a primary carcinoma, the other 14 patients remaining without evidence of any primary.\nQuestion: Should FDG-PET scanning be routinely used for patients with an unknown head and neck squamous primary?",
        "gt": "Despite the high number of positive PET scans, the actual true positive rate was 3/9 (33 per cent); conversely, the true negative rate was 14/16 (88 per cent). We conclude from this study that there is a role for FDG-PET in the patient with an unknown head and neck primary, particularly in the context of a negative PET scan.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: We developed a new multilevel registration technique for pedicle screw (PS) insertion that has the capability of registering three consecutive vertebrae simultaneously, using a reference frame set to one of the caudal vertebrae. PSs are inserted in the consecutive and adjacent one or two vertebrae. This study aimed to investigate the perforation rates of the registered and unregistered adjacent vertebrae and compare the perforation rate of the PS and insertion time per PS between the conventional and new techniques. Sixty-nine consecutive scoliosis patients who underwent PS insertion using multilevel registration were enrolled. The conventional and new techniques were used in 29 subjects, and in 40 subjects, respectively. The total numbers of PSs used were 375 and 492, respectively. Of the 492 PSs, 301 were inserted to the registered vertebrae and 191 were inserted to the unregistered adjacent vertebrae. The PS malposition on postoperative axial computed tomography was classified as grades 2 and 3 perforation, using the Rao classification. The perforation rate and insertion time per PS were compared between the conventional and new techniques. The perforation rates did not significantly differ between the registered and unregistered vertebrae (10.3 vs. 6.3 %,), and between the new and conventional techniques (8.7 vs. 9.6 %). The insertion time per PS was significantly shorter in the new technique than in the conventional technique (3.9 \u00b1 1.0 vs. 4.9 \u00b1 1.3 min; p<0.001).\nQuestion: Are pedicle screw perforation rates influenced by registered or unregistered vertebrae in multilevel registration using a CT-based navigation system in the setting of scoliosis?",
        "gt": "The new technique may be less invasive and decrease operative time without compromising the accuracy of PS placement.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The purpose of this study was to determine whether or not genetic amniocentesis is warranted when isolated choroid plexus cysts (CPC) or echogenic cardiac foci (EF) are noted on prenatal ultrasound. We performed a retrospective analysis on patients from our perinatal database. All obstetric patients with CPC or EF noted on second-trimester perinatology ultrasound from April, 1998 to November, 2004 were included. Information regarding ultrasound findings and neonatal outcome were analyzed. During the study period, 515 patients with CPC or EF were evaluated. Of these, 429 (83.3%) had isolated CPC or EF and 86 (16.7%) had additional risk factors. The incidence of abnormal karyotype was 0 versus 2.3%, respectively (P = .03). The additional risk factors considered were: advanced maternal age, abnormal serum triple marker screening, and/or other abnormal ultrasound findings. Furthermore, during the study period there were 20,122 live births and 27 (0.1%) cases of aneuploidy diagnosed postnatally. Of these, none had isolated CPC or EF on prenatal ultrasound.\nQuestion: Isolated choroid plexus cyst or echogenic cardiac focus on prenatal ultrasound: is genetic amniocentesis indicated?",
        "gt": "CPC or EF noted on prenatal ultrasound warrants referral for careful consultative ultrasound evaluation. In the absence of other risk factors, however, genetic amniocentesis for isolated CPC or EF does not appear to be necessary.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess the impact of age on technical success and complications of carotid stenting in a prospective single-center cohort study. One hundred eleven consecutive patients (74 men; median age 70 years) with>or=70% symptomatic (n=33) or>or=90% asymptomatic (n=78) internal carotid artery (ICA) stenosis underwent carotid artery stent implantation. Primary technical success and periprocedural complications were compared in patients aged>75 years (n=28) to patients<75 years (n=83). Patient groups below and above 75 years compared well with respect to baseline demographic and clinical data. Successful stenting was achieved in 108 (97%) patients. The combined neurological complication rate was 7% (n=8), with 1 (1%) major stroke, 1 (1%) minor stroke, and no 30-day mortality. Technical angiographic complications occurred in 8 (7%) patients. No significant differences between patients>75 years and those<75 years were observed for primary success rates (100% [28/28] versus 96% [80/83]; p=0.8), overall complications (14% [4/28] versus 16% [13/83]; p=1.0), neurological complications (7% [2/28] versus 7% [6/83]; p=1.0), or technical complications (7% [2/28] versus 4% [3/83]; p=0.6).\nQuestion: Carotid artery stenting in older patients: is age a risk factor for poor outcome?",
        "gt": "Elective carotid stenting can be performed safely in older patients with several comorbidities. Patient age does not seem to be an independent risk factor for poor outcome after endovascular treatment of internal carotid artery stenosis.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The fundamental role of video-assisted thoracic surgery (VATS) in the treatment of spontaneous pneumothorax is generally acknowledged today. This study intends to evaluate whether VATS is justified at the onset of a first spontaneous pneumothorax through analysis of parameters tested on two group of patients treated respectively with pleural drainage and VATS.PATIENTS/ The study includes 70 patients affected by first spontaneous pneumothorax divided into two groups of 35 patients for the purpose of therapeutic treatment. The first group underwent pleural drainage while the second underwent VATS. Parameters analyzed were as follows: (1) prolonged air leaks (more than 6 days); (2) time required for pleural drainage; (3) time of hospital stay; (4) management costs; (5) recurrences (follow-up at 12 months). Prolonged air leaks occurred in four patients (11.4%) in the first group and two patients (5.7%) in the second; recurrences occurred in eight patients in the first group (22.8%), and only one in the second group (2.8%). Mean time for drainage and hospitalization was, respectively, 9 and 12 days in patients with pleural drainage against 3.9 and 6 days of those using VATS. Average management costs per patients including hospitalization was calculated at $2,750.00 per patient for the first group compared with $1,925.00 for the second group.\nQuestion: Is video-assisted thoracic surgery justified at first spontaneous pneumothorax?",
        "gt": "The use of VATS at first spontaneous pneumothorax is justified in the interest of both patients and health administrations as demonstrated by the number of recurrences in patients in the first group and economy savings resulting from use of VATS.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Patients, providers, and payers are striving to identify where value in cancer care can be increased. As part of the Choosing Wisely (CW) campaign, ASCO and the American Society for Therapeutic Radiology and Oncology have recommended against specific, yet commonly performed, treatments and procedures. We conducted a retrospective analysis of Medicare claims data to examine concordance with CW recommendations across 12 cancer centers in the southeastern United States. Variability for each measure was evaluated on the basis of patient characteristics and site of care. Hierarchical linear modeling was used to examine differences in average costs per patient by concordance status. Potential cost savings were estimated on the basis of a potential 95% adherence rate and average cost difference. The analysis included 37,686 patients with cancer with Fee-for-Service Medicare insurance. Concordance varied by CW recommendation from 39% to 94%. Patient characteristics were similar for patients receiving concordant and nonconcordant care. Significant variability was noted across centers for all recommendations, with as much as an 89% difference. Nonconcordance was associated with higher costs for every measure. If concordance were to increase to 95% for all measures, we would estimate a $19 million difference in total cost of care per quarter.\nQuestion: Choosing Wisely: Opportunities for Improving Value in Cancer Care Delivery?",
        "gt": "These results demonstrate ample room for reduction of low-value care and corresponding costs associated with the CW recommendations. Because variability in concordance was driven primarily by site of care, rather than by patient factors, continued education about these low-value services is needed to improve the value of cancer care.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The linea aspera is the rough, longitudinal crest on the posterior surface of the femoral shaft. Most orthopedic surgeons depend on the linea aspera as an intraoperative landmark identifying the true posterior aspect of the femur. We investigated the position of the linea aspera to verify whether the surgeon can rely on this accepted belief. One hundred and thirty-three femora from 73 patients were evaluated. Four CT cuts were done of the mid femur, and we measured the angle of rotation of the linea aspera at each cut. The linea aspera was externally rotated in most femora evaluated; average angles of rotation were 15.4\u00b0, 14\u00b0, 11.7\u00b0, and 11.5\u00b0 at 10, 15, 20, and 25\u00a0cm from the intercondylar line, respectively. The angle of rotation of the linea aspera was positively correlated with femoral neck anteversion angle and negatively with age.\nQuestion: The linea aspera as a guide for femoral rotation after tumor resection: is it directly posterior?",
        "gt": "The linea aspera is exactly posterior in a minority of individuals, while it is externally rotated to varying degrees in the majority of individuals. The degree of rotation was positively correlated with femoral neck anteversion angle, and negatively with age. To avoid implant malrotation, accurate estimation of the rotation angle should be determined preoperatively.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: In 87 patients who were operated because of isolated VSD (Group I), VSD was closed under cardioplegic arrest and right atriotomy or right ventriculotomy were closed in the beating heart after aortic cross-clamp removal. The VSD patch was watched out for residual shunt and additional sutures were placed if it existed. Results of this technique have been compared with the other 216 (Group II) in which all procedures of the VSD closure were performed under cardioplegic arrest. Transosephageal echocardiography (TEE) was performed for evidence of residual shunting intraoperatively and postoperatively in all patients. In group I, additional sutures were placed for residual shunt in 14 patients (16.1%), and insignificant residual shunt was detected in only one (1.1%) patient at early postoperative period (p<0.05, according to group II). In group II, there was hemodynamically insignificant residual shunt in 31 patients (14.5%), and 9 patients (4.2%) were reoperated for significant shunt (p<0.05).\nQuestion: Does direct visualization of peripatch areas in beating heart eliminate the risk of residual ventricular septal defect in adult patients?",
        "gt": "Transatrial or transventricular inspection to peripatch areas in the beating heart is a safe technique to detect a residual shunt, an observation that may eliminate reoperation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To assess left ventricular (LV) contractile function and adrenergic responsiveness in septic patients. We used echocardiographically defined fractional area of contraction (FAC), and LV area to end-systolic arterial pressure estimates of end-systolic elastance (E'es) and its change in response to dobutamine (5 microg/kg/min) in 10 subjects in septic shock admitted to an intensive care unit of an academic medical center. Subjects were studied on admission and again at both 5 days and 8-10 days after admission. Three of the 10 subjects died as a result of their acute process, while the others were discharged from hospital. Nine out of 10 subjects required intravenous vasopressor therapy on day 1, while only 1 of 9 subjects required vasopressor support at day 5. LV end-diastolic area (EDA) increased from day 1 to day 5 and days 8-10 (p<0.05), but neither FAC nor E'es was altered by time (EDA 15.7+/-5.8, 21.4+/-5.1, and 19.4+/-5.6 cm2; FAC 0.46+/-0.19, 0.50+/-0.20, and 0.48+/-0.15%; E'es 21.6+/-12.6, 23.2+/-8.5, and 19.2+/-6.3 mmHg/cm2, mean+/-SD, for days 1, 5 and 8-10 respectively). Although dobutamine did not alter E'es on day 1 or day 5, E'es increased in all of the 5 subjects studied on days 8-10 (p<0.05).\nQuestion: Is myocardial adrenergic responsiveness depressed in human septic shock?",
        "gt": "Adrenergic hyporesponsiveness is present in septic shock and persists for at least 5 days into recovery, resolving by days 8-10 in survivors.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Inappropriate harvesting of arterial conduits can lead to severe postoperative complications. We analyzed clinical and functional results of patients undergoing radial artery (RA) harvesting by means of three techniques. From January 2001 to January 2004 188 patients undergoing coronary artery bypass graft with RA were divided into three groups: harmonic scalpel was employed in 61 (RA1), electrocautery in 63 (RA2), Potts-scissors and clips in 64 (RA3) patients. Harvesting time, local complications, number of clips employed, graft flowmetry, postoperative troponin I, incidence of re-exploration for bleeding due to the graft were analyzed. RA1 and RA2 showed a lower harvesting time (RA1 16.2 +/- 8.4 vs RA3 41.4 +/- 7.7 min, p = 0.0001; RA2 21.1 +/- 10.4 min, p = 0.001). Postoperative hand paresthesia was detected in RA1 (5/61; 8.2%) and RA2 (5/63; 7.9%), but not in RA3 (p = 0.048 and p = 0.05, respectively). More clips were necessary in RA3 compared to RA2 (p = 0.04) or RA1 (p = 0.0001 vs RA3; p = 0.001 vs RA2). RA1 showed significant higher values of maximum flow (RA1 59.4 +/- 37.5 vs RA2 22.1 +/- 7.7 ml/min, p = 0.0001; vs RA3 31.3 +/- 12.0 ml/min, p = 0.001), mean flow (RA1 23.4 +/- 17.3 vs RA2 10.2 +/- 5.7 mi/min, p = 0.001; vs RA3 11.6 +/- 8.9 ml/min, p = 0.001), minimum flow (RA1 11.6 +/- 6.5 vs RA2 4.2 +/- 3.7 ml/min, p = 0.01; vs RA3 4.7 +/- 3.3, p = 0.03), and pulsatility index (RA1 0.9 +/- 0.8 vs RA2 2.1 +/- 1.3, p = 0.03; vs RA3 1.7 +/- 2.1, p = 0.04). Troponin I was significantly lower in RA1, compared to RA2 and RA3 at 12 hours (p = 0.01 and p = 0.03, respectively) and 24 hours (p = 0.05 and p = 0.045, respectively). No RA1 patient underwent re-exploration for bleeding compared to RA2 (p = 0.011) and RA3 (p = 0.02).\nQuestion: Can harvesting techniques modify postoperative results of the radial artery conduit?",
        "gt": "RA harvesting with ultrasounds is fast, determines high flowmetry values, low enzyme release and rarely causes local complications.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To describe physical activity (PA) levels in persons with spinal cord injury (SCI) and to investigate associated factors. PA behavior of people with SCI in Switzerland was assessed in a community survey with four items from the Physical Activity Scale for individuals with physical disabilities (PA of light, moderate, and strenuous intensity and muscle-strengthening exercises). In addition to descriptive analyses, the odds of performing PA according to the WHO recommendations (at least 2.5\u00a0h/week of at least moderate intensity) were analyzed by multivariable logistic regression. Participants (n\u00a0=\u00a0485; aged 52.9\u00a0\u00b1\u00a014.8; 73.6\u00a0% male) carried out PA a total of 6.0\u00a0h/week (median). 18.6\u00a0% were physically inactive, 50.3\u00a0% carried out muscle-strengthening exercises, and 48.9\u00a0% fulfilled the WHO recommendations. Regression analyses showed that women, people aged 71+, and people with complete tetraplegia had significantly lower odds of fulfilling the WHO recommendations than participants in the respective reference category (men, ages 17-30, incomplete paraplegia).\nQuestion: Do people with spinal cord injury meet the WHO recommendations on physical activity?",
        "gt": "PA levels of people with SCI in Switzerland are rather high. However, some subgroups need special consideration when planning interventions to increase PA levels.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Screening athletes with ECGs is aimed at identifying \"at-risk\" individuals who may have a cardiac condition predisposing them to sudden cardiac death. The Seattle criteria highlight QRS duration greater than 140 ms and ST segment depression in two or more leads greater than 50 \u03bcV as two abnormal ECG patterns associated with sudden cardiac death. High school, college, and professional athletes underwent 12 lead ECGs as part of routine pre-participation physicals. Prevalence of prolonged QRS duration was measured using cut-points of 120, 125, 130, and 140 ms. ST segment depression was measured in all leads except leads III, aVR, and V1 with cut-points of 25 \u03bcV and 50 \u03bcV. Between June 2010 and November 2013, 1595 participants including 297 (167 male, mean age 16.2) high school athletes, 1016 (541 male, mean age 18.8) college athletes, and 282 (mean age 26.6) male professional athletes underwent screening with an ECG. Only 3 athletes (0.2%) had a QRS duration greater than 125 ms. ST segment depression in two or more leads greater than 50 \u03bcV was uncommon (0.8%), while the prevalence of ST segment depression in two or more leads increased to 4.5% with a cut-point of 25 \u03bcV.\nQuestion: Are the QRS duration and ST depression cut-points from the Seattle criteria too conservative?",
        "gt": "Changing the QRS duration cut-point to 125 ms would increase the sensitivity of the screening ECG, without a significant increase in false-positives. However, changing the ST segment depression cut-point to 25 \u03bcV would lead to a significant increase in false-positives and would therefore not be justified.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Black race affords some protection from retinopathy of prematurity (ROP), but more ROP was previously found in another darkly pigmented race, the Alaskan natives. From fall 1989 through summer 2003, all Alaskan infants with a birth weight of 1500 g or less were examined, documenting mother's stated race, prenatal care, and neonatal intensive care unit course. Retinopathy of prematurity was classified as to predefined threshold for peripheral ablative treatment (region of avascular retina and fibrovascular ridge and vessel tortuosity) in 873 infants. Threshold ROP was more prevalent in Alaskan natives (24.9%) and Asians (15.9%) (10% overall), with no significant difference between Alaskan natives and Asians (P = .24). Alaskan native males had more threshold ROP (69%) compared with non-Alaskan native males (51%). Compared with threshold nonnatives, Alaskan native threshold infants had greater birth weights (829 +/- 222 vs 704 +/- 186 g), required less time on ventilation (46 +/- 22 vs 70 +/- 75 days), and progressed to treatment at a younger age (35.5 +/- 2.2 vs 36.2 +/- 2.6 weeks' gestational age) (data are given as mean +/- SD).\nQuestion: Is Pacific race a retinopathy of prematurity risk factor?",
        "gt": "In this limited study, we find increased risk of threshold ROP in 2 northern Pacific races. Threshold Alaskan natives had similar or better prenatal and neonatal intensive care unit variables than did threshold nonnatives; however, Alaskan native males were still at a greater risk.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Depression is associated with an increased risk of cardiovascular diseases (CVD) in vascular patients as well as in the general population. We investigated whether autonomic dysfunction could explain this relationship. The Finland, Italy and The Netherlands Elderly (FINE) Study is a prospective cohort study. Depressive symptoms were measured with the Zung Self-rating Depression Scale in 870 men, aged 70-90 years, free of CVD and diabetes in 1990. Resting heart rate was determined from a 15-30-s resting electrocardiogram in The Netherlands and Italy and as pulse rate in Finland. In addition, in The Netherlands, heart-rate variability (HRV) and QTc interval were determined. At baseline, depressive symptoms were associated with an increase in resting heart rate, and nonsignificantly with low HRV and prolonged QTc interval. After 10 years of follow-up, 233 (27%) men died from CVD. Prospectively, an increase in resting heart rate with 1 SD was associated with an increased risk of cardiovascular mortality [hazard ratio (HR), 1.22; 95% confidence interval (CI), 1.08-1.38]. In addition, low HRV (HR, 0.78; 95% CI, 0.61-1.01) and prolonged QTc interval (HR, 1.28; 95% CI, 1.06-1.53) per SD were associated with cardiovascular mortality. The increased risk of depressive symptoms for cardiovascular mortality (HR, 1.38; 95% CI, 1.21-1.58) did not change after adjustments for several indicators of autonomic dysfunction.\nQuestion: Autonomic dysfunction: a link between depression and cardiovascular mortality?",
        "gt": "This study suggests that mild depressive symptoms are associated with autonomic dysfunction in elderly men. The increased risk of cardiovascular mortality with increasing magnitude of depressive symptoms could, however, not be explained by autonomic dysfunction.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The objective of the present prospective study was to evaluate the influence of neuromuscular monitoring on the level of neuromuscular blockade from induction of anaesthesia until extubation of the trachea. Forty-two patients aged between 18 and 73 yr undergoing a range of surgical procedures under general anaesthesia were randomly distributed into two groups of 21 patients each. In both groups a Datex NMT Monitor was used and electromyographic responses of the ulnar muscles to supramaximal stimulation of the ulnar nerve were recorded. In Group 1, the anaesthetist could see the movements of the stimulated hand, but not the monitor. In Group 2, the anaesthetist could see neither the stimulated hand nor the monitor. The same anaesthetist administered the neuromuscular relaxants which were succinylcholine 1.5 mg.kg-1 for tracheal intubation and vecuronium 0.1 mg.kg-1 for neuromuscular relaxation during surgery, followed by 1 to 2 mg maintenance injections. Possible residual curarization was evaluated in the recovery room by head life tests and pulse oximetry. Patients in Group 1 had deeper neuromuscular block throughout surgery, despite the use of a comparable dose of vecuronium (10.1 mg for G1 vs 11.2 mg for G2). The EMG values of T1 and train-of-four values were not different at tracheal intubation or at extubation. No patients presented signs of residual curarization in the recovery room.\nQuestion: Neuromuscular monitoring: does it make a difference?",
        "gt": "The study demonstrates that with the same amount of vecuronium the neuromuscular relaxation was deeper with the use of a simple neuromuscular monitoring (visual evaluation of the thumb movements). Despite the deeper neuromuscular block in the monitored group, there was no residual curarization in the recovery room.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Microvascular compression syndromes such as trigeminal neuralgia, hemifacial spasm, and disabling positional vertigo involve an artery or vein compressing a cranial nerve. A cranial nerve is composed of a central nervous system (CNS) segment and a peripheral nervous system (PNS) segment separated by the root entry/exit zone (REZ). Although vascular compression can occur at any point along the cranial nerve, it has been generally assumed that only vascular contact at the REZ of the affected cranial nerve can cause symptoms. On the basis of personal surgical experience, we propose that vascular compression of the CNS segment alone causes symptoms. This has important repercussions for the future diagnosis and treatment of microvascular compression syndromes, especially the cochleovestibular compression syndrome. For the anatomic study, four autopsy specimens and one surgical biopsy specimen of the vestibulocochlear nerve were microscopically and ultramicroscopically analyzed for structural differences between the CNS and PNS segments. For the clinical study, five patients with the clinical picture of cochleovestibular compression syndrome were treated by microsurgical decompression at the level of the CNS segment and not the REZ. One patient underwent reoperation for recurrent symptoms 4 years later, and a 4-mm vestibular neurectomy was performed at that stage. We performed an epidemiological analysis to demonstrate that the known incidences of trigeminal neuralgia, hemifacial spasm, and glossopharyngeal neuralgia are related to the length of their respective CNS segments. Histological differences between the PNS and CNS segments suggest that the PNS segment is more resistant to compression. This was confirmed by neurophysiological data from intraoperative monitoring in posterior fossa surgery and experimental studies. We found a clear epidemiological correlation between the length of the CNS segment, which differed among cranial nerves, and the incidence of the microvascular compression syndrome. Successful decompression of the CNS segment in patients without compression at the REZ of the vestibulocochlear nerve for disabling positional vertigo provides clinical support for this hypothesis.\nQuestion: Is the root entry/exit zone important in microvascular compression syndromes?",
        "gt": "The evidence we present supports the hypothesis that vascular compression syndromes arise from vascular contact along the CNS segment of the cranial nerves.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context:  Rest is usually recommended in acute pericarditis, as it could help to lower heart rate (HR) and contribute to limit \"mechanical inflammation\". Whether HR on admission could be correlated and perhaps participate to inflammation has not been reported. Between March 2007 and February 2010, we conducted a retrospective study on all patients admitted to our center for acute pericarditis. Diagnosis criteria included two of the following ones: typical chest pain, friction rub, pericardial effusion on cardiac echography, or typical electrocardiogram (ECG) findings. Primary endpoint was biology: CRP on admission, on days 1, 2, 3, and especially peak. We included 73 patients. Median age was 38 years (interquartiles 28-51) and median hospitalization duration was 2.0 days (1.5-3.0). Median heart rate was 88.0 beats per minute (bpm) on admission (interquartiles 76.0-100.0) and 72.0 on discharge (65.0-80.0). Heart rate on admission was significantly correlated with CRP peak (p<0.001), independently of temperature on admission, hospitalization duration and age. Recurrences occurred within 1 month in 32% of patients. Heart rate on hospital discharge was correlated with recurrence, independently of age.\nQuestion: Could heart rate play a role in pericardial inflammation?",
        "gt": "In acute pericarditis, heart rate on admission is independently correlated with CRP levels and heart rate on discharge seems to be independently correlated to recurrence. This could suggest a link between heart rate and pericardial inflammation.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine whether the interval between prostate biopsy and radical prostatectomy (RP) affects the immediate postoperative outcome. The study was a retrospective chart review of 169 patients who had retropubic RP at our institution. Using a series of univariate and multivariate logistic regression analyses, we evaluated whether the interval between biopsy and RP was a significant independent predictor of operative duration, estimated blood loss, transfusion rate, nerve-sparing (yes/no), positive margin rate, length of stay, complications, and urinary continence after RP. The interval from biopsy to RP was 14-378 days; there were no significant differences in operative duration, estimated intraoperative blood loss, nerve-sparing rate, transfusion rate and amount, hospitalization time, positive margin rate, major postoperative complications, and continence in patients with biopsy to RP intervals above and below the median. The biopsy to RP interval was not an independent predictor of outcomes during or after RP. There were no direct or indirect correlations between biopsy to RP interval and any of the postoperative outcomes.\nQuestion: Does the interval between prostate biopsy and radical prostatectomy affect the immediate postoperative outcome?",
        "gt": "The interval between prostate biopsy and retropubic RP appears to have no effect on immediate postoperative outcomes. We were unable to determine a specific minimum required interval beyond 2 weeks after prostate biopsy before proceeding with RP.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Prospective randomised masked study. Consent was obtained from 221 patients. Cases were randomised to wearing a new mask or not wearing any mask throughout the procedure. Blood agar settle plates were placed adjacent to the patient's head in the operative field. Duration of procedure was noted. Plates were incubated and read at 48 hours. Colony forming bacteria were counted and identified. There were significantly fewer organisms cultured when the surgeon used a facemask (p=0.0006). The majority of organisms were Staphylococcus epidermidis, Bacillus spp, and Diphtheroid spp; however Staphylococcus aureus and Pseudomonas aeruginosa were cultured on several occasions. There were no cases of infective complication.\nQuestion: The use of surgical facemasks during cataract surgery: is it necessary?",
        "gt": "The main purpose of an operating mask is to prevent bacteria falling on to the operative site from the surgeon's oropharynx or nasopharynx with the concomitant theoretical risk of infective complication. Operating masks were shown to have a significant effect on the volume of bacterial organisms falling to the operative site; however, whether this is clinically significant is unknown.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Serosorting is the practice of preferentially having sex with partners of concordant HIV status or of selectively using condoms with HIV-discordant partners. We evaluated the epidemiology of serosorting among men who have sex with men (MSM) seen in a sexually transmitted disease clinic, Seattle, WA, 2001-2007, and defined the percentage of visits during which MSM tested HIV positive based on whether they reported nonconcordant unprotected anal intercourse (UAI), UAI only with partners thought to be HIV negative (serosorters), no UAI, or no anal intercourse. Men reported serosorting during 3295 (26%) of 12,449 visits. From 2001 to 2007, the proportion of visits during which men reported serosorting increased (P = 0.02); this change was greater among HIV-infected MSM than among HIV-uninfected MSM. Among men who tested HIV negative in the preceding year, HIV tests were positive in 49 (3.5%) of 1386 who reported nonconcordant UAI, 40 (2.6%) of 1526 serosorters, 28 (1.5%) of 1827 who had only protected anal intercourse, and 0 of 410 who had no anal intercourse (P<0.0001); 32% of new HIV infections occurred in serosorters. The prevalence of HIV was higher among serosorters tested during 2004-2007 than among those tested during 2001-2003 (0.85% vs. 3.2%, P = 0.03).\nQuestion: HIV serosorting in men who have sex with men: is it safe?",
        "gt": "Serosorting offers MSM limited protection from HIV.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: Although for decades there has been controversy regarding the relationship between obesity and coronary artery disease (CAD), it has been assumed that high body mass index (BMI) is a risk factor for CAD. However, the findings of some recent studies were paradoxical. The aim of this study was to find a relationship between high BMI and waist-to-hip ratio (WHR) with severity of CAD. This study was a cross-sectional, prospective study where 414 patients with suspected coronary artery disease, in whom coronary angiography was performed, were enrolled. The mean \u00b1 SD of their ages was 61.2 \u00b1 27.4 years (range 25-84), and 250 (60.4%) were male. Regarding cardiovascular risk factors, 113 (27.3%) patients had a history of diabetes mellitus (DM), 162 (39.1%) had hypercholesterolaemia, 238 (57.4%) had hypertension, 109 (26.3%) were current smokers and 24 (5.8%) had a family history of CAD. The mean \u00b1 SD of the patients' BMI was 26.04 \u00b1 4.08 kg/m(2) (range 16-39) and means \u00b1 SD of their WHR ranged from 0.951 \u00b1 0.07 to 0.987 \u00b1 0.05. The mean \u00b1 SD of the severity of CAD according to the SYNTAX and Duke scores were 17.7 \u00b1 9.6 (range 0-64) and 3.2 \u00b1 1.7 (range 0-12), respectively. In this study, findings showed a negative correlation between the severity of CAD and BMI, according to both SYNTAX and Duke scores (p \u2264 0.001 and p = 0.001, respectively). However, there was a positive correlation between WHR and severity of CAD, according to the Duke score (p = 0.03).\nQuestion: Is the relationship of body mass index to severity of coronary artery disease different from that of waist-to-hip ratio and severity of coronary artery disease?",
        "gt": "BMI had a negative correlation with the severity of CAD, but waist-to-hip ratio had a positive correlation with severity of CAD.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: To determine the prevalence of Staphylococcus aureus nasal carriage in patients with chronic hepatitis B virus infection. The prevalence of S. aureus nasal carriage was determined in patients with chronic hepatitis B virus infection and compared with the prevalence of S. aureus nasal carriage among control patients. Between February 2003 and November 2004, 70 chronic hepatitis B patients and 70 control patients were enrolled in the study. S. aureus nasal carriage was shown in 15 (12%) of the patients with chronic hepatitis B and 13 (19%) of the control group (P>0.05). There was no difference in nasal colonization between the cases and controls when analysed by age, sex, frequency of skin infection, prior use of antibiotics and hospital admission in the preceding six months.\nQuestion: Does chronic hepatitis B increase Staphylococcus nasal carriage?",
        "gt": "The results of our study show that chronic hepatitis B virus infection is not associated with S. aureus nasal carriage.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: The composite radial forearm flap is a surgical option in the reconstruction of large traumatic or oncologic orofacial defects. Nevertheless, it has been criticized for its poor bone transport faculties that would make this flap insufficient in large osseous mandibular reconstructions, or for oral prosthetic rehabilitation with dental implants. What is more, the morbidity of the donor site has often been pointed. The aim of this radioanatomic study was to revisit the vascularization of the composite radial forearm flap, focusing on the bone stick. A radioanatomic study was performed on seven upper limbs taken from fresh cadavers. First, the vessels were washed with a 40\u00b0C solution of potassium acetate. Then an intra-arterial injection of a mixture of lead oxide and agar-agar was performed. 3D-CT-scan examinations of the anatomical pieces were performed. In a second step, the flaps were harvested and analyzed with a Microscan examination (NanoSPECT-CT Bioscan(\u00ae), voxel 220\u00a0microns). Collateral branches of the radial artery to the bone and the skin were counted and classified. One radial diaphyseal artery was present in all the cases. The nutrient foramen took place at the anteromedial aspect of the diaphysis, between 45\u00a0and 65\u00a0% of the length of the bone. A dense anastomotic periosteal network was highlightened, supplied by one to four musculoperiosteal branches, and one to six fascio-periosteal arteries arising from the radial artery. A total of mean five osseous branches, and 12\u00a0cutaneous branches have been observed.\nQuestion: Can one harvest a long bone stick in the radial forearm flap?",
        "gt": "The results of the present preclinical study suggested that a 16-cm bone stick could be harvested with an optimal vascular safety, without consideration for the morbidity at the donor site. The original approach in this study, relating anatomy to the preclinical imaging, allowed a precise visualization of the microvascularization of the soft and hard tissues. It opened a field of innovative research in plastic and reconstructive surgery.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    },
    {
        "query": "Answer the question based on the following context: : Abdominal pain-related functional gastrointestinal disorders (AP-FGIDs) following bacterial acute gastroenteritis (AGE) have been demonstrated in adults and children. An adult study demonstrated AP-FGIDs resulting from an outbreak of viral AGE. Viral AGEs are common in children. Thus, the demonstration of AP-FGIDs occurring after a viral infection in children could constitute a significant finding. The aim of the study was to investigate the development of FGIDs following an episode of acute rotavirus gastroenteritis in children. This is the first pediatric multicenter study designed to assess postviral AP-FGIDs. : It is a cohort study. Inclusion criteria of the study are children ages 4 to 18 years with history of AGE secondary to rotavirus. Sample size is 44 exposed and 44 controls (unidirectional alpha of 0.05, power of 0.80). Children consulting at 2 hospitals (Chicago, IL, and Naples, Italy) for AGE (2002-2004) who tested positive for rotavirus were randomly contacted by telephone>2 years after the episode. Each exposed child who visited the emergency department or outpatient site for acute trauma or well-child visit within 4 weeks of the index case was matched with a control of the same age and sex. Gastrointestinal symptoms and disability were evaluated with a validated pediatric questionnaire. : Eighty-eight patients (46 boys, mean age 5.3 years) were recruited. Contacted patients presented with AGE in 2002 (9), 2003 (11), and 2004 (24). Seven (16%) exposed patients and 3 (7%) controls reported AP-FGIDs (P = 0.31).\nQuestion: Rotavirus gastroenteritis: precursor of functional gastrointestinal disorders?",
        "gt": ": Our study suggests that rotavirus infection does not seem to place children at increased risk for AP-FGIDs at long-term follow-up. Larger, prospective studies should be conducted to evaluate whether rotavirus gastroenteritis leads to AP-FGIDs in children.",
        "tag": [
            "PubMedQA",
            "medical"
        ],
        "source": "PubMedQA"
    }
]